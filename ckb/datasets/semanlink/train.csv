Afrique du Sud|skos:broader|Afrique australe
- Siamese network with two deep sub-models  - Projects input and candidate texts into embedding space  - Trained by maximizing cosine similarity between correct input-output pairs    [source](/doc/2019/08/neural_models_for_information_r)|skos:broader|In practice, many NLP applications rely on a simple sentence embedding: the average of the  embeddings of the words in it. We can do better.    Ex of use (besides trivial ones such as classification and similarity): use sentence embeddings to cluster  sentences in documents, which aids in the automatic extraction  of key information from large bodies of text.  
Markus Lanthaler|skos:broader|Technical girls and guys
Google Spreadsheets|skos:broader|Spreadsheets
Semantic Vector Encoding and Similarity Search Using Fulltext Search Engines  The ubiquity of semantic vector space modeling raises the challenge of efficient searching in dense, high-dimensional vector spaces. We would naturally want to take advantage of the design and optimizations behind modern fulltext engines like Elasticsearch so as to meet the scalability and robustness demands of modern IR applications. This is the research challenge addressed in this paper.   The paper describes novel ways of encoding dense vectors into text documents, allowing the use of traditional inverted index engines.    [blog post](https://rare-technologies.com/semantic-search-fulltext-engine-acl-2017/)   Vector representations and vector space modeling (VSM) play a central role in modern machine learning. We propose a novel approach to `vector similarity searching' over dense semantic representations of words and documents that can be deployed on top of traditional inverted-index-based fulltext engines, taking advantage of their robustness, stability, scalability and ubiquity. We show that this approach allows the indexing and querying of dense vectors in text domains. This opens up exciting avenues for major efficiency gains, along with simpler deployment, scaling and monitoring. The end result is a fast and scalable vector database with a tunable trade-off between vector search performance and quality, backed by a standard fulltext engine such as Elasticsearch. We empirically demonstrate its querying performance and quality by applying this solution to the task of semantic searching over a dense vector representation of the entire English Wikipedia.|sl:arxiv_author|Michal Růžička
Safari|skos:broader|Brouteur
Cosmic inflation|skos:broader|Cosmologie
Lost City|skos:broader|Océan
Linked Data Exploration|skos:broader|Linked Data
Self-driving car|skos:broader|Robotics Robot
Catastrophe écologique|skos:broader|Écologie
Bag-of-words|skos:broader|NLP: Text Representation
Neural Models for Information Retrieval|skos:broader|Neural networks
Natural Language Processing with Small Feed-Forward Networks google guys:      We show that small and shallow feed- forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.   We show that small and shallow feed-forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.|sl:arxiv_firstAuthor|Jan A. Botha
RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space  We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.|sl:arxiv_author|Zhiqing Sun
Linking Enterprise Data|skos:broader|Linked Data
France : bureaucratie|skos:broader|Bureaucratie
StackOverFlow Q|skos:broader|Stack Overflow
Named Entity Disambiguation using Deep Learning on Graphs Evaluation of different deep learning techniques to create  a context vector from graphs, aimed at high-accuracy NED. (neural  approach for entity disambiguation using graphs as background  knowledge)     We tackle Named Entity Disambiguation (NED) by comparing entities  in short sentences with Wikidata graphs. Creating a context vector  from graphs through deep learning is a challenging problem that has  never been applied to NED. Our main contribution is to present an  experimental study of recent neural techniques, as well as a discussion  about which graph features are most important for the disambiguation  task...    [published paper](https://rd.springer.com/chapter/10.1007/978-3-030-15719-7_10)      In NED, the system  must be able to generate a context for an entity in a text and an entity  in a knowledge base, then correctly link the two.    Explore whether representing graphs  as triplets is more useful than using the full topological information of the graph    We tackle \\ac{NED} by comparing entities in short sentences with \\wikidata{} graphs. Creating a context vector from graphs through deep learning is a challenging problem that has never been applied to \\ac{NED}. Our main contribution is to present an experimental study of recent neural techniques, as well as a discussion about which graph features are most important for the disambiguation task. In addition, a new dataset (\\wikidatadisamb{}) is created to allow a clean and scalable evaluation of \\ac{NED} with \\wikidata{} entries, and to be used as a reference in future research. In the end our results show that a \\ac{Bi-LSTM} encoding of the graph triplets performs best, improving upon the baseline models and scoring an \ m{F1} value of $91.6\\%$ on the \\wikidatadisamb{} test set|sl:arxiv_author|Alberto Cetoli
MOAT|skos:broader|RDF Vocabularies
Ranking SVM|skos:broader|Support vector machine
LibShortText|skos:broader|NLP tools
BERT Rediscovers the Classical NLP Pipeline  We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.   Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.|sl:tag|tag:bertology
Royaume Uni|skos:broader|Pays d'Europe
Emerging Cross-lingual Structure in Pretrained Language Models We study the problem of multilingual masked language modeling, i.e. the training of a single model on concatenated text from multiple languages, and present a detailed study of several factors that influence why these models are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from independently trained models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these symmetries seem to be automatically discovered and aligned during the joint training process.|sl:arxiv_firstAuthor|Shijie Wu
HuggingFace|skos:broader|NLP Groups
Gradient descent|skos:broader|Machine learning: techniques
Reinforcement learning|skos:broader|Machine learning: techniques
Java dev|skos:broader|Java
URI|skos:broader|Web architecture
Stromatolithes|skos:broader|Paléontologie
Sentence Embeddings|skos:broader|Embeddings in NLP
Bag of Tricks for Efficient Text Classification A simple and efficient baseline for text classification.     Our word features can  be averaged together to form good sentence representations.    Our experiments show that fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.   This paper explores a simple and efficient baseline for text classification. Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.|sl:tag|tag:tomas_mikolov
Romancier|skos:broader|Littérature
Symmetric matrices related to the Mertens function In this paper we explore a family of congruences over N from which a sequence of symmetric matrices related to the Mertens function is built. From the results of numerical experiments we formulate a conjecture, about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may play a more important role in this classical and difficult problem.  In this paper we explore a family of congruences over $\\N^\\ast$ from which one builds a sequence of symmetric matrices related to the Mertens function. From the results of numerical experiments, we formulate a conjecture about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may come to play a more important role in this classical and difficult problem.|sl:tag|tag:arxiv_doc
css|skos:broader|Dev
Droit à l'information|skos:broader|Justice
- Siamese network with two deep sub-models  - Projects input and candidate texts into embedding space  - Trained by maximizing cosine similarity between correct input-output pairs    [source](/doc/2019/08/neural_models_for_information_r)|skos:broader|Introduced in the early 1990s by Bromley and LeCun to solve signature verification as an image matching problem
Histoire de l'Asie|skos:broader|Histoire
Java tip|skos:broader|Dev tips
Feynman|skos:broader|Prix Nobel de physique
Target Entity Disambiguation|skos:broader|Entity linking
Using Information Content to Evaluate Semantic Similarity in a Taxonomy This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content. Experimental evaluation suggests that the measure performs encouragingly well (a correlation of r = 0.79 with a benchmark set of human similarity judgments, with an upper bound of r = 0.90 for human subjects performing the same task), and significantly better than the traditional edge counting approach (r = 0.66).|sl:arxiv_firstAuthor|Philip Resnik
Xenophon|skos:broader|Grèce antique
iMovie|skos:broader|Digital Video
A practical tutorial on autoencoders for nonlinear feature fusion: Taxonomy, models, software and guidelines Many of the existing machine learning algorithms, both supervised and unsupervised, depend on the quality of the input characteristics to generate a good model. The amount of these variables is also important, since performance tends to decline as the input dimensionality increases, hence the interest in using feature fusion techniques, able to produce feature sets that are more compact and higher level. A plethora of procedures to fuse original variables for producing new ones has been developed in the past decades. The most basic ones use linear combinations of the original variables, such as PCA (Principal Component Analysis) and LDA (Linear Discriminant Analysis), while others find manifold embeddings of lower dimensionality based on non-linear combinations, such as Isomap or LLE (Linear Locally Embedding) techniques. More recently, autoencoders (AEs) have emerged as an alternative to manifold learning for conducting nonlinear feature fusion. Dozens of AE models have been proposed lately, each with its own specific traits. Although many of them can be used to generate reduced feature sets through the fusion of the original ones, there also AEs designed with other applications in mind. The goal of this paper is to provide the reader with a broad view of what an AE is, how they are used for feature fusion, a taxonomy gathering a broad range of models, and how they relate to other classical techniques. In addition, a set of didactic guidelines on how to choose the proper AE for a given task is supplied, together with a discussion of the software tools available. Finally, two case studies illustrate the usage of AEs with datasets of handwritten digits and breast cancer.|sl:tag|tag:tutorial
Les 100 pièges de l'Anglais|skos:broader|Anglais
RDF-OWL documentation tool|skos:broader|OWL tool
Acronyms (NLP)|skos:broader|Named Entity Recognition
Jena|skos:broader|Java dev
Wikilinks Corpus|skos:broader|Named Entity Recognition
Applet|skos:broader|Java
Génétique + Histoire|skos:broader|Genetics Génétique
Learning to Remember Rare Events  a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training.    Our memory module can be easily added to any part of a supervised neural network Despite recent advances, memory-augmented deep neural networks are still limited when it comes to life-long and one-shot learning, especially in remembering rare events. We present a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training. Our memory module can be easily added to any part of a supervised neural network. To show its versatility we add it to a number of networks, from simple convolutional ones tested on image classification to deep sequence-to-sequence and recurrent-convolutional models. In all cases, the enhanced network gains the ability to remember and do life-long one-shot learning. Our module remembers training examples shown many thousands of steps in the past and it can successfully generalize from them. We set new state-of-the-art for one-shot learning on the Omniglot dataset and demonstrate, for the first time, life-long one-shot learning in recurrent neural networks on a large-scale machine translation task.|sl:arxiv_firstAuthor|Łukasz Kaiser
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:arxiv_author|Chong Luo
Hydrogen Cars|skos:broader|Automobile
No Fuss Distance Metric Learning using Proxies  We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity...   Traditionnaly, supervision is expressed in the form of sets of points that follow  an ordinal relationship – an anchor point x is similar to  a set of positive points Y , and dissimilar to a set of negative  points Z, and a loss defined over these distances is minimized.   Triplet-Based methods are challenging to optimize (a main issue is the need for finding informative triplets).     We propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss.    Mentioned in this [blog post](/doc/2020/01/training_a_speaker_embedding_fr):     Proxy based triplet learning: instead of generating triplets, we learn an embedding for each class and use the learnt embedding as a proxy for triplets as part of the training. In other words, we can train end to end without the computationally expensive step of resampling triplets after each network update.    Near the conclusion:     Our formulation of Proxy-NCA loss produces a loss very  similar to the standard cross-entropy loss used in classification.  However, we arrive at our formulation from a different  direction: we are not interested in the actual classifier and  indeed discard the proxies once the model has been trained.  Instead, the proxies are auxiliary variables, enabling more  effective optimization of the embedding model parameters.  As such, our formulation not only enables us to surpass the  state of the art in zero-shot learning, but also offers an explanation  to the effectiveness of the standard trick of training  a classifier, and using its penultimate layer’s output as the  embedding. We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity. Traditionally, for this problem supervision is expressed in the form of sets of points that follow an ordinal relationship -- an anchor point $x$ is similar to a set of positive points $Y$, and dissimilar to a set of negative points $Z$, and a loss defined over these distances is minimized. While the specifics of the optimization differ, in this work we collectively call this type of supervision Triplets and all methods that follow this pattern Triplet-Based methods. These methods are challenging to optimize. A main issue is the need for finding informative triplets, which is usually achieved by a variety of tricks such as increasing the batch size, hard or semi-hard triplet mining, etc. Even with these tricks, the convergence rate of such methods is slow. In this paper we propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss. This proxy-based loss is empirically better behaved. As a result, the proxy-loss improves on state-of-art results for three standard zero-shot learning datasets, by up to 15% points, while converging three times as fast as other triplet-based losses.|sl:arxiv_author|Alexander Toshev
JavaScript|skos:broader|Programming language
NLP + juridique|skos:broader|NLP: use cases
Yago|skos:broader|Linked Data
IBM developerWorks|skos:broader|IBM
KZ|skos:broader|Nazisme
Satori|skos:broader|Microsoft Research
Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks Current machine learning systems operate, almost exclusively, in a statistical, or model-free mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks. To demonstrate the essential role of such models, I will present a summary of seven tasks which are beyond reach of current machine learning systems and which have been accomplished using the tools of causal modeling.|sl:arxiv_firstAuthor|Judea Pearl
Obélisque d'Axoum|skos:broader|Italie
Realistic Re-evaluation of Knowledge Graph Completion Methods: An Experimental Study data redundancy (reverse relations), Cartesian product relations     A more fundamental defect  of these models is that the link prediction scenario, given  such data, is non-existent in the real-world In the active research area of employing embedding models for knowledge graph completion, particularly for the task of link prediction, most prior studies used two benchmark datasets FB15k and WN18 in evaluating such models. Most triples in these and other datasets in such studies belong to reverse and duplicate relations which exhibit high data redundancy due to semantic duplication, correlation or data incompleteness. This is a case of excessive data leakage---a model is trained using features that otherwise would not be available when the model needs to be applied for real prediction. There are also Cartesian product relations for which every triple formed by the Cartesian product of applicable subjects and objects is a true fact. Link prediction on the aforementioned relations is easy and can be achieved with even better accuracy using straightforward rules instead of sophisticated embedding models. A more fundamental defect of these models is that the link prediction scenario, given such data, is non-existent in the real-world. This paper is the first systematic study with the main objective of assessing the true effectiveness of embedding models when the unrealistic triples are removed. Our experiment results show these models are much less accurate than what we used to perceive. Their poor accuracy renders link prediction a task without truly effective automated solution. Hence, we call for re-investigation of possible effective approaches.|sl:arxiv_firstAuthor|Farahnaz Akrami Department of Computer Science and Engineering, University of Texas at Arlington
Javascript closures|skos:broader|Closure
Transfer Learning for Sequence Labeling Using Source Model and Target Data use-case ex: NER when the target data contains new categories In this paper, we propose an approach for transferring the knowledge of a neural model for sequence labeling, learned from the source domain, to a new model trained on a target domain, where new label categories appear. Our transfer learning (TL) techniques enable to adapt the source model using the target data and new categories, without accessing to the source data. Our solution consists in adding new neurons in the output layer of the target model and transferring parameters from the source model, which are then fine-tuned with the target data. Additionally, we propose a neural adapter to learn the difference between the source and the target label distribution, which provides additional important information to the target model. Our experiments on Named Entity Recognition show that (i) the learned knowledge in the source model can be effectively transferred when the target data contains new categories and (ii) our neural adapter further improves such transfer.|sl:tag|tag:transfer_learning
Monotrèmes|skos:broader|Animal
Arxiv Doc|skos:broader|Favoris
 Pierre-Yves Vandenbussche|skos:broader|SW guys (and girls)
Neural Architectures for Named Entity Recognition Neural architectures for NER that use no language-specific resources or features beyond a small amount of supervised training data and unlabeled corpora.      Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.|sl:arxiv_author|Kazuya Kawakami
sig.ma|skos:broader|Mashups
What Does BERT Look At? An Analysis of BERT's Attention Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT's attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT's attention.|sl:tag|tag:bert
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:arxiv_author|Cassandra Xia
Beyond Vector Spaces: Compact Data Representation as Differentiable Weighted Graphs  In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE (Probabilistic Differentiable Graph Embeddings): a method that learns a weighted graph representation of data end-to-end by gradient descent.    [Github](https://github.com/stanis-morozov/prodige)     Learning useful representations is a key ingredient to the success of modern machine learning. Currently, representation learning mostly relies on embedding data into Euclidean space. However, recent work has shown that data in some domains is better modeled by non-euclidean metric spaces, and inappropriate geometry can result in inferior performance. In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE: a method that learns a weighted graph representation of data end-to-end by gradient descent. Greater generality and fewer model assumptions make PRODIGE more powerful than existing embedding-based approaches. We confirm the superiority of our method via extensive experiments on a wide range of tasks, including classification, compression, and collaborative filtering.|sl:tag|tag:arxiv_doc
Coursera: Deep Learning|skos:broader|Coursera
SQL to RDF mapping|skos:broader|SQL
Lexicon Infused Phrase Embeddings for Named Entity Resolution Employs lexicons as part of the word embedding training:      The skip-gram model can be trained to  predict not only neighboring words but also lexicon  membership of the central word (or phrase).    Quickly demonstrates how we can plug phrase embeddings  into an existing log-linear CRF System.     Most state-of-the-art approaches for named-entity recognition (NER) use semi supervised information in the form of word clusters and lexicons. Recently neural network-based language models have been explored, as they as a byproduct generate highly informative vector representations for words, known as word embeddings. In this paper we present two contributions: a new form of learning word embeddings that can leverage information from relevant lexicons to improve the representations, and the first system to use neural word embeddings to achieve state-of-the-art results on named-entity recognition in both CoNLL and Ontonotes NER. Our system achieves an F1 score of 90.90 on the test set for CoNLL 2003---significantly better than any previous system trained on public data, and matching a system employing massive private industrial query-log data.|sl:tag|tag:arxiv_doc
SIMILE|skos:broader|Open Source
The Consciousness Prior consciousness seen as the formation of a low-dimensional combination of a few concepts constituting a conscious thought, i.e., consciousness as awareness at a particular time instant: the projection of a big vector (all the things conscious and unconscious in brain). Attention: additional mechanism describing what mind chooses to focus on.    [YouTube video](/doc/?uri=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYr1mOzC93xs) A new prior is proposed for learning representations of high-level concepts of the kind we manipulate with language. This prior can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by cognitive neuroscience theories of consciousness, seen as a bottleneck through which just a few elements, after having been selected by attention from a broader pool, are then broadcast and condition further processing, both in perception and decision-making. The set of recently selected elements one becomes aware of is seen as forming a low-dimensional conscious state. This conscious state is combining the few concepts constituting a conscious thought, i.e., what one is immediately conscious of at a particular moment. We claim that this architectural and information-processing constraint corresponds to assumptions about the joint distribution between high-level concepts. To the extent that these assumptions are generally true (and the form of natural language seems consistent with them), they can form a useful prior for representation learning. A low-dimensional thought or conscious state is analogous to a sentence: it involves only a few variables and yet can make a statement with very high probability of being true. This is consistent with a joint distribution (over high-level concepts) which has the form of a sparse factor graph, i.e., where the dependencies captured by each factor of the factor graph involve only very few variables while creating a strong dip in the overall energy function. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in a form similar to facts and rules, albeit capturing uncertainty as well as efficient search mechanisms implemented by attention mechanisms.|sl:tag|tag:deep_learning_attention
OAuth2|skos:broader|OAuth
Critique du libéralisme|skos:broader|Politique
Semantic web company|skos:broader|Semantic Web
Thérapie génique|skos:broader|Genetics Génétique
Large Memory Layers with Product Keys  a structured memory which can be easily integrated into a neural network. The memory is very large by design and therefore significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time.     a key-value memory layer that can increase model capacity for a negligible computational cost. A 12-layer transformer with a memory outperforms a 24-layer transformer, and is 2x faster!     [Implementation](/doc/2019/08/product_key_memory_pkm_minima) This paper introduces a structured memory which can be easily integrated into a neural network. The memory is very large by design and significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time. This memory layer allows us to tackle very large scale language modeling tasks. In our experiments we consider a dataset with up to 30 billion words, and we plug our memory layer in a state-of-the-art transformer-based architecture. In particular, we found that a memory augmented model with only 12 layers outperforms a baseline transformer model with 24 layers, while being twice faster at inference time. We release our code for reproducibility purposes.|sl:arxiv_author|Marc'Aurelio Ranzato
Conscience artificielle|skos:broader|Technological singularity
Microformats|skos:broader|HTML Data
NLP tools|skos:broader|Tools
Nikolai Vavilov|skos:broader|Grand Homme
OWL-Full|skos:broader|OWL
Football|skos:broader|Sport
Apprendre une langue|skos:broader|Langues
A Strong Baseline for Learning Cross-Lingual Word Embeddings from Sentence Alignments While cross-lingual word embeddings have been studied extensively in recent years, the qualitative differences between the different algorithms remain vague. We observe that whether or not an algorithm uses a particular feature set (sentence IDs) accounts for a significant performance gap among these algorithms. This feature set is also used by traditional alignment algorithms, such as IBM Model-1, which demonstrate similar performance to state-of-the-art embedding algorithms on a variety of benchmarks. Overall, we observe that different algorithmic approaches for utilizing the sentence ID feature space result in similar performance. This paper draws both empirical and theoretical parallels between the embedding and alignment literature, and suggests that adding additional sources of information, which go beyond the traditional signal of bilingual sentence-aligned corpora, may substantially improve cross-lingual word embeddings, and that future baselines should at least take such features into account.|sl:arxiv_firstAuthor|Omer Levy
Semantic web : présentation|skos:broader|Semantic Web
Désertification|skos:broader|Désert
Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective reviews the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. Neural-symbolic computing has now become the subject of interest of both academic and industry research laboratories. Graph Neural Networks (GNN) have been widely used in relational and symbolic domains, with widespread application of GNNs in combinatorial optimization, constraint satisfaction, relational reasoning and other scientific domains. The need for improved explainability, interpretability and trust of AI systems in general demands principled methodologies, as suggested by neural-symbolic computing. In this paper, we review the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. This includes the application of GNNs in several domains as well as its relationship to current developments in neural-symbolic computing.|sl:arxiv_author|Marcelo Prates
NLP and humanities|skos:broader|NLP: use cases
Corée du Sud|skos:broader|Corée
Smart contracts|skos:broader|Blockchain
Bibliothèque numérique|skos:broader|Digital Media
Word Translation Without Parallel Data  we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent studies showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally describe experiments on the English-Esperanto low-resource language pair, on which there only exists a limited amount of parallel data, to show the potential impact of our method in fully unsupervised machine translation. Our code, embeddings and dictionaries are publicly available.|sl:tag|tag:guillaume_lample
Collège|skos:broader|Ecole
Text preprocessing|skos:broader|Text processing
Probing Neural Network Comprehension of Natural Language Arguments what has BERT learned about argument comprehension?    [Comments](/doc/2019/07/bert_s_success_in_some_benchmar) We are surprised to find that BERT's peak performance of 77% on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.|sl:arxiv_firstAuthor|Timothy Niven
Apache Mahout|skos:broader|Hadoop
Frameworks|skos:broader|Programming
A Comprehensive Survey on Graph Neural Networks an overview of graph neural networks (GNNs) in data mining and machine learning fields Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.|sl:arxiv_author|Guodong Long
Memory in deep learning|skos:broader|Mémoire (informatique)
Bombay|skos:broader|Inde
Carrot2|skos:broader|NLP tools
Multi-Task Deep Neural Networks for Natural Language Understanding outperforms BERT in nine of eleven benchmark NLP tasks In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations in order to adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7% (2.2% absolute improvement). We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. The code and pre-trained models are publicly available at https://github.com/namisan/mt-dnn.|sl:tag|tag:bert
iTunes|skos:broader|Apple
Egit|skos:broader|Eclipse
INRIA|skos:broader|Recherche
Representing Sentences as Low-Rank Subspaces  We observe a simple geometry of sentences -- the word representations of a given sentence roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors.    A sentence of N words is a matrix (300, N) (if 300 is the dim of the word embeddings space). We take the eg. 4 (hyperparam) heaviest singular values - a subspace with dim 4    Similarity between docs: principal angle between the subspaces (reminiscent of cosine similarity)     Sentences are important semantic units of natural language. A generic, distributional representation of sentences that can capture the latent semantics is beneficial to multiple downstream applications. We observe a simple geometry of sentences -- the word representations of a given sentence (on average 10.23 words in all SemEval datasets with a standard deviation 4.84) roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors. Such an unsupervised representation is empirically validated via semantic textual similarity tasks on 19 different datasets, where it outperforms the sophisticated neural network models, including skip-thought vectors, by 15% on average.|sl:arxiv_author|Jiaqi Mu
Pékin 2008|skos:broader|Pékin
Roméo Dallaire|skos:broader|Génocide rwandais
Identity Crisis in Linked Data|skos:broader|Linked Data
Karen Blixen|skos:broader|Ecrivain
Imprimantes|skos:broader|Devices
One-Shot Learning|skos:broader|Machine learning
Pablo Neruda|skos:broader|Prix Nobel
Pluton|skos:broader|Système solaire
The web sucks|skos:broader|Web
Semantic web: evangelization|skos:broader|Semantic Web
Messenger|skos:broader|Missions spatiales
Solr and NLP|skos:broader|Solr
Ian Hickson|skos:broader|Technical guys
Jeremy Howard|skos:broader|NLP girls and guys
K-BERT: Enabling Language Representation with Knowledge Graph a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by equipped with a KG without pre-training by-self because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts.|sl:arxiv_author|Zhe Zhao
Backtranslation|skos:broader|Data Augmentation
Stacking (ensemble learning)|skos:broader|Ensemble learning
Aster Aweke|skos:broader|Ethiopie
Solr (not english only)|skos:broader|Solr
fps: paper|skos:broader|fps
Arundhati Roy|skos:broader|Inde
Online Course Materials|skos:broader|Online Learning
C2G|skos:broader|Configuration
SOAP vs REST|skos:broader|SOAP
Javascript RDF Parser in IE|skos:broader|Internet Explorer
Astronomie multi-signaux|skos:broader|Astronomie
PlaNet - Photo Geolocation with Convolutional Neural Networks Is it possible to build a system to determine the location where a photo was taken using just its pixels? In general, the problem seems exceptionally difficult: it is trivial to construct situations where no location can be inferred. Yet images often contain informative cues such as landmarks, weather patterns, vegetation, road markings, and architectural details, which in combination may allow one to determine an approximate location and occasionally an exact location. Websites such as GeoGuessr and View from your Window suggest that humans are relatively good at integrating these cues to geolocate images, especially en-masse. In computer vision, the photo geolocation problem is usually approached using image retrieval methods. In contrast, we pose the problem as one of classification by subdividing the surface of the earth into thousands of multi-scale geographic cells, and train a deep network using millions of geotagged images. While previous approaches only recognize landmarks or perform approximate matching using global image descriptors, our model is able to use and integrate multiple visible cues. We show that the resulting model, called PlaNet, outperforms previous approaches and even attains superhuman levels of accuracy in some cases. Moreover, we extend our model to photo albums by combining it with a long short-term memory (LSTM) architecture. By learning to exploit temporal coherence to geolocate uncertain photos, we demonstrate that this model achieves a 50% performance improvement over the single-image model.|sl:arxiv_author|Ilya Kostrikov
Lexicon Infused Phrase Embeddings for Named Entity Resolution Employs lexicons as part of the word embedding training:      The skip-gram model can be trained to  predict not only neighboring words but also lexicon  membership of the central word (or phrase).    Quickly demonstrates how we can plug phrase embeddings  into an existing log-linear CRF System.     Most state-of-the-art approaches for named-entity recognition (NER) use semi supervised information in the form of word clusters and lexicons. Recently neural network-based language models have been explored, as they as a byproduct generate highly informative vector representations for words, known as word embeddings. In this paper we present two contributions: a new form of learning word embeddings that can leverage information from relevant lexicons to improve the representations, and the first system to use neural word embeddings to achieve state-of-the-art results on named-entity recognition in both CoNLL and Ontonotes NER. Our system achieves an F1 score of 90.90 on the test set for CoNLL 2003---significantly better than any previous system trained on public data, and matching a system employing massive private industrial query-log data.|sl:arxiv_firstAuthor|Alexandre Passos
Equivalence mining|skos:broader|Linking Open Data
GINCO (Culture)|skos:broader|Thesaurus
Relations franco-américaines|skos:broader|France
Caetano Veloso|skos:broader|Musique brésilienne
Obamacare|skos:broader|Obama
Grèce antique|skos:broader|Grèce
Leningrad|skos:broader|Ville
HTTP Cache|skos:broader|HTTP
Bijan Parsia|skos:broader|SW guys (and girls)
Label-aware Document Representation via Hybrid Attention for Extreme Multi-Label Text Classification  This paper is motivated to better explore the semantic relationship between each document and extreme labels by taking advantage of both document content and label correlation. Our objective is to establish an explicit label-aware representation for each document with a hybrid attention deep neural network model(LAHA) Extreme multi-label text classification (XMTC) aims at tagging a document with most relevant labels from an extremely large-scale label set. It is a challenging problem especially for the tail labels because there are only few training documents to build classifier. This paper is motivated to better explore the semantic relationship between each document and extreme labels by taking advantage of both document content and label correlation. Our objective is to establish an explicit label-aware representation for each document with a hybrid attention deep neural network model(LAHA). LAHA consists of three parts. The first part adopts a multi-label self-attention mechanism to detect the contribution of each word to labels. The second part exploits the label structure and document content to determine the semantic connection between words and labels in a same latent space. An adaptive fusion strategy is designed in the third part to obtain the final label-aware document representation so that the essence of previous two parts can be sufficiently integrated. Extensive experiments have been conducted on six benchmark datasets by comparing with the state-of-the-art methods. The results show the superiority of our proposed LAHA method, especially on the tail labels.|sl:tag|tag:text_multi_label_classification
Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation   An embedding method specifically designed for NED that jointly maps words and entities into the same continuous vector space.    We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words Named Entity Disambiguation (NED) refers to the task of resolving multiple named entity mentions in a document to their correct references in a knowledge base (KB) (e.g., Wikipedia). In this paper, we propose a novel embedding method specifically designed for NED. The proposed method jointly maps words and entities into the same continuous vector space. We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words. By combining contexts based on the proposed embedding with standard NED features, we achieved state-of-the-art accuracy of 93.1% on the standard CoNLL dataset and 85.2% on the TAC 2010 dataset.|sl:tag|tag:entity_linking
Sebastian Germesin|skos:broader|SW guys (and girls)
Explainable Deep Learning: A Field Guide for the Uninitiated Deep neural network (DNN) is an indispensable machine learning tool for achieving human-level performance on many learning tasks. Yet, due to its black-box nature, it is inherently difficult to understand which aspects of the input data drive the decisions of the network. There are various real-world scenarios in which humans need to make actionable decisions based on the output DNNs. Such decision support systems can be found in critical domains, such as legislation, law enforcement, etc. It is important that the humans making high-level decisions can be sure that the DNN decisions are driven by combinations of data features that are appropriate in the context of the deployment of the decision support system and that the decisions made are legally or ethically defensible. Due to the incredible pace at which DNN technology is being developed, the development of new methods and studies on explaining the decision-making process of DNNs has blossomed into an active research field. A practitioner beginning to study explainable deep learning may be intimidated by the plethora of orthogonal directions the field is taking. This complexity is further exacerbated by the general confusion that exists in defining what it means to be able to explain the actions of a deep learning system and to evaluate a system's ability to explain. To alleviate this problem, this article offers a field guide to deep learning explainability for those uninitiated in the field. The field guide: i) Discusses the traits of a deep learning system that researchers enhance in explainability research, ii) places explainability in the context of other related deep learning research areas, and iii) introduces three simple dimensions defining the space of foundational methods that contribute to explainable deep learning. The guide is designed as an easy-to-digest starting point for those just embarking in the field.|sl:arxiv_firstAuthor|Ning Xie
Zapata|skos:broader|Personnage historique
Shallow parsing (Chunking)|skos:broader|General NLP tasks
Large Memory Layers with Product Keys  a structured memory which can be easily integrated into a neural network. The memory is very large by design and therefore significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time.     a key-value memory layer that can increase model capacity for a negligible computational cost. A 12-layer transformer with a memory outperforms a 24-layer transformer, and is 2x faster!     [Implementation](/doc/2019/08/product_key_memory_pkm_minima) This paper introduces a structured memory which can be easily integrated into a neural network. The memory is very large by design and significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time. This memory layer allows us to tackle very large scale language modeling tasks. In our experiments we consider a dataset with up to 30 billion words, and we plug our memory layer in a state-of-the-art transformer-based architecture. In particular, we found that a memory augmented model with only 12 layers outperforms a baseline transformer model with 24 layers, while being twice faster at inference time. We release our code for reproducibility purposes.|sl:tag|tag:ludovic_denoyer
Google Rich Cards|skos:broader|Google
Javascript closures|skos:broader|Function closures
TabFact: A Large-scale Dataset for Table-based Fact Verification fact verification given semi-structured data as evidence The problem of verifying whether a textual hypothesis holds based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation. However, existing studies are mainly restricted to dealing with unstructured evidence (e.g., natural language sentences and documents, news, etc), while verification under structured evidence, such as tables, graphs, and databases, remains under-explored. This paper specifically aims to study the fact verification given semi-structured data as evidence. To this end, we construct a large-scale dataset called TabFact with 16k Wikipedia tables as the evidence for 118k human-annotated natural language statements, which are labeled as either ENTAILED or REFUTED. TabFact is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning. To address these reasoning challenges, we design two different models: Table-BERT and Latent Program Algorithm (LPA). Table-BERT leverages the state-of-the-art pre-trained language model to encode the linearized tables and statements into continuous vectors for verification. LPA parses statements into programs and executes them against the tables to obtain the returned binary value for verification. Both methods achieve similar accuracy but still lag far behind human performance. We also perform a comprehensive analysis to demonstrate great future opportunities. The data and code of the dataset are provided in \\url{https://github.com/wenhuchen/Table-Fact-Checking}.|sl:arxiv_author|Hong Wang
Synchrotron|skos:broader|Physique
Damian Steer|skos:broader|SW guys (and girls)
iPod|skos:broader|Devices
Maïs OGM|skos:broader|Maïs
NLP + Sem web|skos:broader|Semantic Web
Multi-Task Deep Neural Networks for Natural Language Understanding outperforms BERT in nine of eleven benchmark NLP tasks In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations in order to adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7% (2.2% absolute improvement). We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. The code and pre-trained models are publicly available at https://github.com/namisan/mt-dnn.|sl:tag|tag:kd_mkb_biblio
Named Entity Recognition with Extremely Limited Data Named Entity Search (NES)     We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.     We do not propose this as a replacement  for NER, but as something to be used for an ephemeral or contextual  class of entity, when it does not make sense to label hundreds or  thousands of instances to learn a classifier Traditional information retrieval treats named entity recognition as a pre-indexing corpus annotation task, allowing entity tags to be indexed and used during search. Named entity taggers themselves are typically trained on thousands or tens of thousands of examples labeled by humans. However, there is a long tail of named entities classes, and for these cases, labeled data may be impossible to find or justify financially. We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.|sl:tag|tag:conditional_random_field
Memory-prediction framework|skos:broader|Machine learning
Combining numerical and text features|skos:broader|Combining text and structured data (ML-NLP)
Contrastive Self-Supervised Learning|skos:broader|Representation learning
Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation   An embedding method specifically designed for NED that jointly maps words and entities into the same continuous vector space.    We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words Named Entity Disambiguation (NED) refers to the task of resolving multiple named entity mentions in a document to their correct references in a knowledge base (KB) (e.g., Wikipedia). In this paper, we propose a novel embedding method specifically designed for NED. The proposed method jointly maps words and entities into the same continuous vector space. We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words. By combining contexts based on the proposed embedding with standard NED features, we achieved state-of-the-art accuracy of 93.1% on the standard CoNLL dataset and 85.2% on the TAC 2010 dataset.|sl:tag|tag:these_irit_renault_biblio_initiale
NLP Teams|skos:broader|AI teams
Quora Question Pairs|skos:broader|NLP datasets
Cohn-Bendit|skos:broader|Politique française
Google: SEO|skos:broader|Google
Zouk|skos:broader|Antilles
Linked Data Platform|skos:broader|W3C Working group
A Comprehensive Survey on Graph Neural Networks an overview of graph neural networks (GNNs) in data mining and machine learning fields Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.|sl:arxiv_author|Philip S. Yu
Chris Manning|skos:broader|NLP girls and guys
Porc|skos:broader|Animal
Knowledge Graphs and NLP|skos:broader|NLP
Distributed Representations of Sentences and Documents Paragraph Vector: an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents.Represents each document by a dense vector which is trained to predict words in the document. Overcomes the weaknesses of the [Bag Of Words](/tag/bag_of_words) model (order of words, semantic of words)       Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, powerful, strong and Paris are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.|sl:tag|tag:doc2vec
Entity recommendation|skos:broader|Entities
Convolutional Knowledge Graph Embeddings|skos:broader|Convolutional neural network
RDF in files|skos:broader|Semanlink related
Chine / Afrique|skos:broader|Afrique
Script tag hack|skos:broader|cross-domain data fetching
Sequence-To-Sequence Encoder-Decoder Architecture|skos:broader|Encoder-Decoder architecture
fps: paper|skos:broader|fps pres
Configuration and SW|skos:broader|Configuration
Paléontologie|skos:broader|Géologie
GAN|skos:broader|Deep latent variable models
Sarkozy : immigration|skos:broader|Immigration
Knowledge Graph Embeddings and Explainable AI survey of     - the state-of-the-art in the field of knowledge graph embeddings  - methods for explaining predictions obtained via knowledge graph embeddings. Knowledge graph embeddings are now a widely adopted approach to knowledge representation in which entities and relationships are embedded in vector spaces. In this chapter, we introduce the reader to the concept of knowledge graph embeddings by explaining what they are, how they can be generated and how they can be evaluated. We summarize the state-of-the-art in this field by describing the approaches that have been introduced to represent knowledge in the vector space. In relation to knowledge representation, we consider the problem of explainability, and discuss models and methods for explaining predictions obtained via knowledge graph embeddings.|sl:arxiv_author|Luca Costabello
A Call for More Rigor in Unsupervised Cross-lingual Learning  a scenario without any parallel data and abundant monolingual data is unrealistic in practice We review motivations, definition, approaches, and methodology for unsupervised cross-lingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of the world's languages. However, we argue that a scenario without any parallel data and abundant monolingual data is unrealistic in practice. We also discuss different training signals that have been used in previous work, which depart from the pure unsupervised setting. We then describe common methodological issues in tuning and evaluation of unsupervised cross-lingual models and present best practices. Finally, we provide a unified outlook for different types of research in this area (i.e., cross-lingual word embeddings, deep multilingual pretraining, and unsupervised machine translation) and argue for comparable evaluation of these models.|sl:tag|tag:cross_lingual_nlp
Nodalities|skos:broader|Talis
Verts|skos:broader|Écologie
SPARQL perfs|skos:broader|SPARQL
The DAO|skos:broader|Ethereum
Décroissance|skos:broader|Croissance
RDFj is a set of conventions forbr/- constructing JSON objects in such a way that they can easily be interpreted as RDF;br/  - taking RDF and arriving at canonical JSON objects.|skos:broader|A JavaScript library that provides cross-browser XForms, RDFa, and SMIL support.
Finlande|skos:broader|Scandinavie
Maven tips|skos:broader|Maven
Natural Language Processing (almost) from Scratch seminal work    Abstract:     a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements   We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.|sl:tag|tag:multi_task_learning
Global workspace theory|skos:broader|Neuroscience
Jsonld-java|skos:broader|JSON-LD
Spiking Neural Networks SNN|skos:broader|ANN NN Artificial neural network
RDF performance issues|skos:broader|RDF dev
D2RQ|skos:broader|Richard Cyganiak
A practical tutorial on autoencoders for nonlinear feature fusion: Taxonomy, models, software and guidelines Many of the existing machine learning algorithms, both supervised and unsupervised, depend on the quality of the input characteristics to generate a good model. The amount of these variables is also important, since performance tends to decline as the input dimensionality increases, hence the interest in using feature fusion techniques, able to produce feature sets that are more compact and higher level. A plethora of procedures to fuse original variables for producing new ones has been developed in the past decades. The most basic ones use linear combinations of the original variables, such as PCA (Principal Component Analysis) and LDA (Linear Discriminant Analysis), while others find manifold embeddings of lower dimensionality based on non-linear combinations, such as Isomap or LLE (Linear Locally Embedding) techniques. More recently, autoencoders (AEs) have emerged as an alternative to manifold learning for conducting nonlinear feature fusion. Dozens of AE models have been proposed lately, each with its own specific traits. Although many of them can be used to generate reduced feature sets through the fusion of the original ones, there also AEs designed with other applications in mind. The goal of this paper is to provide the reader with a broad view of what an AE is, how they are used for feature fusion, a taxonomy gathering a broad range of models, and how they relate to other classical techniques. In addition, a set of didactic guidelines on how to choose the proper AE for a given task is supplied, together with a discussion of the software tools available. Finally, two case studies illustrate the usage of AEs with datasets of handwritten digits and breast cancer.|sl:arxiv_author|David Charte
Tribunal Pénal International|skos:broader|Crime contre l'Humanité
Deep Mutual Learning  In this paper we explore a different but related idea to model distillation – that of mutual learning. Distillation starts with a powerful large and pre-trained teacher network and performs one-way knowledge transfer to a small untrained student. In contrast, in mutual learning we start with a pool of untrained students who learn simultaneously to solve the task together.    [critic here](doc:2020/06/1804_03235_large_scale_distri):     Zhang et al. (2017) reported a benefit in quality over  basic distillation, but they compare distilling model M1 into model M2 with training model M1  and model M2 using codistillation; they do not compare to distilling an ensemble of models M1  and M2 into model M3.     ...     we can achieve the 70.7% they report for online  distillation using traditional offline distillation. Model distillation is an effective and widely used technique to transfer knowledge from a teacher to a student network. The typical application is to transfer from a powerful large network or ensemble to a small network, that is better suited to low-memory or fast execution requirements. In this paper, we present a deep mutual learning (DML) strategy where, rather than one way transfer between a static pre-defined teacher and a student, an ensemble of students learn collaboratively and teach each other throughout the training process. Our experiments show that a variety of network architectures benefit from mutual learning and achieve compelling results on CIFAR-100 recognition and Market-1501 person re-identification benchmarks. Surprisingly, it is revealed that no prior powerful teacher network is necessary -- mutual learning of a collection of simple student networks works, and moreover outperforms distillation from a more powerful yet static teacher.|sl:arxiv_author|Timothy M. Hospedales
Embeddings in IR|skos:broader|IR
Design pattern|skos:broader|Informatique
Atoll|skos:broader|Océan
Graph Embeddings|skos:broader|Graphs+Machine Learning
Cortical.io|skos:broader|Semantic folding
Learning Semantic Similarity for Very Short Texts In order to pair short text  fragments—as a concatenation of separate words—an adequate  distributed sentence representation is needed. Main contribution: a first step towards a hybrid method that  combines the strength of dense distributed representations—  as opposed to sparse term matching—with the strength of  tf-idf based methods. The combination of word embeddings and tf-idf  information might lead to a better model for semantic content  within very short text fragments. Levering data on social media, such as Twitter and Facebook, requires information retrieval algorithms to become able to relate very short text fragments to each other. Traditional text similarity methods such as tf-idf cosine-similarity, based on word overlap, mostly fail to produce good results in this case, since word overlap is little or non-existent. Recently, distributed word representations, or word embeddings, have been shown to successfully allow words to match on the semantic level. In order to pair short text fragments - as a concatenation of separate words - an adequate distributed sentence representation is needed, in existing literature often obtained by naively combining the individual word representations. We therefore investigated several text representations as a combination of word embeddings in the context of semantic pair matching. This paper investigates the effectiveness of several such naive techniques, as well as traditional tf-idf similarity, for fragments of different lengths. Our main contribution is a first step towards a hybrid method that combines the strength of dense distributed representations - as opposed to sparse term matching - with the strength of tf-idf based methods to automatically reduce the impact of less informative terms. Our new approach outperforms the existing techniques in a toy experimental set-up, leading to the conclusion that the combination of word embeddings and tf-idf information might lead to a better model for semantic content within very short text fragments.|sl:tag|tag:nlp_short_texts
NLP: negation|skos:broader|NLP tasks / problems
CoKE: Contextualized Knowledge Graph Embedding A method to build contextualized entity and relation embeddings. Entities and relations may appear in different graph contexts. Edges and paths, both formulated as sequences of entities and relations, are passed as input to a Transformer encoder to learn the contextualized representations..    [Github](https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE) Knowledge graph embedding, which projects symbolic entities and relations into continuous vector spaces, is gaining increasing attention. Previous methods allow a single static embedding for each entity or relation, ignoring their intrinsic contextual nature, i.e., entities and relations may appear in different graph contexts, and accordingly, exhibit different properties. This work presents Contextualized Knowledge Graph Embedding (CoKE), a novel paradigm that takes into account such contextual nature, and learns dynamic, flexible, and fully contextualized entity and relation embeddings. Two types of graph contexts are studied: edges and paths, both formulated as sequences of entities and relations. CoKE takes a sequence as input and uses a Transformer encoder to obtain contextualized representations. These representations are hence naturally adaptive to the input, capturing contextual meanings of entities and relations therein. Evaluation on a wide variety of public benchmarks verifies the superiority of CoKE in link prediction and path query answering. It performs consistently better than, or at least equally well as current state-of-the-art in almost every case, in particular offering an absolute improvement of 21.0% in H@10 on path query answering. Our code is available at \\url{https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE}.|sl:arxiv_author|Songtai Dai
Méroé|skos:broader|Nubie
Origines de l'homme|skos:broader|Préhistoire
AI girls and guys|skos:broader|Artificial Intelligence
Deep Learning: A Critical Appraisal Although deep learning has historical roots going back decades, neither the term deep learning nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic (2012) deep network model of Imagenet. What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.|sl:tag|tag:arxiv_doc
Amérique du sud|skos:broader|Amérique latine
Microsoft Concept Graph|skos:broader|Knowledge Graphs
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|Claudio Gutierrez
Cinéma brésilien|skos:broader|Cinéma
SPARQL: shortcomings|skos:broader|SPARQL
Apprendre une langue|skos:broader|Education
Platonov|skos:broader|Littérature russe
War|skos:broader|Horreur
Enterprise Content Management|skos:broader|GED
Pythagore|skos:broader|Grèce antique
Semantic Networks|skos:broader|Semantic Web
Knowledge Graph Embeddings and Explainable AI survey of     - the state-of-the-art in the field of knowledge graph embeddings  - methods for explaining predictions obtained via knowledge graph embeddings. Knowledge graph embeddings are now a widely adopted approach to knowledge representation in which entities and relationships are embedded in vector spaces. In this chapter, we introduce the reader to the concept of knowledge graph embeddings by explaining what they are, how they can be generated and how they can be evaluated. We summarize the state-of-the-art in this field by describing the approaches that have been introduced to represent knowledge in the vector space. In relation to knowledge representation, we consider the problem of explainability, and discuss models and methods for explaining predictions obtained via knowledge graph embeddings.|sl:arxiv_author|Matteo Palmonari
Good Practice When Generating URIs|skos:broader|Minting URIs
Périclès|skos:broader|Chef d'état
Nicolas Hulot|skos:broader|Écologie
Categorical Metadata Representation for Customized Text Classification  We observe that current representation methods for categorical metadata... are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category The performance of text classification has improved tremendously using intelligently engineered neural-based models, especially those injecting categorical metadata as additional information, e.g., using user/product information for sentiment classification. These information have been used to modify parts of the model (e.g., word embeddings, attention mechanisms) such that results can be customized according to the metadata. We observe that current representation methods for categorical metadata, which are devised for human consumption, are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category, and even such context is often scarce (for tail category). To this end, we propose to use basis vectors to effectively incorporate categorical metadata on various parts of a neural-based model. This additionally decreases the number of parameters dramatically, especially when the number of categorical features is large. Extensive experiments on various datasets with different properties are performed and show that through our method, we can represent categorical metadata more effectively to customize parts of the model, including unexplored ones, and increase the performance of the model greatly.|sl:arxiv_author|Jihyeok Kim
Europeana|skos:broader|Cultural heritage
Axoum|skos:broader|Ethiopie
OWL: Introduction|skos:broader|OWL
Rules language|skos:broader|Rules
Mami Wata|skos:broader|Mythologie
Transformers as Soft Reasoners over Language  AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. We provide the first demonstration that this is possible, and characterize the extent of this capability. To do this, we use a collection of synthetic datasets that test increasing levels of reasoning complexity (number of rules, presence of negation, and depth of chaining). We find transformers appear to learn rule-based reasoning with high (99%) accuracy on these datasets, and in a way that generalizes to test data requiring substantially deeper chaining than in the training data (95%+ scores). We also demonstrate that the models transfer well to two hand-authored rulebases, and to rulebases paraphrased into more natural language. These findings are significant as it suggests a new role for transformers, namely as a limited soft theorem prover operating over explicit theories in language. This in turn suggests new possibilities for explainability, correctability, and counterfactual reasoning in question-answering. All datasets and a live demo are available at http://rule-reasoning.apps.allenai.org/|sl:tag|tag:reasoning
Car Options Ontology|skos:broader|Automotive ontologies
Neural Ranking Models with Weak Supervision Main Idea: To leverage large amounts of unsupervised data to infer “weak” labels and use that signal for learning supervised models as if we had the ground truth labels. See [blog post](/doc/?uri=http%3A%2F%2Fmostafadehghani.com%2F2017%2F04%2F23%2Fbeating-the-teacher-neural-ranking-models-with-weak-supervision%2F):     This is truly awesome since we have only used  BM25 as the supervisor to train a model which performs better than BM25 itself!   Despite the impressive improvements achieved by unsupervised deep neural networks in computer vision and NLP tasks, such improvements have not yet been observed in ranking for information retrieval. The reason may be the complexity of the ranking problem, as it is not obvious how to learn from queries and documents when no supervised signal is available. Hence, in this paper, we propose to train a neural ranking model using weak supervision, where labels are obtained automatically without human annotators or any external resources (e.g., click data). To this aim, we use the output of an unsupervised ranking model, such as BM25, as a weak supervision signal. We further train a set of simple yet effective ranking models based on feed-forward neural networks. We study their effectiveness under various learning scenarios (point-wise and pair-wise models) and using different input representations (i.e., from encoding query-document pairs into dense/sparse vectors to using word embedding representation). We train our networks using tens of millions of training instances and evaluate it on two standard collections: a homogeneous news collection(Robust) and a heterogeneous large-scale web collection (ClueWeb). Our experiments indicate that employing proper objective functions and letting the networks to learn the input representation based on weakly supervised data leads to impressive performance, with over 13% and 35% MAP improvements over the BM25 model on the Robust and the ClueWeb collections. Our findings also suggest that supervised neural ranking models can greatly benefit from pre-training on large amounts of weakly labeled data that can be easily obtained from unsupervised IR models.|sl:arxiv_firstAuthor|Mostafa Dehghani
C2GWeb RDF|skos:broader|C2GWeb
BAM! Born-Again Multi-Task Networks for Natural Language Understanding  knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers It can be challenging to train multi-task neural networks that outperform or even match their single-task counterparts. To help address this, we propose using knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers. We evaluate our approach by multi-task fine-tuning BERT on the GLUE benchmark. Our method consistently improves over standard single-task and multi-task training.|sl:arxiv_firstAuthor|Kevin Clark
OS|skos:broader|Software
Memory Embeddings|skos:broader|Memory in deep learning
Pre-training via Paraphrasing We introduce MARGE, a pre-trained sequence-to-sequence model learned with an unsupervised multi-lingual multi-document paraphrasing objective. MARGE provides an alternative to the dominant masked language modeling paradigm, where we self-supervise the reconstruction of target text by retrieving a set of related texts (in many languages) and conditioning on them to maximize the likelihood of generating the original. We show it is possible to jointly learn to do retrieval and reconstruction, given only a random initialization. The objective noisily captures aspects of paraphrase, translation, multi-document summarization, and information retrieval, allowing for strong zero-shot performance on several tasks. For example, with no additional task-specific training we achieve BLEU scores of up to 35.8 for document translation. We further show that fine-tuning gives strong performance on a range of discriminative and generative tasks in many languages, making MARGE the most generally applicable pre-training method to date.|sl:tag|tag:nlp_pretraining
intent classification intent detection|skos:broader|Chatbot
Russie|skos:broader|Asie
Multilingual embeddings|skos:broader|Cross-lingual NLP
Zika|skos:broader|Virus
Semantic CMS|skos:broader|Semantic Web : Application
Digital economy|skos:broader|Economie
Graph database and NLP|skos:broader|NLP techniques
Similarity queries|skos:broader|Recommender Systems
Origines du sida|skos:broader|Sida
Autoencoder|skos:broader|Dimensionality reduction
HTML Dev|skos:broader|HTML
Do Deep Nets Really Need to be Deep? Currently, deep neural networks are the state of the art on problems such as speech recognition and computer vision. In this extended abstract, we show that shallow feed-forward networks can learn the complex functions previously learned by deep nets and achieve accuracies previously only achievable with deep models. Moreover, in some cases the shallow neural nets can learn these deep functions using a total number of parameters similar to the original deep model. We evaluate our method on the TIMIT phoneme recognition task and are able to train shallow fully-connected nets that perform similarly to complex, well-engineered, deep convolutional architectures. Our success in training shallow neural nets to mimic deeper models suggests that there probably exist better algorithms for training shallow feed-forward nets than those currently available.|sl:arxiv_author|Lei Jimmy Ba
Semantic Web / Web 2.0|skos:broader|Web 2.0
httpRange-14|skos:broader|Information resources
Question Answering over Knowledge Graphs via Structural Query Patterns Natural language question answering over knowledge graphs is an important and interesting task as it enables common users to gain accurate answers in an easy and intuitive manner. However, it remains a challenge to bridge the gap between unstructured questions and structured knowledge graphs. To address the problem, a natural discipline is building a structured query to represent the input question. Searching the structured query over the knowledge graph can produce answers to the question. Distinct from the existing methods that are based on semantic parsing or templates, we propose an effective approach powered by a novel notion, structural query pattern, in this paper. Given an input question, we first generate its query sketch that is compatible with the underlying structure of the knowledge graph. Then, we complete the query graph by labeling the nodes and edges under the guidance of the structural query pattern. Finally, answers can be retrieved by executing the constructed query graph over the knowledge graph. Evaluations on three question answering benchmarks show that our proposed approach outperforms state-of-the-art methods significantly.|sl:tag|tag:arxiv_doc
Bag of Tricks for Efficient Text Classification A simple and efficient baseline for text classification.     Our word features can  be averaged together to form good sentence representations.    Our experiments show that fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.   This paper explores a simple and efficient baseline for text classification. Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.|sl:arxiv_author|Piotr Bojanowski
LOD mailing list|skos:broader|Linking Open Data
Nova Spivak|skos:broader|Technical girls and guys
Emmanuel Ledinot|skos:broader|Technical girls and guys
dbpedia|skos:broader|Linking Open Data
Encyclopedia of Life|skos:broader|Encyclopédie collaborative
Large Memory Layers with Product Keys  a structured memory which can be easily integrated into a neural network. The memory is very large by design and therefore significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time.     a key-value memory layer that can increase model capacity for a negligible computational cost. A 12-layer transformer with a memory outperforms a 24-layer transformer, and is 2x faster!     [Implementation](/doc/2019/08/product_key_memory_pkm_minima) This paper introduces a structured memory which can be easily integrated into a neural network. The memory is very large by design and significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time. This memory layer allows us to tackle very large scale language modeling tasks. In our experiments we consider a dataset with up to 30 billion words, and we plug our memory layer in a state-of-the-art transformer-based architecture. In particular, we found that a memory augmented model with only 12 layers outperforms a baseline transformer model with 24 layers, while being twice faster at inference time. We release our code for reproducibility purposes.|sl:tag|tag:memory_in_deep_learning
RDF Access to Relational Databases|skos:broader|Relational Databases and the Semantic Web
Vénus préhistoriques|skos:broader|Vénus (divinité)
evilstreak/markdown-js|skos:broader|GitHub project
Large-scale Multi-label Learning with Missing Labels The multi-label classification problem has generated significant interest in recent years. However, existing approaches do not adequately address two key challenges: (a) the ability to tackle problems with a large number (say millions) of labels, and (b) the ability to handle data with missing labels. In this paper, we directly address both these problems by studying the multi-label problem in a generic empirical risk minimization (ERM) framework. Our framework, despite being simple, is surprisingly able to encompass several recent label-compression based methods which can be derived as special cases of our method. To optimize the ERM problem, we develop techniques that exploit the structure of specific loss functions - such as the squared loss function - to offer efficient algorithms. We further show that our learning framework admits formal excess risk bounds even in the presence of missing labels. Our risk bounds are tight and demonstrate better generalization performance for low-rank promoting trace-norm regularization when compared to (rank insensitive) Frobenius norm regularization. Finally, we present extensive empirical results on a variety of benchmark datasets and show that our methods perform significantly better than existing label compression based methods and can scale up to very large datasets such as the Wikipedia dataset.|sl:arxiv_author|Inderjit S. Dhillon
Multi-label Text classification|skos:broader|Multi-label classification
Constitution européenne|skos:broader|Institutions européennes
Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks  Sentence-BERT  (SBERT), a modification of the pretrained  BERT network that use siamese and triplet network  structures to derive semantically meaningful  sentence embeddings that can be compared  using cosine-similarity.    Important because     - BERT ist unsuitable for semantic similarity  search as well as for unsupervised tasks  like clustering.  - simple methods such as using the CLS token give low quality sentence embeddings    However, the purpose of SBERT sentence embeddings  are not to be used for transfer learning for other  tasks.    [Related blog post](/doc/2020/01/richer_sentence_embeddings_usin); [Github](https://github.com/UKPLab/sentence-transformers) BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.|sl:tag|tag:huggingface_transformers
RDF and statistics|skos:broader|Web sémantique sw
Distilling Structured Knowledge into Embeddings for Explainable and Accurate Recommendation distilling structured knowledge from a differentiable path-based recommendation model.     proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons Recently, the embedding-based recommendation models (e.g., matrix factorization and deep models) have been prevalent in both academia and industry due to their effectiveness and flexibility. However, they also have such intrinsic limitations as lacking explainability and suffering from data sparsity. In this paper, we propose an end-to-end joint learning framework to get around these limitations without introducing any extra overhead by distilling structured knowledge from a differentiable path-based recommendation model. Through extensive experiments, we show that our proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons.|sl:arxiv_author|Xiaoran Xu
Enhancing the Power of Cardinal's Algorithm Cardinal's factorization algorithm of 1996 splits a univariate polynomial into two factors with root sets separated by the imaginary axis, which is an important goal itself and a basic step toward root-finding. The novelty of the algorithm and its potential power have been well recognized by experts immediately, but by 2016, that is, two decades later, its practical value still remains nil, particularly because of the high computational cost of performing its final stage by means of computing approximate greatest common divisor of two polynomials. We briefly recall Cardinal's algorithm and its difficulties, amend it based on some works performed since 1996, extend its power to splitting out factors of a more general class, and reduce the final stage of the algorithm to quite manageable computations with structured matrices. Some of our techniques can be of independent interest for matrix computations.|sl:arxiv_firstAuthor|Victor Y. Pan
Attention Models in Graphs: A Survey  An attention mechanism aids a model by  allowing it to focus on the most relevant parts of the input to make decisions   Graph-structured data arise naturally in many different application domains. By representing data as graphs, we can capture entities (i.e., nodes) as well as their relationships (i.e., edges) with each other. Many useful insights can be derived from graph-structured data as demonstrated by an ever-growing body of work focused on graph mining. However, in the real-world, graphs can be both large - with many complex patterns - and noisy which can pose a problem for effective graph mining. An effective way to deal with this issue is to incorporate attention into graph mining solutions. An attention mechanism allows a method to focus on task-relevant parts of the graph, helping it to make better decisions. In this work, we conduct a comprehensive and focused survey of the literature on the emerging field of graph attention models. We introduce three intuitive taxonomies to group existing work. These are based on problem setting (type of input and output), the type of attention mechanism used, and the task (e.g., graph classification, link prediction, etc.). We motivate our taxonomies through detailed examples and use each to survey competing approaches from a unique standpoint. Finally, we highlight several challenges in the area and discuss promising directions for future work.|sl:arxiv_author|Nesreen K. Ahmed
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:tag|tag:neuroscience_and_machine_learning
LDOW2008|skos:broader|Linked Data
Pre-trained Models for Natural Language Processing: A Survey Recently, the emergence of pre-trained models (PTMs) has brought natural language processing (NLP) to a new era. In this survey, we provide a comprehensive review of PTMs for NLP. We first briefly introduce language representation learning and its research progress. Then we systematically categorize existing PTMs based on a taxonomy with four perspectives. Next, we describe how to adapt the knowledge of PTMs to the downstream tasks. Finally, we outline some potential directions of PTMs for future research. This survey is purposed to be a hands-on guide for understanding, using, and developing PTMs for various NLP tasks.|sl:arxiv_author|Xipeng Qiu
Tortures américaines|skos:broader|Torture
del.icio.us|skos:broader|Tagging
Lost City|skos:broader|Extrémophiles
Internet tool|skos:broader|Internet
Solid|skos:broader|Privacy and internet
Semantic Folding Theory And its Application in Semantic Fingerprinting Human language is recognized as a very complex domain since decades. No computer system has been able to reach human levels of performance so far. The only known computational system capable of proper language processing is the human brain. While we gather more and more data about the brain, its fundamental computational processes still remain obscure. The lack of a sound computational brain theory also prevents the fundamental understanding of Natural Language Processing. As always when science lacks a theoretical foundation, statistical modeling is applied to accommodate as many sampled real-world data as possible. An unsolved fundamental issue is the actual representation of language (data) within the brain, denoted as the Representational Problem. Starting with Jeff Hawkins' Hierarchical Temporal Memory (HTM) theory, a consistent computational theory of the human cortex, we have developed a corresponding theory of language data representation: The Semantic Folding Theory. The process of encoding words, by using a topographic semantic space as distributional reference frame into a sparse binary representational vector is called Semantic Folding and is the central topic of this document. Semantic Folding describes a method of converting language from its symbolic representation (text) into an explicit, semantically grounded representation that can be generically processed by Hawkins' HTM networks. As it turned out, this change in representation, by itself, can solve many complex NLP problems by applying Boolean operators and a generic similarity function like the Euclidian Distance. Many practical problems of statistical NLP systems, like the high cost of computation, the fundamental incongruity of precision and recall , the complex tuning procedures etc., can be elegantly overcome by applying Semantic Folding.|sl:arxiv_firstAuthor|Francisco De Sousa Webber
End-to-End Neural Entity Linking  We presented the first neural end-to-end entity linking  model and show the benefit of jointly optimizing  entity recognition and linking. Leveraging key  components, namely word, entity and mention embeddings,  we prove that engineered features can  be almost completely replaced by modern neural  networks. Entity Linking (EL) is an essential task for semantic text understanding and information extraction. Popular methods separately address the Mention Detection (MD) and Entity Disambiguation (ED) stages of EL, without leveraging their mutual dependency. We here propose the first neural end-to-end EL system that jointly discovers and links entities in a text document. The main idea is to consider all possible spans as potential mentions and learn contextual similarity scores over their entity candidates that are useful for both MD and ED decisions. Key components are context-aware mention embeddings, entity embeddings and a probabilistic mention - entity map, without demanding other engineered features. Empirically, we show that our end-to-end method significantly outperforms popular systems on the Gerbil platform when enough training data is available. Conversely, if testing datasets follow different annotation conventions compared to the training set (e.g. queries/ tweets vs news documents), our ED model coupled with a traditional NER system offers the best or second best EL accuracy.|sl:tag|tag:entity_linking
RDF and database|skos:broader|Web sémantique sw
Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.|sl:arxiv_author|Zhilin Yang
Kapuscinski|skos:broader|Pologne
Pour les nuls|skos:broader|Howto, tutorial, FAQ
Natural Language Processing with Small Feed-Forward Networks google guys:      We show that small and shallow feed- forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.   We show that small and shallow feed-forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.|sl:arxiv_author|Emily Pitler
schema.org|skos:broader|Web of data
Label-Embedding for Image Classification Attributes act as intermediate representations that enable parameter sharing between classes, a must when training data is scarce. We propose to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors. We introduce a function that measures the compatibility between an image and a label embedding. The parameters of this function are learned on a training set of labeled samples to ensure that, given an image, the correct classes rank higher than the incorrect ones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasets show that the proposed framework outperforms the standard Direct Attribute Prediction baseline in a zero-shot learning scenario. Label embedding enjoys a built-in ability to leverage alternative sources of information instead of or in addition to attributes, such as e.g. class hierarchies or textual descriptions. Moreover, label embedding encompasses the whole range of learning settings from zero-shot learning to regular learning with a large number of labeled examples.|sl:arxiv_author|Florent Perronnin
A Review of Relational Machine Learning for Knowledge Graphs Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be trained on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive datasets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Google's Knowledge Vault project as an example of such combination.|sl:arxiv_author|Evgeniy Gabrilovich
Windows|skos:broader|Microsoft
Layered Graph Embedding for Entity Recommendation using Wikipedia in the Yahoo! Knowledge Graph an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia In this paper, we describe an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia. Through offline and online evaluations, we show that the resulting embeddings and recommendations perform well in terms of quality and user engagement. Balancing simplicity and quality, this framework provides default entity recommendations for English and other languages in the Yahoo! Knowledge Graph, which Wikipedia is a core subset of.|sl:tag|tag:arxiv_doc
OpenAI GPT|skos:broader|OpenAI
Pillage du palais d'été|skos:broader|Guerres coloniales
Terrorisme islamiste|skos:broader|Terrorisme
Hypothèse de Riemann|skos:broader|Nombres premiers
Jean-Claude Ameisen|skos:broader|Darwin
Google: SEO|skos:broader|SEO
Technique of analyzing relationships between a set of documents and the terms they contain, by producing a set of concepts related to the documents and terms. LSA assumes that words that are close in meaning will occur in similar pieces of text.    LSI transforms documents from either bag-of-words or (preferrably) TfIdf-weighted space into a latent space of a lower dimensionality.    A matrix containing word counts (in lines) per paragraph (column) is constructed from a large piece of text. [Singular value decomposition (SVD)](singular_value_decomposition) is used to reduce the number of rows while preserving the similarity structure among columns. Similarities between words and/or docs can then be evaluated using cosine-distance in the low-dimensional space    - pros:      - alleviate the problem of synonymy (note: wikipedia se contredit en ce qui concerne la polysémie. Je dirais que LSI ne peut pas régler ce pb)      - can output topics in a ranked order.   - cons:      - requires a num_topics parameter.      - dimensions have no easily interpretable meaning in natural language      - SVD is computation intensive (still a pb with improved algos?)      - wikipedia says that the probabilistic model of LSA does not match observed data: LSA assumes that words and documents form a joint Gaussian model (ergodic hypothesis), while a Poisson distribution has been observed. Thus, a newer alternative is probabilistic latent semantic analysis, based on a multinomial model, which is reported to give better results than standard LSA    [Gensim tuto about transformations](https://markroxor.github.io/gensim/static/notebooks/Topics_and_Transformations.html) says that LSI training is unique in that it can continue at any point, simply by providing more training documents.    (LSI or LSA ? Truncated SVD applied to document similarity is called Latent Semantic Indexing (LSI), but it is called Latent Semantic Analysis (LSA) when applied to word similarity.)      4 ways of looking at the Truncated SVD ([cf.](http://www.jair.org/media/2934/live-2934-4846-jair.pdf)) :    - Latent meaning: the truncated SVD creates a low-dimensional linear mapping between words in row space and context in columns which captures the hidden (latent) meaning in the words and contexts    - Noise reduction: the truncated SVD can be seen as a smoothed version of the original matrix ( which captures the signal and leaves out the noise)    - A way to discover high-order co-occurrence: when 2 words appear in similar context    - Sparsity reduction: the origin matrix is sparse, but the truncated SVD is dense. Sparsity may be viewed as a problem of insufficient data and truncated SVD as a way of simulating the missing text    [See also Introduction to Information Retrieval Manning 2008](https://nlp.stanford.edu/IR-book/html/htmledition/latent-semantic-indexing-1.html)                                      |skos:broader|Methods for quantifying and categorizing semantic similarities between linguistic items based on their distributional properties in large samples of language data.    Basic idea: the Distributional hypothesis: linguistic items with similar distributions have similar meanings.    Basic approach: collect distributional information in high-dimensional vectors, and define similarity in terms of vector similarity    Models: latent semantic analysis (LSA), Hyperspace Analogue to Language (HAL), syntax- or dependency-based models, random indexing, semantic folding and various variants of the topic model.      
ML: conditioning|skos:broader|Machine learning: problems
GloVe|skos:broader|NLP@Stanford
Immigration|skos:broader|Grands problèmes
Folksonomies vs ontologies|skos:broader|Ontologies
Jena dev|skos:broader|Jena
Attention in Graphs|skos:broader|Graphs+Machine Learning
A Comparative Study of Word Embeddings for Reading Comprehension abstract:   The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on    1.  the use of pre-trained word embeddings, and  2. the representation of out-of-vocabulary tokens at test time,     can turn out to have a larger impact than architectural choices on the final performance         The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on (1) the use of pre-trained word embeddings, and (2) the representation of out-of-vocabulary tokens at test time, can turn out to have a larger impact than architectural choices on the final performance. We systematically explore several options for these choices, and provide recommendations to researchers working in this area.|sl:arxiv_firstAuthor|Bhuwan Dhingra
Semantic Enterprise Architecture|skos:broader|Semantic Enterprise
Universal Language Model Fine-tuning for Text Classification code is available in the fastai lib    [blog post](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html)    [see also](/doc/?uri=https%3A%2F%2Fyashuseth.blog%2F2018%2F06%2F17%2Funderstanding-universal-language-model-fine-tuning-ulmfit%2F)             Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.|sl:arxiv_firstAuthor|Jeremy Howard
Guillaume Genthial|skos:broader|NLP girls and guys
Tombe d'amphipolis|skos:broader|Découverte archéologique
Niger : agriculture|skos:broader|Niger
Andrew Ng|skos:broader|AI girls and guys
Knowledge Enhanced Contextual Word Representations General method to embed multiple knowledge bases into pre-trained language models (KB in the   sense as fixed collection of entity nodes)     The key idea is to explicitly model  entity spans in the input text and use an entity  linker to retrieve relevant entity embeddings from  a KB to form knowledge enhanced entity-span  representations.   Then,  update contextual word representations via a form of word-to-entity attention.    In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert's runtime is comparable to BERT's and it scales to large KBs.|sl:tag|tag:arxiv_doc
Pauli|skos:broader|Mécanique quantique
David Peterson|skos:broader|Australie
OAT|skos:broader|XMLHttpRequest
Mandelbrot|skos:broader|Mathématicien
Web 3.0|skos:broader|Semantic Web
Littérature africaine|skos:broader|Littérature
CJNN|skos:broader|Souvenirs
Pangloss: Fast Entity Linking in Noisy Text Environments a production system for entity disambiguation on messy tex, based  on probabilistic tokenization and context-dependent document embeddings    Probabilistic tokenization: uses the method described [here](/doc/2019/07/mining_quality_phrases_from_mas) Entity linking is the task of mapping potentially ambiguous terms in text to their constituent entities in a knowledge base like Wikipedia. This is useful for organizing content, extracting structured data from textual documents, and in machine learning relevance applications like semantic search, knowledge graph construction, and question answering. Traditionally, this work has focused on text that has been well-formed, like news articles, but in common real world datasets such as messaging, resumes, or short-form social media, non-grammatical, loosely-structured text adds a new dimension to this problem. This paper presents Pangloss, a production system for entity disambiguation on noisy text. Pangloss combines a probabilistic linear-time key phrase identification algorithm with a semantic similarity engine based on context-dependent document embeddings to achieve better than state-of-the-art results (5% in F1) compared to other research or commercially available systems. In addition, Pangloss leverages a local embedded database with a tiered architecture to house its statistics and metadata, which allows rapid disambiguation in streaming contexts and on-device disambiguation in low-memory environments such as mobile phones.|sl:tag|tag:loosely_formatted_text
Lucilie bouchère|skos:broader|Insecte
Zero-shot Entity Linking|skos:broader|Zero-Shot Learning
hyperdoc2vec: Distributed Representations of Hypertext Documents Hypertext documents, such as web pages and academic papers, are of great importance in delivering information in our daily life. Although being effective on plain documents, conventional text embedding methods suffer from information loss if directly adapted to hyper-documents. In this paper, we propose a general embedding approach for hyper-documents, namely, hyperdoc2vec, along with four criteria characterizing necessary information that hyper-document embedding models should preserve. Systematic comparisons are conducted between hyperdoc2vec and several competitors on two tasks, i.e., paper classification and citation recommendation, in the academic paper domain. Analyses and experiments both validate the superiority of hyperdoc2vec to other models w.r.t. the four criteria.|sl:arxiv_author|Wayne Xin Zhao
14 juillet|skos:broader|Fête nationale
OPML|skos:broader|Outliner
Mission \Voulet-Chanoine\|skos:broader|Histoire du Niger
On the Efficacy of Knowledge Distillation Evaluation of the efficacy  of knowledge distillation and its dependence on student  and teacher architectures. IEEE International Conference on Computer Vision (ICCV), 2019     Despite  widespread use, an understanding of when the student can  learn from the teacher is missing.     Our key finding  is that knowledge distillation is not a panacea and cannot  succeed when student capacity is too low to successfully  mimic the teacher. We have presented an approach  to mitigate this issue by stopping teacher training early In this paper, we present a thorough evaluation of the efficacy of knowledge distillation and its dependence on student and teacher architectures. Starting with the observation that more accurate teachers often don't make good teachers, we attempt to tease apart the factors that affect knowledge distillation performance. We find crucially that larger models do not often make better teachers. We show that this is a consequence of mismatched capacity, and that small students are unable to mimic large teachers. We find typical ways of circumventing this (such as performing a sequence of knowledge distillation steps) to be ineffective. Finally, we show that this effect can be mitigated by stopping the teacher's training early. Our results generalize across datasets and models.|sl:arxiv_author|Bharath Hariharan
Entities to topics|skos:broader|Knowledge Graphs
Machine Learning Course|skos:broader|Online Course Materials
NLP Groups|skos:broader|Natural Language Processing
Périclès|skos:broader|Athènes
Présidentielles 2007|skos:broader|Politique française
Amsterdam|skos:broader|Pays-Bas
A Hierarchical Multi-task Approach for Learning Embeddings from Semantic Tasks [Blog post](https://medium.com/dair-ai/hmtl-multi-task-learning-for-state-of-the-art-nlp-245572bbb601), [GitHub repo](https://github.com/huggingface/hmtl)   Much effort has been devoted to evaluate whether multi-task learning can be leveraged to learn rich representations that can be used in various Natural Language Processing (NLP) down-stream applications. However, there is still a lack of understanding of the settings in which multi-task learning has a significant effect. In this work, we introduce a hierarchical model trained in a multi-task learning setup on a set of carefully selected semantic tasks. The model is trained in a hierarchical fashion to introduce an inductive bias by supervising a set of low level tasks at the bottom layers of the model and more complex tasks at the top layers of the model. This model achieves state-of-the-art results on a number of tasks, namely Named Entity Recognition, Entity Mention Detection and Relation Extraction without hand-engineered features or external NLP tools like syntactic parsers. The hierarchical training supervision induces a set of shared semantic representations at lower layers of the model. We show that as we move from the bottom to the top layers of the model, the hidden states of the layers tend to represent more complex semantic information.|sl:tag|tag:sebastian_ruder
A La Carte Embedding|skos:broader|Word embeddings
Sören Auer|skos:broader|Technical girls and guys
Ontoprise|skos:broader|Semantic web company
Advances in Pre-Training Distributed Word Representations  we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks Many Natural Language Processing applications nowadays rely on pre-trained word representations estimated from large text corpora such as news collections, Wikipedia and Web Crawl. In this paper, we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks.|sl:tag|tag:word2vec
Sense embeddings|skos:broader|Embeddings in NLP
AI, robots and jobs|skos:broader|Robotisation
A suivre|skos:broader|Todo list
Retrofitting Word Vectors to Semantic Lexicons Method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed.     Graph-based learning technique for using lexical relational resources to obtain higher quality semantic vectors, which we call “retrofitting.” Retrofitting is applied as a post-processing step by running belief propagation on a graph constructed from lexicon-derived relational information to update word vectors. This allows retrofitting to be used on pre-trained word vectors obtained using any vector training model.    [github](https://github.com/mfaruqui/retrofitting)     Vector space word representations are learned from distributional information of words in large corpora. Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database. This paper proposes a method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed. Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, we obtain substantial improvements starting with a variety of word vector models. Our refinement method outperforms prior techniques for incorporating semantic lexicons into the word vector training algorithms.|sl:arxiv_author|Eduard Hovy
NLP: current state|skos:broader|NLP
LDP: implementations|skos:broader|Linked Data Platform
Entities as Experts: Sparse Memory Access with Entity Supervision   the problem of capturing declarative knowledge in the learned parameters of a language model...     Entities as Experts (EaE) can access distinct memories of the entities mentioned in a piece of text;     To understand the motivation for distinct and  independent entity representations: A traditional Transformer would need to build an internal representation  of Charles Darwin from the words “Charles”  and “Darwin”... Conversely, EAE can access  a dedicated representation of “Charles Darwin”,  which is a memory of all of the contexts in which  this entity has previously been mentioned.... Having retrieved  and re-integrated this memory it is much easier for  EAE to relate the question to the answer     EaE's entity representations are learned directly from text. Correct identification, and representation, of entities is essential to EaE's performance    Based on transformer architecture    Extension: [Facts as Experts](doc:2020/07/2007_00849_facts_as_experts_) We focus on the problem of capturing declarative knowledge in the learned parameters of a language model. We introduce a new model, Entities as Experts (EaE), that can access distinct memories of the entities mentioned in a piece of text. Unlike previous efforts to integrate entity knowledge into sequence models, EaE's entity representations are learned directly from text. These representations capture sufficient knowledge to answer TriviaQA questions such as Which Dr. Who villain has been played by Roger Delgado, Anthony Ainley, Eric Roberts?. EaE outperforms a Transformer model with $30\\times$ the parameters on this task. According to the Lama knowledge probes, EaE also contains more factual knowledge than a similar sized Bert. We show that associating parameters with specific entities means that EaE only needs to access a fraction of its parameters at inference time, and we show that the correct identification, and representation, of entities is essential to EaE's performance. We also argue that the discrete and independent entity representations in EaE make it more modular and interpretable than the Transformer architecture on which it is based.|sl:tag|tag:nlp_google
2eme guerre mondiale|skos:broader|Histoire
Bag of Tricks for Efficient Text Classification A simple and efficient baseline for text classification.     Our word features can  be averaged together to form good sentence representations.    Our experiments show that fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.   This paper explores a simple and efficient baseline for text classification. Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.|sl:tag|tag:nlp_facebook
fps AND LDOW2008|skos:broader|fps and WWW 2008
JavaScript librairies|skos:broader|Library (code)
Egypte antique|skos:broader|Archéologie africaine
GoodRelations|skos:broader|Ontologies
Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective reviews the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. Neural-symbolic computing has now become the subject of interest of both academic and industry research laboratories. Graph Neural Networks (GNN) have been widely used in relational and symbolic domains, with widespread application of GNNs in combinatorial optimization, constraint satisfaction, relational reasoning and other scientific domains. The need for improved explainability, interpretability and trust of AI systems in general demands principled methodologies, as suggested by neural-symbolic computing. In this paper, we review the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. This includes the application of GNNs in several domains as well as its relationship to current developments in neural-symbolic computing.|sl:tag|tag:graph_neural_networks
LinkNBed: Multi-Graph Representation Learning with Entity Linkage   a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure     We posit that combining  graph alignment task with deep representation  learning across multi-relational graphs has potential  to induce a synergistic effect on both tasks Knowledge graphs have emerged as an important model for studying complex multi-relational data. This has given rise to the construction of numerous large scale but incomplete knowledge graphs encoding information extracted from various resources. An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledge-based inference for many downstream applications. To this end, we propose LinkNBed, a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure. Experiments on link prediction and entity linkage demonstrate substantial improvements over the state-of-the-art relational learning approaches.|sl:tag|tag:kd_mkb_biblio
Spellchecker|skos:broader|NLP tasks / problems
Etat policier|skos:broader|Ca craint
GNU Octave|skos:broader|GNU
Spiking Neural Network|skos:broader|Neural networks
A Survey Of Cross-lingual Word Embedding Models Cross-lingual representations of words enable us to reason about word meaning in multilingual contexts and are a key facilitator of cross-lingual transfer when developing natural language processing models for low-resource languages. In this survey, we provide a comprehensive typology of cross-lingual word embedding models. We compare their data requirements and objective functions. The recurring theme of the survey is that many of the models presented in the literature optimize for the same objectives, and that seemingly different models are often equivalent modulo optimization strategies, hyper-parameters, and such. We also discuss the different ways cross-lingual word embeddings are evaluated, as well as future challenges and research horizons.|sl:arxiv_firstAuthor|Sebastian Ruder
Conjecture de Poincaré|skos:broader|Poincaré
Angela Merkel|skos:broader|Allemagne
Same architecture as autoencoder, but make strong assumptions concerning the distribution of latent variables. They use variational approach for latent representation learning (\Stochastic Gradient Variational Bayes\ (SGVB) training algorithm)|skos:broader|ANN used for unsupervised learning of efficient codings: learning a representation (encoding) for a set of data, typically for the purpose of dimensionality reduction.    an unsupervised neural network  which is trained to reconstruct a given input  from its latent representation (Bengio, 2009).    Unlike principal components analysis, the encoding and decoding steps are not limited to linear transformations (PCA learns an encoding linear transform, while auto-encoders learn an encoding program).  
Twine|skos:broader|Nova Spivak
Content negotiation|skos:broader|HTTP
Approximate nearest-neighbor|skos:broader|Nearest neighbor search
How do we do node embeddings? ([source](http://snap.stanford.edu/proj/embeddings-www/index.html#materials))    Intuition: Find embedding of nodes so that “similar” nodes in the graph have embeddings that are close together.    1. Define an encoder (i.e., a mapping from nodes to embeddings)  	- Shallow embedding (simplest encoding approach): encoder is just an embedding-lookup. Ex: [node2vec](/tag/node2vec), DeepWalk, LINE  2. Define a node similarity function, eg. nodes are similar if:   	- they are connected?  	- they share neighbours?  	- have structural similar roles?  	- ...   3. Optimize the parameters of the encoder so that similarity in the embedding space (e.g., dot product) approximates similarity in the original network    Defining similarity:    - Adjacency-based Similarity  - Multihop similarity (measure overlap between node neighborhoods)    these two methods are expensive.  - Random-walk Embeddings (Estimate probability of visiting node v on a random walk starting from node u using some random walk strategy, optimize embeddings to encode random walk statistics). Expressivity (incorporates both local and higher-order neighbourhood information) and efficiency (do not need to consider all pairs when training)    Which random walk strategy?    - fixed-length random walks starting from each node: DeepWalk (Perozzi et al., 2013)  - biased random walks that can trade off between local and global views of the network: Node2Vec (Micro-view / marco-view of neighbourhood)    No method wins in all the cases      |skos:broader|Traditionally, networks are usually represented as adjacency matrices. This suffers from data sparsity and high-dimensionality. Network embeddings aim to represent network  vertices into a low-dimensional vector space, by preserving  both network topology structure and node content information.    Algorithms are typically unsupervised  and can be broadly classified into  three groups ([source](/doc/2019/07/_1901_00596_a_comprehensive_su)):    - matrix factorization  - random walks   - deep learning approaches (graph neural networks - GNNs)  	- graph convolution networks (GraphSage)  	- graph attention networks,   	- graph auto-encoders (e.g., DNGR and SDNE)  	- graph generative networks,   	- graph spatial-temporal networks.    Node embeddings (intuition: similar nodes should have similar vectors).    - Laplacian EigenMap (an eigenvector based computation, OK when matrix is not too large)  - LINE Large-scale Information Network Embedding, most cited paper at WWW2015; Breadth first search  - DeepWalk (Perozzi et al. 2014) (the technique to learn word embeddings adapted to nodes: treating nodes as words and generating short random walks as sentences)  - Node2Vec (2016) (mixed strategy)    etc.  
Boulgakov|skos:broader|Ukraine
Hepp's PropertyValue|skos:broader|Product description
AI cloud service|skos:broader|Cloud
supervised learning models used for classification and regression analysis.    An SVM model is a representation of the training examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible.    Non-probabilistic binary linear classifier (some methods exist to use SVM in a probabilistic classification setting). Can be made non-linear with the kernel trick (implicitly mapping the inputs into high-dimensional feature spaces.)        |skos:broader|Class of algorithms for pattern analysis (eg. SVM). Kernel trick: transforming data into another dimension that has a clear dividing margin between classes of data, without computing the coordinates of the data in that space, but the inner products between the images of all pairs of data in the feature space (using a user-defined similarity function, the kernel function)    Kernel methods are powerful learning methodologies that provide a simple way to construct nonlinear algorithms from linear ones. Despite their popularity, they suffer from poor scalability in big data scenarios ([src](https://arxiv.org/abs/1706.06296)).    Kernel trick: Kernel functions enable to operate in a high-dimensional, implicit feature space without computing the coordinates of the data in that space, by simply computing the inner products between the images of all pairs of data in the feature space.    Algorithms capable of operating with kernels include SVM, Gaussian processes,PCA, spectral clustering... Any linear model can be turned into a non-linear model by applying the kernel trick to the model: replacing its features (predictors) by a kernel function.  
NLP@Facebook|skos:broader|Facebook
Belzoni|skos:broader|Explorateur
TensorFlow|skos:broader|Google Research
Javascript RDF Parser in IE|skos:broader|Tabulator
AI: books & journals|skos:broader|Livre
SL GUI|skos:broader|Semanlink
Archéologie du Niger|skos:broader|Archéologie africaine
Music of Africa|skos:broader|Afrique
Nigeria|skos:broader|Afrique de l'Ouest
DocBERT: BERT for Document Classification We present, to our knowledge, the first application of BERT to document classification. A few characteristics of the task might lead one to think that BERT is not the most appropriate model: syntactic structures matter less for content categories, documents can often be longer than typical BERT input, and documents often have multiple labels. Nevertheless, we show that a straightforward classification model using BERT is able to achieve the state of the art across four popular datasets. To address the computational expense associated with BERT inference, we distill knowledge from BERT-large to small bidirectional LSTMs, reaching BERT-base parity on multiple datasets using 30x fewer parameters. The primary contribution of our paper is improved baselines that can provide the foundation for future work.|sl:arxiv_author|Raphael Tang
Combining Statistics and Semantics|skos:broader|Statistics
de Broglie|skos:broader|Mécanique quantique
Large scale distributed neural network training through online distillation   we use codistillation to refer to distillation performed:   1. using the same architecture for all the models;   2. using the same dataset to train all the models; and   3. using the distillation loss during training before any model has fully converged.     In general, we believe the quality gains of codistillation over well-tuned offline distillation will be  minor in practice and the more interesting research direction is exploring codistillation as a distributed  training algorithm     Codistillation with  the same data seems to be slightly better than the baseline, but codistillation using different data  gets much better results. These results show that the codistilling models are indeed successfully  transmitting useful information about different parts of the training data to each other.    Related to [Deep mutual learning](doc:2020/05/1706_00384_deep_mutual_learni) paper Techniques such as ensembling and distillation promise model quality improvements when paired with almost any base model. However, due to increased test-time cost (for ensembles) and increased complexity of the training pipeline (for distillation), these techniques are challenging to use in industrial settings. In this paper we explore a variant of distillation which is relatively straightforward to use as it does not require a complicated multi-stage setup or many new hyperparameters. Our first claim is that online distillation enables us to use extra parallelism to fit very large datasets about twice as fast. Crucially, we can still speed up training even after we have already reached the point at which additional parallelism provides no benefit for synchronous or asynchronous stochastic gradient descent. Two neural networks trained on disjoint subsets of the data can share knowledge by encouraging each model to agree with the predictions the other model would have made. These predictions can come from a stale version of the other model so they can be safely computed using weights that only rarely get transmitted. Our second claim is that online distillation is a cost-effective way to make the exact predictions of a model dramatically more reproducible. We support our claims using experiments on the Criteo Display Ad Challenge dataset, ImageNet, and the largest to-date dataset used for neural language modeling, containing $6\\times 10^{11}$ tokens and based on the Common Crawl repository of web data.|sl:tag|tag:knowledge_distillation
SearchMonkey|skos:broader|Semantic Web : Application
Common Tag|skos:broader|Semanlink related
Deep latent variable models|skos:broader|Latent variable model
Horizontal gene transfer|skos:broader|Génétique et Évolution
Deep Patent Landscaping Model Using Transformer and Graph Embedding a transformer encoder  for analyzing textual data present in patent documents  and a graph convolutional network for analyzing  patent metadata.    A benchmarking dataset for patent landscaping  based on patent trends reports published by the  Korean Patent Office. Data acquisition using Google's BigQuery public datasets.    10% improvement comparing to Google’s proposed Automated Patent Landscaping.    Empirical analysis of the importance of features (text vs metadata, citations vs classification)     Patent landscaping is a method used for searching related patents during a research and development (R&D) project. To avoid the risk of patent infringement and to follow current trends in technology, patent landscaping is a crucial task required during the early stages of an R&D project. As the process of patent landscaping requires advanced resources and can be tedious, the demand for automated patent landscaping has been gradually increasing. However, a shortage of well-defined benchmark datasets and comparable models makes it difficult to find related research studies. In this paper, we propose an automated patent landscaping model based on deep learning. To analyze the text of patents, the proposed model uses a modified transformer structure. To analyze the metadata of patents, we propose a graph embedding method that uses a diffusion graph called Diff2Vec. Furthermore, we introduce four benchmark datasets for comparing related research studies in patent landscaping. The datasets are produced by querying Google BigQuery, based on a search formula from a Korean patent attorney. The obtained results indicate that the proposed model and datasets can attain state-of-the-art performance, as compared with current patent landscaping models.|sl:arxiv_author|Hyeonju Lee
Emerging Cross-lingual Structure in Pretrained Language Models We study the problem of multilingual masked language modeling, i.e. the training of a single model on concatenated text from multiple languages, and present a detailed study of several factors that influence why these models are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from independently trained models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these symmetries seem to be automatically discovered and aligned during the joint training process.|sl:tag|tag:arxiv_doc
Kindle|skos:broader|Amazon
Black hole|skos:broader|Gravity
Color naming|skos:broader|Language
High-frequency trading|skos:broader|Marchés financiers
Dynamic Semantic Publishing|skos:broader|Semantic Web Dev
Moussa Kaka|skos:broader|RFI
Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation   An embedding method specifically designed for NED that jointly maps words and entities into the same continuous vector space.    We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words Named Entity Disambiguation (NED) refers to the task of resolving multiple named entity mentions in a document to their correct references in a knowledge base (KB) (e.g., Wikipedia). In this paper, we propose a novel embedding method specifically designed for NED. The proposed method jointly maps words and entities into the same continuous vector space. We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words. By combining contexts based on the proposed embedding with standard NED features, we achieved state-of-the-art accuracy of 93.1% on the standard CoNLL dataset and 85.2% on the TAC 2010 dataset.|sl:arxiv_author|Yoshiyasu Takefuji
TDB|skos:broader|RDF database
ELMo|skos:broader|Pre-Trained Language Models
The Matrix Calculus You Need For Deep Learning Related blog post [The Math Behind Neural Networks](https://towardsdatascience.com/step-by-step-the-math-behind-neural-networks-490dc1f3cfd9) This paper is an attempt to explain all the matrix calculus you need in order to understand the training of deep neural networks. We assume no math knowledge beyond what you learned in calculus 1, and provide links to help you refresh the necessary math where needed. Note that you do not need to understand this material before you start learning to train and use deep learning in practice; rather, this material is for those who are already familiar with the basics of neural networks, and wish to deepen their understanding of the underlying math. Don't worry if you get stuck at some point along the way---just go back and reread the previous section, and try writing down and working through some examples. And if you're still stuck, we're happy to answer your questions in the Theory category at forums.fast.ai. Note: There is a reference section at the end of the paper summarizing all the key matrix calculus rules and terminology discussed here. See related articles at http://explained.ai|sl:arxiv_firstAuthor|Terence Parr
Fossile|skos:broader|Paléontologie
Train a model in an unsupervised way on a large amount of data, and then fine-tune it to achieve good performance on many different tasks|skos:broader|In machine learning, unsupervised learning refers to the problem of trying to find hidden structure in unlabeled data
Concept Bottleneck Models|skos:broader|Explainable AI
Socrate|skos:broader|Grèce antique
A Metric Learning Reality Check Deep metric learning papers from the past four years have consistently claimed great advances in accuracy, often more than doubling the performance of decade-old methods. In this paper, we take a closer look at the field to see if this is actually true. We find flaws in the experimental setup of these papers, and propose a new way to evaluate metric learning algorithms. Finally, we present experimental results that show that the improvements over time have been marginal at best.|sl:arxiv_firstAuthor|Kevin Musgrave
Garbage Collector|skos:broader|Programming language
Probabilistic relevance model|skos:broader|Similarity queries
BERT-of-Theseus: Compressing BERT by Progressive Module Replacing approach to compress BERT by progressive module replacing.     Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter    [Github](https://github.com/JetRunner/BERT-of-Theseus) In this paper, we propose a novel model compression approach to effectively compress BERT by progressive module replacing. Our approach first divides the original BERT into several modules and builds their compact substitutes. Then, we randomly replace the original modules with their substitutes to train the compact modules to mimic the behavior of the original modules. We progressively increase the probability of replacement through the training. In this way, our approach brings a deeper level of interaction between the original and compact models, and smooths the training process. Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter, liberating human effort from hyper-parameter tuning. Our approach outperforms existing knowledge distillation approaches on GLUE benchmark, showing a new perspective of model compression.|sl:arxiv_author|Furu Wei
Athlétisme|skos:broader|Sport
GBIF|skos:broader|Biodiversity data
Mission Villani sur l'IA|skos:broader|Cédric Villani
Arduino|skos:broader|Open Source
Tree embeddings|skos:broader|Embeddings
Immigration familiale|skos:broader|Immigration
Interactive Concept Mining on Personal Data -- Bootstrapping Semantic Services Semantic services (e.g. Semantic Desktops) are still afflicted by a cold start problem: in the beginning, the user's personal information sphere, i.e. files, mails, bookmarks, etc., is not represented by the system. Information extraction tools used to kick-start the system typically create 1:1 representations of the different information items. Higher level concepts, for example found in file names, mail subjects or in the content body of these items, are not extracted. Leaving these concepts out may lead to underperformance, having to many of them (e.g. by making every found term a concept) will clutter the arising knowledge graph with non-helpful relations. In this paper, we present an interactive concept mining approach proposing concept candidates gathered by exploiting given schemata of usual personal information management applications and analysing the personal information sphere using various metrics. To heed the subjective view of the user, a graphical user interface allows to easily rank and give feedback on proposed concept candidates, thus keeping only those actually considered relevant. A prototypical implementation demonstrates major steps of our approach.|sl:tag|tag:semanlink2_related
K-BERT: Enabling Language Representation with Knowledge Graph a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by equipped with a KG without pre-training by-self because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts.|sl:arxiv_author|Ping Wang
Semences paysanes|skos:broader|Semencier
DistilBERT|skos:broader|Knowledge distillation
WordPress|skos:broader|Blog software
Pre-training via Paraphrasing We introduce MARGE, a pre-trained sequence-to-sequence model learned with an unsupervised multi-lingual multi-document paraphrasing objective. MARGE provides an alternative to the dominant masked language modeling paradigm, where we self-supervise the reconstruction of target text by retrieving a set of related texts (in many languages) and conditioning on them to maximize the likelihood of generating the original. We show it is possible to jointly learn to do retrieval and reconstruction, given only a random initialization. The objective noisily captures aspects of paraphrase, translation, multi-document summarization, and information retrieval, allowing for strong zero-shot performance on several tasks. For example, with no additional task-specific training we achieve BLEU scores of up to 35.8 for document translation. We further show that fine-tuning gives strong performance on a range of discriminative and generative tasks in many languages, making MARGE the most generally applicable pre-training method to date.|sl:arxiv_author|Luke Zettlemoyer
Cambridge Analytica|skos:broader|Personal data
Zero-shot Entity Linking with Dense Entity Retrieval We consider the zero-shot entity-linking challenge where each entity is defined by a short textual description, and the model must read these descriptions together with the mention context to make the final linking decisions. In this setting, retrieving entity candidates can be particularly challenging, since many of the common linking cues such as entity alias tables and link popularity are not available. In this paper, we introduce a simple and effective two stage approach for zero-shot linking, based on fine-tuned BERT architectures. In the first stage, we do retrieval in a dense space defined by a bi-encoder that independently embeds the mention context and the entity descriptions. Each candidate is then examined more carefully with a cross-encoder, that concatenates the mention and entity text. Our approach achieves a nearly 5 point absolute gain on a recently introduced zero-shot entity linking benchmark, driven largely by improvements over previous IR-based candidate retrieval. We also show that it performs well in the non-zero-shot setting, obtaining the state-of-the-art result on TACKBP-2010.|sl:arxiv_author|Fabio Petroni
Meetup Web Sémantique|skos:broader|Meetup
SémanticPédia|skos:broader|dbpedia francophone
Autoencoder|skos:broader|Neural networks
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|George Dahl
Peer to peer|skos:broader|Internet Related Technologies
ML technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. Allows the optimization of an arbitrary differentiable loss function.  |skos:broader|ML ensemble meta-algorithm for primarily reducing bias, and also variance in supervised learning, and a family of machine learning algorithms that convert weak learners to strong ones.    
Emerging Cross-lingual Structure in Pretrained Language Models We study the problem of multilingual masked language modeling, i.e. the training of a single model on concatenated text from multiple languages, and present a detailed study of several factors that influence why these models are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from independently trained models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these symmetries seem to be automatically discovered and aligned during the joint training process.|sl:arxiv_author|Luke Zettlemoyer
Cocoon|skos:broader|XML
Pythagore|skos:broader|Géométrie
Industrie du disque|skos:broader|Content industries
Debug|skos:broader|Dev
Guéant|skos:broader|Gouvernement Sarkozy
Subword Semantic Hashing for Intent Classification on Small Datasets In this paper, we introduce the use of Semantic Hashing as embedding for the task of Intent Classification and achieve state-of-the-art performance on three frequently used benchmarks. Intent Classification on a small dataset is a challenging task for data-hungry state-of-the-art Deep Learning based systems. Semantic Hashing is an attempt to overcome such a challenge and learn robust text classification. Current word embedding based are dependent on vocabularies. One of the major drawbacks of such methods is out-of-vocabulary terms, especially when having small training datasets and using a wider vocabulary. This is the case in Intent Classification for chatbots, where typically small datasets are extracted from internet communication. Two problems arise by the use of internet communication. First, such datasets miss a lot of terms in the vocabulary to use word embeddings efficiently. Second, users frequently make spelling errors. Typically, the models for intent classification are not trained with spelling errors and it is difficult to think about ways in which users will make mistakes. Models depending on a word vocabulary will always face such issues. An ideal classifier should handle spelling errors inherently. With Semantic Hashing, we overcome these challenges and achieve state-of-the-art results on three datasets: AskUbuntu, Chatbot, and Web Application. Our benchmarks are available online: https://github.com/kumar-shridhar/Know-Your-Intent|sl:arxiv_author|Gustav Grund Pihlgren
New Africa|skos:broader|NTIC et développement
Pauli|skos:broader|Scientifique
Ian Horrocks|skos:broader|SW guys (and girls)
Differentiable Top-k Operator with Optimal Transport  if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator   ...   We apply the proposed operator to the [k-nearest neighbors](tag:k_nearest_neighbors_algorithm) and [beam search](tag:beam_search) algorithms, and demonstrate improved performance The top-k operation, i.e., finding the k largest or smallest elements from a collection of scores, is an important model component, which is widely used in information retrieval, machine learning, and data mining. However, if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator. Specifically, our SOFT top-k operator approximates the output of the top-k operation as the solution of an Entropic Optimal Transport (EOT) problem. The gradient of the SOFT operator can then be efficiently approximated based on the optimality conditions of EOT problem. We apply the proposed operator to the k-nearest neighbors and beam search algorithms, and demonstrate improved performance.|sl:tag|tag:top_k
Unsupervised keyword/keyphrase extraction algorithm. Creates a graph of the words and relationships between them from a document (using a sliding window), then identifies the most important vertices of the graph (words) based on importance scores calculated recursively from the entire graph.        |skos:broader|“the automatic  selection of important and topical phrases  from the body of a document” (Turney, 2000)
RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space  We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.|sl:tag|tag:kd_mkb_biblio
Interactive Concept Mining on Personal Data -- Bootstrapping Semantic Services Semantic services (e.g. Semantic Desktops) are still afflicted by a cold start problem: in the beginning, the user's personal information sphere, i.e. files, mails, bookmarks, etc., is not represented by the system. Information extraction tools used to kick-start the system typically create 1:1 representations of the different information items. Higher level concepts, for example found in file names, mail subjects or in the content body of these items, are not extracted. Leaving these concepts out may lead to underperformance, having to many of them (e.g. by making every found term a concept) will clutter the arising knowledge graph with non-helpful relations. In this paper, we present an interactive concept mining approach proposing concept candidates gathered by exploiting given schemata of usual personal information management applications and analysing the personal information sphere using various metrics. To heed the subjective view of the user, a graphical user interface allows to easily rank and give feedback on proposed concept candidates, thus keeping only those actually considered relevant. A prototypical implementation demonstrates major steps of our approach.|sl:arxiv_author|Christian Jilek
Thrace|skos:broader|Bulgarie
IGN|skos:broader|Géographie
Google|skos:broader|Internet
Abstractions in AI|skos:broader|Artificial general intelligence
Universal Language Model Fine-tuning for Text Classification code is available in the fastai lib    [blog post](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html)    [see also](/doc/?uri=https%3A%2F%2Fyashuseth.blog%2F2018%2F06%2F17%2Funderstanding-universal-language-model-fine-tuning-ulmfit%2F)             Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.|sl:tag|tag:jeremy_howard
Neural Memory|skos:broader|Memory in deep learning
Representing Sentences as Low-Rank Subspaces  We observe a simple geometry of sentences -- the word representations of a given sentence roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors.    A sentence of N words is a matrix (300, N) (if 300 is the dim of the word embeddings space). We take the eg. 4 (hyperparam) heaviest singular values - a subspace with dim 4    Similarity between docs: principal angle between the subspaces (reminiscent of cosine similarity)     Sentences are important semantic units of natural language. A generic, distributional representation of sentences that can capture the latent semantics is beneficial to multiple downstream applications. We observe a simple geometry of sentences -- the word representations of a given sentence (on average 10.23 words in all SemEval datasets with a standard deviation 4.84) roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors. Such an unsupervised representation is empirically validated via semantic textual similarity tasks on 19 different datasets, where it outperforms the sophisticated neural network models, including skip-thought vectors, by 15% on average.|sl:arxiv_firstAuthor|Jiaqi Mu
GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden unit), or embedding-free units such as image pixels.|sl:arxiv_author|Bhuwan Dhingra
Multiword Expressions|skos:broader|NLP tasks / problems
Layered Graph Embedding for Entity Recommendation using Wikipedia in the Yahoo! Knowledge Graph an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia In this paper, we describe an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia. Through offline and online evaluations, we show that the resulting embeddings and recommendations perform well in terms of quality and user engagement. Balancing simplicity and quality, this framework provides default entity recommendations for English and other languages in the Yahoo! Knowledge Graph, which Wikipedia is a core subset of.|sl:tag|tag:graph_embeddings
D2RQ|skos:broader|Chris Bizer
KGE KG embedding Knowledge graph embedding|skos:broader|Network embeddings Representation Learning on Networks Graph representation learning Network Representation Learning
Do Deep Nets Really Need to be Deep? Currently, deep neural networks are the state of the art on problems such as speech recognition and computer vision. In this extended abstract, we show that shallow feed-forward networks can learn the complex functions previously learned by deep nets and achieve accuracies previously only achievable with deep models. Moreover, in some cases the shallow neural nets can learn these deep functions using a total number of parameters similar to the original deep model. We evaluate our method on the TIMIT phoneme recognition task and are able to train shallow fully-connected nets that perform similarly to complex, well-engineered, deep convolutional architectures. Our success in training shallow neural nets to mimic deeper models suggests that there probably exist better algorithms for training shallow feed-forward nets than those currently available.|sl:tag|tag:deep_learning
Label-Embedding for Image Classification Attributes act as intermediate representations that enable parameter sharing between classes, a must when training data is scarce. We propose to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors. We introduce a function that measures the compatibility between an image and a label embedding. The parameters of this function are learned on a training set of labeled samples to ensure that, given an image, the correct classes rank higher than the incorrect ones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasets show that the proposed framework outperforms the standard Direct Attribute Prediction baseline in a zero-shot learning scenario. Label embedding enjoys a built-in ability to leverage alternative sources of information instead of or in addition to attributes, such as e.g. class hierarchies or textual descriptions. Moreover, label embedding encompasses the whole range of learning settings from zero-shot learning to regular learning with a large number of labeled examples.|sl:arxiv_firstAuthor|Zeynep Akata
Alexandria|skos:broader|Egypte
Large deviations for the perceptron model and consequences for active learning the task of choosing the subset of samples to be labeled from a fixed finite pool of samples Active learning is a branch of machine learning that deals with problems where unlabeled data is abundant yet obtaining labels is expensive. The learning algorithm has the possibility of querying a limited number of samples to obtain the corresponding labels, subsequently used for supervised learning. In this work, we consider the task of choosing the subset of samples to be labeled from a fixed finite pool of samples. We assume the pool of samples to be a random matrix and the ground truth labels to be generated by a single-layer teacher random neural network. We employ replica methods to analyze the large deviations for the accuracy achieved after supervised learning on a subset of the original pool. These large deviations then provide optimal achievable performance boundaries for any active learning algorithm. We show that the optimal learning performance can be efficiently approached by simple message-passing active learning algorithms. We also provide a comparison with the performance of some other popular active learning strategies.|sl:tag|tag:active_learning
Capitalistes|skos:broader|Capitalisme
Unsupervised keyword/keyphrase extraction algorithm. Creates a graph of the words and relationships between them from a document (using a sliding window), then identifies the most important vertices of the graph (words) based on importance scores calculated recursively from the entire graph.        |skos:broader|application of machine learning in the construction of ranking models. Training data consists of lists of items with some partial order specified between items in each list. 
Roam|skos:broader|Semanlink related
Chinafrique|skos:broader|Africa
The task of identifying target entities of the same domain|skos:broader|= named entity disambiguation: the task of resolving multiple named entity mentions in a document to their correct references in a knowledge base.
Google App Engine|skos:broader|Google
Chine-Europe|skos:broader|Chine
Amsterdam|skos:broader|Ville
Jermakoye|skos:broader|Jerma
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.|sl:arxiv_author|Zoubin Ghahramani
Type system|skos:broader|Programming language
Araméen|skos:broader|Langues
Multi-Task Deep Neural Networks for Natural Language Understanding outperforms BERT in nine of eleven benchmark NLP tasks In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations in order to adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7% (2.2% absolute improvement). We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. The code and pre-trained models are publicly available at https://github.com/namisan/mt-dnn.|sl:tag|tag:nlu
StarSpace: Embed All The Things! We present StarSpace, a general-purpose neural embedding model that can solve a wide variety of problems: labeling tasks such as text classification, ranking tasks such as information retrieval/web search, collaborative filtering-based or content-based recommendation, embedding of multi-relational graphs, and learning word, sentence or document level embeddings. In each case the model works by embedding those entities comprised of discrete features and comparing them against each other -- learning similarities dependent on the task. Empirical results on a number of tasks show that StarSpace is highly competitive with existing methods, whilst also being generally applicable to new cases where those methods are not.|sl:arxiv_author|Sumit Chopra
Global brain|skos:broader|Brain
APIs and Linked Data|skos:broader|Linked Data
Continent de plastique|skos:broader|Pollution des océans
Artificial Human Intelligence|skos:broader|Artificial Intelligence
ISP / Servlet Hosting|skos:broader|Servlet
The Consciousness Prior consciousness seen as the formation of a low-dimensional combination of a few concepts constituting a conscious thought, i.e., consciousness as awareness at a particular time instant: the projection of a big vector (all the things conscious and unconscious in brain). Attention: additional mechanism describing what mind chooses to focus on.    [YouTube video](/doc/?uri=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYr1mOzC93xs) A new prior is proposed for learning representations of high-level concepts of the kind we manipulate with language. This prior can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by cognitive neuroscience theories of consciousness, seen as a bottleneck through which just a few elements, after having been selected by attention from a broader pool, are then broadcast and condition further processing, both in perception and decision-making. The set of recently selected elements one becomes aware of is seen as forming a low-dimensional conscious state. This conscious state is combining the few concepts constituting a conscious thought, i.e., what one is immediately conscious of at a particular moment. We claim that this architectural and information-processing constraint corresponds to assumptions about the joint distribution between high-level concepts. To the extent that these assumptions are generally true (and the form of natural language seems consistent with them), they can form a useful prior for representation learning. A low-dimensional thought or conscious state is analogous to a sentence: it involves only a few variables and yet can make a statement with very high probability of being true. This is consistent with a joint distribution (over high-level concepts) which has the form of a sparse factor graph, i.e., where the dependencies captured by each factor of the factor graph involve only very few variables while creating a strong dip in the overall energy function. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in a form similar to facts and rules, albeit capturing uncertainty as well as efficient search mechanisms implemented by attention mechanisms.|sl:tag|tag:yoshua_bengio
Evaluation of sentence embeddings in downstream and linguistic probing tasks a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets     We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.           Despite the fast developmental pace of new sentence embedding methods, it is still challenging to find comprehensive evaluations of these different techniques. In the past years, we saw significant improvements in the field of sentence embeddings and especially towards the development of universal sentence encoders that could provide inductive transfer to a wide variety of downstream tasks. In this work, we perform a comprehensive evaluation of recent methods using a wide variety of downstream and linguistic feature probing tasks. We show that a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets. We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.|sl:tag|tag:elmo
PlaNet - Photo Geolocation with Convolutional Neural Networks Is it possible to build a system to determine the location where a photo was taken using just its pixels? In general, the problem seems exceptionally difficult: it is trivial to construct situations where no location can be inferred. Yet images often contain informative cues such as landmarks, weather patterns, vegetation, road markings, and architectural details, which in combination may allow one to determine an approximate location and occasionally an exact location. Websites such as GeoGuessr and View from your Window suggest that humans are relatively good at integrating these cues to geolocate images, especially en-masse. In computer vision, the photo geolocation problem is usually approached using image retrieval methods. In contrast, we pose the problem as one of classification by subdividing the surface of the earth into thousands of multi-scale geographic cells, and train a deep network using millions of geotagged images. While previous approaches only recognize landmarks or perform approximate matching using global image descriptors, our model is able to use and integrate multiple visible cues. We show that the resulting model, called PlaNet, outperforms previous approaches and even attains superhuman levels of accuracy in some cases. Moreover, we extend our model to photo albums by combining it with a long short-term memory (LSTM) architecture. By learning to exploit temporal coherence to geolocate uncertain photos, we demonstrate that this model achieves a 50% performance improvement over the single-image model.|sl:arxiv_author|James Philbin
Dev tools|skos:broader|Tools
Disco Hyperdata Browser|skos:broader|Linked Data
First Americans|skos:broader|Paléontologie humaine
Symmetric matrices related to the Mertens function In this paper we explore a family of congruences over N from which a sequence of symmetric matrices related to the Mertens function is built. From the results of numerical experiments we formulate a conjecture, about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may play a more important role in this classical and difficult problem.  In this paper we explore a family of congruences over $\\N^\\ast$ from which one builds a sequence of symmetric matrices related to the Mertens function. From the results of numerical experiments, we formulate a conjecture about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may come to play a more important role in this classical and difficult problem.|sl:arxiv_firstAuthor|Jean-Paul Cardinal
NLP+Automotive|skos:broader|NLP in enterprise
Kind of supervised learning, where labels can be generated automatically. Uses signals or domain knowledge, intrinsically correlated to the data, as automatic sources of supervision, thus removing the need for humans to label data.    Examples include [#autoencoders](/tag/autoencoder) and computation of [#word embeddings](/tag/word_embedding)       In self-supervised learning, the system learns to predict part of its input from other parts of it input. ([Lecun](https://www.facebook.com/722677142/posts/10155934004262143/))|skos:broader|Machine learning focuses on prediction, based on known properties learned from the training data. Data mining (which is the analysis step of Knowledge Discovery in Databases) focuses on the discovery of (previously) unknown properties on the data.    [Glossary (by google)](https://developers.google.com/machine-learning/glossary/)
Data mining|skos:broader|Data science
Carl Lewis|skos:broader|Athlétisme
Jeni Tennison|skos:broader|SW guys (and girls)
Bacterial to Animal Gene Transfer|skos:broader|Horizontal gene transfer
Rosetta Project|skos:broader|Langues
Daphne Koller|skos:broader|Education
Semantic Web Dev|skos:broader|Dev
RIF|skos:broader|Rules
Intervention française au Mali|skos:broader|France / Afrique
EventKG: A Multilingual Event-Centric Temporal Knowledge Graph 690 thousand contemporary and historical events and over 2.3 million temporal relations One of the key requirements to facilitate semantic analytics of information regarding contemporary and historical events on the Web, in the news and in social media is the availability of reference knowledge repositories containing comprehensive representations of events and temporal relations. Existing knowledge graphs, with popular examples including DBpedia, YAGO and Wikidata, focus mostly on entity-centric information and are insufficient in terms of their coverage and completeness with respect to events and temporal relations. EventKG presented in this paper is a multilingual event-centric temporal knowledge graph that addresses this gap. EventKG incorporates over 690 thousand contemporary and historical events and over 2.3 million temporal relations extracted from several large-scale knowledge graphs and semi-structured sources and makes them available through a canonical representation.|sl:tag|tag:arxiv_doc
A Brief Introduction to Machine Learning for Engineers This monograph aims at providing an introduction to key concepts, algorithms, and theoretical results in machine learning. The treatment concentrates on probabilistic models for supervised and unsupervised learning problems. It introduces fundamental concepts and algorithms by building on first principles, while also exposing the reader to more advanced topics with extensive pointers to the literature, within a unified notation and mathematical framework. The material is organized according to clearly defined categories, such as discriminative and generative models, frequentist and Bayesian approaches, exact and approximate inference, as well as directed and undirected models. This monograph is meant as an entry point for researchers with a background in probability and linear algebra.|sl:tag|tag:arxiv_doc
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:arxiv_firstAuthor|Thomas Dean
ELMo|skos:broader|Word embeddings
Patent Landscaping|skos:broader|Patent
Lenka Zdeborová|skos:broader|Physicien
ERNIE: Enhanced Language Representation with Informative Entities  We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.|sl:arxiv_author|Zhengyan Zhang
EMNLP 2018|skos:broader|J'y étais
Boulgakov|skos:broader|Littérature russe
Probing Neural Network Comprehension of Natural Language Arguments what has BERT learned about argument comprehension?    [Comments](/doc/2019/07/bert_s_success_in_some_benchmar) We are surprised to find that BERT's peak performance of 77% on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.|sl:arxiv_author|Timothy Niven
Word2Bits - Quantized Word Vectors We show that high quality quantized word vectors using 1-2 bits per parameter can be learned by introducing a quantization function into Word2Vec. We furthermore show that training with the quantization function acts as a regularizer Word vectors require significant amounts of memory and storage, posing issues to resource limited devices like mobile phones and GPUs. We show that high quality quantized word vectors using 1-2 bits per parameter can be learned by introducing a quantization function into Word2Vec. We furthermore show that training with the quantization function acts as a regularizer. We train word vectors on English Wikipedia (2017) and evaluate them on standard word similarity and analogy tasks and on question answering (SQuAD). Our quantized word vectors not only take 8-16x less space than full precision (32 bit) word vectors but also outperform them on word similarity tasks and question answering.|sl:tag|tag:word2vec
Entity discovery and linking|skos:broader|NLP tasks / problems
Cassini|skos:broader|Missions spatiales
Pékin|skos:broader|Chine
Deep Unsupervised Learning|skos:broader|Deep Learning
BNF|skos:broader|Bibliothèque
AI@Google|skos:broader|Google
Semantic Desktop|skos:broader|Semantic Web
Niger : pétrole|skos:broader|Pétrole
Vénus préhistoriques|skos:broader|Sculpture
Deep Learning|skos:broader|Machine learning: techniques
Bush|skos:broader|USA
Explainable Deep Learning: A Field Guide for the Uninitiated Deep neural network (DNN) is an indispensable machine learning tool for achieving human-level performance on many learning tasks. Yet, due to its black-box nature, it is inherently difficult to understand which aspects of the input data drive the decisions of the network. There are various real-world scenarios in which humans need to make actionable decisions based on the output DNNs. Such decision support systems can be found in critical domains, such as legislation, law enforcement, etc. It is important that the humans making high-level decisions can be sure that the DNN decisions are driven by combinations of data features that are appropriate in the context of the deployment of the decision support system and that the decisions made are legally or ethically defensible. Due to the incredible pace at which DNN technology is being developed, the development of new methods and studies on explaining the decision-making process of DNNs has blossomed into an active research field. A practitioner beginning to study explainable deep learning may be intimidated by the plethora of orthogonal directions the field is taking. This complexity is further exacerbated by the general confusion that exists in defining what it means to be able to explain the actions of a deep learning system and to evaluate a system's ability to explain. To alleviate this problem, this article offers a field guide to deep learning explainability for those uninitiated in the field. The field guide: i) Discusses the traits of a deep learning system that researchers enhance in explainability research, ii) places explainability in the context of other related deep learning research areas, and iii) introduces three simple dimensions defining the space of foundational methods that contribute to explainable deep learning. The guide is designed as an easy-to-digest starting point for those just embarking in the field.|sl:tag|tag:arxiv_doc
Neural coding|skos:broader|Computational Neuroscience
Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus.     In practice, some questions are best answered  using text, while others are best answered using  KBs. A natural question, then, is how to effectively  combine both types of information. Surprisingly  little prior work has looked at this problem. Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting. Source code is available at https://github.com/OceanskySun/GraftNet .|sl:arxiv_firstAuthor|Haitian Sun
Siri|skos:broader|Speech-to-Text
Çatalhöyük|skos:broader|Néolithique
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:arxiv_author|Rahul Kuchhal
Configuration and SW|skos:broader|Semantic Web
Film indien|skos:broader|Inde
Orange (data mining)|skos:broader|Python 4 Data science
Parlement européen|skos:broader|Union européenne
RDF Thrift|skos:broader|RDF/binary
Freie Universität Berlin|skos:broader|Berlin
Système solaire|skos:broader|Astronomie
Triple Pattern Fragment|skos:broader|Linked Data Fragments
Nok|skos:broader|Art d'Afrique
John Sofakolle|skos:broader|Musicien
User Driven Modelling|skos:broader|Informatique
semblog|skos:broader|Jena
Javascript RDF Parser in IE|skos:broader|Compatibilité Javascript
AI Conference|skos:broader|Conférences
Structured Knowledge Distillation for Dense Prediction In this paper, we consider transferring the structure information from large networks to small ones for dense prediction tasks. Previous knowledge distillation strategies used for dense prediction tasks often directly borrow the distillation scheme for image classification and perform knowledge distillation for each pixel separately, leading to sub-optimal performance. Here we propose to distill structured knowledge from large networks to small networks, taking into account the fact that dense prediction is a structured prediction problem. Specifically, we study two structured distillation schemes: i)pair-wise distillation that distills the pairwise similarities by building a static graph, and ii)holistic distillation that uses adversarial training to distill holistic knowledge. The effectiveness of our knowledge distillation approaches is demonstrated by extensive experiments on three dense prediction tasks: semantic segmentation, depth estimation, and object detection.|sl:tag|tag:pixelwise_dense_prediction
RDFizers|skos:broader|RDF
SW guys (and girls)|skos:broader|Technical girls and guys
Pangloss: Fast Entity Linking in Noisy Text Environments a production system for entity disambiguation on messy tex, based  on probabilistic tokenization and context-dependent document embeddings    Probabilistic tokenization: uses the method described [here](/doc/2019/07/mining_quality_phrases_from_mas) Entity linking is the task of mapping potentially ambiguous terms in text to their constituent entities in a knowledge base like Wikipedia. This is useful for organizing content, extracting structured data from textual documents, and in machine learning relevance applications like semantic search, knowledge graph construction, and question answering. Traditionally, this work has focused on text that has been well-formed, like news articles, but in common real world datasets such as messaging, resumes, or short-form social media, non-grammatical, loosely-structured text adds a new dimension to this problem. This paper presents Pangloss, a production system for entity disambiguation on noisy text. Pangloss combines a probabilistic linear-time key phrase identification algorithm with a semantic similarity engine based on context-dependent document embeddings to achieve better than state-of-the-art results (5% in F1) compared to other research or commercially available systems. In addition, Pangloss leverages a local embedded database with a tiered architecture to house its statistics and metadata, which allows rapid disambiguation in streaming contexts and on-device disambiguation in low-memory environments such as mobile phones.|sl:arxiv_author|Pete Skomoroch
esa|skos:broader|Exploration spatiale
ML: Sequential data|skos:broader|Machine learning: problems
Hubble|skos:broader|Télescope
Prix Nobel d'économie|skos:broader|Economie
NLP@Stanford|skos:broader|NLP Teams
RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space  We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.|sl:tag|tag:rotate
Crise des banlieues|skos:broader|Banlieue
NLP|skos:broader|Language
Lula|skos:broader|Brésil
HBase|skos:broader|apache.org
Reproducible Research|skos:broader|Recherche
Graph-based Semi-Supervised Learning|skos:broader|Graphs+Machine Learning
Zouk|skos:broader|Musique
Miriam Makeba|skos:broader|Afrique du Sud
Attention is All You Need Transformer Transformers|skos:broader|Sequence Modeling Seq2Seq
Ben Adida|skos:broader|Technical girls and guys
Unsupervised machine learning|skos:broader|Machine learning
Pékin 2008|skos:broader|Jeux Olympiques
Histoire de l'Europe|skos:broader|Europe
Open Domain Question Answering|skos:broader|Question Answering
Yago|skos:broader|Semantic Web : Application
Consciousness Prior|skos:broader|Human Level AI
Stacked Approximated Regression Machine: A Simple Deep Learning Approach This paper seems too good to be true! They can train a VGG-like net VERY quickly to good accuracy, without backprop. With the agreement of my coauthors, I Zhangyang Wang would like to withdraw the manuscript Stacked Approximated Regression Machine: A Simple Deep Learning Approach. Some experimental procedures were not included in the manuscript, which makes a part of important claims not meaningful. In the relevant research, I was solely responsible for carrying out the experiments; the other coauthors joined in the discussions leading to the main algorithm. Please see the updated text for more details.|sl:arxiv_author|Thomas S. Huang
Recurrent Memory Networks for Language Modeling  Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge.     In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data.     We demonstrate the power of RMN on language modeling and sentence completion tasks.     On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.   Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge. In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data. We demonstrate the power of RMN on language modeling and sentence completion tasks. On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.|sl:tag|tag:arxiv_doc
Semanlink todo|skos:broader|Semanlink dev
Beyond Vector Spaces: Compact Data Representation as Differentiable Weighted Graphs  In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE (Probabilistic Differentiable Graph Embeddings): a method that learns a weighted graph representation of data end-to-end by gradient descent.    [Github](https://github.com/stanis-morozov/prodige)     Learning useful representations is a key ingredient to the success of modern machine learning. Currently, representation learning mostly relies on embedding data into Euclidean space. However, recent work has shown that data in some domains is better modeled by non-euclidean metric spaces, and inappropriate geometry can result in inferior performance. In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE: a method that learns a weighted graph representation of data end-to-end by gradient descent. Greater generality and fewer model assumptions make PRODIGE more powerful than existing embedding-based approaches. We confirm the superiority of our method via extensive experiments on a wide range of tasks, including classification, compression, and collaborative filtering.|sl:arxiv_author|Stanislav Morozov
SGNN|skos:broader|On device NLP
Concept Bottleneck Models  We seek to learn models that we can interact with using high-level concepts... We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these concept bottleneck models by editing their predicted concept values and propagating these changes to the final prediction... These models allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time. We seek to learn models that we can interact with using high-level concepts: if the model did not think there was a bone spur in the x-ray, would it still predict severe arthritis? State-of-the-art models today do not typically support the manipulation of concepts like the existence of bone spurs, as they are trained end-to-end to go directly from raw input (e.g., pixels) to output (e.g., arthritis severity). We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these \\emph{concept bottleneck models} by editing their predicted concept values and propagating these changes to the final prediction. On x-ray grading and bird identification, concept bottleneck models achieve competitive accuracy with standard end-to-end models, while enabling interpretation in terms of high-level clinical concepts (bone spurs) or bird attributes (wing color). These models also allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time.|sl:arxiv_author|Stephen Mussmann
Multilingual embeddings|skos:broader|Embeddings
C2GWeb, Product description and Makolab|skos:broader|C2GWeb and Product description
Automotive Ontology Community Group|skos:broader|Automotive AND W3C
La France vue de l'étranger|skos:broader|France
Generalization through Memorization: Nearest Neighbor Language Models extend LMs with nearest neighbor search in embedding space We introduce $k$NN-LMs, which extend a pre-trained neural language model (LM) by linearly interpolating it with a $k$-nearest neighbors ($k$NN) model. The nearest neighbors are computed according to distance in the pre-trained LM embedding space, and can be drawn from any text collection, including the original LM training data. Applying this augmentation to a strong Wikitext-103 LM, with neighbors drawn from the original training set, our $k$NN-LM achieves a new state-of-the-art perplexity of 15.79 - a 2.9 point improvement with no additional training. We also show that this approach has implications for efficiently scaling up to larger training sets and allows for effective domain adaptation, by simply varying the nearest neighbor datastore, again without further training. Qualitatively, the model is particularly helpful in predicting rare patterns, such as factual knowledge. Together, these results strongly suggest that learning similarity between sequences of text is easier than predicting the next word, and that nearest neighbor search is an effective approach for language modeling in the long tail.|sl:arxiv_author|Omer Levy
QuickTime|skos:broader|Apple
Solr|skos:broader|Text Search
Smart energy grids|skos:broader|Economies d'énergie
BAM! Born-Again Multi-Task Networks for Natural Language Understanding  knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers It can be challenging to train multi-task neural networks that outperform or even match their single-task counterparts. To help address this, we propose using knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers. We evaluate our approach by multi-task fine-tuning BERT on the GLUE benchmark. Our method consistently improves over standard single-task and multi-task training.|sl:arxiv_author|Quoc V. Le
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:tag|tag:global_workspace_theory
Learning Deep Latent Spaces for Multi-Label Classification Uses [Deep Canonical Correlation Analysis](/tag/deep_canonical_correlation_analysis) and autoencoder structures to learn a latent subspace from both feature and label domains for multi-label classification.    (several implementations on github)       Multi-label classification is a practical yet challenging task in machine learning related fields, since it requires the prediction of more than one label category for each input instance. We propose a novel deep neural networks (DNN) based model, Canonical Correlated AutoEncoder (C2AE), for solving this task. Aiming at better relating feature and label domain data for improved classification, we uniquely perform joint feature and label embedding by deriving a deep latent space, followed by the introduction of label-correlation sensitive loss function for recovering the predicted label outputs. Our C2AE is achieved by integrating the DNN architectures of canonical correlation analysis and autoencoder, which allows end-to-end learning and prediction with the ability to exploit label dependency. Moreover, our C2AE can be easily extended to address the learning problem with missing labels. Our experiments on multiple datasets with different scales confirm the effectiveness and robustness of our proposed method, which is shown to perform favorably against state-of-the-art methods for multi-label classification.|sl:tag|tag:arxiv_doc
On the Efficacy of Knowledge Distillation Evaluation of the efficacy  of knowledge distillation and its dependence on student  and teacher architectures. IEEE International Conference on Computer Vision (ICCV), 2019     Despite  widespread use, an understanding of when the student can  learn from the teacher is missing.     Our key finding  is that knowledge distillation is not a panacea and cannot  succeed when student capacity is too low to successfully  mimic the teacher. We have presented an approach  to mitigate this issue by stopping teacher training early In this paper, we present a thorough evaluation of the efficacy of knowledge distillation and its dependence on student and teacher architectures. Starting with the observation that more accurate teachers often don't make good teachers, we attempt to tease apart the factors that affect knowledge distillation performance. We find crucially that larger models do not often make better teachers. We show that this is a consequence of mismatched capacity, and that small students are unable to mimic large teachers. We find typical ways of circumventing this (such as performing a sequence of knowledge distillation steps) to be ineffective. Finally, we show that this effect can be mitigated by stopping the teacher's training early. Our results generalize across datasets and models.|sl:tag|tag:arxiv_doc
Language Models as Knowledge Bases? an analysis of the relational knowledge present in pretrained language models shows an ability of these models to recall factual knowledge  Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as fill-in-the-blank cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.|sl:arxiv_author|Sebastian Riedel
Macintosh|skos:broader|Apple
js|skos:broader|Web app dev
Graph Convolution for Multimodal Information Extraction from Visually Rich Documents Visually rich documents (VRDs) are ubiquitous in daily business and life. Examples are purchase receipts, insurance policy documents, custom declaration forms and so on. In VRDs, visual and layout information is critical for document understanding, and texts in such documents cannot be serialized into the one-dimensional sequence without losing information. Classic information extraction models such as BiLSTM-CRF typically operate on text sequences and do not incorporate visual features. In this paper, we introduce a graph convolution based model to combine textual and visual information presented in VRDs. Graph embeddings are trained to summarize the context of a text segment in the document, and further combined with text embeddings for entity extraction. Extensive experiments have been conducted to show that our method outperforms BiLSTM-CRF baselines by significant margins, on two real-world datasets. Additionally, ablation studies are also performed to evaluate the effectiveness of each component of our model.|sl:arxiv_author|Feiyu Gao
Climate crisis|skos:broader|Changement climatique
WS- vs. POX/HTTP|skos:broader|Web Services
Insecte|skos:broader|Animal
J'ai un petit problème avec mon ordinateur|skos:broader|J'ai un petit problème
InceptionTime: Finding AlexNet for Time Series Classification Time series classification (TSC) is the area of machine learning interested in learning how to assign labels to time series. The last few decades of work in this area have led to significant progress in the accuracy of classifiers, with the state of the art now represented by the HIVE-COTE algorithm. While extremely accurate, HIVE-COTE is infeasible to use in many applications because of its very high training time complexity in O(N^2T^4) for a dataset with N time series of length T. For example, it takes HIVE-COTE more than 72,000s to learn from a small dataset with N=700 time series of short length T=46. Deep learning, on the other hand, has now received enormous attention because of its high scalability and state-of-the-art accuracy in computer vision and natural language processing tasks. Deep learning for TSC has only very recently started to be explored, with the first few architectures developed over the last 3 years only. The accuracy of deep learning for TSC has been raised to a competitive level, but has not quite reached the level of HIVE-COTE. This is what this paper achieves: outperforming HIVE-COTE's accuracy together with scalability. We take an important step towards finding the AlexNet network for TSC by presenting InceptionTime---an ensemble of deep Convolutional Neural Network (CNN) models, inspired by the Inception-v4 architecture. Our experiments show that InceptionTime slightly outperforms HIVE-COTE with a win/draw/loss on the UCR archive of 40/6/39. Not only is InceptionTime more accurate, but it is much faster: InceptionTime learns from that same dataset with 700 time series in 2,300s but can also learn from a dataset with 8M time series in 13 hours, a quantity of data that is fully out of reach of HIVE-COTE.|sl:arxiv_firstAuthor|Hassan Ismail Fawaz
Neural Architectures for Named Entity Recognition Neural architectures for NER that use no language-specific resources or features beyond a small amount of supervised training data and unlabeled corpora.      Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.|sl:tag|tag:arxiv_doc
Variational Inference: A Review for Statisticians One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.|sl:arxiv_author|Alp Kucukelbir
Politique française|skos:broader|France
Multitask Learning in NLP|skos:broader|Multi-task learning
W3C Data Activity|skos:broader|W3C
Representation Learning with Contrastive Predictive Coding  a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful [autoregressive models](/tag/autoregressive_model). We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using [negative sampling](/tag/negative_sampling).    a contrastive method that can be applied to any form of data that can be expressed in an ordered sequence: text, speech, video... While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.|sl:arxiv_author|Yazhe Li
Henri Bergius|skos:broader|SW guys (and girls)
Olivier Grisel|skos:broader|AI girls and guys
Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.|sl:arxiv_author|Son N. Tran
Singe|skos:broader|Primate
La main à la pâte|skos:broader|Science
Google Web Toolkit|skos:broader|Dev
BERT Rediscovers the Classical NLP Pipeline  We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.   Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.|sl:arxiv_author|Ellie Pavlick
Hydra|skos:broader|HATEOAS
Girafe|skos:broader|Animal
(LOV) Linked Open Vocabularies|skos:broader|Linked Data
Traversing Knowledge Graphs in Vector Space Knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new \compositional\ training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. Path queries on a knowledge graph can be used to answer compositional questions such as What languages are spoken by people living in Lisbon?. However, knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new compositional training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. On a standard knowledge base completion task, we also demonstrate that compositional training acts as a novel form of structural regularization, reliably improving performance across all base models (reducing errors by up to 43%) and achieving new state-of-the-art results.|sl:tag|tag:embeddings
Euro Crisis|skos:broader|Euro
evilstreak/markdown-js|skos:broader|Markown / Javascript
classification decision based on the value of a linear combination of the feature values  |skos:broader|the machine learning task of inferring a function from labeled training data.
Franco-Allemand|skos:broader|France
COO|skos:broader|Car ontology
Jena : Introduction|skos:broader|Introduction
Archéologie du Niger|skos:broader|Niger
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:tag|tag:yoshua_bengio
Banque mondiale|skos:broader|Institutions internationales
Fado tropical|skos:broader|Portugal
Howto|skos:broader|Howto, tutorial, FAQ
FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence [github](https://github.com/google-research/fixmatch)     we demonstrate the power of a  simple combination of two common Semi-Supervised Learning methods: consistency  regularization and pseudo-labeling.    1. First generates pseudo-labels using the model’s  predictions on weakly-augmented unlabeled images. For a  given image, the pseudo-label is only retained if the model  produces a high-confidence prediction.   2. The model is then  trained to predict the pseudo-label when fed a strongly augmented  version of the same image. Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. In this paper, we demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling. Our algorithm, FixMatch, first generates pseudo-labels using the model's predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just 4 labels per class. Since FixMatch bears many similarities to existing SSL methods that achieve worse performance, we carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. We make our code available at https://github.com/google-research/fixmatch.|sl:arxiv_author|Kihyuk Sohn
Learning Deep Latent Spaces for Multi-Label Classification Uses [Deep Canonical Correlation Analysis](/tag/deep_canonical_correlation_analysis) and autoencoder structures to learn a latent subspace from both feature and label domains for multi-label classification.    (several implementations on github)       Multi-label classification is a practical yet challenging task in machine learning related fields, since it requires the prediction of more than one label category for each input instance. We propose a novel deep neural networks (DNN) based model, Canonical Correlated AutoEncoder (C2AE), for solving this task. Aiming at better relating feature and label domain data for improved classification, we uniquely perform joint feature and label embedding by deriving a deep latent space, followed by the introduction of label-correlation sensitive loss function for recovering the predicted label outputs. Our C2AE is achieved by integrating the DNN architectures of canonical correlation analysis and autoencoder, which allows end-to-end learning and prediction with the ability to exploit label dependency. Moreover, our C2AE can be easily extended to address the learning problem with missing labels. Our experiments on multiple datasets with different scales confirm the effectiveness and robustness of our proposed method, which is shown to perform favorably against state-of-the-art methods for multi-label classification.|sl:arxiv_author|Wei-Jen Ko
Rijksmuseum|skos:broader|Amsterdam
A Survey Of Cross-lingual Word Embedding Models Cross-lingual representations of words enable us to reason about word meaning in multilingual contexts and are a key facilitator of cross-lingual transfer when developing natural language processing models for low-resource languages. In this survey, we provide a comprehensive typology of cross-lingual word embedding models. We compare their data requirements and objective functions. The recurring theme of the survey is that many of the models presented in the literature optimize for the same objectives, and that seemingly different models are often equivalent modulo optimization strategies, hyper-parameters, and such. We also discuss the different ways cross-lingual word embeddings are evaluated, as well as future challenges and research horizons.|sl:tag|tag:sebastian_ruder
NLP datasets|skos:broader|NLP
A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efficient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximally preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We first introduce the formal definition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work address these challenges in their solutions. Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efficiency, problem settings, techniques and application scenarios.|sl:arxiv_author|Vincent W. Zheng
Diffa|skos:broader|Niger
Tasmanie|skos:broader|Australie
Parameter-free Sentence Embedding via Orthogonal Basis training-free approach for building sentence representations, Geometric Embedding (GEM), based on the geometric structure of word embedding space.     we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word’s novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace    [on www.groundai.com](https://www.groundai.com/project/zero-training-sentence-embedding-via-orthogonal-basis/)    [Open Revieww](/doc/?uri=https%3A%2F%2Fopenreview.net%2Fforum%3Fid%3DrJedbn0ctQ) ; [Related to this paper](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1704.05358)       We propose a simple and robust non-parameterized approach for building sentence representations. Inspired by the Gram-Schmidt Process in geometric theory, we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word's novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace. Following this motivation, we develop an innovative method based on orthogonal basis to combine pre-trained word embeddings into sentence representations. This approach requires zero parameters, along with efficient inference performance. We evaluate our approach on 11 downstream NLP tasks. Our model shows superior performance compared with non-parameterized alternatives and it is competitive to other approaches relying on either large amounts of labelled data or prolonged training time.|sl:tag|tag:good
Selective Question Answering under Domain Shift How you can get a QA model to abstain from answering when it doesn’t know the answer.     Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. To avoid giving wrong answers, question answering (QA) models need to know when to abstain from answering. Moreover, users often ask questions that diverge from the model's training data, making errors more likely and thus abstention more critical. In this work, we propose the setting of selective question answering under domain shift, in which a QA model is tested on a mixture of in-domain and out-of-domain data, and must answer (i.e., not abstain on) as many questions as possible while maintaining high accuracy. Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. Crucially, the calibrator benefits from observing the model's behavior on out-of-domain data, even if from a different domain than the test data. We combine this method with a SQuAD-trained QA model and evaluate on mixtures of SQuAD and five other QA datasets. Our method answers 56% of questions while maintaining 80% accuracy; in contrast, directly using the model's probabilities only answers 48% at 80% accuracy.|sl:tag|tag:arxiv_doc
Yves Raymond|skos:broader|SW guys (and girls)
IPython|skos:broader|Python
A Little Annotation does a Lot of Good: A Study in Bootstrapping Low-resource Named Entity Recognizers Most state-of-the-art models for named entity recognition (NER) rely on the availability of large amounts of labeled data, making them challenging to extend to new, lower-resourced languages. However, there are now several proposed approaches involving either cross-lingual transfer learning, which learns from other highly resourced languages, or active learning, which efficiently selects effective training data based on model predictions. This paper poses the question: given this recent progress, and limited human annotation, what is the most effective method for efficiently creating high-quality entity recognizers in under-resourced languages? Based on extensive experimentation using both simulated and real human annotation, we find a dual-strategy approach best, starting with a cross-lingual transferred model, then performing targeted annotation of only uncertain entity spans in the target language, minimizing annotator effort. Results demonstrate that cross-lingual transfer is a powerful tool when very little data can be annotated, but an entity-targeted annotation strategy can achieve competitive accuracy quickly, with just one-tenth of training data.|sl:arxiv_author|Jaime G. Carbonell
DistilBERT|skos:broader|BERT
Named Entity Disambiguation using Deep Learning on Graphs Evaluation of different deep learning techniques to create  a context vector from graphs, aimed at high-accuracy NED. (neural  approach for entity disambiguation using graphs as background  knowledge)     We tackle Named Entity Disambiguation (NED) by comparing entities  in short sentences with Wikidata graphs. Creating a context vector  from graphs through deep learning is a challenging problem that has  never been applied to NED. Our main contribution is to present an  experimental study of recent neural techniques, as well as a discussion  about which graph features are most important for the disambiguation  task...    [published paper](https://rd.springer.com/chapter/10.1007/978-3-030-15719-7_10)      In NED, the system  must be able to generate a context for an entity in a text and an entity  in a knowledge base, then correctly link the two.    Explore whether representing graphs  as triplets is more useful than using the full topological information of the graph    We tackle \\ac{NED} by comparing entities in short sentences with \\wikidata{} graphs. Creating a context vector from graphs through deep learning is a challenging problem that has never been applied to \\ac{NED}. Our main contribution is to present an experimental study of recent neural techniques, as well as a discussion about which graph features are most important for the disambiguation task. In addition, a new dataset (\\wikidatadisamb{}) is created to allow a clean and scalable evaluation of \\ac{NED} with \\wikidata{} entries, and to be used as a reference in future research. In the end our results show that a \\ac{Bi-LSTM} encoding of the graph triplets performs best, improving upon the baseline models and scoring an \ m{F1} value of $91.6\\%$ on the \\wikidatadisamb{} test set|sl:arxiv_author|Mohammad Akbari
Antiracisme|skos:broader|Racisme
(LOV) Linked Open Vocabularies|skos:broader|Bernard Vatant
ACL|skos:broader|NLP conference
SW: coreferences|skos:broader|URI
Hepp's PropertyValue|skos:broader|Martin Hepp
Boucle ferroviaire d’Afrique de l’Ouest|skos:broader|New Africa
Intent detection|skos:broader|Chatbots
SPARQL Demo|skos:broader|SPARQL
Unsupervised machine translation|skos:broader|Unsupervised machine learning
K-BERT: Enabling Language Representation with Knowledge Graph a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by equipped with a KG without pre-training by-self because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts.|sl:arxiv_author|Haotang Deng
Web site design|skos:broader|Internet
Word Mover’s Distance|skos:broader|Using word embeddings
Biopiles|skos:broader|Energies renouvelables
Sebastian Ruder|skos:broader|NLP girls and guys
Detecting Out-of-Distribution Examples with In-distribution Examples and Gram Matrices  we propose to detect OOD examples by identifying inconsistencies between activity patterns and class predicted...    Unlike many approaches, this can be used with any pre-trained softmax classifier and does not require access to OOD data When presented with Out-of-Distribution (OOD) examples, deep neural networks yield confident, incorrect predictions. Detecting OOD examples is challenging, and the potential risks are high. In this paper, we propose to detect OOD examples by identifying inconsistencies between activity patterns and class predicted. We find that characterizing activity patterns by Gram matrices and identifying anomalies in gram matrix values can yield high OOD detection rates. We identify anomalies in the gram matrices by simply comparing each value with its respective range observed over the training data. Unlike many approaches, this can be used with any pre-trained softmax classifier and does not require access to OOD data for fine-tuning hyperparameters, nor does it require OOD access for inferring parameters. The method is applicable across a variety of architectures and vision datasets and, for the important and surprisingly hard task of detecting far-from-distribution out-of-distribution examples, it generally performs better than or equal to state-of-the-art OOD detection methods (including those that do assume access to OOD examples).|sl:tag|tag:arxiv_doc
Beijing Genomics Institute|skos:broader|Shenzhen
Sida|skos:broader|Immune system Système immunitaire
Fukushima|skos:broader|Catastrophe écologique
Federated SPARQL queries|skos:broader|SPARQL
Micropayments on the web|skos:broader|Payment
“one learning algorithm” hypothesis|skos:broader|Computational Neuroscience
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:arxiv_firstAuthor|Jiaming Shen
Crète antique|skos:broader|Crète
QuickTime|skos:broader|Apple Software
Indo-européen|skos:broader|Antiquité
t-SNE|skos:broader|Dimensionality reduction
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Yujia Li
XML Schema|skos:broader|XML
From Word to Sense Embeddings: A Survey on Vector Representations of Meaning Survey focused on semantic representation of meaning (methods that try to directly model individual meanings of words).    Pb with word embeddings: the meaning conflation deficiency (representing a word with all its possible meanings as a single vector). Can be addressed by a method for modelling unambiguous lexical meaning.    two main branches of sense representation :    - unsupervised   - knowledge-based Over the past years, distributed semantic representations have proved to be effective and flexible keepers of prior knowledge to be integrated into downstream applications. This survey focuses on the representation of meaning. We start from the theoretical background behind word vector space models and highlight one of their major limitations: the meaning conflation deficiency, which arises from representing a word with all its possible meanings as a single vector. Then, we explain how this deficiency can be addressed through a transition from the word level to the more fine-grained level of word senses (in its broader acceptation) as a method for modelling unambiguous lexical meaning. We present a comprehensive overview of the wide range of techniques in the two main branches of sense representation, i.e., unsupervised and knowledge-based. Finally, this survey covers the main evaluation procedures and applications for this type of representation, and provides an analysis of four of its important aspects: interpretability, sense granularity, adaptability to different domains and compositionality.|sl:tag|tag:sense_embeddings
Président des USA|skos:broader|USA
IBM|skos:broader|Informatique
GooglePlus|skos:broader|Social Networks
J'y étais|skos:broader|Souvenirs
FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence [github](https://github.com/google-research/fixmatch)     we demonstrate the power of a  simple combination of two common Semi-Supervised Learning methods: consistency  regularization and pseudo-labeling.    1. First generates pseudo-labels using the model’s  predictions on weakly-augmented unlabeled images. For a  given image, the pseudo-label is only retained if the model  produces a high-confidence prediction.   2. The model is then  trained to predict the pseudo-label when fed a strongly augmented  version of the same image. Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. In this paper, we demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling. Our algorithm, FixMatch, first generates pseudo-labels using the model's predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just 4 labels per class. Since FixMatch bears many similarities to existing SSL methods that achieve worse performance, we carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. We make our code available at https://github.com/google-research/fixmatch.|sl:arxiv_author|Chun-Liang Li
EMNLP 2019|skos:broader|NLP conference
Alexandre le Grand|skos:broader|Personnage historique
Information retrieval: techniques|skos:broader|Information retrieval
Semanlink2 related|skos:broader|Semanlink related
Chico Buarque|skos:broader|Brésil
Disparition des abeilles|skos:broader|Abeille
Tutorial|skos:broader|Howto, tutorial, FAQ
On Extractive and Abstractive Neural Document Summarization with Transformer Language Models  Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper. We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We show that this extractive step significantly improves summarization results. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher rouge scores. Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper.|sl:arxiv_author|Sandeep Subramanian
Hugh Glaser|skos:broader|SW guys (and girls)
TabFact: A Large-scale Dataset for Table-based Fact Verification fact verification given semi-structured data as evidence The problem of verifying whether a textual hypothesis holds based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation. However, existing studies are mainly restricted to dealing with unstructured evidence (e.g., natural language sentences and documents, news, etc), while verification under structured evidence, such as tables, graphs, and databases, remains under-explored. This paper specifically aims to study the fact verification given semi-structured data as evidence. To this end, we construct a large-scale dataset called TabFact with 16k Wikipedia tables as the evidence for 118k human-annotated natural language statements, which are labeled as either ENTAILED or REFUTED. TabFact is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning. To address these reasoning challenges, we design two different models: Table-BERT and Latent Program Algorithm (LPA). Table-BERT leverages the state-of-the-art pre-trained language model to encode the linearized tables and statements into continuous vectors for verification. LPA parses statements into programs and executes them against the tables to obtain the returned binary value for verification. Both methods achieve similar accuracy but still lag far behind human performance. We also perform a comprehensive analysis to demonstrate great future opportunities. The data and code of the dataset are provided in \\url{https://github.com/wenhuchen/Table-Fact-Checking}.|sl:arxiv_firstAuthor|Wenhu Chen
Eurogroupe|skos:broader|Europe
L'Afrique à la Bastille - 13 juillet 2007|skos:broader|RFI
HADOPI|skos:broader|Loi sur le téléchargement
Carrot2|skos:broader|Clustering of text documents
SDMX|skos:broader|Statistical data
Film turc|skos:broader|Turquie
Macaw: An Extensible Conversational Information Seeking Platform Conversational information seeking (CIS) has been recognized as a major emerging research area in information retrieval. Such research will require data and tools, to allow the implementation and study of conversational systems. This paper introduces Macaw, an open-source framework with a modular architecture for CIS research. Macaw supports multi-turn, multi-modal, and mixed-initiative interactions, and enables research for tasks such as document retrieval, question answering, recommendation, and structured data exploration. It has a modular design to encourage the study of new CIS algorithms, which can be evaluated in batch mode. It can also integrate with a user interface, which allows user studies and data collection in an interactive mode, where the back end can be fully algorithmic or a wizard of oz setup. Macaw is distributed under the MIT License.|sl:arxiv_author|Hamed Zamani
Peintre|skos:broader|Artiste
Entities as Experts: Sparse Memory Access with Entity Supervision   the problem of capturing declarative knowledge in the learned parameters of a language model...     Entities as Experts (EaE) can access distinct memories of the entities mentioned in a piece of text;     To understand the motivation for distinct and  independent entity representations: A traditional Transformer would need to build an internal representation  of Charles Darwin from the words “Charles”  and “Darwin”... Conversely, EAE can access  a dedicated representation of “Charles Darwin”,  which is a memory of all of the contexts in which  this entity has previously been mentioned.... Having retrieved  and re-integrated this memory it is much easier for  EAE to relate the question to the answer     EaE's entity representations are learned directly from text. Correct identification, and representation, of entities is essential to EaE's performance    Based on transformer architecture    Extension: [Facts as Experts](doc:2020/07/2007_00849_facts_as_experts_) We focus on the problem of capturing declarative knowledge in the learned parameters of a language model. We introduce a new model, Entities as Experts (EaE), that can access distinct memories of the entities mentioned in a piece of text. Unlike previous efforts to integrate entity knowledge into sequence models, EaE's entity representations are learned directly from text. These representations capture sufficient knowledge to answer TriviaQA questions such as Which Dr. Who villain has been played by Roger Delgado, Anthony Ainley, Eric Roberts?. EaE outperforms a Transformer model with $30\\times$ the parameters on this task. According to the Lama knowledge probes, EaE also contains more factual knowledge than a similar sized Bert. We show that associating parameters with specific entities means that EaE only needs to access a fraction of its parameters at inference time, and we show that the correct identification, and representation, of entities is essential to EaE's performance. We also argue that the discrete and independent entity representations in EaE make it more modular and interpretable than the Transformer architecture on which it is based.|sl:arxiv_author|Thibault Févry
Constraint Programming|skos:broader|Logic
classification method that generalizes logistic regression to multiclass problems.    Assumes that a linear combination of the observed features and some problem-specific parameters can be used to determine the probability of each particular outcome of the dependent variable.     If you want to assign probabilities to an object being one of several different things, softmax is the thing to do. Even later on, when we train more sophisticated models, the final step will be a layer of softmax. [cf.](http://www.tensorflow.org/tutorials/mnist/beginners/index.md)  |skos:broader|predicting a single label among mutually exclusive labels.
Learning Confidence for Out-of-Distribution Detection in Neural Networks Modern neural networks are very powerful predictive models, but they are often incapable of recognizing when their predictions may be wrong. Closely related to this is the task of out-of-distribution detection, where a network must determine whether or not an input is outside of the set on which it is expected to safely perform. To jointly address these issues, we propose a method of learning confidence estimates for neural networks that is simple to implement and produces intuitively interpretable outputs. We demonstrate that on the task of out-of-distribution detection, our technique surpasses recently proposed techniques which construct confidence based on the network's output distribution, without requiring any additional labels or access to out-of-distribution examples. Additionally, we address the problem of calibrating out-of-distribution detectors, where we demonstrate that misclassified in-distribution examples can be used as a proxy for out-of-distribution examples.|sl:tag|tag:arxiv_doc
Histoire des Jermas|skos:broader|Jerma
Knowledge Graphs + Text KG + NLP|skos:broader|Knowledge Graph KG
NASA|skos:broader|USA
JSP|skos:broader|Java
The HSIC Bottleneck: Deep Learning without Back-Propagation  we show that it is possible to learn classification tasks at near competitive accuracy without  backpropagation, by maximizing a surrogate of the mutual information between hidden representations and labels and  simultaneously minimizing the mutual dependency between hidden representations and the inputs...  the hidden units of a network trained in this way form useful representations. Specifically, fully competitive accuracy  can be obtained by freezing the network trained without backpropagation and appending and training a one-layer  network using conventional SGD to convert convert the representation to the desired format.    The training method uses an approximation of the [#information bottleneck](/tag/information_bottleneck_method).    Advantages:     - The method facilitates parallel processing and requires significantly less operations.    - It does not suffer from exploding or vanishing gradients.   - It is biologically more plausible than Backpropagation     We introduce the HSIC (Hilbert-Schmidt independence criterion) bottleneck for training deep neural networks. The HSIC bottleneck is an alternative to the conventional cross-entropy loss and backpropagation that has a number of distinct advantages. It mitigates exploding and vanishing gradients, resulting in the ability to learn very deep networks without skip connections. There is no requirement for symmetric feedback or update locking. We find that the HSIC bottleneck provides performance on MNIST/FashionMNIST/CIFAR10 classification comparable to backpropagation with a cross-entropy target, even when the system is not encouraged to make the output resemble the classification labels. Appending a single layer trained with SGD (without backpropagation) to reformat the information further improves performance.|sl:arxiv_author|Wan-Duo Kurt Ma
Roman|skos:broader|Livre
An efficient framework for learning sentence representations Quick Thoughts. Framework for learning sentence representations from unlabelled data.     we reformulate the problem of predicting the context in which a sentence appears as a classification problem.   In this work we propose a simple and efficient framework for learning sentence representations from unlabelled data. Drawing inspiration from the distributional hypothesis and recent work on learning sentence representations, we reformulate the problem of predicting the context in which a sentence appears as a classification problem. Given a sentence and its context, a classifier distinguishes context sentences from other contrastive sentences based on their vector representations. This allows us to efficiently learn different types of encoding functions, and we show that the model learns high-quality sentence representations. We demonstrate that our sentence representations outperform state-of-the-art unsupervised and supervised representation learning methods on several downstream NLP tasks that involve understanding sentence semantics while achieving an order of magnitude speedup in training time.|sl:arxiv_author|Lajanugen Logeswaran
Language Models + Knowledge|skos:broader|Language model
Blosxom|skos:broader|Blog software
Julie Grollier|skos:broader|AI girls and guys
Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs [GitHub](https://github.com/deepakn97/relationPrediction) [Blog post](/doc/2020/04/deepak_nathani_%7C_pay_attention_) The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention based feature embedding that captures both entity and relation features in any given entity's neighborhood. Additionally, we also encapsulate relation clusters and multihop relations in our model. Our empirical study offers insights into the efficacy of our attention based model and we show marked performance gains in comparison to state of the art methods on all datasets.|sl:tag|tag:attention_knowledge_graphs
Gouvernement français|skos:broader|France
Craig Venter|skos:broader|Scientifique
Pierre de Volvic|skos:broader|Volcan
Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks  Sentence-BERT  (SBERT), a modification of the pretrained  BERT network that use siamese and triplet network  structures to derive semantically meaningful  sentence embeddings that can be compared  using cosine-similarity.    Important because     - BERT ist unsuitable for semantic similarity  search as well as for unsupervised tasks  like clustering.  - simple methods such as using the CLS token give low quality sentence embeddings    However, the purpose of SBERT sentence embeddings  are not to be used for transfer learning for other  tasks.    [Related blog post](/doc/2020/01/richer_sentence_embeddings_usin); [Github](https://github.com/UKPLab/sentence-transformers) BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.|sl:arxiv_firstAuthor|Nils Reimers
DeleteFB|skos:broader|The web sucks
Google Visualization API|skos:broader|Data Visualization Tools
Digital Video|skos:broader|Digital Media
Transformer + Knowledge Graphs|skos:broader|Graph + Transformer
Coreference resolution|skos:broader|NLP tasks / problems
OWL: Introduction|skos:broader|Introduction
URI Synonymity|skos:broader|Synonym URIs
Cross-Origin Resource Sharing|skos:broader|cross-domain data fetching
RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space  We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.|sl:tag|tag:knowledge_graph_completion
Thesaurus & Taxonomies |skos:broader|Knowledge Representation
Manuscrits de Tombouctou|skos:broader|Tombouctou
Tagging|skos:broader|Semantic annotation
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:arxiv_author|Rob Malkin
Deep latent variable models assume a generative process whereby a simple random variable is transformed from the latent space to the observed, output space through a deep neural network. Generative Adversarial Networks (GAN) and Variational Autoencoders (VAE) are two of the most popular variants of this approach|skos:broader|a set of algorithms in machine learning that attempt to model high-level abstractions in data by using architectures composed of multiple non-linear transformations. Deep learning is part of a broader family of machine learning methods based on learning representations of data.    One of the promises of deep learning is replacing handcrafted features with efficient algorithms for unsupervised or semi-supervised feature learning and hierarchical feature extraction    With Deep Learning, Ng says, you just give the system a lot of data so it can discover by itself what some of the concepts in the world are ([cf.](http://www.wired.com/2013/05/neuro-artificial-intelligence/all/))  
Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation   An embedding method specifically designed for NED that jointly maps words and entities into the same continuous vector space.    We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words Named Entity Disambiguation (NED) refers to the task of resolving multiple named entity mentions in a document to their correct references in a knowledge base (KB) (e.g., Wikipedia). In this paper, we propose a novel embedding method specifically designed for NED. The proposed method jointly maps words and entities into the same continuous vector space. We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words. By combining contexts based on the proposed embedding with standard NED features, we achieved state-of-the-art accuracy of 93.1% on the standard CoNLL dataset and 85.2% on the TAC 2010 dataset.|sl:arxiv_author|Ikuya Yamada
Attention Is All You Need  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.|sl:arxiv_author|Lukasz Kaiser
SGNN|skos:broader|NLP@Google
Raphaël Troncy|skos:broader|SW guys (and girls)
Semantic Web conferences|skos:broader|Conférences
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:arxiv_author|Jacob Andreas
dbpedia francophone|skos:broader|dbpedia
jersey|skos:broader|Java dev
Fichage génétique|skos:broader|Fichage
Semantic Web Client Library|skos:broader|Chris Bizer
Database to RDF mapping|skos:broader|Relational Databases and the Semantic Web
An efficient framework for learning sentence representations Quick Thoughts. Framework for learning sentence representations from unlabelled data.     we reformulate the problem of predicting the context in which a sentence appears as a classification problem.   In this work we propose a simple and efficient framework for learning sentence representations from unlabelled data. Drawing inspiration from the distributional hypothesis and recent work on learning sentence representations, we reformulate the problem of predicting the context in which a sentence appears as a classification problem. Given a sentence and its context, a classifier distinguishes context sentences from other contrastive sentences based on their vector representations. This allows us to efficiently learn different types of encoding functions, and we show that the model learns high-quality sentence representations. We demonstrate that our sentence representations outperform state-of-the-art unsupervised and supervised representation learning methods on several downstream NLP tasks that involve understanding sentence semantics while achieving an order of magnitude speedup in training time.|sl:tag|tag:arxiv_doc
JavaScript librairies|skos:broader|JavaScript
Société française Société française|skos:broader|Société
Compagnies pétrolières|skos:broader|Exploitation pétrolière
Layered Graph Embedding for Entity Recommendation using Wikipedia in the Yahoo! Knowledge Graph an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia In this paper, we describe an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia. Through offline and online evaluations, we show that the resulting embeddings and recommendations perform well in terms of quality and user engagement. Balancing simplicity and quality, this framework provides default entity recommendations for English and other languages in the Yahoo! Knowledge Graph, which Wikipedia is a core subset of.|sl:arxiv_firstAuthor|Chien-Chun Ni
CNRS|skos:broader|Recherche française
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:arxiv_author|Michelle Lam
RDFa|skos:broader|RDF
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|Aidan Hogan
XMLHttpRequest|skos:broader|js
BLINK|skos:broader|NLP@Facebook
Illusion d'optique|skos:broader|Divers
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:tag|tag:dans_deep_averaging_neural_networks
Décroissance|skos:broader|Critique du libéralisme
GoogleTechTalks|skos:broader|Google
Robert McLiam Wilson|skos:broader|Ecrivain
Label-aware Document Representation via Hybrid Attention for Extreme Multi-Label Text Classification  This paper is motivated to better explore the semantic relationship between each document and extreme labels by taking advantage of both document content and label correlation. Our objective is to establish an explicit label-aware representation for each document with a hybrid attention deep neural network model(LAHA) Extreme multi-label text classification (XMTC) aims at tagging a document with most relevant labels from an extremely large-scale label set. It is a challenging problem especially for the tail labels because there are only few training documents to build classifier. This paper is motivated to better explore the semantic relationship between each document and extreme labels by taking advantage of both document content and label correlation. Our objective is to establish an explicit label-aware representation for each document with a hybrid attention deep neural network model(LAHA). LAHA consists of three parts. The first part adopts a multi-label self-attention mechanism to detect the contribution of each word to labels. The second part exploits the label structure and document content to determine the semantic connection between words and labels in a same latent space. An adaptive fusion strategy is designed in the third part to obtain the final label-aware document representation so that the essence of previous two parts can be sufficiently integrated. Extensive experiments have been conducted on six benchmark datasets by comparing with the state-of-the-art methods. The results show the superiority of our proposed LAHA method, especially on the tail labels.|sl:arxiv_author|Xin Huang
David Peterson|skos:broader|SW guys (and girls)
Cédric Villani|skos:broader|Mathématicien
Unifying distillation and privileged information A framework to learn from multiple machines and data representations, unifying two techniques that enable machines to learn from other machines: [distillation](tag:knowledge_distillation) ([Hinton et al., 2015](doc:2020/04/1503_02531_distilling_the_kno)) and privileged information (Vapnik & Izmailov, 2015)   Distillation (Hinton et al., 2015) and privileged information (Vapnik & Izmailov, 2015) are two techniques that enable machines to learn from other machines. This paper unifies these two techniques into generalized distillation, a framework to learn from multiple machines and data representations. We provide theoretical and causal insight about the inner workings of generalized distillation, extend it to unsupervised, semisupervised and multitask learning scenarios, and illustrate its efficacy on a variety of numerical simulations on both synthetic and real-world data.|sl:tag|tag:knowledge_distillation
Tag Clusters|skos:broader|Tagging
Neural Ranking Models with Weak Supervision Main Idea: To leverage large amounts of unsupervised data to infer “weak” labels and use that signal for learning supervised models as if we had the ground truth labels. See [blog post](/doc/?uri=http%3A%2F%2Fmostafadehghani.com%2F2017%2F04%2F23%2Fbeating-the-teacher-neural-ranking-models-with-weak-supervision%2F):     This is truly awesome since we have only used  BM25 as the supervisor to train a model which performs better than BM25 itself!   Despite the impressive improvements achieved by unsupervised deep neural networks in computer vision and NLP tasks, such improvements have not yet been observed in ranking for information retrieval. The reason may be the complexity of the ranking problem, as it is not obvious how to learn from queries and documents when no supervised signal is available. Hence, in this paper, we propose to train a neural ranking model using weak supervision, where labels are obtained automatically without human annotators or any external resources (e.g., click data). To this aim, we use the output of an unsupervised ranking model, such as BM25, as a weak supervision signal. We further train a set of simple yet effective ranking models based on feed-forward neural networks. We study their effectiveness under various learning scenarios (point-wise and pair-wise models) and using different input representations (i.e., from encoding query-document pairs into dense/sparse vectors to using word embedding representation). We train our networks using tens of millions of training instances and evaluate it on two standard collections: a homogeneous news collection(Robust) and a heterogeneous large-scale web collection (ClueWeb). Our experiments indicate that employing proper objective functions and letting the networks to learn the input representation based on weakly supervised data leads to impressive performance, with over 13% and 35% MAP improvements over the BM25 model on the Robust and the ClueWeb collections. Our findings also suggest that supervised neural ranking models can greatly benefit from pre-training on large amounts of weakly labeled data that can be easily obtained from unsupervised IR models.|sl:tag|tag:machine_learned_ranking
Knowledge Graph Embeddings and Explainable AI survey of     - the state-of-the-art in the field of knowledge graph embeddings  - methods for explaining predictions obtained via knowledge graph embeddings. Knowledge graph embeddings are now a widely adopted approach to knowledge representation in which entities and relationships are embedded in vector spaces. In this chapter, we introduce the reader to the concept of knowledge graph embeddings by explaining what they are, how they can be generated and how they can be evaluated. We summarize the state-of-the-art in this field by describing the approaches that have been introduced to represent knowledge in the vector space. In relation to knowledge representation, we consider the problem of explainability, and discuss models and methods for explaining predictions obtained via knowledge graph embeddings.|sl:arxiv_author|Gaetano Rossiello
Apache web server|skos:broader|apache.org
Paris NLP meetup|skos:broader|Meetup
Hash URIs|skos:broader|httpRange-14
Apple|skos:broader|Entreprise
OntoWiki|skos:broader|PHP
Tombouctou|skos:broader|Sahara
OWL tool|skos:broader|Semantic Web : Tools
Ténéré|skos:broader|Niger
Chatbots|skos:broader|NLP: use cases
Rwanda|skos:broader|Afrique
Chômage|skos:broader|Société
Talis RDF/JSON|skos:broader|Talis
Horreur économique|skos:broader|Critique du libéralisme
phpMyAdmin|skos:broader|MySQL
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.|sl:tag|tag:bayesian_deep_learning
Agriculture|skos:broader|Economie
Bulgarie|skos:broader|Europe
Chris Welty|skos:broader|Technical girls and guys
SQL to RDF mapping|skos:broader|RDF
Attention Is All You Need  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.|sl:arxiv_author|Ashish Vaswani
Emerging Cross-lingual Structure in Pretrained Language Models We study the problem of multilingual masked language modeling, i.e. the training of a single model on concatenated text from multiple languages, and present a detailed study of several factors that influence why these models are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from independently trained models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these symmetries seem to be automatically discovered and aligned during the joint training process.|sl:arxiv_author|Shijie Wu
What is life ?|skos:broader|Origine de la vie
HP|skos:broader|Entreprise
Lynn Margulis|skos:broader|Femme célèbre (où qui mérite de l'être)
FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence [github](https://github.com/google-research/fixmatch)     we demonstrate the power of a  simple combination of two common Semi-Supervised Learning methods: consistency  regularization and pseudo-labeling.    1. First generates pseudo-labels using the model’s  predictions on weakly-augmented unlabeled images. For a  given image, the pseudo-label is only retained if the model  produces a high-confidence prediction.   2. The model is then  trained to predict the pseudo-label when fed a strongly augmented  version of the same image. Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. In this paper, we demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling. Our algorithm, FixMatch, first generates pseudo-labels using the model's predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just 4 labels per class. Since FixMatch bears many similarities to existing SSL methods that achieve worse performance, we carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. We make our code available at https://github.com/google-research/fixmatch.|sl:tag|tag:google_research
Spectral clustering|skos:broader|Statistics
Musique en ligne|skos:broader|NTIC
A Metric Learning Reality Check Deep metric learning papers from the past four years have consistently claimed great advances in accuracy, often more than doubling the performance of decade-old methods. In this paper, we take a closer look at the field to see if this is actually true. We find flaws in the experimental setup of these papers, and propose a new way to evaluate metric learning algorithms. Finally, we present experimental results that show that the improvements over time have been marginal at best.|sl:arxiv_author|Serge Belongie
Film français|skos:broader|Film
public-hydra@w3.org|skos:broader|Mailing list
The HSIC Bottleneck: Deep Learning without Back-Propagation  we show that it is possible to learn classification tasks at near competitive accuracy without  backpropagation, by maximizing a surrogate of the mutual information between hidden representations and labels and  simultaneously minimizing the mutual dependency between hidden representations and the inputs...  the hidden units of a network trained in this way form useful representations. Specifically, fully competitive accuracy  can be obtained by freezing the network trained without backpropagation and appending and training a one-layer  network using conventional SGD to convert convert the representation to the desired format.    The training method uses an approximation of the [#information bottleneck](/tag/information_bottleneck_method).    Advantages:     - The method facilitates parallel processing and requires significantly less operations.    - It does not suffer from exploding or vanishing gradients.   - It is biologically more plausible than Backpropagation     We introduce the HSIC (Hilbert-Schmidt independence criterion) bottleneck for training deep neural networks. The HSIC bottleneck is an alternative to the conventional cross-entropy loss and backpropagation that has a number of distinct advantages. It mitigates exploding and vanishing gradients, resulting in the ability to learn very deep networks without skip connections. There is no requirement for symmetric feedback or update locking. We find that the HSIC bottleneck provides performance on MNIST/FashionMNIST/CIFAR10 classification comparable to backpropagation with a cross-entropy target, even when the system is not encouraged to make the output resemble the classification labels. Appending a single layer trained with SGD (without backpropagation) to reformat the information further improves performance.|sl:tag|tag:information_theory_and_deep_learning
Mobile apps dev|skos:broader|Mobile apps
the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations whose category membership is known.|skos:broader|the machine learning task of inferring a function from labeled training data.
Layered Graph Embedding for Entity Recommendation using Wikipedia in the Yahoo! Knowledge Graph an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia In this paper, we describe an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia. Through offline and online evaluations, we show that the resulting embeddings and recommendations perform well in terms of quality and user engagement. Balancing simplicity and quality, this framework provides default entity recommendations for English and other languages in the Yahoo! Knowledge Graph, which Wikipedia is a core subset of.|sl:tag|tag:yahoo
XML|skos:broader|Dev
NER|skos:broader|Sequence Tagging
Semantic Web Outliner|skos:broader|Semantic Web : Application
Building Machines That Learn and Think Like People  we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations   Recent progress in artificial intelligence (AI) has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn, and how they learn it. Specifically, we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models.|sl:arxiv_author|Joshua B. Tenenbaum
Subword Semantic Hashing for Intent Classification on Small Datasets In this paper, we introduce the use of Semantic Hashing as embedding for the task of Intent Classification and achieve state-of-the-art performance on three frequently used benchmarks. Intent Classification on a small dataset is a challenging task for data-hungry state-of-the-art Deep Learning based systems. Semantic Hashing is an attempt to overcome such a challenge and learn robust text classification. Current word embedding based are dependent on vocabularies. One of the major drawbacks of such methods is out-of-vocabulary terms, especially when having small training datasets and using a wider vocabulary. This is the case in Intent Classification for chatbots, where typically small datasets are extracted from internet communication. Two problems arise by the use of internet communication. First, such datasets miss a lot of terms in the vocabulary to use word embeddings efficiently. Second, users frequently make spelling errors. Typically, the models for intent classification are not trained with spelling errors and it is difficult to think about ways in which users will make mistakes. Models depending on a word vocabulary will always face such issues. An ideal classifier should handle spelling errors inherently. With Semantic Hashing, we overcome these challenges and achieve state-of-the-art results on three datasets: AskUbuntu, Chatbot, and Web Application. Our benchmarks are available online: https://github.com/kumar-shridhar/Know-Your-Intent|sl:arxiv_author|Vinaychandran Pondenkandath
Election|skos:broader|Société
SIF embeddings|skos:broader|Sentence Embeddings
Astronomie|skos:broader|Science
Database to RDF mapping|skos:broader|Converting data into RDF
Mobile phone|skos:broader|Mobile device
Leopard|skos:broader|Mac OS X
GNU Octave|skos:broader|Open Source
TEMIS|skos:broader|French Semantic web company
\Why Should I Trust You?\: Explaining the Predictions of Any Classifier technique that explains the predictions of any classifier by learning an interpretable model locally around the prediction Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.|sl:tag|tag:arxiv_doc
Towards a Seamless Integration of Word Senses into Downstream NLP Applications Lexical ambiguity can impede NLP systems from accurate understanding of semantics. Despite its potential benefits, the integration of sense-level information into NLP systems has remained understudied. By incorporating a novel disambiguation algorithm into a state-of-the-art classification model, we create a pipeline to integrate sense-level information into downstream NLP applications. We show that a simple disambiguation of the input text can lead to consistent performance improvement on multiple topic categorization and polarity detection datasets, particularly when the fine granularity of the underlying sense inventory is reduced and the document is sufficiently large. Our results also point to the need for sense representation research to focus more on in vivo evaluations which target the performance in downstream NLP applications rather than artificial benchmarks.|sl:arxiv_author|Mohammad Taher Pilehvar
DSSM (Deep Semantic Similarity Model)|skos:broader|Similarity queries
Plante|skos:broader|Botanique
Entity Embeddings of Categorical Variables  We map categorical variables in a function approximation problem into Euclidean spaces, which are the entity embeddings of the categorical variables. The mapping is learned by a neural network during the standard supervised training process. Entity embedding not only reduces memory usage and speeds up neural networks compared with one-hot encoding, but more importantly by mapping similar values close to each other in the embedding space it reveals the intrinsic properties of the categorical variables We map categorical variables in a function approximation problem into Euclidean spaces, which are the entity embeddings of the categorical variables. The mapping is learned by a neural network during the standard supervised training process. Entity embedding not only reduces memory usage and speeds up neural networks compared with one-hot encoding, but more importantly by mapping similar values close to each other in the embedding space it reveals the intrinsic properties of the categorical variables. We applied it successfully in a recent Kaggle competition and were able to reach the third position with relative simple features. We further demonstrate in this paper that entity embedding helps the neural network to generalize better when the data is sparse and statistics is unknown. Thus it is especially useful for datasets with lots of high cardinality features, where other methods tend to overfit. We also demonstrate that the embeddings obtained from the trained neural network boost the performance of all tested machine learning methods considerably when used as the input features instead. As entity embedding defines a distance measure for categorical variables it can be used for visualizing categorical data and for data clustering.|sl:tag|tag:categorical_variables
Android|skos:broader|Google
Combining text and structured data (ML-NLP)|skos:broader|Features (Machine Learning)
RDF2h|skos:broader|Linked Data Browser
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|Axel-Cyrille Ngonga Ngomo
fps@EC-Web'14|skos:broader|EC-Web'14
535|skos:broader|Accident climatique
SDB: A SPARQL Database for Jena|skos:broader|SPARQL AND Jena
SIF embeddings|skos:broader|Sanjeev Arora
Knowledge Graph Embeddings and Explainable AI survey of     - the state-of-the-art in the field of knowledge graph embeddings  - methods for explaining predictions obtained via knowledge graph embeddings. Knowledge graph embeddings are now a widely adopted approach to knowledge representation in which entities and relationships are embedded in vector spaces. In this chapter, we introduce the reader to the concept of knowledge graph embeddings by explaining what they are, how they can be generated and how they can be evaluated. We summarize the state-of-the-art in this field by describing the approaches that have been introduced to represent knowledge in the vector space. In relation to knowledge representation, we consider the problem of explainability, and discuss models and methods for explaining predictions obtained via knowledge graph embeddings.|sl:tag|tag:survey
Improving Entity Linking by Modeling Latent Entity Type Information Existing state of the art neural entity linking models employ attention-based bag-of-words context model and pre-trained entity embeddings bootstrapped from word embeddings to assess topic level context compatibility. However, the latent entity type information in the immediate context of the mention is neglected, which causes the models often link mentions to incorrect entities with incorrect type. To tackle this problem, we propose to inject latent entity type information into the entity embeddings based on pre-trained BERT. In addition, we integrate a BERT-based entity similarity score into the local context model of a state-of-the-art model to better capture latent entity type information. Our model significantly outperforms the state-of-the-art entity linking models on standard benchmark (AIDA-CoNLL). Detailed experiment analysis demonstrates that our model corrects most of the type errors produced by the direct baseline.|sl:arxiv_firstAuthor|Shuang Chen
Traversing Knowledge Graphs in Vector Space Knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new \compositional\ training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. Path queries on a knowledge graph can be used to answer compositional questions such as What languages are spoken by people living in Lisbon?. However, knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new compositional training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. On a standard knowledge base completion task, we also demonstrate that compositional training acts as a novel form of structural regularization, reliably improving performance across all base models (reducing errors by up to 43%) and achieving new state-of-the-art results.|sl:arxiv_author|John Miller
Une suite de matrices symétriques en rapport avec la fonction de Mertens  we explore a class of equivalence relations over N from which is constructed a sequence of symetric matrices related to the Mertens function. From numerical experimentations we suggest a conjecture, about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may play a more important part in this classical and difficult problem. In this paper we explore a class of equivalence relations over $\\N^\\ast$ from which is constructed a sequence of symetric matrices related to the Mertens function. From numerical experimentations we suggest a conjecture, about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may play a more important part in this classical and difficult problem.|sl:arxiv_firstAuthor|Jean-Paul Cardinal
Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks  Sentence-BERT  (SBERT), a modification of the pretrained  BERT network that use siamese and triplet network  structures to derive semantically meaningful  sentence embeddings that can be compared  using cosine-similarity.    Important because     - BERT ist unsuitable for semantic similarity  search as well as for unsupervised tasks  like clustering.  - simple methods such as using the CLS token give low quality sentence embeddings    However, the purpose of SBERT sentence embeddings  are not to be used for transfer learning for other  tasks.    [Related blog post](/doc/2020/01/richer_sentence_embeddings_usin); [Github](https://github.com/UKPLab/sentence-transformers) BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.|sl:tag|tag:arxiv_doc
Scandale des écoutes en Allemagne|skos:broader|Allemagne
Semanlink dev|skos:broader|Semanlink
Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus.     In practice, some questions are best answered  using text, while others are best answered using  KBs. A natural question, then, is how to effectively  combine both types of information. Surprisingly  little prior work has looked at this problem. Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting. Source code is available at https://github.com/OceanskySun/GraftNet .|sl:tag|tag:emnlp_2018
Boulgakov|skos:broader|Ecrivain
Génocide|skos:broader|Horreur
Ford|skos:broader|Automobile
Large-scale Multi-label Learning with Missing Labels The multi-label classification problem has generated significant interest in recent years. However, existing approaches do not adequately address two key challenges: (a) the ability to tackle problems with a large number (say millions) of labels, and (b) the ability to handle data with missing labels. In this paper, we directly address both these problems by studying the multi-label problem in a generic empirical risk minimization (ERM) framework. Our framework, despite being simple, is surprisingly able to encompass several recent label-compression based methods which can be derived as special cases of our method. To optimize the ERM problem, we develop techniques that exploit the structure of specific loss functions - such as the squared loss function - to offer efficient algorithms. We further show that our learning framework admits formal excess risk bounds even in the presence of missing labels. Our risk bounds are tight and demonstrate better generalization performance for low-rank promoting trace-norm regularization when compared to (rank insensitive) Frobenius norm regularization. Finally, we present extensive empirical results on a variety of benchmark datasets and show that our methods perform significantly better than existing label compression based methods and can scale up to very large datasets such as the Wikipedia dataset.|sl:arxiv_firstAuthor|Hsiang-Fu Yu
Liberté de pensée|skos:broader|Liberté
Ethereum|skos:broader|Virtual currency
Intent detection|skos:broader|Search Engines
Patent Infringement|skos:broader|Patent
What Does BERT Look At? An Analysis of BERT's Attention Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT's attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT's attention.|sl:arxiv_firstAuthor|Kevin Clark
De-extinction|skos:broader|Clonage
Hello World|skos:broader|Sample code
Plantu|skos:broader|Humour
Martynas Jusevicius|skos:broader|SW guys (and girls)
Lesk algorithm|skos:broader|Algorithmes
\Better entity LINKing\, @facebookai open-source entity linker. [GitHub](https://github.com/facebookresearch/BLINK)|skos:broader|Entity linking with Wikipedia as the target knowledge base
Back Propagation|skos:broader|ANN NN Artificial neural network
What Does BERT Look At? An Analysis of BERT's Attention Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT's attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT's attention.|sl:arxiv_author|Christopher D. Manning
Peace Corps|skos:broader|Coopération
Aster Aweke|skos:broader|Music of Africa
Realistic Re-evaluation of Knowledge Graph Completion Methods: An Experimental Study data redundancy (reverse relations), Cartesian product relations     A more fundamental defect  of these models is that the link prediction scenario, given  such data, is non-existent in the real-world In the active research area of employing embedding models for knowledge graph completion, particularly for the task of link prediction, most prior studies used two benchmark datasets FB15k and WN18 in evaluating such models. Most triples in these and other datasets in such studies belong to reverse and duplicate relations which exhibit high data redundancy due to semantic duplication, correlation or data incompleteness. This is a case of excessive data leakage---a model is trained using features that otherwise would not be available when the model needs to be applied for real prediction. There are also Cartesian product relations for which every triple formed by the Cartesian product of applicable subjects and objects is a true fact. Link prediction on the aforementioned relations is easy and can be achieved with even better accuracy using straightforward rules instead of sophisticated embedding models. A more fundamental defect of these models is that the link prediction scenario, given such data, is non-existent in the real-world. This paper is the first systematic study with the main objective of assessing the true effectiveness of embedding models when the unrealistic triples are removed. Our experiment results show these models are much less accurate than what we used to perceive. Their poor accuracy renders link prediction a task without truly effective automated solution. Hence, we call for re-investigation of possible effective approaches.|sl:arxiv_author|Qingheng Zhang State Key Laboratory for Novel Software Technology, Nanjing University
Equivalence mining|skos:broader|Linked Data
C2GWeb, Product description and Makolab|skos:broader|Product description
Three-way decisions|skos:broader|Statistical classification
Apache Marmotta|skos:broader|apache.org
Afrique|skos:broader|Géographie
Chinese|skos:broader|China
Memory-prediction framework|skos:broader|Neuroscience
Markown / Javascript|skos:broader|Markdown
Bigtable|skos:broader|Big Data
Soudan|skos:broader|Afrique de l'Est
PBS program|skos:broader|PBS
Compressive Transformers for Long-Range Sequence Modelling  the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning.    [Blog post](/doc/2020/02/a_new_model_and_dataset_for_lon) We present the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning. We find the Compressive Transformer obtains state-of-the-art language modelling results in the WikiText-103 and Enwik8 benchmarks, achieving 17.1 ppl and 0.97 bpc respectively. We also find it can model high-frequency speech effectively and can be used as a memory mechanism for RL, demonstrated on an object matching task. To promote the domain of long-range sequence learning, we propose a new open-vocabulary language modelling benchmark derived from books, PG-19.|sl:arxiv_author|Timothy P. Lillicrap
data.gouv.fr|skos:broader|Government data
Parthe|skos:broader|Mésopotamie
Variable Selection Methods for Model-based Clustering Model-based clustering is a popular approach for clustering multivariate data which has seen applications in numerous fields. Nowadays, high-dimensional data are more and more common and the model-based clustering approach has adapted to deal with the increasing dimensionality. In particular, the development of variable selection techniques has received a lot of attention and research effort in recent years. Even for small size problems, variable selection has been advocated to facilitate the interpretation of the clustering results. This review provides a summary of the methods developed for variable selection in model-based clustering. Existing R packages implementing the different methods are indicated and illustrated in application to two data analysis examples.|sl:tag|tag:cluster_analysis
Andrej Karpathy|skos:broader|AI girls and guys
One-Shot Generalization in Deep Generative Models Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our models are able to generate compelling and diverse samples---having seen new examples just once---providing an important class of general-purpose models for one-shot machine learning.|sl:arxiv_author|Danilo Jimenez Rezende
Décisions en entreprise|skos:broader|Management
Fermi's paradox|skos:broader|Astronomie
Cooperative Knowledge Distillation for Representation Learning Across Multiple Knowledge Bases    [GitHub](doc:2020/07/raphaelsty_kdmkb)|skos:broader| Apprentissage profond pour l’accès aux textes et bases de connaissances    Apprentissage de représentations d'informations sémantiques, adaptées au Traitement du Langage Naturel et à la Recherche d'Information, à partir de textes et de bases de connaissances formelles du domaine automobile  
EventKG: A Multilingual Event-Centric Temporal Knowledge Graph 690 thousand contemporary and historical events and over 2.3 million temporal relations One of the key requirements to facilitate semantic analytics of information regarding contemporary and historical events on the Web, in the news and in social media is the availability of reference knowledge repositories containing comprehensive representations of events and temporal relations. Existing knowledge graphs, with popular examples including DBpedia, YAGO and Wikidata, focus mostly on entity-centric information and are insufficient in terms of their coverage and completeness with respect to events and temporal relations. EventKG presented in this paper is a multilingual event-centric temporal knowledge graph that addresses this gap. EventKG incorporates over 690 thousand contemporary and historical events and over 2.3 million temporal relations extracted from several large-scale knowledge graphs and semi-structured sources and makes them available through a canonical representation.|sl:arxiv_author|Elena Demidova
RDF-in-JSON|skos:broader|JSON
Exploration marsienne|skos:broader|Missions spatiales
BERT for Joint Intent Classification and Slot Filling  Experimental results show that our  proposed joint BERT model outperforms BERT  models modeling intent classification and slot filling  separately, demonstrating the efficacy of exploiting  the relationship between the two tasks.    Adding a CRF on top of the model doesn't improve the results. Intent classification and slot filling are two essential tasks for natural language understanding. They often suffer from small-scale human-labeled training data, resulting in poor generalization capability, especially for rare words. Recently a new language representation model, BERT (Bidirectional Encoder Representations from Transformers), facilitates pre-training deep bidirectional representations on large-scale unlabeled corpora, and has created state-of-the-art models for a wide variety of natural language processing tasks after simple fine-tuning. However, there has not been much effort on exploring BERT for natural language understanding. In this work, we propose a joint intent classification and slot filling model based on BERT. Experimental results demonstrate that our proposed model achieves significant improvement on intent classification accuracy, slot filling F1, and sentence-level semantic frame accuracy on several public benchmark datasets, compared to the attention-based recurrent neural network models and slot-gated models.|sl:tag|tag:intent_classification_and_slot_filling
SW online tools|skos:broader|Semantic Web : Tools
One-Shot Learning|skos:broader|Few-shot learning
fastai: A Layered API for Deep Learning Paper describing the fast.ai v2 API fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes: a new type dispatch system for Python along with a semantic type hierarchy for tensors; a GPU-optimized computer vision library which can be extended in pure Python; an optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 4-5 lines of code; a novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training; a new data block API; and much more. We have used this library to successfully create a complete deep learning course, which we were able to write more quickly than using previous approaches, and the code was more clear. The library is already in wide use in research, industry, and teaching. NB: This paper covers fastai v2, which is currently in pre-release at http://dev.fast.ai/|sl:arxiv_author|Jeremy Howard
Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.|sl:arxiv_author|Jaime Carbonell
Taiwan|skos:broader|Asie
Lee Sedol|skos:broader|Go (Game)
AI: books & journals|skos:broader|Artificial Intelligence
Text Generation from Knowledge Graphs with Graph Transformers Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.|sl:arxiv_author|Dhanush Bekal
Inde moderne|skos:broader|Inde
Criquet|skos:broader|Insecte
Google Hummingbird|skos:broader|Google
Explainable Deep Learning: A Field Guide for the Uninitiated Deep neural network (DNN) is an indispensable machine learning tool for achieving human-level performance on many learning tasks. Yet, due to its black-box nature, it is inherently difficult to understand which aspects of the input data drive the decisions of the network. There are various real-world scenarios in which humans need to make actionable decisions based on the output DNNs. Such decision support systems can be found in critical domains, such as legislation, law enforcement, etc. It is important that the humans making high-level decisions can be sure that the DNN decisions are driven by combinations of data features that are appropriate in the context of the deployment of the decision support system and that the decisions made are legally or ethically defensible. Due to the incredible pace at which DNN technology is being developed, the development of new methods and studies on explaining the decision-making process of DNNs has blossomed into an active research field. A practitioner beginning to study explainable deep learning may be intimidated by the plethora of orthogonal directions the field is taking. This complexity is further exacerbated by the general confusion that exists in defining what it means to be able to explain the actions of a deep learning system and to evaluate a system's ability to explain. To alleviate this problem, this article offers a field guide to deep learning explainability for those uninitiated in the field. The field guide: i) Discusses the traits of a deep learning system that researchers enhance in explainability research, ii) places explainability in the context of other related deep learning research areas, and iii) introduces three simple dimensions defining the space of foundational methods that contribute to explainable deep learning. The guide is designed as an easy-to-digest starting point for those just embarking in the field.|sl:arxiv_author|Gabrielle Ras
Film italien|skos:broader|Film
Recommended reading |skos:broader|Livre à lire
Flippant|skos:broader|Ca craint
Rare events|skos:broader|Machine learning: problems
Hydrogen Cars|skos:broader|Hydrogen economy
EDUCE: Explaining model Decisions through Unsupervised Concepts Extraction  Providing explanations along with predictions is crucial in some text processing tasks. Therefore, we propose a new self-interpretable model that performs output prediction and simultaneously provides an explanation in terms of the presence of particular concepts in the input. To do so, our model's prediction relies solely on a low-dimensional binary representation of the input, where each feature denotes the presence or absence of concepts.    Presented in these [slides](/doc/2019/12/unsupervised_learning_with_text) Providing explanations along with predictions is crucial in some text processing tasks. Therefore, we propose a new self-interpretable model that performs output prediction and simultaneously provides an explanation in terms of the presence of particular concepts in the input. To do so, our model's prediction relies solely on a low-dimensional binary representation of the input, where each feature denotes the presence or absence of concepts. The presence of a concept is decided from an excerpt i.e. a small sequence of consecutive words in the text. Relevant concepts for the prediction task at hand are automatically defined by our model, avoiding the need for concept-level annotations. To ease interpretability, we enforce that for each concept, the corresponding excerpts share similar semantics and are differentiable from each others. We experimentally demonstrate the relevance of our approach on text classification and multi-sentiment analysis tasks.|sl:arxiv_author|Diane Bouchacourt
Separation of man and ape|skos:broader|Origines de l'homme
OKKAM|skos:broader|Semantic Web : Application
FAQ|skos:broader|Howto, tutorial, FAQ
Diacritics in URI|skos:broader|URI
Facts as Experts: Adaptable and Interpretable Neural Memory over Symbolic Knowledge  a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge.... The model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones.     a  neural language model which learns to access information  in a symbolic knowledge graph.     This  model builds on the recently-proposed [Entities as  Experts](doc:2020/07/2004_07202_entities_as_expert) (EaE) language model (Févry et al., 2020),  which extends the same transformer (Vaswani  et al., 2017) architecture of BERT (Devlin et al., 2019) with an additional external memory for entities.     After training EaE, the embedding associated  with an entity will (ideally) capture information  about the textual context in which that  entity appears, and by inference, the entity’s semantic  properties     we include an additional  memory called a fact memory, which encodes  triples from a symbolic KB.     This combination results in a  neural language model which learns to access information  in a the symbolic knowledge graph.        TODO: read again IBM's [Span Selection Pre-training for Question Answering](doc:2019/09/_1909_04120_span_selection_pre) (an effort to avoid encoding general knowledge in the transformer network itself) Massive language models are the core of modern NLP modeling and have been shown to encode impressive amounts of commonsense and factual information. However, that knowledge exists only within the latent parameters of the model, inaccessible to inspection and interpretation, and even worse, factual information memorized from the training corpora is likely to become stale as the world changes. Knowledge stored as parameters will also inevitably exhibit all of the biases inherent in the source materials. To address these problems, we develop a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge. We show that this model dramatically improves performance on two knowledge-intensive question-answering tasks. More interestingly, the model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones in ways that are not possible for earlier models.|sl:tag|tag:ai_knowledge_bases
RDF Schema inferencing|skos:broader|Inference
Courtadon|skos:broader|Pierre de Volvic
FN|skos:broader|Extrème droite
NG4J|skos:broader|Named Graphs
Stanford NER|skos:broader|Conditional random fields
Similarity Search for Efficient Active Learning and Search of Rare Concepts  Similarity search for Efficient Active Learning and Search (SEALS)    In [Active Learning](tag:active_learning): instead of searching globally for the optimal examples to label, leverage the fact that data is often heavily skewed and expand the candidate pool with the nearest neighbors of the labeled set.     Our work attacks both the labeling and computational costs of machine learning...SEALS dramatically reduces the barrier to machine learning, enabling small teams or individuals to  build accurate classifiers. SEALS does, however, introduce another system component, a similarity  search index, which adds some additional engineering complexity to build, tune, and maintain.  Fortunately, several highly optimized implementations like Annoy and [Faiss](doc:2020/06/facebookresearch_faiss_a_libra) work reasonably well  out of the box. Many active learning and search approaches are intractable for industrial settings with billions of unlabeled examples. Existing approaches, such as uncertainty sampling or information density, search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. However, in practice, data is often heavily skewed; only a small fraction of collected data will be relevant for a given learning task. For example, when identifying rare classes, detecting malicious content, or debugging model performance, the ratio of positive to negative examples can be 1 to 1,000 or more. In this work, we exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round by only looking at the nearest neighbors to the labeled examples. Empirically, we observe that learned representations effectively cluster unseen concepts, making active learning very effective and substantially reducing the number of viable unlabeled examples. We evaluate several active learning and search techniques in this setting on three large-scale datasets: ImageNet, Goodreads spoiler detection, and OpenImages. For rare classes, active learning methods need as little as 0.31% of the labeled data to match the average precision of full supervision. By limiting active learning methods to only consider the immediate neighbors of the labeled data as candidates for labeling, we need only process as little as 1% of the unlabeled data while achieving similar reductions in labeling costs as the traditional global approach. This process of expanding the candidate pool with the nearest neighbors of the labeled set can be done efficiently and reduces the computational complexity of selection by orders of magnitude.|sl:tag|tag:nearest_neighbor_search
Neuroscience|skos:broader|Brain
GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden unit), or embedding-free units such as image pixels.|sl:tag|tag:arxiv_doc
A Comparative Study of Word Embeddings for Reading Comprehension abstract:   The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on    1.  the use of pre-trained word embeddings, and  2. the representation of out-of-vocabulary tokens at test time,     can turn out to have a larger impact than architectural choices on the final performance         The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on (1) the use of pre-trained word embeddings, and (2) the representation of out-of-vocabulary tokens at test time, can turn out to have a larger impact than architectural choices on the final performance. We systematically explore several options for these choices, and provide recommendations to researchers working in this area.|sl:arxiv_author|William W. Cohen
Diplomatie américaine|skos:broader|Diplomatie
Test ADN de filiation|skos:broader|ADN
ERNIE: Enhanced Language Representation with Informative Entities  We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.|sl:arxiv_author|Xin Jiang
Liberté de la presse|skos:broader|Liberté
LinkNBed: Multi-Graph Representation Learning with Entity Linkage   a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure     We posit that combining  graph alignment task with deep representation  learning across multi-relational graphs has potential  to induce a synergistic effect on both tasks Knowledge graphs have emerged as an important model for studying complex multi-relational data. This has given rise to the construction of numerous large scale but incomplete knowledge graphs encoding information extracted from various resources. An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledge-based inference for many downstream applications. To this end, we propose LinkNBed, a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure. Experiments on link prediction and entity linkage demonstrate substantial improvements over the state-of-the-art relational learning approaches.|sl:arxiv_author|Rakshit Trivedi
Mladic|skos:broader|Serbie
Poker|skos:broader|Jeux
Scalable Nearest Neighbor Search for Optimal Transport The Optimal Transport (a.k.a. Wasserstein) distance is an increasingly popular similarity measure for rich data domains, such as images or text documents. This raises the necessity for fast nearest neighbor search with respect to this distance, a problem that poses a substantial computational bottleneck for various tasks on massive datasets. In this work, we study fast tree-based approximation algorithms for searching nearest neighbors w.r.t. the Wasserstein-1 distance. A standard tree-based technique, known as Quadtree, has been previously shown to obtain good results. We introduce a variant of this algorithm, called Flowtree, and formally prove it achieves asymptotically better accuracy. Our extensive experiments, on real-world text and image datasets, show that Flowtree improves over various baselines and existing methods in either running time or accuracy. In particular, its quality of approximation is in line with previous high-accuracy methods, while its running time is much faster.|sl:arxiv_author|Piotr Indyk
Deep Patent Landscaping Model Using Transformer and Graph Embedding a transformer encoder  for analyzing textual data present in patent documents  and a graph convolutional network for analyzing  patent metadata.    A benchmarking dataset for patent landscaping  based on patent trends reports published by the  Korean Patent Office. Data acquisition using Google's BigQuery public datasets.    10% improvement comparing to Google’s proposed Automated Patent Landscaping.    Empirical analysis of the importance of features (text vs metadata, citations vs classification)     Patent landscaping is a method used for searching related patents during a research and development (R&D) project. To avoid the risk of patent infringement and to follow current trends in technology, patent landscaping is a crucial task required during the early stages of an R&D project. As the process of patent landscaping requires advanced resources and can be tedious, the demand for automated patent landscaping has been gradually increasing. However, a shortage of well-defined benchmark datasets and comparable models makes it difficult to find related research studies. In this paper, we propose an automated patent landscaping model based on deep learning. To analyze the text of patents, the proposed model uses a modified transformer structure. To analyze the metadata of patents, we propose a graph embedding method that uses a diffusion graph called Diff2Vec. Furthermore, we introduce four benchmark datasets for comparing related research studies in patent landscaping. The datasets are produced by querying Google BigQuery, based on a search formula from a Korean patent attorney. The obtained results indicate that the proposed model and datasets can attain state-of-the-art performance, as compared with current patent landscaping models.|sl:tag|tag:graph_convolutional_networks
Apache web server|skos:broader|Open Source
RDF2RDFa|skos:broader|RDFa
Online Course Materials|skos:broader|MOOC
Mathieu d'Aquin|skos:broader|SW guys (and girls)
Clustering|skos:broader|Machine learning: problems
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).|sl:tag|tag:neural_machine_translation
Antiwork|skos:broader|Travail
Beyond Vector Spaces: Compact Data Representation as Differentiable Weighted Graphs  In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE (Probabilistic Differentiable Graph Embeddings): a method that learns a weighted graph representation of data end-to-end by gradient descent.    [Github](https://github.com/stanis-morozov/prodige)     Learning useful representations is a key ingredient to the success of modern machine learning. Currently, representation learning mostly relies on embedding data into Euclidean space. However, recent work has shown that data in some domains is better modeled by non-euclidean metric spaces, and inappropriate geometry can result in inferior performance. In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE: a method that learns a weighted graph representation of data end-to-end by gradient descent. Greater generality and fewer model assumptions make PRODIGE more powerful than existing embedding-based approaches. We confirm the superiority of our method via extensive experiments on a wide range of tasks, including classification, compression, and collaborative filtering.|sl:arxiv_author|Vage Egiazarian
Belgique|skos:broader|Pays d'Europe
LODr|skos:broader|Semanlink related
Jeopardy|skos:broader|Jeux
Gina Lollobrigida|skos:broader|Actrice
Feature selection|skos:broader|Features (Machine Learning)
general implementation of (arbitrary order) linear chain Conditional Random Field (CRF) sequence models |skos:broader|Class of statistical modelling method for structured prediction ( prediction of structured objects, rather than scalar) that can take context into account; e.g., in NLP, the linear chain CRF predicts sequences of labels for sequences of input samples (take  as input a set of features for each token in a  sentence, and learn to predict an optimal sequence of  labels for the full sentence)    Applications in POS Tagging, shallow parsing, named entity recognition, gene finding      
QuickTime|skos:broader|Media Player
Ranking SVM|skos:broader|Learning to rank
Efficient Estimation of Word Representations in Vector Space We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.   We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.|sl:tag|tag:word2vec
k-nearest neighbors algorithm|skos:broader|Algorithmes
Semantic Statistics|skos:broader|RDF
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:arxiv_author|Yun-Hsuan Sung
Wikilinks Corpus|skos:broader|Google Research
Neural networks|skos:broader|Artificial Intelligence
SPARQL AND Jena|skos:broader|Jena
Distant reading|skos:broader|Livre
Semantic Web : Portal|skos:broader|Semantic Web
Archéologie chinoise|skos:broader|Chine
Genetically Engineered Micro and Nanodevices|skos:broader|DNA nanotechnology
Credit default swap|skos:broader|Marchés financiers
Neural Architectures for Named Entity Recognition Neural architectures for NER that use no language-specific resources or features beyond a small amount of supervised training data and unlabeled corpora.      Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.|sl:tag|tag:guillaume_lample
Semantic Web Products|skos:broader|Semantic Web
Multimedia|skos:broader|Technologie
Bijan Parsia|skos:broader|Technical girls and guys
Steve Jobs|skos:broader|Homme célèbre
Facts as Experts: Adaptable and Interpretable Neural Memory over Symbolic Knowledge  a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge.... The model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones.     a  neural language model which learns to access information  in a symbolic knowledge graph.     This  model builds on the recently-proposed [Entities as  Experts](doc:2020/07/2004_07202_entities_as_expert) (EaE) language model (Févry et al., 2020),  which extends the same transformer (Vaswani  et al., 2017) architecture of BERT (Devlin et al., 2019) with an additional external memory for entities.     After training EaE, the embedding associated  with an entity will (ideally) capture information  about the textual context in which that  entity appears, and by inference, the entity’s semantic  properties     we include an additional  memory called a fact memory, which encodes  triples from a symbolic KB.     This combination results in a  neural language model which learns to access information  in a the symbolic knowledge graph.        TODO: read again IBM's [Span Selection Pre-training for Question Answering](doc:2019/09/_1909_04120_span_selection_pre) (an effort to avoid encoding general knowledge in the transformer network itself) Massive language models are the core of modern NLP modeling and have been shown to encode impressive amounts of commonsense and factual information. However, that knowledge exists only within the latent parameters of the model, inaccessible to inspection and interpretation, and even worse, factual information memorized from the training corpora is likely to become stale as the world changes. Knowledge stored as parameters will also inevitably exhibit all of the biases inherent in the source materials. To address these problems, we develop a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge. We show that this model dramatically improves performance on two knowledge-intensive question-answering tasks. More interestingly, the model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones in ways that are not possible for earlier models.|sl:tag|tag:nn_symbolic_ai_hybridation
Facts as Experts: Adaptable and Interpretable Neural Memory over Symbolic Knowledge  a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge.... The model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones.     a  neural language model which learns to access information  in a symbolic knowledge graph.     This  model builds on the recently-proposed [Entities as  Experts](doc:2020/07/2004_07202_entities_as_expert) (EaE) language model (Févry et al., 2020),  which extends the same transformer (Vaswani  et al., 2017) architecture of BERT (Devlin et al., 2019) with an additional external memory for entities.     After training EaE, the embedding associated  with an entity will (ideally) capture information  about the textual context in which that  entity appears, and by inference, the entity’s semantic  properties     we include an additional  memory called a fact memory, which encodes  triples from a symbolic KB.     This combination results in a  neural language model which learns to access information  in a the symbolic knowledge graph.        TODO: read again IBM's [Span Selection Pre-training for Question Answering](doc:2019/09/_1909_04120_span_selection_pre) (an effort to avoid encoding general knowledge in the transformer network itself) Massive language models are the core of modern NLP modeling and have been shown to encode impressive amounts of commonsense and factual information. However, that knowledge exists only within the latent parameters of the model, inaccessible to inspection and interpretation, and even worse, factual information memorized from the training corpora is likely to become stale as the world changes. Knowledge stored as parameters will also inevitably exhibit all of the biases inherent in the source materials. To address these problems, we develop a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge. We show that this model dramatically improves performance on two knowledge-intensive question-answering tasks. More interestingly, the model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones in ways that are not possible for earlier models.|sl:tag|tag:knowledge_augmented_language_models
Semantic Web : UI|skos:broader|UI
Driverless car|skos:broader|Automobile
TripleStore|skos:broader|RDF
Consciousness Prior|skos:broader|Representation learning
InceptionTime: Finding AlexNet for Time Series Classification Time series classification (TSC) is the area of machine learning interested in learning how to assign labels to time series. The last few decades of work in this area have led to significant progress in the accuracy of classifiers, with the state of the art now represented by the HIVE-COTE algorithm. While extremely accurate, HIVE-COTE is infeasible to use in many applications because of its very high training time complexity in O(N^2T^4) for a dataset with N time series of length T. For example, it takes HIVE-COTE more than 72,000s to learn from a small dataset with N=700 time series of short length T=46. Deep learning, on the other hand, has now received enormous attention because of its high scalability and state-of-the-art accuracy in computer vision and natural language processing tasks. Deep learning for TSC has only very recently started to be explored, with the first few architectures developed over the last 3 years only. The accuracy of deep learning for TSC has been raised to a competitive level, but has not quite reached the level of HIVE-COTE. This is what this paper achieves: outperforming HIVE-COTE's accuracy together with scalability. We take an important step towards finding the AlexNet network for TSC by presenting InceptionTime---an ensemble of deep Convolutional Neural Network (CNN) models, inspired by the Inception-v4 architecture. Our experiments show that InceptionTime slightly outperforms HIVE-COTE with a win/draw/loss on the UCR archive of 40/6/39. Not only is InceptionTime more accurate, but it is much faster: InceptionTime learns from that same dataset with 700 time series in 2,300s but can also learn from a dataset with 8M time series in 13 hours, a quantity of data that is fully out of reach of HIVE-COTE.|sl:arxiv_author|Hassan Ismail Fawaz
IKS Workshop Salzburg 2012|skos:broader|Workshop
Duck Typing|skos:broader|Type system
Knowledge Graph Embeddings and Explainable AI survey of     - the state-of-the-art in the field of knowledge graph embeddings  - methods for explaining predictions obtained via knowledge graph embeddings. Knowledge graph embeddings are now a widely adopted approach to knowledge representation in which entities and relationships are embedded in vector spaces. In this chapter, we introduce the reader to the concept of knowledge graph embeddings by explaining what they are, how they can be generated and how they can be evaluated. We summarize the state-of-the-art in this field by describing the approaches that have been introduced to represent knowledge in the vector space. In relation to knowledge representation, we consider the problem of explainability, and discuss models and methods for explaining predictions obtained via knowledge graph embeddings.|sl:arxiv_author|Federico Bianchi
Messenger|skos:broader|NASA
Disque à retrouver|skos:broader|Musique
LODr|skos:broader|Linked Data
RDF editor|skos:broader|RDF Tools
Continual Lifelong Learning with Neural Networks: A Review Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.|sl:arxiv_author|German I. Parisi
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Peter W. Battaglia
A Theoretical Analysis of Contrastive Unsupervised Representation Learning [blog post](/doc/?uri=http%3A%2F%2Fwww.offconvex.org%2F2019%2F03%2F19%2FCURL%2F) Recent empirical works have successfully used unlabeled data to learn feature representations that are broadly useful in downstream classification tasks. Several of these methods are reminiscent of the well-known word2vec embedding algorithm: leveraging availability of pairs of semantically similar data points and negative samples, the learner forces the inner product of representations of similar pairs with each other to be higher on average than with negative samples. The current paper uses the term contrastive learning for such algorithms and presents a theoretical framework for analyzing them by introducing latent classes and hypothesizing that semantically similar points are sampled from the same latent class. This framework allows us to show provable guarantees on the performance of the learned representations on the average classification task that is comprised of a subset of the same set of latent classes. Our generalization bound also shows that learned representations can reduce (labeled) sample complexity on downstream tasks. We conduct controlled experiments in both the text and image domains to support the theory.|sl:arxiv_author|Nikunj Saunshi
Le Pen|skos:broader|Immigration
Sustainable materials lifecycle|skos:broader|Économie écologique
ElasticSearch: annotated text field|skos:broader|ElasticSearch
Insecticide|skos:broader|Insecte
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).|sl:arxiv_author|Ming-Wei Chang
Hash Embeddings for Efficient Word Representations  A hash embedding may be seen as an interpolation between  a standard word embedding and a word embedding created using a random hash  function (the hashing trick).    recommandé par [Raphaël Sourty](tag:raphaelsty) We present hash embeddings, an efficient method for representing words in a continuous vector form. A hash embedding may be seen as an interpolation between a standard word embedding and a word embedding created using a random hash function (the hashing trick). In hash embeddings each token is represented by $k$ $d$-dimensional embeddings vectors and one $k$ dimensional weight vector. The final $d$ dimensional representation of the token is the product of the two. Rather than fitting the embedding vectors for each token these are selected by the hashing trick from a shared pool of $B$ embedding vectors. Our experiments show that hash embeddings can easily deal with huge vocabularies consisting of millions of tokens. When using a hash embedding there is no need to create a dictionary before training nor to perform any kind of vocabulary pruning after training. We show that models trained using hash embeddings exhibit at least the same level of performance as models trained using regular embeddings across a wide range of tasks. Furthermore, the number of parameters needed by such an embedding is only a fraction of what is required by a regular embedding. Since standard embeddings and embeddings constructed using the hashing trick are actually just special cases of a hash embedding, hash embeddings can be considered an extension and improvement over the existing regular embedding types.|sl:arxiv_author|Dan Svenstrup
fast.ai|skos:broader|Online Course Materials
Graph database|skos:broader|Database
Facts as Experts: Adaptable and Interpretable Neural Memory over Symbolic Knowledge  a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge.... The model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones.     a  neural language model which learns to access information  in a symbolic knowledge graph.     This  model builds on the recently-proposed [Entities as  Experts](doc:2020/07/2004_07202_entities_as_expert) (EaE) language model (Févry et al., 2020),  which extends the same transformer (Vaswani  et al., 2017) architecture of BERT (Devlin et al., 2019) with an additional external memory for entities.     After training EaE, the embedding associated  with an entity will (ideally) capture information  about the textual context in which that  entity appears, and by inference, the entity’s semantic  properties     we include an additional  memory called a fact memory, which encodes  triples from a symbolic KB.     This combination results in a  neural language model which learns to access information  in a the symbolic knowledge graph.        TODO: read again IBM's [Span Selection Pre-training for Question Answering](doc:2019/09/_1909_04120_span_selection_pre) (an effort to avoid encoding general knowledge in the transformer network itself) Massive language models are the core of modern NLP modeling and have been shown to encode impressive amounts of commonsense and factual information. However, that knowledge exists only within the latent parameters of the model, inaccessible to inspection and interpretation, and even worse, factual information memorized from the training corpora is likely to become stale as the world changes. Knowledge stored as parameters will also inevitably exhibit all of the biases inherent in the source materials. To address these problems, we develop a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge. We show that this model dramatically improves performance on two knowledge-intensive question-answering tasks. More interestingly, the model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones in ways that are not possible for earlier models.|sl:arxiv_firstAuthor|Pat Verga
A Tutorial on Network Embeddings Network embedding methods aim at learning low-dimensional latent representation of nodes in a network. These representations can be used as features for a wide range of tasks on graphs such as classification, clustering, link prediction, and visualization. In this survey, we give an overview of network embeddings by summarizing and categorizing recent advancements in this research field. We first discuss the desirable properties of network embeddings and briefly introduce the history of network embedding algorithms. Then, we discuss network embedding methods under different scenarios, such as supervised versus unsupervised learning, learning embeddings for homogeneous networks versus for heterogeneous networks, etc. We further demonstrate the applications of network embeddings, and conclude the survey with future work in this area.|sl:arxiv_author|Rami Al-Rfou
Jardinage|skos:broader|Divers
KG-BERT: BERT for Knowledge Graph Completion Pre-trained language models for knowledge graph completion. Triples are treated as textual sequences. (Hum, j'ai déjà vu ça quelque part) Knowledge graphs are important resources for many artificial intelligence tasks but often suffer from incompleteness. In this work, we propose to use pre-trained language models for knowledge graph completion. We treat triples in knowledge graphs as textual sequences and propose a novel framework named Knowledge Graph Bidirectional Encoder Representations from Transformer (KG-BERT) to model these triples. Our method takes entity and relation descriptions of a triple as input and computes scoring function of the triple with the KG-BERT language model. Experimental results on multiple benchmark knowledge graphs show that our method can achieve state-of-the-art performance in triple classification, link prediction and relation prediction tasks.|sl:tag|tag:arxiv_doc
Recherche française|skos:broader|Recherche
Deep Patent Landscaping Model Using Transformer and Graph Embedding a transformer encoder  for analyzing textual data present in patent documents  and a graph convolutional network for analyzing  patent metadata.    A benchmarking dataset for patent landscaping  based on patent trends reports published by the  Korean Patent Office. Data acquisition using Google's BigQuery public datasets.    10% improvement comparing to Google’s proposed Automated Patent Landscaping.    Empirical analysis of the importance of features (text vs metadata, citations vs classification)     Patent landscaping is a method used for searching related patents during a research and development (R&D) project. To avoid the risk of patent infringement and to follow current trends in technology, patent landscaping is a crucial task required during the early stages of an R&D project. As the process of patent landscaping requires advanced resources and can be tedious, the demand for automated patent landscaping has been gradually increasing. However, a shortage of well-defined benchmark datasets and comparable models makes it difficult to find related research studies. In this paper, we propose an automated patent landscaping model based on deep learning. To analyze the text of patents, the proposed model uses a modified transformer structure. To analyze the metadata of patents, we propose a graph embedding method that uses a diffusion graph called Diff2Vec. Furthermore, we introduce four benchmark datasets for comparing related research studies in patent landscaping. The datasets are produced by querying Google BigQuery, based on a search formula from a Korean patent attorney. The obtained results indicate that the proposed model and datasets can attain state-of-the-art performance, as compared with current patent landscaping models.|sl:arxiv_firstAuthor|Seokkyu Choi
Javascript RDF|skos:broader|JavaScript
Distilling the Knowledge in a Neural Network  a different kind of training, which we call “distillation” to transfer the  knowledge from the cumbersome model to a small model that is more  suitable for deployment       Caruana and his collaborators have shown that it is possible to compress the knowledge in an [#ensemble](/tag/ensemble_learning.html) into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST. A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.|sl:arxiv_firstAuthor|Geoffrey Hinton
Specializing Word Embeddings (for Parsing) by Information Bottleneck EMNLP best paper award. [Related blog post](doc:2020/06/information_bottleneck_for_nlp_) Pre-trained word embeddings like ELMo and BERT contain rich syntactic and semantic information, resulting in state-of-the-art performance on various tasks. We propose a very fast variational information bottleneck (VIB) method to nonlinearly compress these embeddings, keeping only the information that helps a discriminative parser. We compress each word embedding to either a discrete tag or a continuous vector. In the discrete version, our automatically compressed tags form an alternative tag set: we show experimentally that our tags capture most of the information in traditional POS tag annotations, but our tag sequences can be parsed more accurately at the same level of tag granularity. In the continuous version, we show experimentally that moderately compressing the word embeddings by our method yields a more accurate parser in 8 of 9 languages, unlike simple dimensionality reduction.|sl:arxiv_author|Xiang Lisa Li
Ondes gravitationnelles|skos:broader|Gravitation
Semi-supervised Clustering for Short Text via Deep Representation Learning semi-supervised method for short text clustering, where we represent texts as distributed vectors with neural networks, and use a small amount of labeled data to specify our intention for clustering. We design a novel objective to combine the representation learning process and the k-means clustering process together, and optimize the objective with both labeled data and unlabeled data iteratively until convergence through three steps:     1. assign each short text to its nearest centroid based on its representation from the current neural networks;  2. re-estimate the cluster centroids based on cluster assignments from step (1);  3. update neural networks according to the objective by keeping centroids and cluster assignments fixed.   In this work, we propose a semi-supervised method for short text clustering, where we represent texts as distributed vectors with neural networks, and use a small amount of labeled data to specify our intention for clustering. We design a novel objective to combine the representation learning process and the k-means clustering process together, and optimize the objective with both labeled data and unlabeled data iteratively until convergence through three steps: (1) assign each short text to its nearest centroid based on its representation from the current neural networks; (2) re-estimate the cluster centroids based on cluster assignments from step (1); (3) update neural networks according to the objective by keeping centroids and cluster assignments fixed. Experimental results on four datasets show that our method works significantly better than several other text clustering methods.|sl:arxiv_author|Zhiguo Wang
Etudes scientifiques|skos:broader|Enseignement
Chine : technologie|skos:broader|Chine
Ex URSS URSS|skos:broader|Europe
Replace or Retrieve Keywords In Documents at Scale For a document of size N (characters) and a dictionary of M keywords, the time complexity is O(N) (compared to O(MxN) with regex). FlashText is designed to only match complete words (words with boundary characters on both sides). Different from Aho Corasick Algorithm, as it doesn't match substrings. This algorithm is also designed to go for the longest match first. For an input dictionary {Machine, Learning, Machine learning} on a string 'I like Machine learning', it will only consider the longest match, which is Machine Learning    [Github](https://github.com/vi3k6i5/flashtext) In this paper we introduce, the FlashText algorithm for replacing keywords or finding keywords in a given text. FlashText can search or replace keywords in one pass over a document. The time complexity of this algorithm is not dependent on the number of terms being searched or replaced. For a document of size N (characters) and a dictionary of M keywords, the time complexity will be O(N). This algorithm is much faster than Regex, because regex time complexity is O(MxN). It is also different from Aho Corasick Algorithm, as it doesn't match substrings. FlashText is designed to only match complete words (words with boundary characters on both sides). For an input dictionary of {Apple}, this algorithm won't match it to 'I like Pineapple'. This algorithm is also designed to go for the longest match first. For an input dictionary {Machine, Learning, Machine learning} on a string 'I like Machine learning', it will only consider the longest match, which is Machine Learning. We have made python implementation of this algorithm available as open-source on GitHub, released under the permissive MIT License.|sl:tag|tag:regex
Retrofitting Word Vectors to Semantic Lexicons Method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed.     Graph-based learning technique for using lexical relational resources to obtain higher quality semantic vectors, which we call “retrofitting.” Retrofitting is applied as a post-processing step by running belief propagation on a graph constructed from lexicon-derived relational information to update word vectors. This allows retrofitting to be used on pre-trained word vectors obtained using any vector training model.    [github](https://github.com/mfaruqui/retrofitting)     Vector space word representations are learned from distributional information of words in large corpora. Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database. This paper proposes a method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed. Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, we obtain substantial improvements starting with a variety of word vector models. Our refinement method outperforms prior techniques for incorporating semantic lexicons into the word vector training algorithms.|sl:arxiv_author|Sujay K. Jauhar
Blogs Le Monde|skos:broader|Blog
BAM! Born-Again Multi-Task Networks for Natural Language Understanding  knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers It can be challenging to train multi-task neural networks that outperform or even match their single-task counterparts. To help address this, we propose using knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers. We evaluate our approach by multi-task fine-tuning BERT on the GLUE benchmark. Our method consistently improves over standard single-task and multi-task training.|sl:arxiv_author|Minh-Thang Luong
NLP: Français|skos:broader|Natural Language Processing
Efficient Contextual Representation Learning Without Softmax Layer how to accelerate contextual representation learning.     Contextual representation models are difficult to train due to the large parameter sizes and high computational complexity     We find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size.  Therefore, we redesign the learning objectiv.   Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings.  Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary.  When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.    decouples learning contexts and words     Instead of using  a softmax layer to predict the distribution of the  missing word, we utilize and extend the SEMFIT  layer (Kumar and Tsvetkov, 2018) to predict the  embedding of the missing word. Contextual representation models have achieved great success in improving various downstream tasks. However, these language-model-based encoders are difficult to train due to the large parameter sizes and high computational complexity. By carefully examining the training procedure, we find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size. Therefore, we redesign the learning objective and propose an efficient framework for training contextual representation models. Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings. Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary. When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.|sl:arxiv_author|Patrick H. Chen
Peinture rupestre|skos:broader|Rockart
Beijing Genomics Institute|skos:broader|Clonage
WSDL|skos:broader|Web Services
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:arxiv_firstAuthor|Daniel Cer
A Little Annotation does a Lot of Good: A Study in Bootstrapping Low-resource Named Entity Recognizers Most state-of-the-art models for named entity recognition (NER) rely on the availability of large amounts of labeled data, making them challenging to extend to new, lower-resourced languages. However, there are now several proposed approaches involving either cross-lingual transfer learning, which learns from other highly resourced languages, or active learning, which efficiently selects effective training data based on model predictions. This paper poses the question: given this recent progress, and limited human annotation, what is the most effective method for efficiently creating high-quality entity recognizers in under-resourced languages? Based on extensive experimentation using both simulated and real human annotation, we find a dual-strategy approach best, starting with a cross-lingual transferred model, then performing targeted annotation of only uncertain entity spans in the target language, minimizing annotator effort. Results demonstrate that cross-lingual transfer is a powerful tool when very little data can be annotated, but an entity-targeted annotation strategy can achieve competitive accuracy quickly, with just one-tenth of training data.|sl:arxiv_author|Jiateng Xie
Tandja|skos:broader|Niger
Lexical Resource Text corpus Text corpora|skos:broader|Natural Language Processing
Java 8 lambdas|skos:broader|Java 8
XTech 2007|skos:broader|XTech
Néolithique|skos:broader|Archéologie
Juan Sequeda|skos:broader|SW guys (and girls)
Aho–Corasick algorithm|skos:broader|String-searching algorithm
Stefan Zweig|skos:broader|Grand Homme
Tomas Mikolov|skos:broader|AI girls and guys
Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective reviews the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. Neural-symbolic computing has now become the subject of interest of both academic and industry research laboratories. Graph Neural Networks (GNN) have been widely used in relational and symbolic domains, with widespread application of GNNs in combinatorial optimization, constraint satisfaction, relational reasoning and other scientific domains. The need for improved explainability, interpretability and trust of AI systems in general demands principled methodologies, as suggested by neural-symbolic computing. In this paper, we review the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. This includes the application of GNNs in several domains as well as its relationship to current developments in neural-symbolic computing.|sl:arxiv_author|Artur Garcez
Réparation automobile|skos:broader|Automobile
AutoML-Zero: Evolving Machine Learning Algorithms From Scratch  Fun AutoML-Zero experiments: Evolutionary search discovers fundamental ML algorithms from scratch, e.g., small neural nets with backprop.   Can evolution be the “Master Algorithm”? ;) Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.|sl:tag|tag:automl
Duck Typing|skos:broader|Programming
Beyond Vector Spaces: Compact Data Representation as Differentiable Weighted Graphs  In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE (Probabilistic Differentiable Graph Embeddings): a method that learns a weighted graph representation of data end-to-end by gradient descent.    [Github](https://github.com/stanis-morozov/prodige)     Learning useful representations is a key ingredient to the success of modern machine learning. Currently, representation learning mostly relies on embedding data into Euclidean space. However, recent work has shown that data in some domains is better modeled by non-euclidean metric spaces, and inappropriate geometry can result in inferior performance. In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE: a method that learns a weighted graph representation of data end-to-end by gradient descent. Greater generality and fewer model assumptions make PRODIGE more powerful than existing embedding-based approaches. We confirm the superiority of our method via extensive experiments on a wide range of tasks, including classification, compression, and collaborative filtering.|sl:arxiv_author|Artem Babenko
BBC semantic publishing|skos:broader|semantic web sites
Logiciel libre|skos:broader|Open Source
Wikipedia page to concept|skos:broader|Wikipedia
Tomcat|skos:broader|apache.org
Recurrent Memory Networks for Language Modeling  Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge.     In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data.     We demonstrate the power of RMN on language modeling and sentence completion tasks.     On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.   Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge. In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data. We demonstrate the power of RMN on language modeling and sentence completion tasks. On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.|sl:tag|tag:lstm_networks
What Does BERT Look At? An Analysis of BERT's Attention Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT's attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT's attention.|sl:tag|tag:deep_learning_attention
Attention Models in Graphs: A Survey  An attention mechanism aids a model by  allowing it to focus on the most relevant parts of the input to make decisions   Graph-structured data arise naturally in many different application domains. By representing data as graphs, we can capture entities (i.e., nodes) as well as their relationships (i.e., edges) with each other. Many useful insights can be derived from graph-structured data as demonstrated by an ever-growing body of work focused on graph mining. However, in the real-world, graphs can be both large - with many complex patterns - and noisy which can pose a problem for effective graph mining. An effective way to deal with this issue is to incorporate attention into graph mining solutions. An attention mechanism allows a method to focus on task-relevant parts of the graph, helping it to make better decisions. In this work, we conduct a comprehensive and focused survey of the literature on the emerging field of graph attention models. We introduce three intuitive taxonomies to group existing work. These are based on problem setting (type of input and output), the type of attention mechanism used, and the task (e.g., graph classification, link prediction, etc.). We motivate our taxonomies through detailed examples and use each to survey competing approaches from a unique standpoint. Finally, we highlight several challenges in the area and discuss promising directions for future work.|sl:tag|tag:survey
RFID passports|skos:broader|Big Brother
Large deviations for the perceptron model and consequences for active learning the task of choosing the subset of samples to be labeled from a fixed finite pool of samples Active learning is a branch of machine learning that deals with problems where unlabeled data is abundant yet obtaining labels is expensive. The learning algorithm has the possibility of querying a limited number of samples to obtain the corresponding labels, subsequently used for supervised learning. In this work, we consider the task of choosing the subset of samples to be labeled from a fixed finite pool of samples. We assume the pool of samples to be a random matrix and the ground truth labels to be generated by a single-layer teacher random neural network. We employ replica methods to analyze the large deviations for the accuracy achieved after supervised learning on a subset of the original pool. These large deviations then provide optimal achievable performance boundaries for any active learning algorithm. We show that the optimal learning performance can be efficiently approached by simple message-passing active learning algorithms. We also provide a comparison with the performance of some other popular active learning strategies.|sl:arxiv_author|Hugo Cui
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:arxiv_author|Kuansan Wang
Joint Embedding of Hierarchical Categories and Entities for Concept Categorization and Dataless Classification a framework that embeds entities and categories into a semantic space by integrating structured  knowledge and taxonomy hierarchy from large knowledge bases.    two methods:    1. Category Embedding model): it replaces the entities in the context with their directly  labeled categories to build categories’ context;   2. Hierarchical Category Embedding: it  further incorporates all ancestor categories of the context entities to utilize the hierarchical information. Due to the lack of structured knowledge applied in learning distributed representation of cate- gories, existing work cannot incorporate category hierarchies into entity information. We propose a framework that embeds entities and categories into a semantic space by integrating structured knowledge and taxonomy hierarchy from large knowledge bases. The framework allows to com- pute meaningful semantic relatedness between entities and categories. Our framework can han- dle both single-word concepts and multiple-word concepts with superior performance on concept categorization and yield state of the art results on dataless hierarchical classification.|sl:arxiv_author|Tian Tian
Lynda Tamine|skos:broader|NLP girls and guys
Variabilité du génome humain|skos:broader|Génétique humaine
Using word embeddings|skos:broader|Word embeddings
Hollywood|skos:broader|Content industries
Conjecture de Poincaré|skos:broader|Grands problèmes mathématiques
Machine learning: problems|skos:broader|Machine learning
Doc by Google|skos:broader|Google
Prix Nobel de physique|skos:broader|Physique
Pre-Trained Language Models|skos:broader|NLP techniques
Goldman Sachs|skos:broader|Finance
W3C Note|skos:broader|W3C
Nombres premiers|skos:broader|Mathématiques
Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective reviews the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. Neural-symbolic computing has now become the subject of interest of both academic and industry research laboratories. Graph Neural Networks (GNN) have been widely used in relational and symbolic domains, with widespread application of GNNs in combinatorial optimization, constraint satisfaction, relational reasoning and other scientific domains. The need for improved explainability, interpretability and trust of AI systems in general demands principled methodologies, as suggested by neural-symbolic computing. In this paper, we review the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. This includes the application of GNNs in several domains as well as its relationship to current developments in neural-symbolic computing.|sl:arxiv_author|Luis Lamb
Internet en Afrique|skos:broader|Internet
Rosetta|skos:broader|Missions spatiales
Object Oriented Programming|skos:broader|Dev
Decision tree learning|skos:broader|Machine learning: techniques
Mutual information|skos:broader|Information theory
Government data|skos:broader|Public data
Pollueurs payeurs|skos:broader|Économie écologique
Zero-shot Entity Linking with Dense Entity Retrieval We consider the zero-shot entity-linking challenge where each entity is defined by a short textual description, and the model must read these descriptions together with the mention context to make the final linking decisions. In this setting, retrieving entity candidates can be particularly challenging, since many of the common linking cues such as entity alias tables and link popularity are not available. In this paper, we introduce a simple and effective two stage approach for zero-shot linking, based on fine-tuned BERT architectures. In the first stage, we do retrieval in a dense space defined by a bi-encoder that independently embeds the mention context and the entity descriptions. Each candidate is then examined more carefully with a cross-encoder, that concatenates the mention and entity text. Our approach achieves a nearly 5 point absolute gain on a recently introduced zero-shot entity linking benchmark, driven largely by improvements over previous IR-based candidate retrieval. We also show that it performs well in the non-zero-shot setting, obtaining the state-of-the-art result on TACKBP-2010.|sl:arxiv_author|Sebastian Riedel
Scientologie|skos:broader|Manipulation
Fado tropical|skos:broader|Conquistadores
Emmanuelle Bernes|skos:broader|SW guys (and girls)
Sarraounia Mangou|skos:broader|Empire colonial français
A Review of Relational Machine Learning for Knowledge Graphs Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be trained on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive datasets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Google's Knowledge Vault project as an example of such combination.|sl:tag|tag:statistical_relational_learning
Minimum wage|skos:broader|Bas salaires
Scientifique|skos:broader|Science
FastText|skos:broader|Text Classification
Axel Ngonga|skos:broader|SW guys (and girls)
Hypermedia driven web APIs.br/  The basic idea behind Hydra is to provide a bvocabulary which enables a server to advertise valid state transitions to a client/b. A client can then use this information to construct HTTP requests which modify the server’s state so that a certain desired goal is achieved. Since all the information about the valid state transitions is exchanged in a machine-processable way at runtime instead of being hardcoded into the client at design time, clients can be decoupled from the server and adapt to changes more easily.|skos:broader|Hypermedia as the Engine of Application State  
Multi-Task Deep Neural Networks for Natural Language Understanding outperforms BERT in nine of eleven benchmark NLP tasks In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations in order to adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7% (2.2% absolute improvement). We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. The code and pre-trained models are publicly available at https://github.com/namisan/mt-dnn.|sl:tag|tag:multi_task_learning
Histoire de la Chine|skos:broader|Histoire
k-means clustering|skos:broader|Clustering
IMS VDEX|skos:broader|Thesaurus
LD|skos:broader|Web sémantique sw
Topic2Vec: Learning Distributed Representations of Topics Topic2Vec aims at learning topic representations along with word representations. Considering the simplicity and efficient solution, we just follow the optimization scheme that used in Word2Vec Latent Dirichlet Allocation (LDA) mining thematic structure of documents plays an important role in nature language processing and machine learning areas. However, the probability distribution from LDA only describes the statistical relationship of occurrences in the corpus and usually in practice, probability is not the best choice for feature representations. Recently, embedding methods have been proposed to represent words and documents by learning essential concepts and representations, such as Word2Vec and Doc2Vec. The embedded representations have shown more effectiveness than LDA-style representations in many tasks. In this paper, we propose the Topic2Vec approach which can learn topic representations in the same semantic vector space with words, as an alternative to probability. The experimental results show that Topic2Vec achieves interesting and meaningful results.|sl:arxiv_author|Xin-Yu Dai
Semantic Web Services vs SOAP|skos:broader|SOAP
Krakatoa|skos:broader|Indonésie
Variable Selection Methods for Model-based Clustering Model-based clustering is a popular approach for clustering multivariate data which has seen applications in numerous fields. Nowadays, high-dimensional data are more and more common and the model-based clustering approach has adapted to deal with the increasing dimensionality. In particular, the development of variable selection techniques has received a lot of attention and research effort in recent years. Even for small size problems, variable selection has been advocated to facilitate the interpretation of the clustering results. This review provides a summary of the methods developed for variable selection in model-based clustering. Existing R packages implementing the different methods are indicated and illustrated in application to two data analysis examples.|sl:arxiv_firstAuthor|Michael Fop
AI 4 IP|skos:broader|IA/ML: domaines d'application
Terrorisme islamiste|skos:broader|Guerres de religion
Océan indien|skos:broader|Océan
js|skos:broader|Langage de programmation
BRAIN Initiative|skos:broader|Neuroscience
Steve Cayzer|skos:broader|Technical girls and guys
Dynamic Semantic Publishing|skos:broader|Linked Data
Similarity Search for Efficient Active Learning and Search of Rare Concepts  Similarity search for Efficient Active Learning and Search (SEALS)    In [Active Learning](tag:active_learning): instead of searching globally for the optimal examples to label, leverage the fact that data is often heavily skewed and expand the candidate pool with the nearest neighbors of the labeled set.     Our work attacks both the labeling and computational costs of machine learning...SEALS dramatically reduces the barrier to machine learning, enabling small teams or individuals to  build accurate classifiers. SEALS does, however, introduce another system component, a similarity  search index, which adds some additional engineering complexity to build, tune, and maintain.  Fortunately, several highly optimized implementations like Annoy and [Faiss](doc:2020/06/facebookresearch_faiss_a_libra) work reasonably well  out of the box. Many active learning and search approaches are intractable for industrial settings with billions of unlabeled examples. Existing approaches, such as uncertainty sampling or information density, search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. However, in practice, data is often heavily skewed; only a small fraction of collected data will be relevant for a given learning task. For example, when identifying rare classes, detecting malicious content, or debugging model performance, the ratio of positive to negative examples can be 1 to 1,000 or more. In this work, we exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round by only looking at the nearest neighbors to the labeled examples. Empirically, we observe that learned representations effectively cluster unseen concepts, making active learning very effective and substantially reducing the number of viable unlabeled examples. We evaluate several active learning and search techniques in this setting on three large-scale datasets: ImageNet, Goodreads spoiler detection, and OpenImages. For rare classes, active learning methods need as little as 0.31% of the labeled data to match the average precision of full supervision. By limiting active learning methods to only consider the immediate neighbors of the labeled data as candidates for labeling, we need only process as little as 1% of the unlabeled data while achieving similar reductions in labeling costs as the traditional global approach. This process of expanding the candidate pool with the nearest neighbors of the labeled set can be done efficiently and reduces the computational complexity of selection by orders of magnitude.|sl:tag|tag:facebook_fair
H5N1|skos:broader|Virus
Outlier Detection|skos:broader|Machine learning: problems
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Jessica B. Hamrick
Bart van Leeuwen|skos:broader|Firefighter
Relational inductive bias|skos:broader|Learning bias
Learning with Memory Embeddings Embedding learning, a.k.a. representation learning, has been shown to be able to model large-scale semantic knowledge graphs. A key concept is a mapping of the knowledge graph to a tensor representation whose entries are predicted by models using latent representations of generalized entities. Latent variable models are well suited to deal with the high dimensionality and sparsity of typical knowledge graphs. In recent publications the embedding models were extended to also consider time evolutions, time patterns and subsymbolic representations. In this paper we map embedding models, which were developed purely as solutions to technical problems for modelling temporal knowledge graphs, to various cognitive memory functions, in particular to semantic and concept memory, episodic memory, sensory memory, short-term memory, and working memory. We discuss learning, query answering, the path from sensory input to semantic decoding, and the relationship between episodic memory and semantic memory. We introduce a number of hypotheses on human memory that can be derived from the developed mathematical models.|sl:arxiv_author|Volker Tresp
Identification of similar documents|skos:broader|Text Similarity
Apes|skos:broader|Endangered Species
SIMILE|skos:broader|Semantic Web : Application
Cliqz|skos:broader|Search Engines
RapidMiner|skos:broader|Analyse sémantique
Semantic Web: CRM|skos:broader|Semantic Web
Laurent Lafforgue|skos:broader|Médaille Fields
Turquie|skos:broader|Asie
Jermakoye|skos:broader|Dosso
Exploring the Limits of Language Modeling recent advances in Recurrent Neural Networks for large scale Language Modeling In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon.|sl:tag|tag:language_model
A Survey Of Cross-lingual Word Embedding Models Cross-lingual representations of words enable us to reason about word meaning in multilingual contexts and are a key facilitator of cross-lingual transfer when developing natural language processing models for low-resource languages. In this survey, we provide a comprehensive typology of cross-lingual word embedding models. We compare their data requirements and objective functions. The recurring theme of the survey is that many of the models presented in the literature optimize for the same objectives, and that seemingly different models are often equivalent modulo optimization strategies, hyper-parameters, and such. We also discuss the different ways cross-lingual word embeddings are evaluated, as well as future challenges and research horizons.|sl:arxiv_author|Ivan Vulić
Text feature extraction|skos:broader|General NLP tasks
LinkNBed: Multi-Graph Representation Learning with Entity Linkage   a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure     We posit that combining  graph alignment task with deep representation  learning across multi-relational graphs has potential  to induce a synergistic effect on both tasks Knowledge graphs have emerged as an important model for studying complex multi-relational data. This has given rise to the construction of numerous large scale but incomplete knowledge graphs encoding information extracted from various resources. An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledge-based inference for many downstream applications. To this end, we propose LinkNBed, a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure. Experiments on link prediction and entity linkage demonstrate substantial improvements over the state-of-the-art relational learning approaches.|sl:arxiv_author|Christos Faloutsos
Deep Unsupervised Learning|skos:broader|Unsupervised machine learning
Catastrophe naturelle|skos:broader|Catastrophe
NLP: Reading Comprehension|skos:broader|NLP tasks / problems
email classification|skos:broader|email
FBI v. Apple|skos:broader|Tim Cook
Zika|skos:broader|Moustique
China's Social Credit System|skos:broader|Reputation system
Cloud based LOD platform|skos:broader|Linked Data Platform
General NLP tasks|skos:broader|NLP tasks / problems
One-Shot Generalization in Deep Generative Models Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our models are able to generate compelling and diverse samples---having seen new examples just once---providing an important class of general-purpose models for one-shot machine learning.|sl:tag|tag:arxiv_doc
Syngenta|skos:broader|Biotech industry
Fichage génétique|skos:broader|Big Brother
TopQuadrant|skos:broader|Semantic web company
Lexicon Infused Phrase Embeddings for Named Entity Resolution Employs lexicons as part of the word embedding training:      The skip-gram model can be trained to  predict not only neighboring words but also lexicon  membership of the central word (or phrase).    Quickly demonstrates how we can plug phrase embeddings  into an existing log-linear CRF System.     Most state-of-the-art approaches for named-entity recognition (NER) use semi supervised information in the form of word clusters and lexicons. Recently neural network-based language models have been explored, as they as a byproduct generate highly informative vector representations for words, known as word embeddings. In this paper we present two contributions: a new form of learning word embeddings that can leverage information from relevant lexicons to improve the representations, and the first system to use neural word embeddings to achieve state-of-the-art results on named-entity recognition in both CoNLL and Ontonotes NER. Our system achieves an F1 score of 90.90 on the test set for CoNLL 2003---significantly better than any previous system trained on public data, and matching a system employing massive private industrial query-log data.|sl:arxiv_author|Vineet Kumar
A Metric Learning Reality Check Deep metric learning papers from the past four years have consistently claimed great advances in accuracy, often more than doubling the performance of decade-old methods. In this paper, we take a closer look at the field to see if this is actually true. We find flaws in the experimental setup of these papers, and propose a new way to evaluate metric learning algorithms. Finally, we present experimental results that show that the improvements over time have been marginal at best.|sl:tag|tag:arxiv_doc
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:tag|tag:axel_polleres
Self-Taught Hashing for Fast Similarity Search Emphasise following issue in Semantic Hashing: obtaining the codes for previously unseen documents. Propose following approach:  first find the optimal l-bit binary codes for all documents in  the given corpus via unsupervised learning, then train  l classifiers via supervised learning to predict the l-bit code  for any query document unseen before.    (méthode résumée [ici](https://www.semanticscholar.org/paper/Semantic-hashing-using-tags-and-topic-modeling-Wang-Zhang/1a0f660f70fd179003edc271694736baaa39dec4))       The ability of fast similarity search at large scale is of great importance to many Information Retrieval (IR) applications. A promising way to accelerate similarity search is semantic hashing which designs compact binary codes for a large number of documents so that semantically similar documents are mapped to similar codes (within a short Hamming distance). Although some recently proposed techniques are able to generate high-quality codes for documents known in advance, obtaining the codes for previously unseen documents remains to be a very challenging problem. In this paper, we emphasise this issue and propose a novel Self-Taught Hashing (STH) approach to semantic hashing: we first find the optimal $l$-bit binary codes for all documents in the given corpus via unsupervised learning, and then train $l$ classifiers via supervised learning to predict the $l$-bit code for any query document unseen before. Our experiments on three real-world text datasets show that the proposed approach using binarised Laplacian Eigenmap (LapEig) and linear Support Vector Machine (SVM) outperforms state-of-the-art techniques significantly.|sl:arxiv_author|Deng Cai
Bayesian analysis|skos:broader|Artificial Intelligence
Macaw: An Extensible Conversational Information Seeking Platform Conversational information seeking (CIS) has been recognized as a major emerging research area in information retrieval. Such research will require data and tools, to allow the implementation and study of conversational systems. This paper introduces Macaw, an open-source framework with a modular architecture for CIS research. Macaw supports multi-turn, multi-modal, and mixed-initiative interactions, and enables research for tasks such as document retrieval, question answering, recommendation, and structured data exploration. It has a modular design to encourage the study of new CIS algorithms, which can be evaluated in batch mode. It can also integrate with a user interface, which allows user studies and data collection in an interactive mode, where the back end can be fully algorithmic or a wizard of oz setup. Macaw is distributed under the MIT License.|sl:arxiv_firstAuthor|Hamed Zamani
the task of grouping a set of objects in such a way that objects in the same group (cluster) are more similar (in some sense or another) to each other than to those in other groups.  |skos:broader|In machine learning, unsupervised learning refers to the problem of trying to find hidden structure in unlabeled data
Industrie nucléaire|skos:broader|Energie
Bidirectional LSTM-CRF Models for Sequence Tagging In this paper, we propose a variety of Long Short-Term Memory (LSTM) based models for sequence tagging. These models include LSTM networks, bidirectional LSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer (LSTM-CRF) and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work is the first to apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model to NLP benchmark sequence tagging data sets. We show that the BI-LSTM-CRF model can efficiently use both past and future input features thanks to a bidirectional LSTM component. It can also use sentence level tag information thanks to a CRF layer. The BI-LSTM-CRF model can produce state of the art (or close to) accuracy on POS, chunking and NER data sets. In addition, it is robust and has less dependence on word embedding as compared to previous observations.|sl:tag|tag:conditional_random_field
Term Frequency-Inverse Document Frequency.    major limitations:    - It computes document similarity directly in the word-count space, which could be slow for large vocabularies.  - It assumes that the counts of different words provide independent evidence of similarity.  - It makes no use of semantic similarities between words.  |skos:broader|Algebraic model for representing text documents as vectors of identifiers such as index terms.br/  Documents and queries are represented as vectors.  Each dimension corresponds to a separate term. If a term occurs in the document, its value in the vector is non-zero. One way of computing the value: TD-IDF          
CNN 4 NLP|skos:broader|Convolutional neural network
Generalization through Memorization: Nearest Neighbor Language Models extend LMs with nearest neighbor search in embedding space We introduce $k$NN-LMs, which extend a pre-trained neural language model (LM) by linearly interpolating it with a $k$-nearest neighbors ($k$NN) model. The nearest neighbors are computed according to distance in the pre-trained LM embedding space, and can be drawn from any text collection, including the original LM training data. Applying this augmentation to a strong Wikitext-103 LM, with neighbors drawn from the original training set, our $k$NN-LM achieves a new state-of-the-art perplexity of 15.79 - a 2.9 point improvement with no additional training. We also show that this approach has implications for efficiently scaling up to larger training sets and allows for effective domain adaptation, by simply varying the nearest neighbor datastore, again without further training. Qualitatively, the model is particularly helpful in predicting rare patterns, such as factual knowledge. Together, these results strongly suggest that learning similarity between sequences of text is easier than predicting the next word, and that nearest neighbor search is an effective approach for language modeling in the long tail.|sl:arxiv_author|Dan Jurafsky
Socrate|skos:broader|Grand Homme
EC-Web'14|skos:broader|Munich
Explainable Deep Learning: A Field Guide for the Uninitiated Deep neural network (DNN) is an indispensable machine learning tool for achieving human-level performance on many learning tasks. Yet, due to its black-box nature, it is inherently difficult to understand which aspects of the input data drive the decisions of the network. There are various real-world scenarios in which humans need to make actionable decisions based on the output DNNs. Such decision support systems can be found in critical domains, such as legislation, law enforcement, etc. It is important that the humans making high-level decisions can be sure that the DNN decisions are driven by combinations of data features that are appropriate in the context of the deployment of the decision support system and that the decisions made are legally or ethically defensible. Due to the incredible pace at which DNN technology is being developed, the development of new methods and studies on explaining the decision-making process of DNNs has blossomed into an active research field. A practitioner beginning to study explainable deep learning may be intimidated by the plethora of orthogonal directions the field is taking. This complexity is further exacerbated by the general confusion that exists in defining what it means to be able to explain the actions of a deep learning system and to evaluate a system's ability to explain. To alleviate this problem, this article offers a field guide to deep learning explainability for those uninitiated in the field. The field guide: i) Discusses the traits of a deep learning system that researchers enhance in explainability research, ii) places explainability in the context of other related deep learning research areas, and iii) introduces three simple dimensions defining the space of foundational methods that contribute to explainable deep learning. The guide is designed as an easy-to-digest starting point for those just embarking in the field.|sl:tag|tag:survey
Visualizing and Measuring the Geometry of BERT  At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.|sl:tag|tag:bert
HTTP Cache|skos:broader|Cache
No Fuss Distance Metric Learning using Proxies  We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity...   Traditionnaly, supervision is expressed in the form of sets of points that follow  an ordinal relationship – an anchor point x is similar to  a set of positive points Y , and dissimilar to a set of negative  points Z, and a loss defined over these distances is minimized.   Triplet-Based methods are challenging to optimize (a main issue is the need for finding informative triplets).     We propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss.    Mentioned in this [blog post](/doc/2020/01/training_a_speaker_embedding_fr):     Proxy based triplet learning: instead of generating triplets, we learn an embedding for each class and use the learnt embedding as a proxy for triplets as part of the training. In other words, we can train end to end without the computationally expensive step of resampling triplets after each network update.    Near the conclusion:     Our formulation of Proxy-NCA loss produces a loss very  similar to the standard cross-entropy loss used in classification.  However, we arrive at our formulation from a different  direction: we are not interested in the actual classifier and  indeed discard the proxies once the model has been trained.  Instead, the proxies are auxiliary variables, enabling more  effective optimization of the embedding model parameters.  As such, our formulation not only enables us to surpass the  state of the art in zero-shot learning, but also offers an explanation  to the effectiveness of the standard trick of training  a classifier, and using its penultimate layer’s output as the  embedding. We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity. Traditionally, for this problem supervision is expressed in the form of sets of points that follow an ordinal relationship -- an anchor point $x$ is similar to a set of positive points $Y$, and dissimilar to a set of negative points $Z$, and a loss defined over these distances is minimized. While the specifics of the optimization differ, in this work we collectively call this type of supervision Triplets and all methods that follow this pattern Triplet-Based methods. These methods are challenging to optimize. A main issue is the need for finding informative triplets, which is usually achieved by a variety of tricks such as increasing the batch size, hard or semi-hard triplet mining, etc. Even with these tricks, the convergence rate of such methods is slow. In this paper we propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss. This proxy-based loss is empirically better behaved. As a result, the proxy-loss improves on state-of-art results for three standard zero-shot learning datasets, by up to 15% points, while converging three times as fast as other triplet-based losses.|sl:arxiv_author|Yair Movshovitz-Attias
NLP@Microsoft|skos:broader|NLP Teams
Programming language|skos:broader|Dev
Sparse coding|skos:broader|Feature learning
Sommet de Copenhague|skos:broader|Négociations climat 
Mai 68|skos:broader|Contestation
KBPedia|skos:broader|Knowledge-based AI
Knowledge Graph + Deep Learning|skos:broader|Knowledge Graphs
XLNet: Generalized Autoregressive Pretraining for Language Understanding a new pretraining method for NLP that significantly improves upon BERT on 20 tasks (e.g., SQuAD, GLUE, RACE) With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.|sl:arxiv_author|Zhilin Yang
Google über alles|skos:broader|Google
Deep Learning and the Information Bottleneck Principle  Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN.   Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.|sl:tag|tag:arxiv_doc
Intent detection|skos:broader|NLP tasks / problems
Bart van Leeuwen|skos:broader|SW guys (and girls)
Distributional semantics|skos:broader|Analyse sémantique
TAP|skos:broader|Guha
gnowsis|skos:broader|Leo Sauermann
JUnit|skos:broader|Java dev
Pre-training via Paraphrasing We introduce MARGE, a pre-trained sequence-to-sequence model learned with an unsupervised multi-lingual multi-document paraphrasing objective. MARGE provides an alternative to the dominant masked language modeling paradigm, where we self-supervise the reconstruction of target text by retrieving a set of related texts (in many languages) and conditioning on them to maximize the likelihood of generating the original. We show it is possible to jointly learn to do retrieval and reconstruction, given only a random initialization. The objective noisily captures aspects of paraphrase, translation, multi-document summarization, and information retrieval, allowing for strong zero-shot performance on several tasks. For example, with no additional task-specific training we achieve BLEU scores of up to 35.8 for document translation. We further show that fine-tuning gives strong performance on a range of discriminative and generative tasks in many languages, making MARGE the most generally applicable pre-training method to date.|sl:tag|tag:zero_shot_learning
BlackboxNLP (2018 workshop)|skos:broader|Blackbox NLP
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Chris Dyer
Neural machine translation|skos:broader|Machine translation
Realistic Re-evaluation of Knowledge Graph Completion Methods: An Experimental Study data redundancy (reverse relations), Cartesian product relations     A more fundamental defect  of these models is that the link prediction scenario, given  such data, is non-existent in the real-world In the active research area of employing embedding models for knowledge graph completion, particularly for the task of link prediction, most prior studies used two benchmark datasets FB15k and WN18 in evaluating such models. Most triples in these and other datasets in such studies belong to reverse and duplicate relations which exhibit high data redundancy due to semantic duplication, correlation or data incompleteness. This is a case of excessive data leakage---a model is trained using features that otherwise would not be available when the model needs to be applied for real prediction. There are also Cartesian product relations for which every triple formed by the Cartesian product of applicable subjects and objects is a true fact. Link prediction on the aforementioned relations is easy and can be achieved with even better accuracy using straightforward rules instead of sophisticated embedding models. A more fundamental defect of these models is that the link prediction scenario, given such data, is non-existent in the real-world. This paper is the first systematic study with the main objective of assessing the true effectiveness of embedding models when the unrealistic triples are removed. Our experiment results show these models are much less accurate than what we used to perceive. Their poor accuracy renders link prediction a task without truly effective automated solution. Hence, we call for re-investigation of possible effective approaches.|sl:arxiv_author|Farahnaz Akrami Department of Computer Science and Engineering, University of Texas at Arlington
Deep Learning and the Information Bottleneck Principle  Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN.   Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.|sl:tag|tag:information_theory_and_deep_learning
SWEO: Renault use case|skos:broader|SWEO Interest Group
Learning Sparse, Distributed Representations using the Hebbian Principle The \fire together, wire together\ Hebbian model is a central principle for learning in neuroscience, but surprisingly, it has found limited applicability in modern machine learning. In this paper, we take a first step towards bridging this gap, by developing flavors of competitive Hebbian learning which produce sparse, distributed neural codes using online adaptation with minimal tuning The fire together, wire together Hebbian model is a central principle for learning in neuroscience, but surprisingly, it has found limited applicability in modern machine learning. In this paper, we take a first step towards bridging this gap, by developing flavors of competitive Hebbian learning which produce sparse, distributed neural codes using online adaptation with minimal tuning. We propose an unsupervised algorithm, termed Adaptive Hebbian Learning (AHL). We illustrate the distributed nature of the learned representations via output entropy computations for synthetic data, and demonstrate superior performance, compared to standard alternatives such as autoencoders, in training a deep convolutional net on standard image datasets.|sl:arxiv_firstAuthor|Aseem Wadhwa
Semantic Web : Business|skos:broader|Semantic Web
CKAN|skos:broader|Open Source
Parrot|skos:broader|OWL tool
Facts as Experts: Adaptable and Interpretable Neural Memory over Symbolic Knowledge  a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge.... The model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones.     a  neural language model which learns to access information  in a symbolic knowledge graph.     This  model builds on the recently-proposed [Entities as  Experts](doc:2020/07/2004_07202_entities_as_expert) (EaE) language model (Févry et al., 2020),  which extends the same transformer (Vaswani  et al., 2017) architecture of BERT (Devlin et al., 2019) with an additional external memory for entities.     After training EaE, the embedding associated  with an entity will (ideally) capture information  about the textual context in which that  entity appears, and by inference, the entity’s semantic  properties     we include an additional  memory called a fact memory, which encodes  triples from a symbolic KB.     This combination results in a  neural language model which learns to access information  in a the symbolic knowledge graph.        TODO: read again IBM's [Span Selection Pre-training for Question Answering](doc:2019/09/_1909_04120_span_selection_pre) (an effort to avoid encoding general knowledge in the transformer network itself) Massive language models are the core of modern NLP modeling and have been shown to encode impressive amounts of commonsense and factual information. However, that knowledge exists only within the latent parameters of the model, inaccessible to inspection and interpretation, and even worse, factual information memorized from the training corpora is likely to become stale as the world changes. Knowledge stored as parameters will also inevitably exhibit all of the biases inherent in the source materials. To address these problems, we develop a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge. We show that this model dramatically improves performance on two knowledge-intensive question-answering tasks. More interestingly, the model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones in ways that are not possible for earlier models.|sl:arxiv_author|William W. Cohen
Crise financière|skos:broader|Finance
Semi-supervised Clustering for Short Text via Deep Representation Learning semi-supervised method for short text clustering, where we represent texts as distributed vectors with neural networks, and use a small amount of labeled data to specify our intention for clustering. We design a novel objective to combine the representation learning process and the k-means clustering process together, and optimize the objective with both labeled data and unlabeled data iteratively until convergence through three steps:     1. assign each short text to its nearest centroid based on its representation from the current neural networks;  2. re-estimate the cluster centroids based on cluster assignments from step (1);  3. update neural networks according to the objective by keeping centroids and cluster assignments fixed.   In this work, we propose a semi-supervised method for short text clustering, where we represent texts as distributed vectors with neural networks, and use a small amount of labeled data to specify our intention for clustering. We design a novel objective to combine the representation learning process and the k-means clustering process together, and optimize the objective with both labeled data and unlabeled data iteratively until convergence through three steps: (1) assign each short text to its nearest centroid based on its representation from the current neural networks; (2) re-estimate the cluster centroids based on cluster assignments from step (1); (3) update neural networks according to the objective by keeping centroids and cluster assignments fixed. Experimental results on four datasets show that our method works significantly better than several other text clustering methods.|sl:arxiv_firstAuthor|Zhiguo Wang
Drupal|skos:broader|CMS
jsFiddle|skos:broader|Javascript tool
Afrique australe|skos:broader|Afrique
Visualizing and Measuring the Geometry of BERT  At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.|sl:arxiv_author|Emily Reif
Hierarchical text classification|skos:broader|Text Classification
Berkeley|skos:broader|Universités américaines
Cameroun|skos:broader|Afrique
Realistic Re-evaluation of Knowledge Graph Completion Methods: An Experimental Study data redundancy (reverse relations), Cartesian product relations     A more fundamental defect  of these models is that the link prediction scenario, given  such data, is non-existent in the real-world In the active research area of employing embedding models for knowledge graph completion, particularly for the task of link prediction, most prior studies used two benchmark datasets FB15k and WN18 in evaluating such models. Most triples in these and other datasets in such studies belong to reverse and duplicate relations which exhibit high data redundancy due to semantic duplication, correlation or data incompleteness. This is a case of excessive data leakage---a model is trained using features that otherwise would not be available when the model needs to be applied for real prediction. There are also Cartesian product relations for which every triple formed by the Cartesian product of applicable subjects and objects is a true fact. Link prediction on the aforementioned relations is easy and can be achieved with even better accuracy using straightforward rules instead of sophisticated embedding models. A more fundamental defect of these models is that the link prediction scenario, given such data, is non-existent in the real-world. This paper is the first systematic study with the main objective of assessing the true effectiveness of embedding models when the unrealistic triples are removed. Our experiment results show these models are much less accurate than what we used to perceive. Their poor accuracy renders link prediction a task without truly effective automated solution. Hence, we call for re-investigation of possible effective approaches.|sl:tag|tag:link_prediction
Woody Allen|skos:broader|Réalisateur
Lynn Margulis|skos:broader|Biology
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Andrew Ballard
Embedding evaluation|skos:broader|ML: evaluation
Computes embeddings  for the vertices of unlabeled graphs. DeepWalk bridges the gap between network  embeddings and word embeddings by treating nodes as words and generating short random walks  as sentences. Then, neural language models such as Skip-gram can be applied on these random  walks to obtain network embedding.|skos:broader|How do we do node embeddings? ([source](http://snap.stanford.edu/proj/embeddings-www/index.html#materials))    Intuition: Find embedding of nodes so that “similar” nodes in the graph have embeddings that are close together.    1. Define an encoder (i.e., a mapping from nodes to embeddings)  	- Shallow embedding (simplest encoding approach): encoder is just an embedding-lookup. Ex: [node2vec](/tag/node2vec), DeepWalk, LINE  2. Define a node similarity function, eg. nodes are similar if:   	- they are connected?  	- they share neighbours?  	- have structural similar roles?  	- ...   3. Optimize the parameters of the encoder so that similarity in the embedding space (e.g., dot product) approximates similarity in the original network    Defining similarity:    - Adjacency-based Similarity  - Multihop similarity (measure overlap between node neighborhoods)    these two methods are expensive.  - Random-walk Embeddings (Estimate probability of visiting node v on a random walk starting from node u using some random walk strategy, optimize embeddings to encode random walk statistics). Expressivity (incorporates both local and higher-order neighbourhood information) and efficiency (do not need to consider all pairs when training)    Which random walk strategy?    - fixed-length random walks starting from each node: DeepWalk (Perozzi et al., 2013)  - biased random walks that can trade off between local and global views of the network: Node2Vec (Micro-view / marco-view of neighbourhood)    No method wins in all the cases      
SL Feature Request|skos:broader|SL todo
Learning to rank|skos:broader|Supervised machine learning
Sequence Modeling: CNN vs RNN|skos:broader|Sequence-to-sequence learning
Uncertainty in Deep Learning|skos:broader|Accountable AI
The Consciousness Prior consciousness seen as the formation of a low-dimensional combination of a few concepts constituting a conscious thought, i.e., consciousness as awareness at a particular time instant: the projection of a big vector (all the things conscious and unconscious in brain). Attention: additional mechanism describing what mind chooses to focus on.    [YouTube video](/doc/?uri=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYr1mOzC93xs) A new prior is proposed for learning representations of high-level concepts of the kind we manipulate with language. This prior can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by cognitive neuroscience theories of consciousness, seen as a bottleneck through which just a few elements, after having been selected by attention from a broader pool, are then broadcast and condition further processing, both in perception and decision-making. The set of recently selected elements one becomes aware of is seen as forming a low-dimensional conscious state. This conscious state is combining the few concepts constituting a conscious thought, i.e., what one is immediately conscious of at a particular moment. We claim that this architectural and information-processing constraint corresponds to assumptions about the joint distribution between high-level concepts. To the extent that these assumptions are generally true (and the form of natural language seems consistent with them), they can form a useful prior for representation learning. A low-dimensional thought or conscious state is analogous to a sentence: it involves only a few variables and yet can make a statement with very high probability of being true. This is consistent with a joint distribution (over high-level concepts) which has the form of a sparse factor graph, i.e., where the dependencies captured by each factor of the factor graph involve only very few variables while creating a strong dip in the overall energy function. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in a form similar to facts and rules, albeit capturing uncertainty as well as efficient search mechanisms implemented by attention mechanisms.|sl:tag|tag:consciousness_prior
Enhancing the Power of Cardinal's Algorithm Cardinal's factorization algorithm of 1996 splits a univariate polynomial into two factors with root sets separated by the imaginary axis, which is an important goal itself and a basic step toward root-finding. The novelty of the algorithm and its potential power have been well recognized by experts immediately, but by 2016, that is, two decades later, its practical value still remains nil, particularly because of the high computational cost of performing its final stage by means of computing approximate greatest common divisor of two polynomials. We briefly recall Cardinal's algorithm and its difficulties, amend it based on some works performed since 1996, extend its power to splitting out factors of a more general class, and reduce the final stage of the algorithm to quite manageable computations with structured matrices. Some of our techniques can be of independent interest for matrix computations.|sl:tag|tag:arxiv_doc
Displaying XML with css|skos:broader|XML
Cloud and Linked Data|skos:broader|Linked Data
RDFj|skos:broader|RDF-in-JSON
Recherche française|skos:broader|France
Multimodal Models|skos:broader|Machine learning: problems
REST|skos:broader|Roy T. Fielding
Clerezza|skos:broader|apache.org
Python sample code|skos:broader|Python
Bringing Light Into the Dark: A Large-scale Evaluation of Knowledge Graph Embedding Models Under a Unified Framework The heterogeneity in recently published knowledge graph embedding models' implementations, training, and evaluation has made fair and thorough comparisons difficult. In order to assess the reproducibility of previously published results, we re-implemented and evaluated 19 interaction models in the PyKEEN software package. Here, we outline which results could be reproduced with their reported hyper-parameters, which could only be reproduced with alternate hyper-parameters, and which could not be reproduced at all as well as provide insight as to why this might be the case. We then performed a large-scale benchmarking on four datasets with several thousands of experiments and 21,246 GPU hours of computation time. We present insights gained as to best practices, best configurations for each model, and where improvements could be made over previously published best configurations. Our results highlight that the combination of model architecture, training approach, loss function, and the explicit modeling of inverse relations is crucial for a model's performances, and not only determined by the model architecture. We provide evidence that several architectures can obtain results competitive to the state-of-the-art when configured carefully. We have made all code, experimental configurations, results, and analyses that lead to our interpretations available at https://github.com/pykeen/pykeen and https://github.com/pykeen/benchmarking|sl:arxiv_author|Charles Tapley Hoyt
Hypothèse de Riemann|skos:broader|Grands problèmes mathématiques
Slime mold|skos:broader|Curiosité naturelle
Read-Write Linked Data|skos:broader|Linked Data
A mathematical theory of semantic development in deep neural networks  a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences?   An extensive body of empirical research has revealed remarkable regularities in the acquisition, organization, deployment, and neural representation of human semantic knowledge, thereby raising a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences? We address this question by mathematically analyzing the nonlinear dynamics of learning in deep linear networks. We find exact solutions to this learning dynamics that yield a conceptual explanation for the prevalence of many disparate phenomena in semantic cognition, including the hierarchical differentiation of concepts through rapid developmental transitions, the ubiquity of semantic illusions between such transitions, the emergence of item typicality and category coherence as factors controlling the speed of semantic processing, changing patterns of inductive projection over development, and the conservation of semantic similarity in neural representations across species. Thus, surprisingly, our simple neural model qualitatively recapitulates many diverse regularities underlying semantic development, while providing analytic insight into how the statistical structure of an environment can interact with nonlinear deep learning dynamics to give rise to these regularities.|sl:tag|tag:knowledge
Libéralisme|skos:broader|Capitalisme
Alexandre Passant|skos:broader|SW guys (and girls)
de Broglie|skos:broader|Scientifique
Graph Convolution for Multimodal Information Extraction from Visually Rich Documents Visually rich documents (VRDs) are ubiquitous in daily business and life. Examples are purchase receipts, insurance policy documents, custom declaration forms and so on. In VRDs, visual and layout information is critical for document understanding, and texts in such documents cannot be serialized into the one-dimensional sequence without losing information. Classic information extraction models such as BiLSTM-CRF typically operate on text sequences and do not incorporate visual features. In this paper, we introduce a graph convolution based model to combine textual and visual information presented in VRDs. Graph embeddings are trained to summarize the context of a text segment in the document, and further combined with text embeddings for entity extraction. Extensive experiments have been conducted to show that our method outperforms BiLSTM-CRF baselines by significant margins, on two real-world datasets. Additionally, ablation studies are also performed to evaluate the effectiveness of each component of our model.|sl:tag|tag:alibaba
Shoira Otabekova|skos:broader|Musique
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|Claudia d'Amato
ESWC 2019|skos:broader|ESWC
PFIA 2018|skos:broader|AI Conference
InceptionTime: Finding AlexNet for Time Series Classification Time series classification (TSC) is the area of machine learning interested in learning how to assign labels to time series. The last few decades of work in this area have led to significant progress in the accuracy of classifiers, with the state of the art now represented by the HIVE-COTE algorithm. While extremely accurate, HIVE-COTE is infeasible to use in many applications because of its very high training time complexity in O(N^2T^4) for a dataset with N time series of length T. For example, it takes HIVE-COTE more than 72,000s to learn from a small dataset with N=700 time series of short length T=46. Deep learning, on the other hand, has now received enormous attention because of its high scalability and state-of-the-art accuracy in computer vision and natural language processing tasks. Deep learning for TSC has only very recently started to be explored, with the first few architectures developed over the last 3 years only. The accuracy of deep learning for TSC has been raised to a competitive level, but has not quite reached the level of HIVE-COTE. This is what this paper achieves: outperforming HIVE-COTE's accuracy together with scalability. We take an important step towards finding the AlexNet network for TSC by presenting InceptionTime---an ensemble of deep Convolutional Neural Network (CNN) models, inspired by the Inception-v4 architecture. Our experiments show that InceptionTime slightly outperforms HIVE-COTE with a win/draw/loss on the UCR archive of 40/6/39. Not only is InceptionTime more accurate, but it is much faster: InceptionTime learns from that same dataset with 700 time series in 2,300s but can also learn from a dataset with 8M time series in 13 hours, a quantity of data that is fully out of reach of HIVE-COTE.|sl:arxiv_author|François Petitjean
Efficient Contextual Representation Learning Without Softmax Layer how to accelerate contextual representation learning.     Contextual representation models are difficult to train due to the large parameter sizes and high computational complexity     We find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size.  Therefore, we redesign the learning objectiv.   Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings.  Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary.  When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.    decouples learning contexts and words     Instead of using  a softmax layer to predict the distribution of the  missing word, we utilize and extend the SEMFIT  layer (Kumar and Tsvetkov, 2018) to predict the  embedding of the missing word. Contextual representation models have achieved great success in improving various downstream tasks. However, these language-model-based encoders are difficult to train due to the large parameter sizes and high computational complexity. By carefully examining the training procedure, we find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size. Therefore, we redesign the learning objective and propose an efficient framework for training contextual representation models. Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings. Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary. When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.|sl:arxiv_author|Liunian Harold Li
Extracting Tables from Documents using Conditional Generative Adversarial Networks and Genetic Algorithms Extracting information from tables in documents presents a significant challenge in many industries and in academic research. Existing methods which take a bottom-up approach of integrating lines into cells and rows or columns neglect the available prior information relating to table structure. Our proposed method takes a top-down approach, first using a generative adversarial network to map a table image into a standardised `skeleton' table form denoting the approximate row and column borders without table content, then fitting renderings of candidate latent table structures to the skeleton structure using a distance measure optimised by a genetic algorithm.|sl:arxiv_author|Mark Rowan
Automating the search for a patent's prior art with a full text similarity search [github](https://github.com/helmersl/patent_similarity_search)    mouais     More than ever, technical inventions are the symbol of our society's advance. Patents guarantee their creators protection against infringement. For an invention being patentable, its novelty and inventiveness have to be assessed. Therefore, a search for published work that describes similar inventions to a given patent application needs to be performed. Currently, this so-called search for prior art is executed with semi-automatically composed keyword queries, which is not only time consuming, but also prone to errors. In particular, errors may systematically arise by the fact that different keywords for the same technical concepts may exist across disciplines. In this paper, a novel approach is proposed, where the full text of a given patent application is compared to existing patents using machine learning and natural language processing techniques to automatically detect inventions that are similar to the one described in the submitted document. Various state-of-the-art approaches for feature extraction and document comparison are evaluated. In addition to that, the quality of the current search process is assessed based on ratings of a domain expert. The evaluation results show that our automated approach, besides accelerating the search process, also improves the search results for prior art with respect to their quality.|sl:arxiv_author|Klaus-Robert Müller
Self-Taught Convolutional Neural Networks for Short Text Clustering  We propose a flexible short text clustering framework which explores the feasibility and effectiveness of combining CNN and traditional unsupervised dimensionality reduction methods.     Non-biased deep feature representations can be learned through our self- taught CNN framework which does not use any external tags/labels or complicated NLP pre-processing.     The original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations.    [conf paper, same authors](http://www.aclweb.org/anthology/W15-1509) ; [gitgub repo (matlab)](https://github.com/jacoxu/STC2)   Short text clustering is a challenging problem due to its sparseness of text representation. Here we propose a flexible Self-Taught Convolutional neural network framework for Short Text Clustering (dubbed STC^2), which can flexibly and successfully incorporate more useful semantic features and learn non-biased deep text representation in an unsupervised manner. In our framework, the original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations. Extensive experimental results demonstrate that the proposed framework is effective, flexible and outperform several popular clustering methods when tested on three public short text datasets.|sl:arxiv_author|Peng Wang
Human Level AI|skos:broader|Artificial general intelligence
Syrie|skos:broader|Asie
Moral machines|skos:broader|Nous vivons une époque moderne
Kaguya|skos:broader|Japon
jersey|skos:broader|JAX-RS
Realistic Re-evaluation of Knowledge Graph Completion Methods: An Experimental Study data redundancy (reverse relations), Cartesian product relations     A more fundamental defect  of these models is that the link prediction scenario, given  such data, is non-existent in the real-world In the active research area of employing embedding models for knowledge graph completion, particularly for the task of link prediction, most prior studies used two benchmark datasets FB15k and WN18 in evaluating such models. Most triples in these and other datasets in such studies belong to reverse and duplicate relations which exhibit high data redundancy due to semantic duplication, correlation or data incompleteness. This is a case of excessive data leakage---a model is trained using features that otherwise would not be available when the model needs to be applied for real prediction. There are also Cartesian product relations for which every triple formed by the Cartesian product of applicable subjects and objects is a true fact. Link prediction on the aforementioned relations is easy and can be achieved with even better accuracy using straightforward rules instead of sophisticated embedding models. A more fundamental defect of these models is that the link prediction scenario, given such data, is non-existent in the real-world. This paper is the first systematic study with the main objective of assessing the true effectiveness of embedding models when the unrealistic triples are removed. Our experiment results show these models are much less accurate than what we used to perceive. Their poor accuracy renders link prediction a task without truly effective automated solution. Hence, we call for re-investigation of possible effective approaches.|sl:tag|tag:embedding_evaluation
Bacterial to Animal Gene Transfer|skos:broader|Bacteria
Javascript RDF Parser|skos:broader|RDF Parser
Money|skos:broader|Finance
Antiquité iranienne|skos:broader|Antiquité
Genetics Génétique|skos:broader|Science
Jeux en ligne|skos:broader|Jeux
Word Translation Without Parallel Data  we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent studies showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally describe experiments on the English-Esperanto low-resource language pair, on which there only exists a limited amount of parallel data, to show the potential impact of our method in fully unsupervised machine translation. Our code, embeddings and dictionaries are publicly available.|sl:arxiv_author|Hervé Jégou
Von Mises-Fisher Loss for Training Sequence to Sequence Models with Continuous Outputs predicting embeddings instead of word IDs (avoids a discrete softmax, using a new loss)    [@honnibal](https://twitter.com/honnibal/status/1073513114468081664)     The Softmax function is used in the final layer of nearly all existing sequence-to-sequence models for language generation. However, it is usually the slowest layer to compute which limits the vocabulary size to a subset of most frequent types; and it has a large memory footprint. We propose a general technique for replacing the softmax layer with a continuous embedding layer. Our primary innovations are a novel probabilistic loss, and a training and inference procedure in which we generate a probability distribution over pre-trained word embeddings, instead of a multinomial distribution over the vocabulary obtained via softmax. We evaluate this new class of sequence-to-sequence models with continuous outputs on the task of neural machine translation. We show that our models obtain upto 2.5x speed-up in training time while performing on par with the state-of-the-art models in terms of translation quality. These models are capable of handling very large vocabularies without compromising on translation quality. They also produce more meaningful errors than in the softmax-based models, as these errors typically lie in a subspace of the vector space of the reference translations.|sl:tag|tag:arxiv_doc
Tag ontology|skos:broader|Semanlink related
Punk|skos:broader|Musique
Enterprise Knowledge Graph|skos:broader|Knowledge Graphs
Hip Hop|skos:broader|Musique
A Hierarchical Multi-task Approach for Learning Embeddings from Semantic Tasks [Blog post](https://medium.com/dair-ai/hmtl-multi-task-learning-for-state-of-the-art-nlp-245572bbb601), [GitHub repo](https://github.com/huggingface/hmtl)   Much effort has been devoted to evaluate whether multi-task learning can be leveraged to learn rich representations that can be used in various Natural Language Processing (NLP) down-stream applications. However, there is still a lack of understanding of the settings in which multi-task learning has a significant effect. In this work, we introduce a hierarchical model trained in a multi-task learning setup on a set of carefully selected semantic tasks. The model is trained in a hierarchical fashion to introduce an inductive bias by supervising a set of low level tasks at the bottom layers of the model and more complex tasks at the top layers of the model. This model achieves state-of-the-art results on a number of tasks, namely Named Entity Recognition, Entity Mention Detection and Relation Extraction without hand-engineered features or external NLP tools like syntactic parsers. The hierarchical training supervision induces a set of shared semantic representations at lower layers of the model. We show that as we move from the bottom to the top layers of the model, the hidden states of the layers tend to represent more complex semantic information.|sl:arxiv_firstAuthor|Victor Sanh
matplotlib|skos:broader|Python
iphone|skos:broader|Smartphone
Cambridge Analytica|skos:broader|Privacy and internet
Java 1.5 Mac OS X|skos:broader|Mac OS X
Compatibilité Javascript|skos:broader|JavaScript
Génétique + Histoire|skos:broader|Histoire
VSO|skos:broader|GoodRelations
Open Source|skos:broader|Software
The Description Length of Deep Learning Models  Solomonoff’s general theory of inference (Solomonoff, 1964) and the [Minimum Description Length Principle](tag:minimum_description_length_principle) (Grünwald, 2007; Rissanen, 2007) formalize [Occam's razor](tag:occam_s_razor), and hold that a good model of data is a model that is good at losslessly  compressing the data, including the cost of describing the model itself. Deep neural  networks might seem to go against this principle given the large number of  parameters to be encoded.  We demonstrate experimentally the ability of deep neural networks to compress  the training data even when accounting for parameter encoding. Solomonoff's general theory of inference and the Minimum Description Length principle formalize Occam's razor, and hold that a good model of data is a model that is good at losslessly compressing the data, including the cost of describing the model itself. Deep neural networks might seem to go against this principle given the large number of parameters to be encoded. We demonstrate experimentally the ability of deep neural networks to compress the training data even when accounting for parameter encoding. The compression viewpoint originally motivated the use of variational methods in neural networks. Unexpectedly, we found that these variational methods provide surprisingly poor compression bounds, despite being explicitly built to minimize such bounds. This might explain the relatively poor practical performance of variational methods in deep learning. On the other hand, simple incremental encoding methods yield excellent compression values on deep networks, vindicating Solomonoff's approach.|sl:tag|tag:overfitting
Google Visualization API|skos:broader|Google
Income inequality|skos:broader|Inégalités
Insect collapse|skos:broader|Insecte
Acteur|skos:broader|Cinéma
PyTorch|skos:broader|Deep Learning frameworks
Stefano Mazzocchi|skos:broader|Technical girls and guys
Tiger|skos:broader|Mac OS X
Stack Overflow|skos:broader|FAQ
Masse manquante|skos:broader|Physique
Alexandria Ocasio-Cortez|skos:broader|USA
Antarctique|skos:broader|Régions polaires
Hypercard|skos:broader|Software
Sicile|skos:broader|Italie
Conjecture de Goldbach|skos:broader|Nombres premiers
[Proceedings](https://aclanthology.coli.uni-saarland.de/events/ws-2018#W18-54)     the introduction of neural networks has typically come at the cost of our understanding of the system: what are the representations and computations that the network learns? The goal of this workshop is to bring together people who are attempting to peek inside the neural network black box, taking inspiration from machine learning, psychology, linguistics and neuroscience.|skos:broader|Conference on Empirical Methods in Natural Language Processing. [Proceedings](https://aclanthology.coli.uni-saarland.de/events/emnlp-2018)
A Theoretical Analysis of Contrastive Unsupervised Representation Learning [blog post](/doc/?uri=http%3A%2F%2Fwww.offconvex.org%2F2019%2F03%2F19%2FCURL%2F) Recent empirical works have successfully used unlabeled data to learn feature representations that are broadly useful in downstream classification tasks. Several of these methods are reminiscent of the well-known word2vec embedding algorithm: leveraging availability of pairs of semantically similar data points and negative samples, the learner forces the inner product of representations of similar pairs with each other to be higher on average than with negative samples. The current paper uses the term contrastive learning for such algorithms and presents a theoretical framework for analyzing them by introducing latent classes and hypothesizing that semantically similar points are sampled from the same latent class. This framework allows us to show provable guarantees on the performance of the learned representations on the average classification task that is comprised of a subset of the same set of latent classes. Our generalization bound also shows that learned representations can reduce (labeled) sample complexity on downstream tasks. We conduct controlled experiments in both the text and image domains to support the theory.|sl:tag|tag:arxiv_doc
ISWC|skos:broader|Semantic Web conferences
Google Patents|skos:broader|AI 4 IP
Pétrole et corruption|skos:broader|Pétrole
Deep Learning for Symbolic Mathematics Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.|sl:tag|tag:mathematiques
Fossile vivant|skos:broader|Evolution
Struts|skos:broader|MVC
Sagesse du langage|skos:broader|Language
PlaNet - Photo Geolocation with Convolutional Neural Networks Is it possible to build a system to determine the location where a photo was taken using just its pixels? In general, the problem seems exceptionally difficult: it is trivial to construct situations where no location can be inferred. Yet images often contain informative cues such as landmarks, weather patterns, vegetation, road markings, and architectural details, which in combination may allow one to determine an approximate location and occasionally an exact location. Websites such as GeoGuessr and View from your Window suggest that humans are relatively good at integrating these cues to geolocate images, especially en-masse. In computer vision, the photo geolocation problem is usually approached using image retrieval methods. In contrast, we pose the problem as one of classification by subdividing the surface of the earth into thousands of multi-scale geographic cells, and train a deep network using millions of geotagged images. While previous approaches only recognize landmarks or perform approximate matching using global image descriptors, our model is able to use and integrate multiple visible cues. We show that the resulting model, called PlaNet, outperforms previous approaches and even attains superhuman levels of accuracy in some cases. Moreover, we extend our model to photo albums by combining it with a long short-term memory (LSTM) architecture. By learning to exploit temporal coherence to geolocate uncertain photos, we demonstrate that this model achieves a 50% performance improvement over the single-image model.|sl:tag|tag:arxiv_doc
Describing a Knowledge Base We aim to automatically generate natural language descriptions about an input structured knowledge base (KB). We build our generation framework based on a pointer network which can copy facts from the input KB, and add two attention mechanisms: (i) slot-aware attention to capture the association between a slot type and its corresponding slot value; and (ii) a new \\emph{table position self-attention} to capture the inter-dependencies among related slots. For evaluation, besides standard metrics including BLEU, METEOR, and ROUGE, we propose a KB reconstruction based metric by extracting a KB from the generation output and comparing it with the input KB. We also create a new data set which includes 106,216 pairs of structured KBs and their corresponding natural language descriptions for two distinct entity types. Experiments show that our approach significantly outperforms state-of-the-art methods. The reconstructed KB achieves 68.8% - 72.6% F-score.|sl:arxiv_author|Kevin Knight
Mac Mini|skos:broader|Macintosh
Ramanujan|skos:broader|Mathématicien
Accident climatique|skos:broader|Climat
Astrophysique|skos:broader|Physique
From Word to Sense Embeddings: A Survey on Vector Representations of Meaning Survey focused on semantic representation of meaning (methods that try to directly model individual meanings of words).    Pb with word embeddings: the meaning conflation deficiency (representing a word with all its possible meanings as a single vector). Can be addressed by a method for modelling unambiguous lexical meaning.    two main branches of sense representation :    - unsupervised   - knowledge-based Over the past years, distributed semantic representations have proved to be effective and flexible keepers of prior knowledge to be integrated into downstream applications. This survey focuses on the representation of meaning. We start from the theoretical background behind word vector space models and highlight one of their major limitations: the meaning conflation deficiency, which arises from representing a word with all its possible meanings as a single vector. Then, we explain how this deficiency can be addressed through a transition from the word level to the more fine-grained level of word senses (in its broader acceptation) as a method for modelling unambiguous lexical meaning. We present a comprehensive overview of the wide range of techniques in the two main branches of sense representation, i.e., unsupervised and knowledge-based. Finally, this survey covers the main evaluation procedures and applications for this type of representation, and provides an analysis of four of its important aspects: interpretability, sense granularity, adaptability to different domains and compositionality.|sl:arxiv_author|Mohammad Taher Pilehvar
Eclipse project|skos:broader|fps dev
The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives [blog post](http://www.semanlink.net/doc/2019/09/evolution_of_representations_in) We seek to understand how the representations of individual tokens and the structure of the learned feature space evolve between layers in deep neural networks under different learning objectives. We focus on the Transformers for our analysis as they have been shown effective on various tasks, including machine translation (MT), standard left-to-right language models (LM) and masked language modeling (MLM). Previous work used black-box probing tasks to show that the representations learned by the Transformer differ significantly depending on the objective. In this work, we use canonical correlation analysis and mutual information estimators to study how information flows across Transformer layers and how this process depends on the choice of learning objective. For example, as you go from bottom to top layers, information about the past in left-to-right language models gets vanished and predictions about the future get formed. In contrast, for MLM, representations initially acquire information about the context around the token, partially forgetting the token identity and producing a more generalized token representation. The token identity then gets recreated at the top MLM layers.|sl:arxiv_author|Elena Voita
The Description Length of Deep Learning Models  Solomonoff’s general theory of inference (Solomonoff, 1964) and the [Minimum Description Length Principle](tag:minimum_description_length_principle) (Grünwald, 2007; Rissanen, 2007) formalize [Occam's razor](tag:occam_s_razor), and hold that a good model of data is a model that is good at losslessly  compressing the data, including the cost of describing the model itself. Deep neural  networks might seem to go against this principle given the large number of  parameters to be encoded.  We demonstrate experimentally the ability of deep neural networks to compress  the training data even when accounting for parameter encoding. Solomonoff's general theory of inference and the Minimum Description Length principle formalize Occam's razor, and hold that a good model of data is a model that is good at losslessly compressing the data, including the cost of describing the model itself. Deep neural networks might seem to go against this principle given the large number of parameters to be encoded. We demonstrate experimentally the ability of deep neural networks to compress the training data even when accounting for parameter encoding. The compression viewpoint originally motivated the use of variational methods in neural networks. Unexpectedly, we found that these variational methods provide surprisingly poor compression bounds, despite being explicitly built to minimize such bounds. This might explain the relatively poor practical performance of variational methods in deep learning. On the other hand, simple incremental encoding methods yield excellent compression values on deep networks, vindicating Solomonoff's approach.|sl:tag|tag:minimum_description_length_principle
Similarity Search for Efficient Active Learning and Search of Rare Concepts  Similarity search for Efficient Active Learning and Search (SEALS)    In [Active Learning](tag:active_learning): instead of searching globally for the optimal examples to label, leverage the fact that data is often heavily skewed and expand the candidate pool with the nearest neighbors of the labeled set.     Our work attacks both the labeling and computational costs of machine learning...SEALS dramatically reduces the barrier to machine learning, enabling small teams or individuals to  build accurate classifiers. SEALS does, however, introduce another system component, a similarity  search index, which adds some additional engineering complexity to build, tune, and maintain.  Fortunately, several highly optimized implementations like Annoy and [Faiss](doc:2020/06/facebookresearch_faiss_a_libra) work reasonably well  out of the box. Many active learning and search approaches are intractable for industrial settings with billions of unlabeled examples. Existing approaches, such as uncertainty sampling or information density, search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. However, in practice, data is often heavily skewed; only a small fraction of collected data will be relevant for a given learning task. For example, when identifying rare classes, detecting malicious content, or debugging model performance, the ratio of positive to negative examples can be 1 to 1,000 or more. In this work, we exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round by only looking at the nearest neighbors to the labeled examples. Empirically, we observe that learned representations effectively cluster unseen concepts, making active learning very effective and substantially reducing the number of viable unlabeled examples. We evaluate several active learning and search techniques in this setting on three large-scale datasets: ImageNet, Goodreads spoiler detection, and OpenImages. For rare classes, active learning methods need as little as 0.31% of the labeled data to match the average precision of full supervision. By limiting active learning methods to only consider the immediate neighbors of the labeled data as candidates for labeling, we need only process as little as 1% of the unlabeled data while achieving similar reductions in labeling costs as the traditional global approach. This process of expanding the candidate pool with the nearest neighbors of the labeled set can be done efficiently and reduces the computational complexity of selection by orders of magnitude.|sl:arxiv_author|I. Zeki Yalniz
Private equity|skos:broader|Capitalisme financier
Propriété intellectuelle|skos:broader|Juridique
Exploring the Limits of Language Modeling recent advances in Recurrent Neural Networks for large scale Language Modeling In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon.|sl:tag|tag:recurrent_neural_network
HTTP PATCH|skos:broader|HTTP
Hash Embeddings for Efficient Word Representations  A hash embedding may be seen as an interpolation between  a standard word embedding and a word embedding created using a random hash  function (the hashing trick).    recommandé par [Raphaël Sourty](tag:raphaelsty) We present hash embeddings, an efficient method for representing words in a continuous vector form. A hash embedding may be seen as an interpolation between a standard word embedding and a word embedding created using a random hash function (the hashing trick). In hash embeddings each token is represented by $k$ $d$-dimensional embeddings vectors and one $k$ dimensional weight vector. The final $d$ dimensional representation of the token is the product of the two. Rather than fitting the embedding vectors for each token these are selected by the hashing trick from a shared pool of $B$ embedding vectors. Our experiments show that hash embeddings can easily deal with huge vocabularies consisting of millions of tokens. When using a hash embedding there is no need to create a dictionary before training nor to perform any kind of vocabulary pruning after training. We show that models trained using hash embeddings exhibit at least the same level of performance as models trained using regular embeddings across a wide range of tasks. Furthermore, the number of parameters needed by such an embedding is only a fraction of what is required by a regular embedding. Since standard embeddings and embeddings constructed using the hashing trick are actually just special cases of a hash embedding, hash embeddings can be considered an extension and improvement over the existing regular embedding types.|sl:arxiv_author|Jonas Meinertz Hansen
Transformers as Soft Reasoners over Language  AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. We provide the first demonstration that this is possible, and characterize the extent of this capability. To do this, we use a collection of synthetic datasets that test increasing levels of reasoning complexity (number of rules, presence of negation, and depth of chaining). We find transformers appear to learn rule-based reasoning with high (99%) accuracy on these datasets, and in a way that generalizes to test data requiring substantially deeper chaining than in the training data (95%+ scores). We also demonstrate that the models transfer well to two hand-authored rulebases, and to rulebases paraphrased into more natural language. These findings are significant as it suggests a new role for transformers, namely as a limited soft theorem prover operating over explicit theories in language. This in turn suggests new possibilities for explainability, correctability, and counterfactual reasoning in question-answering. All datasets and a live demo are available at http://rule-reasoning.apps.allenai.org/|sl:arxiv_author|Peter Clark
Protection de l'environnement|skos:broader|Environnement
Replace or Retrieve Keywords In Documents at Scale For a document of size N (characters) and a dictionary of M keywords, the time complexity is O(N) (compared to O(MxN) with regex). FlashText is designed to only match complete words (words with boundary characters on both sides). Different from Aho Corasick Algorithm, as it doesn't match substrings. This algorithm is also designed to go for the longest match first. For an input dictionary {Machine, Learning, Machine learning} on a string 'I like Machine learning', it will only consider the longest match, which is Machine Learning    [Github](https://github.com/vi3k6i5/flashtext) In this paper we introduce, the FlashText algorithm for replacing keywords or finding keywords in a given text. FlashText can search or replace keywords in one pass over a document. The time complexity of this algorithm is not dependent on the number of terms being searched or replaced. For a document of size N (characters) and a dictionary of M keywords, the time complexity will be O(N). This algorithm is much faster than Regex, because regex time complexity is O(MxN). It is also different from Aho Corasick Algorithm, as it doesn't match substrings. FlashText is designed to only match complete words (words with boundary characters on both sides). For an input dictionary of {Apple}, this algorithm won't match it to 'I like Pineapple'. This algorithm is also designed to go for the longest match first. For an input dictionary {Machine, Learning, Machine learning} on a string 'I like Machine learning', it will only consider the longest match, which is Machine Learning. We have made python implementation of this algorithm available as open-source on GitHub, released under the permissive MIT License.|sl:arxiv_firstAuthor|Vikash Singh
Time in RDF|skos:broader|Temps
Recurrent Memory Networks for Language Modeling  Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge.     In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data.     We demonstrate the power of RMN on language modeling and sentence completion tasks.     On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.   Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge. In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data. We demonstrate the power of RMN on language modeling and sentence completion tasks. On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.|sl:arxiv_author|Ke Tran
Bob DuCharme|skos:broader|Technical girls and guys
AdaBoost|skos:broader|Boosting
Denisovan|skos:broader|Paléontologie humaine
End-To-End Memory Networks Neural network with a recurrent attention model over a possibly large external memory.    cité par [#A. Bordes](/tag/antoine_bordes) à [#ParisIsAI conf 2018](/tag/france_is_ai_2018.html) We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network (Weston et al., 2015) but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.|sl:tag|tag:deep_learning_attention
Describing a Knowledge Base We aim to automatically generate natural language descriptions about an input structured knowledge base (KB). We build our generation framework based on a pointer network which can copy facts from the input KB, and add two attention mechanisms: (i) slot-aware attention to capture the association between a slot type and its corresponding slot value; and (ii) a new \\emph{table position self-attention} to capture the inter-dependencies among related slots. For evaluation, besides standard metrics including BLEU, METEOR, and ROUGE, we propose a KB reconstruction based metric by extracting a KB from the generation output and comparing it with the input KB. We also create a new data set which includes 106,216 pairs of structured KBs and their corresponding natural language descriptions for two distinct entity types. Experiments show that our approach significantly outperforms state-of-the-art methods. The reconstructed KB achieves 68.8% - 72.6% F-score.|sl:arxiv_author|Lifu Huang
in cosine similarity, the number of common attributes is divided by the total number of possible attributes. Whereas in Jaccard Similarity, the number of common attributes is divided by the number of attributes that exist in at least one of the two objects.|skos:broader|Finding items that are similar to a given query is the core  aspect of search and retrieval systems, as well as of  recommendation engines.
DARPA Grand Challenge|skos:broader|Driverless car
LinkNBed: Multi-Graph Representation Learning with Entity Linkage   a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure     We posit that combining  graph alignment task with deep representation  learning across multi-relational graphs has potential  to induce a synergistic effect on both tasks Knowledge graphs have emerged as an important model for studying complex multi-relational data. This has given rise to the construction of numerous large scale but incomplete knowledge graphs encoding information extracted from various resources. An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledge-based inference for many downstream applications. To this end, we propose LinkNBed, a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure. Experiments on link prediction and entity linkage demonstrate substantial improvements over the state-of-the-art relational learning approaches.|sl:arxiv_author|Hongyuan Zha
Semantic Vector Encoding and Similarity Search Using Fulltext Search Engines  The ubiquity of semantic vector space modeling raises the challenge of efficient searching in dense, high-dimensional vector spaces. We would naturally want to take advantage of the design and optimizations behind modern fulltext engines like Elasticsearch so as to meet the scalability and robustness demands of modern IR applications. This is the research challenge addressed in this paper.   The paper describes novel ways of encoding dense vectors into text documents, allowing the use of traditional inverted index engines.    [blog post](https://rare-technologies.com/semantic-search-fulltext-engine-acl-2017/)   Vector representations and vector space modeling (VSM) play a central role in modern machine learning. We propose a novel approach to `vector similarity searching' over dense semantic representations of words and documents that can be deployed on top of traditional inverted-index-based fulltext engines, taking advantage of their robustness, stability, scalability and ubiquity. We show that this approach allows the indexing and querying of dense vectors in text domains. This opens up exciting avenues for major efficiency gains, along with simpler deployment, scaling and monitoring. The end result is a fast and scalable vector database with a tunable trade-off between vector search performance and quality, backed by a standard fulltext engine such as Elasticsearch. We empirically demonstrate its querying performance and quality by applying this solution to the task of semantic searching over a dense vector representation of the entire English Wikipedia.|sl:arxiv_author|Jan Rygl
EventKG: A Multilingual Event-Centric Temporal Knowledge Graph 690 thousand contemporary and historical events and over 2.3 million temporal relations One of the key requirements to facilitate semantic analytics of information regarding contemporary and historical events on the Web, in the news and in social media is the availability of reference knowledge repositories containing comprehensive representations of events and temporal relations. Existing knowledge graphs, with popular examples including DBpedia, YAGO and Wikidata, focus mostly on entity-centric information and are insufficient in terms of their coverage and completeness with respect to events and temporal relations. EventKG presented in this paper is a multilingual event-centric temporal knowledge graph that addresses this gap. EventKG incorporates over 690 thousand contemporary and historical events and over 2.3 million temporal relations extracted from several large-scale knowledge graphs and semi-structured sources and makes them available through a canonical representation.|sl:tag|tag:rdf
Ethiopie|skos:broader|Afrique de l'Est
Word Translation Without Parallel Data  we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent studies showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally describe experiments on the English-Esperanto low-resource language pair, on which there only exists a limited amount of parallel data, to show the potential impact of our method in fully unsupervised machine translation. Our code, embeddings and dictionaries are publicly available.|sl:arxiv_author|Guillaume Lample
Struts|skos:broader|JSP
Causal inference|skos:broader|Inference
Seyni Kountché|skos:broader|Histoire du Niger
Suède|skos:broader|Pays d'Europe
RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space  We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.|sl:tag|tag:knowledge_graph_embeddings
Cyborg|skos:broader|Robotique
Robot humanoïde|skos:broader|Robotique
public-hydra@w3.org|skos:broader|Hydra
Distilling the Knowledge in a Neural Network  a different kind of training, which we call “distillation” to transfer the  knowledge from the cumbersome model to a small model that is more  suitable for deployment       Caruana and his collaborators have shown that it is possible to compress the knowledge in an [#ensemble](/tag/ensemble_learning.html) into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST. A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.|sl:arxiv_author|Jeff Dean
Evolution|skos:broader|Science
Museum d'Histoire Naturelle|skos:broader|Musée
Wembedder: Wikidata entity embedding web service web service for querying an embedding of entities in the Wikidata knowledge graph. The embedding is trained on the Wikidata dump using Gensim's Word2Vec implementation and a simple graph walk I present a web service for querying an embedding of entities in the Wikidata knowledge graph. The embedding is trained on the Wikidata dump using Gensim's Word2Vec implementation and a simple graph walk. A REST API is implemented. Together with the Wikidata API the web service exposes a multilingual resource for over 600'000 Wikidata items and properties.|sl:arxiv_author|Finn Årup Nielsen
Semanlink|skos:broader|Personal-information management
Musique|skos:broader|Art
Span Selection Pre-training for Question Answering  a new pre-training task inspired by reading  comprehension and an effort to avoid encoding general knowledge in the transformer network itself    Current transformer architectures store general knowledge - large models, long pre-training time. Better to offload the requirement of general knowledge to a sparsely activated network.    Span selection as an additional auxiliary task: the query is a sentence drawn from a corpus  with a term replaced with a special token: [BLANK]. The term replaced by the blank is the answer term. The passage is  relevant as determined by a BM25 search, and answer-bearing (containing the answer  term). Unlike BERT’s cloze task, where the answer must be drawn from the model itself, the answer is found in a passage  using language understanding.     We hope to progress to a model of general purpose language modeling that uses an indexed long  term memory to retrieve world knowledge, rather than holding it in the densely activated transformer encoder layers. BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pre-trained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension and an effort to avoid encoding general knowledge in the transformer network itself. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple reading comprehension (MRC) and paraphrasing datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also establish a new SOTA in HotpotQA, improving answer prediction F1 by 4 F1 points and supporting fact prediction by 1 F1 point. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.|sl:arxiv_author|G P Shrivatsa Bhargav
JsonLD + MongoDB|skos:broader|MongoDB
"Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One We propose to reinterpret a standard discriminative classifier of p(y|x) as an energy based model for the joint distribution p(x,y). In this setting, the standard class probabilities can be easily computed as well as unnormalized values of p(x) and p(x|y). Within this framework, standard discriminative architectures may beused and the model can also be trained on unlabeled data. We demonstrate that energy based training of the joint distribution improves calibration, robustness, andout-of-distribution detection while also enabling our models to generate samplesrivaling the quality of recent GAN approaches. We improve upon recently proposed techniques for scaling up the training of energy based models and presentan approach which adds little overhead compared to standard classification training. Our approach is the first to achieve performance rivaling the state-of-the-artin both generative and discriminative learning within one hybrid model."|sl:arxiv_author|Will Grathwohl
JavaScript Tutorial|skos:broader|Tutorial
Aho–Corasick algorithm|skos:broader|Algorithmes
StarSpace|skos:broader|Embeddings
Concise Bounded Description|skos:broader|RDF graphs
Deep Learning frameworks|skos:broader|Machine Learning tool
W3C Data Activity|skos:broader|Semantic Web
Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.|sl:tag|tag:arxiv_doc
Patricia Highsmith|skos:broader|Thriller
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Francis Song
Neurala: Lifelong-DNN|skos:broader|Continual Learning
Self-Taught Convolutional Neural Networks for Short Text Clustering  We propose a flexible short text clustering framework which explores the feasibility and effectiveness of combining CNN and traditional unsupervised dimensionality reduction methods.     Non-biased deep feature representations can be learned through our self- taught CNN framework which does not use any external tags/labels or complicated NLP pre-processing.     The original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations.    [conf paper, same authors](http://www.aclweb.org/anthology/W15-1509) ; [gitgub repo (matlab)](https://github.com/jacoxu/STC2)   Short text clustering is a challenging problem due to its sparseness of text representation. Here we propose a flexible Self-Taught Convolutional neural network framework for Short Text Clustering (dubbed STC^2), which can flexibly and successfully incorporate more useful semantic features and learn non-biased deep text representation in an unsupervised manner. In our framework, the original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations. Extensive experimental results demonstrate that the proposed framework is effective, flexible and outperform several popular clustering methods when tested on three public short text datasets.|sl:tag|tag:nlp_short_texts
The Matrix Calculus You Need For Deep Learning Related blog post [The Math Behind Neural Networks](https://towardsdatascience.com/step-by-step-the-math-behind-neural-networks-490dc1f3cfd9) This paper is an attempt to explain all the matrix calculus you need in order to understand the training of deep neural networks. We assume no math knowledge beyond what you learned in calculus 1, and provide links to help you refresh the necessary math where needed. Note that you do not need to understand this material before you start learning to train and use deep learning in practice; rather, this material is for those who are already familiar with the basics of neural networks, and wish to deepen their understanding of the underlying math. Don't worry if you get stuck at some point along the way---just go back and reread the previous section, and try writing down and working through some examples. And if you're still stuck, we're happy to answer your questions in the Theory category at forums.fast.ai. Note: There is a reference section at the end of the paper summarizing all the key matrix calculus rules and terminology discussed here. See related articles at http://explained.ai|sl:arxiv_author|Jeremy Howard
Self-Taught Hashing for Fast Similarity Search Emphasise following issue in Semantic Hashing: obtaining the codes for previously unseen documents. Propose following approach:  first find the optimal l-bit binary codes for all documents in  the given corpus via unsupervised learning, then train  l classifiers via supervised learning to predict the l-bit code  for any query document unseen before.    (méthode résumée [ici](https://www.semanticscholar.org/paper/Semantic-hashing-using-tags-and-topic-modeling-Wang-Zhang/1a0f660f70fd179003edc271694736baaa39dec4))       The ability of fast similarity search at large scale is of great importance to many Information Retrieval (IR) applications. A promising way to accelerate similarity search is semantic hashing which designs compact binary codes for a large number of documents so that semantically similar documents are mapped to similar codes (within a short Hamming distance). Although some recently proposed techniques are able to generate high-quality codes for documents known in advance, obtaining the codes for previously unseen documents remains to be a very challenging problem. In this paper, we emphasise this issue and propose a novel Self-Taught Hashing (STH) approach to semantic hashing: we first find the optimal $l$-bit binary codes for all documents in the given corpus via unsupervised learning, and then train $l$ classifiers via supervised learning to predict the $l$-bit code for any query document unseen before. Our experiments on three real-world text datasets show that the proposed approach using binarised Laplacian Eigenmap (LapEig) and linear Support Vector Machine (SVM) outperforms state-of-the-art techniques significantly.|sl:arxiv_firstAuthor|Dell Zhang
Learning with Memory Embeddings Embedding learning, a.k.a. representation learning, has been shown to be able to model large-scale semantic knowledge graphs. A key concept is a mapping of the knowledge graph to a tensor representation whose entries are predicted by models using latent representations of generalized entities. Latent variable models are well suited to deal with the high dimensionality and sparsity of typical knowledge graphs. In recent publications the embedding models were extended to also consider time evolutions, time patterns and subsymbolic representations. In this paper we map embedding models, which were developed purely as solutions to technical problems for modelling temporal knowledge graphs, to various cognitive memory functions, in particular to semantic and concept memory, episodic memory, sensory memory, short-term memory, and working memory. We discuss learning, query answering, the path from sensory input to semantic decoding, and the relationship between episodic memory and semantic memory. We introduce a number of hypotheses on human memory that can be derived from the developed mathematical models.|sl:arxiv_author|Denis Krompaß
Business Intelligence and Semantic Web|skos:broader|Semantic Web
Roy T. Fielding|skos:broader|REST
NLP event|skos:broader|NLP
Semantic Vector Encoding and Similarity Search Using Fulltext Search Engines  The ubiquity of semantic vector space modeling raises the challenge of efficient searching in dense, high-dimensional vector spaces. We would naturally want to take advantage of the design and optimizations behind modern fulltext engines like Elasticsearch so as to meet the scalability and robustness demands of modern IR applications. This is the research challenge addressed in this paper.   The paper describes novel ways of encoding dense vectors into text documents, allowing the use of traditional inverted index engines.    [blog post](https://rare-technologies.com/semantic-search-fulltext-engine-acl-2017/)   Vector representations and vector space modeling (VSM) play a central role in modern machine learning. We propose a novel approach to `vector similarity searching' over dense semantic representations of words and documents that can be deployed on top of traditional inverted-index-based fulltext engines, taking advantage of their robustness, stability, scalability and ubiquity. We show that this approach allows the indexing and querying of dense vectors in text domains. This opens up exciting avenues for major efficiency gains, along with simpler deployment, scaling and monitoring. The end result is a fast and scalable vector database with a tunable trade-off between vector search performance and quality, backed by a standard fulltext engine such as Elasticsearch. We empirically demonstrate its querying performance and quality by applying this solution to the task of semantic searching over a dense vector representation of the entire English Wikipedia.|sl:tag|tag:vector_space_model
Rembrandt|skos:broader|Peintre
AdSense|skos:broader|Google
Francis Pisani|skos:broader|Technical girls and guys
Statistical classification|skos:broader|Supervised machine learning
Markets|skos:broader|Finance
Charlie Hebdo|skos:broader|Presse
log4j|skos:broader|Java dev
ANN: introduction|skos:broader|Neural networks
Apache Spark|skos:broader|Big Data
Monsanto|skos:broader|Semencier
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:tag|tag:arxiv_doc
backplanejs|skos:broader|RDFa
Anticolonialisme|skos:broader|Colonisation
Named Graphs|skos:broader|RDF
Einstein|skos:broader|Grand Homme
Chatbot|skos:broader|NLP: applications
Universal Language Model Fine-tuning for Text Classification code is available in the fastai lib    [blog post](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html)    [see also](/doc/?uri=https%3A%2F%2Fyashuseth.blog%2F2018%2F06%2F17%2Funderstanding-universal-language-model-fine-tuning-ulmfit%2F)             Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.|sl:tag|tag:transfer_learning
Binary classification models with \Uncertain\ predictions Binary classification models which can assign probabilities to categories such as the tissue is 75% likely to be tumorous or the chemical is 25% likely to be toxic are well understood statistically, but their utility as an input to decision making is less well explored. We argue that users need to know which is the most probable outcome, how likely that is to be true and, in addition, whether the model is capable enough to provide an answer. It is the last case, where the potential outcomes of the model explicitly include don't know that is addressed in this paper. Including this outcome would better separate those predictions that can lead directly to a decision from those where more data is needed. Where models produce an Uncertain answer similar to a human reply of don't know or 50:50 in the examples we refer to earlier, this would translate to actions such as operate on tumour or remove compound from use where the models give a more true than not answer. Where the models judge the result Uncertain the practical decision might be carry out more detailed laboratory testing of compound or commission new tissue analyses. The paper presents several examples where we first analyse the effect of its introduction, then present a methodology for separating Uncertain from binary predictions and finally, we provide arguments for its use in practice.|sl:arxiv_author|Ljubomir Buturovic
Terrorisme|skos:broader|Grands problèmes
Brain vs Deep Learning|skos:broader|Brain
AI@Google|skos:broader|AI teams
Jean-Claude Juncker|skos:broader|Eurogroupe
W3C Recommendation|skos:broader|W3C
semblog|skos:broader|Steve Cayzer
FBI v. Apple|skos:broader|iphone
fps@EC-Web'14|skos:broader|schema.org
Ranking (information retrieval)|skos:broader|Information retrieval: techniques
Twine|skos:broader|Semantic Web : Application
Mali|skos:broader|Afrique de l'Ouest
ANN used for unsupervised learning of efficient codings: learning a representation (encoding) for a set of data, typically for the purpose of dimensionality reduction.    an unsupervised neural network  which is trained to reconstruct a given input  from its latent representation (Bengio, 2009).    Unlike principal components analysis, the encoding and decoding steps are not limited to linear transformations (PCA learns an encoding linear transform, while auto-encoders learn an encoding program).  |skos:broader|In machine learning, unsupervised learning refers to the problem of trying to find hidden structure in unlabeled data
EDUCE: Explaining model Decisions through Unsupervised Concepts Extraction  Providing explanations along with predictions is crucial in some text processing tasks. Therefore, we propose a new self-interpretable model that performs output prediction and simultaneously provides an explanation in terms of the presence of particular concepts in the input. To do so, our model's prediction relies solely on a low-dimensional binary representation of the input, where each feature denotes the presence or absence of concepts.    Presented in these [slides](/doc/2019/12/unsupervised_learning_with_text) Providing explanations along with predictions is crucial in some text processing tasks. Therefore, we propose a new self-interpretable model that performs output prediction and simultaneously provides an explanation in terms of the presence of particular concepts in the input. To do so, our model's prediction relies solely on a low-dimensional binary representation of the input, where each feature denotes the presence or absence of concepts. The presence of a concept is decided from an excerpt i.e. a small sequence of consecutive words in the text. Relevant concepts for the prediction task at hand are automatically defined by our model, avoiding the need for concept-level annotations. To ease interpretability, we enforce that for each concept, the corresponding excerpts share similar semantics and are differentiable from each others. We experimentally demonstrate the relevance of our approach on text classification and multi-sentiment analysis tasks.|sl:arxiv_author|Ludovic Denoyer
nbdev.fast.ai|skos:broader|fast.ai
faiss|skos:broader|Facebook FAIR
Deep Learning: Optimization methods|skos:broader|Deep Learning
A Strong Baseline for Learning Cross-Lingual Word Embeddings from Sentence Alignments While cross-lingual word embeddings have been studied extensively in recent years, the qualitative differences between the different algorithms remain vague. We observe that whether or not an algorithm uses a particular feature set (sentence IDs) accounts for a significant performance gap among these algorithms. This feature set is also used by traditional alignment algorithms, such as IBM Model-1, which demonstrate similar performance to state-of-the-art embedding algorithms on a variety of benchmarks. Overall, we observe that different algorithmic approaches for utilizing the sentence ID feature space result in similar performance. This paper draws both empirical and theoretical parallels between the embedding and alignment literature, and suggests that adding additional sources of information, which go beyond the traditional signal of bilingual sentence-aligned corpora, may substantially improve cross-lingual word embeddings, and that future baselines should at least take such features into account.|sl:tag|tag:arxiv_doc
Yves Peirsman|skos:broader|NLP girls and guys
W3C Community Group|skos:broader|W3C
LDOW2008|skos:broader|Workshop
Calais|skos:broader|Linking Open Data
Word embeddings|skos:broader|NLP techniques
France / Afrique|skos:broader|France
Three Mile Island|skos:broader|Industrie nucléaire
An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks For most deep learning practitioners, sequence modeling is synonymous with recurrent networks. Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation. Given a new sequence modeling task or dataset, which architecture should one use? We conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling. The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks. Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as LSTMs across a diverse range of tasks and datasets, while demonstrating longer effective memory. We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks. To assist related work, we have made code available at http://github.com/locuslab/TCN .|sl:arxiv_author|J. Zico Kolter
Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus.     In practice, some questions are best answered  using text, while others are best answered using  KBs. A natural question, then, is how to effectively  combine both types of information. Surprisingly  little prior work has looked at this problem. Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting. Source code is available at https://github.com/OceanskySun/GraftNet .|sl:arxiv_author|Kathryn Mazaitis
Ng|skos:broader|Technical guys
Neural-Symbolic Computing|skos:broader|NN / Symbolic AI hybridation
Stanford classifier|skos:broader|NLP@Stanford
Maidsafe|skos:broader|Peer to peer
GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden unit), or embedding-free units such as image pixels.|sl:arxiv_author|Ruslan Salakhutdinov
Detecting Out-of-Distribution Examples with In-distribution Examples and Gram Matrices  we propose to detect OOD examples by identifying inconsistencies between activity patterns and class predicted...    Unlike many approaches, this can be used with any pre-trained softmax classifier and does not require access to OOD data When presented with Out-of-Distribution (OOD) examples, deep neural networks yield confident, incorrect predictions. Detecting OOD examples is challenging, and the potential risks are high. In this paper, we propose to detect OOD examples by identifying inconsistencies between activity patterns and class predicted. We find that characterizing activity patterns by Gram matrices and identifying anomalies in gram matrix values can yield high OOD detection rates. We identify anomalies in the gram matrices by simply comparing each value with its respective range observed over the training data. Unlike many approaches, this can be used with any pre-trained softmax classifier and does not require access to OOD data for fine-tuning hyperparameters, nor does it require OOD access for inferring parameters. The method is applicable across a variety of architectures and vision datasets and, for the important and surprisingly hard task of detecting far-from-distribution out-of-distribution examples, it generally performs better than or equal to state-of-the-art OOD detection methods (including those that do assume access to OOD examples).|sl:tag|tag:out_of_distribution_detection
Memory leak|skos:broader|Mémoire (informatique)
Rosetta|skos:broader|esa
Learning with Memory Embeddings Embedding learning, a.k.a. representation learning, has been shown to be able to model large-scale semantic knowledge graphs. A key concept is a mapping of the knowledge graph to a tensor representation whose entries are predicted by models using latent representations of generalized entities. Latent variable models are well suited to deal with the high dimensionality and sparsity of typical knowledge graphs. In recent publications the embedding models were extended to also consider time evolutions, time patterns and subsymbolic representations. In this paper we map embedding models, which were developed purely as solutions to technical problems for modelling temporal knowledge graphs, to various cognitive memory functions, in particular to semantic and concept memory, episodic memory, sensory memory, short-term memory, and working memory. We discuss learning, query answering, the path from sensory input to semantic decoding, and the relationship between episodic memory and semantic memory. We introduce a number of hypotheses on human memory that can be derived from the developed mathematical models.|sl:arxiv_author|Yinchong Yang
Decentralized social network|skos:broader|Social Networks
RDF Tools|skos:broader|RDF
SKOS W3C document|skos:broader|W3C
Edvige|skos:broader|Fichage
RFID passports|skos:broader|Etat policier
Colza transgénique|skos:broader|Colza
Intervention française au Mali|skos:broader|Mali
Encyclopedia of Life|skos:broader|Biodiversity data
AllenNLP|skos:broader|NLP tools
Semantic web: training|skos:broader|Semantic Web
Link Prediction|skos:broader|Knowledge Graph Completion
Piratage des œuvres|skos:broader|Propriété intellectuelle
Information visualization|skos:broader|GUI
Google|skos:broader|Entreprise
Using Information Content to Evaluate Semantic Similarity in a Taxonomy This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content. Experimental evaluation suggests that the measure performs encouragingly well (a correlation of r = 0.79 with a benchmark set of human similarity judgments, with an upper bound of r = 0.90 for human subjects performing the same task), and significantly better than the traditional edge counting approach (r = 0.66).|sl:arxiv_author|Philip Resnik
Binary classification models with \Uncertain\ predictions Binary classification models which can assign probabilities to categories such as the tissue is 75% likely to be tumorous or the chemical is 25% likely to be toxic are well understood statistically, but their utility as an input to decision making is less well explored. We argue that users need to know which is the most probable outcome, how likely that is to be true and, in addition, whether the model is capable enough to provide an answer. It is the last case, where the potential outcomes of the model explicitly include don't know that is addressed in this paper. Including this outcome would better separate those predictions that can lead directly to a decision from those where more data is needed. Where models produce an Uncertain answer similar to a human reply of don't know or 50:50 in the examples we refer to earlier, this would translate to actions such as operate on tumour or remove compound from use where the models give a more true than not answer. Where the models judge the result Uncertain the practical decision might be carry out more detailed laboratory testing of compound or commission new tissue analyses. The paper presents several examples where we first analyse the effect of its introduction, then present a methodology for separating Uncertain from binary predictions and finally, we provide arguments for its use in practice.|sl:tag|tag:three_way_decisions
KG-BERT: BERT for Knowledge Graph Completion Pre-trained language models for knowledge graph completion. Triples are treated as textual sequences. (Hum, j'ai déjà vu ça quelque part) Knowledge graphs are important resources for many artificial intelligence tasks but often suffer from incompleteness. In this work, we propose to use pre-trained language models for knowledge graph completion. We treat triples in knowledge graphs as textual sequences and propose a novel framework named Knowledge Graph Bidirectional Encoder Representations from Transformer (KG-BERT) to model these triples. Our method takes entity and relation descriptions of a triple as input and computes scoring function of the triple with the KG-BERT language model. Experimental results on multiple benchmark knowledge graphs show that our method can achieve state-of-the-art performance in triple classification, link prediction and relation prediction tasks.|sl:arxiv_author|Yuan Luo
bash|skos:broader|Unix
Span Selection Pre-training for Question Answering  a new pre-training task inspired by reading  comprehension and an effort to avoid encoding general knowledge in the transformer network itself    Current transformer architectures store general knowledge - large models, long pre-training time. Better to offload the requirement of general knowledge to a sparsely activated network.    Span selection as an additional auxiliary task: the query is a sentence drawn from a corpus  with a term replaced with a special token: [BLANK]. The term replaced by the blank is the answer term. The passage is  relevant as determined by a BM25 search, and answer-bearing (containing the answer  term). Unlike BERT’s cloze task, where the answer must be drawn from the model itself, the answer is found in a passage  using language understanding.     We hope to progress to a model of general purpose language modeling that uses an indexed long  term memory to retrieve world knowledge, rather than holding it in the densely activated transformer encoder layers. BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pre-trained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension and an effort to avoid encoding general knowledge in the transformer network itself. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple reading comprehension (MRC) and paraphrasing datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also establish a new SOTA in HotpotQA, improving answer prediction F1 by 4 F1 points and supporting fact prediction by 1 F1 point. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.|sl:arxiv_author|Alfio Gliozzo
Ford|skos:broader|Entreprise
Brad Pitt|skos:broader|Acteur
Tika|skos:broader|apache.org
Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks Current machine learning systems operate, almost exclusively, in a statistical, or model-free mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks. To demonstrate the essential role of such models, I will present a summary of seven tasks which are beyond reach of current machine learning systems and which have been accomplished using the tools of causal modeling.|sl:tag|tag:arxiv_doc
Orange (data mining)|skos:broader|Data mining tools
Linked Learning|skos:broader|Linked Data
Technique de l'insecte stérile|skos:broader|Nous vivons une époque moderne
Championnat du monde d'athlétisme|skos:broader|Athlétisme
DuckDuckGo|skos:broader|Search Engines
Glue|skos:broader|Social Networks
Knowledge Graph + Deep Learning|skos:broader|Graph neural networks
Uranium|skos:broader|Matière première
LD-PATCH|skos:broader|LDP: updates
Coursera: Introduction to Data Science|skos:broader|Coursera
Cancer|skos:broader|Grands problèmes
Windows|skos:broader|OS
Unsupervised Transfer Learning for Spoken Language Understanding in Intelligent Agents  We apply ELMo, ULMFiT (unsupervised transfer) with supervised transfer to reduce labeled data required for launching domains in Alexa by 10-15x User interaction with voice-powered agents generates large amounts of unlabeled utterances. In this paper, we explore techniques to efficiently transfer the knowledge from these unlabeled utterances to improve model performance on Spoken Language Understanding (SLU) tasks. We use Embeddings from Language Model (ELMo) to take advantage of unlabeled data by learning contextualized word representations. Additionally, we propose ELMo-Light (ELMoL), a faster and simpler unsupervised pre-training method for SLU. Our findings suggest unsupervised pre-training on a large corpora of unlabeled utterances leads to significantly better SLU performance compared to training from scratch and it can even outperform conventional supervised transfer. Additionally, we show that the gains from unsupervised transfer techniques can be further improved by supervised transfer. The improvements are more pronounced in low resource settings and when using only 1000 labeled in-domain samples, our techniques match the performance of training from scratch on 10-15x more labeled in-domain data.|sl:arxiv_author|Aditya Siddhant
Hittites|skos:broader|Anatolie
Knowledge Graph Embeddings and Explainable AI survey of     - the state-of-the-art in the field of knowledge graph embeddings  - methods for explaining predictions obtained via knowledge graph embeddings. Knowledge graph embeddings are now a widely adopted approach to knowledge representation in which entities and relationships are embedded in vector spaces. In this chapter, we introduce the reader to the concept of knowledge graph embeddings by explaining what they are, how they can be generated and how they can be evaluated. We summarize the state-of-the-art in this field by describing the approaches that have been introduced to represent knowledge in the vector space. In relation to knowledge representation, we consider the problem of explainability, and discuss models and methods for explaining predictions obtained via knowledge graph embeddings.|sl:tag|tag:explainable_ai
Semanlink|skos:broader|Personal Knowledge Management
Attention + Knowledge Graphs|skos:broader|Knowledge Graph + Deep Learning
Detecting Out-of-Distribution Examples with In-distribution Examples and Gram Matrices  we propose to detect OOD examples by identifying inconsistencies between activity patterns and class predicted...    Unlike many approaches, this can be used with any pre-trained softmax classifier and does not require access to OOD data When presented with Out-of-Distribution (OOD) examples, deep neural networks yield confident, incorrect predictions. Detecting OOD examples is challenging, and the potential risks are high. In this paper, we propose to detect OOD examples by identifying inconsistencies between activity patterns and class predicted. We find that characterizing activity patterns by Gram matrices and identifying anomalies in gram matrix values can yield high OOD detection rates. We identify anomalies in the gram matrices by simply comparing each value with its respective range observed over the training data. Unlike many approaches, this can be used with any pre-trained softmax classifier and does not require access to OOD data for fine-tuning hyperparameters, nor does it require OOD access for inferring parameters. The method is applicable across a variety of architectures and vision datasets and, for the important and surprisingly hard task of detecting far-from-distribution out-of-distribution examples, it generally performs better than or equal to state-of-the-art OOD detection methods (including those that do assume access to OOD examples).|sl:arxiv_firstAuthor|Chandramouli Shama Sastry
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:arxiv_author|Sheng-yi Kong
Online Security|skos:broader|Cybersecurity Sécurité informatique
Drupal modules|skos:broader|Drupal
Nok|skos:broader|Nigeria
Artificial general intelligence|skos:broader|Artificial Intelligence
Wiki|skos:broader|Collaborative editing
Evaluation of sentence embeddings in downstream and linguistic probing tasks a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets     We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.           Despite the fast developmental pace of new sentence embedding methods, it is still challenging to find comprehensive evaluations of these different techniques. In the past years, we saw significant improvements in the field of sentence embeddings and especially towards the development of universal sentence encoders that could provide inductive transfer to a wide variety of downstream tasks. In this work, we perform a comprehensive evaluation of recent methods using a wide variety of downstream and linguistic feature probing tasks. We show that a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets. We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.|sl:arxiv_author|Roberto Silveira
AI + Knowledge Bases|skos:broader|Knowledge bases
A Hierarchical Multi-task Approach for Learning Embeddings from Semantic Tasks [Blog post](https://medium.com/dair-ai/hmtl-multi-task-learning-for-state-of-the-art-nlp-245572bbb601), [GitHub repo](https://github.com/huggingface/hmtl)   Much effort has been devoted to evaluate whether multi-task learning can be leveraged to learn rich representations that can be used in various Natural Language Processing (NLP) down-stream applications. However, there is still a lack of understanding of the settings in which multi-task learning has a significant effect. In this work, we introduce a hierarchical model trained in a multi-task learning setup on a set of carefully selected semantic tasks. The model is trained in a hierarchical fashion to introduce an inductive bias by supervising a set of low level tasks at the bottom layers of the model and more complex tasks at the top layers of the model. This model achieves state-of-the-art results on a number of tasks, namely Named Entity Recognition, Entity Mention Detection and Relation Extraction without hand-engineered features or external NLP tools like syntactic parsers. The hierarchical training supervision induces a set of shared semantic representations at lower layers of the model. We show that as we move from the bottom to the top layers of the model, the hidden states of the layers tend to represent more complex semantic information.|sl:arxiv_author|Victor Sanh
Chevènement|skos:broader|Homme politique
SL todo|skos:broader|Todo
Ensemble learning|skos:broader|Machine learning: techniques
Language Models as Knowledge Bases? an analysis of the relational knowledge present in pretrained language models shows an ability of these models to recall factual knowledge  Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as fill-in-the-blank cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.|sl:arxiv_author|Alexander H. Miller
Amazon|skos:broader|Internet
Ultralingua|skos:broader|Online dictionary
Similarity Search for Efficient Active Learning and Search of Rare Concepts  Similarity search for Efficient Active Learning and Search (SEALS)    In [Active Learning](tag:active_learning): instead of searching globally for the optimal examples to label, leverage the fact that data is often heavily skewed and expand the candidate pool with the nearest neighbors of the labeled set.     Our work attacks both the labeling and computational costs of machine learning...SEALS dramatically reduces the barrier to machine learning, enabling small teams or individuals to  build accurate classifiers. SEALS does, however, introduce another system component, a similarity  search index, which adds some additional engineering complexity to build, tune, and maintain.  Fortunately, several highly optimized implementations like Annoy and [Faiss](doc:2020/06/facebookresearch_faiss_a_libra) work reasonably well  out of the box. Many active learning and search approaches are intractable for industrial settings with billions of unlabeled examples. Existing approaches, such as uncertainty sampling or information density, search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. However, in practice, data is often heavily skewed; only a small fraction of collected data will be relevant for a given learning task. For example, when identifying rare classes, detecting malicious content, or debugging model performance, the ratio of positive to negative examples can be 1 to 1,000 or more. In this work, we exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round by only looking at the nearest neighbors to the labeled examples. Empirically, we observe that learned representations effectively cluster unseen concepts, making active learning very effective and substantially reducing the number of viable unlabeled examples. We evaluate several active learning and search techniques in this setting on three large-scale datasets: ImageNet, Goodreads spoiler detection, and OpenImages. For rare classes, active learning methods need as little as 0.31% of the labeled data to match the average precision of full supervision. By limiting active learning methods to only consider the immediate neighbors of the labeled data as candidates for labeling, we need only process as little as 1% of the unlabeled data while achieving similar reductions in labeling costs as the traditional global approach. This process of expanding the candidate pool with the nearest neighbors of the labeled set can be done efficiently and reduces the computational complexity of selection by orders of magnitude.|sl:arxiv_author|Peter Bailis
Musée de Niamey|skos:broader|Niamey
Death of Hyperlink|skos:broader|Hyperlinks
Savant|skos:broader|sciences
Naomi Klein|skos:broader|Critique de la société occidentale
Kullback–Leibler divergence|skos:broader|Information theory
Ecriture|skos:broader|Divers
Europeana|skos:broader|Bibliothèque numérique
Knowledge Enhanced Contextual Word Representations General method to embed multiple knowledge bases into pre-trained language models (KB in the   sense as fixed collection of entity nodes)     The key idea is to explicitly model  entity spans in the input text and use an entity  linker to retrieve relevant entity embeddings from  a KB to form knowledge enhanced entity-span  representations.   Then,  update contextual word representations via a form of word-to-entity attention.    In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert's runtime is comparable to BERT's and it scales to large KBs.|sl:arxiv_author|Roy Schwartz
Texaco|skos:broader|Compagnies pétrolières
The Case for Learned Index Structures  we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs  Indexes are models: a B-Tree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term learned indexes. The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show, that by using neural nets we are able to outperform cache-optimized B-Trees by up to 70% in speed while saving an order-of-magnitude in memory over several real-world data sets. More importantly though, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work just provides a glimpse of what might be possible.|sl:arxiv_firstAuthor|Tim Kraska
Danemark|skos:broader|Europe
LIME|skos:broader|Statistical classification
Turtle|skos:broader|RDF
A Comparative Study of Word Embeddings for Reading Comprehension abstract:   The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on    1.  the use of pre-trained word embeddings, and  2. the representation of out-of-vocabulary tokens at test time,     can turn out to have a larger impact than architectural choices on the final performance         The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on (1) the use of pre-trained word embeddings, and (2) the representation of out-of-vocabulary tokens at test time, can turn out to have a larger impact than architectural choices on the final performance. We systematically explore several options for these choices, and provide recommendations to researchers working in this area.|sl:tag|tag:word_embedding
JDD Apple|skos:broader|Apple
EventKG: A Multilingual Event-Centric Temporal Knowledge Graph 690 thousand contemporary and historical events and over 2.3 million temporal relations One of the key requirements to facilitate semantic analytics of information regarding contemporary and historical events on the Web, in the news and in social media is the availability of reference knowledge repositories containing comprehensive representations of events and temporal relations. Existing knowledge graphs, with popular examples including DBpedia, YAGO and Wikidata, focus mostly on entity-centric information and are insufficient in terms of their coverage and completeness with respect to events and temporal relations. EventKG presented in this paper is a multilingual event-centric temporal knowledge graph that addresses this gap. EventKG incorporates over 690 thousand contemporary and historical events and over 2.3 million temporal relations extracted from several large-scale knowledge graphs and semi-structured sources and makes them available through a canonical representation.|sl:arxiv_firstAuthor|Simon Gottschalk
Semantic Web Client Library|skos:broader|SPARQL
Still a Pain in the Neck: Evaluating Text Representations on Lexical Composition How well do contextualized word embeddings address lexical composition? They are good in recognizing meaning shift (\give in\ is different from \give\) but much worse with revealing implicit meaning (\hot tea\ is about temperature, \hot debate\ isn't). Building meaningful phrase representations is challenging because phrase meanings are not simply the sum of their constituent meanings. Lexical composition can shift the meanings of the constituent words and introduce implicit information. We tested a broad range of textual representations for their capacity to address these issues. We found that as expected, contextualized word representations perform better than static word embeddings, more so on detecting meaning shift than in recovering implicit information, in which their performance is still far from that of humans. Our evaluation suite, including 5 tasks related to lexical composition effects, can serve future research aiming to improve such representations.|sl:tag|tag:contextualised_word_representations
Feynman|skos:broader|Scientifique
Eclipse project|skos:broader|Eclipse
Europeana|skos:broader|European project
 general-purpose neural embedding  model that can solve a wide variety of problems: labeling  tasks such as text classification, ranking tasks such as information  retrieval/web search, collaborative filtering-based  or content-based recommendation, embedding of multirelational  graphs, and learning word, sentence or document  level embeddings    [Github](https://github.com/facebookresearch/starSpace)    (seems to be the solution for [#Multi-Label classification](/tag/multi_label_classification) that [#FastText](/tag/fasttext) doesn't support very well)  |skos:broader|The objective of embedding methods is to organize symbolic objects (e.g., words, entities, concepts) in a way such that their similarity in the embedding space reflects their semantic or functional similarity  
Rada Mihalcea|skos:broader|NLP girls and guys
BERT for Joint Intent Classification and Slot Filling  Experimental results show that our  proposed joint BERT model outperforms BERT  models modeling intent classification and slot filling  separately, demonstrating the efficacy of exploiting  the relationship between the two tasks.    Adding a CRF on top of the model doesn't improve the results. Intent classification and slot filling are two essential tasks for natural language understanding. They often suffer from small-scale human-labeled training data, resulting in poor generalization capability, especially for rare words. Recently a new language representation model, BERT (Bidirectional Encoder Representations from Transformers), facilitates pre-training deep bidirectional representations on large-scale unlabeled corpora, and has created state-of-the-art models for a wide variety of natural language processing tasks after simple fine-tuning. However, there has not been much effort on exploring BERT for natural language understanding. In this work, we propose a joint intent classification and slot filling model based on BERT. Experimental results demonstrate that our proposed model achieves significant improvement on intent classification accuracy, slot filling F1, and sentence-level semantic frame accuracy on several public benchmark datasets, compared to the attention-based recurrent neural network models and slot-gated models.|sl:tag|tag:arxiv_doc
SOAP vs REST|skos:broader|REST
Disparition des abeilles|skos:broader|Catastrophe écologique
Tepuys|skos:broader|Venezuela
Configuration ontology|skos:broader|C2GWeb RDF
Deep Learning: A Critical Appraisal Although deep learning has historical roots going back decades, neither the term deep learning nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic (2012) deep network model of Imagenet. What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.|sl:tag|tag:nn_symbolic_ai_hybridation
Nuclear war|skos:broader|War
Functional programming|skos:broader|Programming language
Stack Overflow|skos:broader|Dev tools
RDF Validator|skos:broader|Validator
Richard Stallman|skos:broader|Technical girls and guys
Vector space model|skos:broader|Information retrieval: techniques
On Extractive and Abstractive Neural Document Summarization with Transformer Language Models  Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper. We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We show that this extractive step significantly improves summarization results. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher rouge scores. Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper.|sl:tag|tag:arxiv_doc
Word Representations via Gaussian Embedding  Current work in lexical distributed representations maps each word to a point vector in low-dimensional space. Mapping instead to a density provides many interesting advantages     Novel word embedding algorithms that embed words directly as Gaussian distributional potential functions in an infinite dimensional function space. This allows us to map word types not only to vectors but to soft regions in space, modeling uncertainty, inclusion, and entailment, as well as providing a rich geometry of the latent space. Current work in lexical distributed representations maps each word to a point vector in low-dimensional space. Mapping instead to a density provides many interesting advantages, including better capturing uncertainty about a representation and its relationships, expressing asymmetries more naturally than dot product or cosine similarity, and enabling more expressive parameterization of decision boundaries. This paper advocates for density-based distributed embeddings and presents a method for learning representations in the space of Gaussian distributions. We compare performance on various word embedding benchmarks, investigate the ability of these embeddings to model entailment and other asymmetric relationships, and explore novel properties of the representation.|sl:tag|tag:arxiv_doc
Intelligence collective|skos:broader|Intelligence
Transformers as Soft Reasoners over Language  AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. We provide the first demonstration that this is possible, and characterize the extent of this capability. To do this, we use a collection of synthetic datasets that test increasing levels of reasoning complexity (number of rules, presence of negation, and depth of chaining). We find transformers appear to learn rule-based reasoning with high (99%) accuracy on these datasets, and in a way that generalizes to test data requiring substantially deeper chaining than in the training data (95%+ scores). We also demonstrate that the models transfer well to two hand-authored rulebases, and to rulebases paraphrased into more natural language. These findings are significant as it suggests a new role for transformers, namely as a limited soft theorem prover operating over explicit theories in language. This in turn suggests new possibilities for explainability, correctability, and counterfactual reasoning in question-answering. All datasets and a live demo are available at http://rule-reasoning.apps.allenai.org/|sl:arxiv_author|Kyle Richardson
open-source framework for gradient boosting (java, python, etc)|skos:broader|ML technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. Allows the optimization of an arbitrary differentiable loss function.  
Self-Taught Convolutional Neural Networks for Short Text Clustering  We propose a flexible short text clustering framework which explores the feasibility and effectiveness of combining CNN and traditional unsupervised dimensionality reduction methods.     Non-biased deep feature representations can be learned through our self- taught CNN framework which does not use any external tags/labels or complicated NLP pre-processing.     The original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations.    [conf paper, same authors](http://www.aclweb.org/anthology/W15-1509) ; [gitgub repo (matlab)](https://github.com/jacoxu/STC2)   Short text clustering is a challenging problem due to its sparseness of text representation. Here we propose a flexible Self-Taught Convolutional neural network framework for Short Text Clustering (dubbed STC^2), which can flexibly and successfully incorporate more useful semantic features and learn non-biased deep text representation in an unsupervised manner. In our framework, the original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations. Extensive experimental results demonstrate that the proposed framework is effective, flexible and outperform several popular clustering methods when tested on three public short text datasets.|sl:arxiv_author|Bo Xu
delicious api|skos:broader|API
Deep Learning: A Critical Appraisal Although deep learning has historical roots going back decades, neither the term deep learning nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic (2012) deep network model of Imagenet. What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.|sl:arxiv_firstAuthor|Gary Marcus
Encyclopedia of Life|skos:broader|Biology
GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden unit), or embedding-free units such as image pixels.|sl:arxiv_author|William W. Cohen
fpservant@slideshare|skos:broader|slides fps
Gilberto Gil|skos:broader|Musique brésilienne
RDF dev|skos:broader|RDF
SemWeb Pro|skos:broader|Conférences
Panthéon (Paris)|skos:broader|Paris
Consciousness Prior|skos:broader|NN / Symbolic AI hybridation
scikit-learn|skos:broader|Python 4 Data science
Dev tools|skos:broader|Dev
Brain-to-Brain Interface|skos:broader|Brain
Penseur|skos:broader|Divers
Euro 2016|skos:broader|Football
Jeux en ligne|skos:broader|Computer game
Antiquité|skos:broader|Histoire
Flair|skos:broader|NLP tools
TensorFlow|skos:broader|Deep Learning frameworks
Dremel|skos:broader|Google
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:arxiv_author|Ari Holtzman
Web Services|skos:broader|Dev
Google car|skos:broader|Google
Pre-trained Models for Natural Language Processing: A Survey Recently, the emergence of pre-trained models (PTMs) has brought natural language processing (NLP) to a new era. In this survey, we provide a comprehensive review of PTMs for NLP. We first briefly introduce language representation learning and its research progress. Then we systematically categorize existing PTMs based on a taxonomy with four perspectives. Next, we describe how to adapt the knowledge of PTMs to the downstream tasks. Finally, we outline some potential directions of PTMs for future research. This survey is purposed to be a hands-on guide for understanding, using, and developing PTMs for various NLP tasks.|sl:arxiv_author|Ning Dai
Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data Word embeddings are a popular approach to unsupervised learning of word relationships that are widely used in natural language processing. In this article, we present a new set of embeddings for medical concepts learned using an extremely large collection of multimodal medical data. Leaning on recent theoretical insights, we demonstrate how an insurance claims database of 60 million members, a collection of 20 million clinical notes, and 1.7 million full text biomedical journal articles can be combined to embed concepts into a common space, resulting in the largest ever set of embeddings for 108,477 medical concepts. To evaluate our approach, we present a new benchmark methodology based on statistical power specifically designed to test embeddings of medical concepts. Our approach, called cui2vec, attains state-of-the-art performance relative to previous methods in most instances. Finally, we provide a downloadable set of pre-trained embeddings for other researchers to use, as well as an online tool for interactive exploration of the cui2vec embeddings|sl:arxiv_author|Allen Schmaltz
Minimum wage|skos:broader|Salaire
Generalization through Memorization: Nearest Neighbor Language Models extend LMs with nearest neighbor search in embedding space We introduce $k$NN-LMs, which extend a pre-trained neural language model (LM) by linearly interpolating it with a $k$-nearest neighbors ($k$NN) model. The nearest neighbors are computed according to distance in the pre-trained LM embedding space, and can be drawn from any text collection, including the original LM training data. Applying this augmentation to a strong Wikitext-103 LM, with neighbors drawn from the original training set, our $k$NN-LM achieves a new state-of-the-art perplexity of 15.79 - a 2.9 point improvement with no additional training. We also show that this approach has implications for efficiently scaling up to larger training sets and allows for effective domain adaptation, by simply varying the nearest neighbor datastore, again without further training. Qualitatively, the model is particularly helpful in predicting rare patterns, such as factual knowledge. Together, these results strongly suggest that learning similarity between sequences of text is easier than predicting the next word, and that nearest neighbor search is an effective approach for language modeling in the long tail.|sl:arxiv_firstAuthor|Urvashi Khandelwal
REST Security|skos:broader|REST
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:tag|tag:taxonomies
ATerm|skos:broader|Dev
Cross-Entropy|skos:broader|Information theory
Structured Knowledge Distillation for Dense Prediction In this paper, we consider transferring the structure information from large networks to small ones for dense prediction tasks. Previous knowledge distillation strategies used for dense prediction tasks often directly borrow the distillation scheme for image classification and perform knowledge distillation for each pixel separately, leading to sub-optimal performance. Here we propose to distill structured knowledge from large networks to small networks, taking into account the fact that dense prediction is a structured prediction problem. Specifically, we study two structured distillation schemes: i)pair-wise distillation that distills the pairwise similarities by building a static graph, and ii)holistic distillation that uses adversarial training to distill holistic knowledge. The effectiveness of our knowledge distillation approaches is demonstrated by extensive experiments on three dense prediction tasks: semantic segmentation, depth estimation, and object detection.|sl:arxiv_author|Yifan Liu
C2GWeb and Product description|skos:broader|C2GWeb
Learning Confidence for Out-of-Distribution Detection in Neural Networks Modern neural networks are very powerful predictive models, but they are often incapable of recognizing when their predictions may be wrong. Closely related to this is the task of out-of-distribution detection, where a network must determine whether or not an input is outside of the set on which it is expected to safely perform. To jointly address these issues, we propose a method of learning confidence estimates for neural networks that is simple to implement and produces intuitively interpretable outputs. We demonstrate that on the task of out-of-distribution detection, our technique surpasses recently proposed techniques which construct confidence based on the network's output distribution, without requiring any additional labels or access to out-of-distribution examples. Additionally, we address the problem of calibrating out-of-distribution detectors, where we demonstrate that misclassified in-distribution examples can be used as a proxy for out-of-distribution examples.|sl:arxiv_author|Graham W. Taylor
k-means clustering|skos:broader|Unsupervised machine learning
RDF Framework|skos:broader|RDF
Hidden Markov model|skos:broader|Machine learning: techniques
New Horizons|skos:broader|Missions spatiales
Unsupervised Transfer Learning for Spoken Language Understanding in Intelligent Agents  We apply ELMo, ULMFiT (unsupervised transfer) with supervised transfer to reduce labeled data required for launching domains in Alexa by 10-15x User interaction with voice-powered agents generates large amounts of unlabeled utterances. In this paper, we explore techniques to efficiently transfer the knowledge from these unlabeled utterances to improve model performance on Spoken Language Understanding (SLU) tasks. We use Embeddings from Language Model (ELMo) to take advantage of unlabeled data by learning contextualized word representations. Additionally, we propose ELMo-Light (ELMoL), a faster and simpler unsupervised pre-training method for SLU. Our findings suggest unsupervised pre-training on a large corpora of unlabeled utterances leads to significantly better SLU performance compared to training from scratch and it can even outperform conventional supervised transfer. Additionally, we show that the gains from unsupervised transfer techniques can be further improved by supervised transfer. The improvements are more pronounced in low resource settings and when using only 1000 labeled in-domain samples, our techniques match the performance of training from scratch on 10-15x more labeled in-domain data.|sl:arxiv_author|Angeliki Metallinou
Advances in Pre-Training Distributed Word Representations  we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks Many Natural Language Processing applications nowadays rely on pre-trained word representations estimated from large text corpora such as news collections, Wikipedia and Web Crawl. In this paper, we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks.|sl:arxiv_author|Armand Joulin
matplotlib|skos:broader|Data Visualization Tools
Word Representations via Gaussian Embedding  Current work in lexical distributed representations maps each word to a point vector in low-dimensional space. Mapping instead to a density provides many interesting advantages     Novel word embedding algorithms that embed words directly as Gaussian distributional potential functions in an infinite dimensional function space. This allows us to map word types not only to vectors but to soft regions in space, modeling uncertainty, inclusion, and entailment, as well as providing a rich geometry of the latent space. Current work in lexical distributed representations maps each word to a point vector in low-dimensional space. Mapping instead to a density provides many interesting advantages, including better capturing uncertainty about a representation and its relationships, expressing asymmetries more naturally than dot product or cosine similarity, and enabling more expressive parameterization of decision boundaries. This paper advocates for density-based distributed embeddings and presents a method for learning representations in the space of Gaussian distributions. We compare performance on various word embedding benchmarks, investigate the ability of these embeddings to model entailment and other asymmetric relationships, and explore novel properties of the representation.|sl:arxiv_author|Andrew McCallum
LOD mailing list|skos:broader|Mailing list
Langues|skos:broader|Language
Keras|skos:broader|Deep Learning frameworks
Linked Data: application|skos:broader|Linked Data
One-Shot Generalization in Deep Generative Models Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our models are able to generate compelling and diverse samples---having seen new examples just once---providing an important class of general-purpose models for one-shot machine learning.|sl:tag|tag:machine_learning
The HSIC Bottleneck: Deep Learning without Back-Propagation  we show that it is possible to learn classification tasks at near competitive accuracy without  backpropagation, by maximizing a surrogate of the mutual information between hidden representations and labels and  simultaneously minimizing the mutual dependency between hidden representations and the inputs...  the hidden units of a network trained in this way form useful representations. Specifically, fully competitive accuracy  can be obtained by freezing the network trained without backpropagation and appending and training a one-layer  network using conventional SGD to convert convert the representation to the desired format.    The training method uses an approximation of the [#information bottleneck](/tag/information_bottleneck_method).    Advantages:     - The method facilitates parallel processing and requires significantly less operations.    - It does not suffer from exploding or vanishing gradients.   - It is biologically more plausible than Backpropagation     We introduce the HSIC (Hilbert-Schmidt independence criterion) bottleneck for training deep neural networks. The HSIC bottleneck is an alternative to the conventional cross-entropy loss and backpropagation that has a number of distinct advantages. It mitigates exploding and vanishing gradients, resulting in the ability to learn very deep networks without skip connections. There is no requirement for symmetric feedback or update locking. We find that the HSIC bottleneck provides performance on MNIST/FashionMNIST/CIFAR10 classification comparable to backpropagation with a cross-entropy target, even when the system is not encouraged to make the output resemble the classification labels. Appending a single layer trained with SGD (without backpropagation) to reformat the information further improves performance.|sl:arxiv_firstAuthor|Wan-Duo Kurt Ma
RW Linked Data|skos:broader|LD
Java 1.5 Mac OS X|skos:broader|Java 5
Attention Is All You Need  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.|sl:arxiv_author|Llion Jones
Twittérature|skos:broader|Twitter
Common Tag|skos:broader|RDFa
Ora Lassila|skos:broader|Technical girls and guys
Relation Extraction|skos:broader|NLP tasks / problems
Daimler|skos:broader|Automobile
Docker-Tomcat|skos:broader|Docker
Spam|skos:broader|Internet
Droit et internet|skos:broader|Droit
ACL 2019|skos:broader|ACL
Embeddings in NLP|skos:broader|Embeddings
Sun Microsystems|skos:broader|Entreprise
WWW 2015|skos:broader|TheWebConf
1ere guerre mondiale|skos:broader|War
Gabon|skos:broader|Afrique équatoriale
Dan Connolly|skos:broader|Technical girls and guys
Compressive Transformers for Long-Range Sequence Modelling  the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning.    [Blog post](/doc/2020/02/a_new_model_and_dataset_for_lon) We present the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning. We find the Compressive Transformer obtains state-of-the-art language modelling results in the WikiText-103 and Enwik8 benchmarks, achieving 17.1 ppl and 0.97 bpc respectively. We also find it can model high-frequency speech effectively and can be used as a memory mechanism for RL, demonstrated on an object matching task. To promote the domain of long-range sequence learning, we propose a new open-vocabulary language modelling benchmark derived from books, PG-19.|sl:tag|tag:memory_in_deep_learning
gnowsis|skos:broader|Semanlink related
OWLED|skos:broader|OWL
Blair|skos:broader|UK
The Web is dying|skos:broader|Web
LinkNBed: Multi-Graph Representation Learning with Entity Linkage   a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure     We posit that combining  graph alignment task with deep representation  learning across multi-relational graphs has potential  to induce a synergistic effect on both tasks Knowledge graphs have emerged as an important model for studying complex multi-relational data. This has given rise to the construction of numerous large scale but incomplete knowledge graphs encoding information extracted from various resources. An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledge-based inference for many downstream applications. To this end, we propose LinkNBed, a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure. Experiments on link prediction and entity linkage demonstrate substantial improvements over the state-of-the-art relational learning approaches.|sl:tag|tag:graph_embeddings
Bidirectional LSTM-CRF Models for Sequence Tagging In this paper, we propose a variety of Long Short-Term Memory (LSTM) based models for sequence tagging. These models include LSTM networks, bidirectional LSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer (LSTM-CRF) and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work is the first to apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model to NLP benchmark sequence tagging data sets. We show that the BI-LSTM-CRF model can efficiently use both past and future input features thanks to a bidirectional LSTM component. It can also use sentence level tag information thanks to a CRF layer. The BI-LSTM-CRF model can produce state of the art (or close to) accuracy on POS, chunking and NER data sets. In addition, it is robust and has less dependence on word embedding as compared to previous observations.|sl:arxiv_author|Wei Xu
Europe and UK|skos:broader|Union européenne
N-gram|skos:broader|Language Modeling Statistical Language Model
Neural network interpretability|skos:broader|Neural networks
Bayesian analysis|skos:broader|Uncertainty Reasoning
Knowledge Discovery|skos:broader|Knowledge Engineering
Iapetus|skos:broader|Saturne
TabFact: A Large-scale Dataset for Table-based Fact Verification fact verification given semi-structured data as evidence The problem of verifying whether a textual hypothesis holds based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation. However, existing studies are mainly restricted to dealing with unstructured evidence (e.g., natural language sentences and documents, news, etc), while verification under structured evidence, such as tables, graphs, and databases, remains under-explored. This paper specifically aims to study the fact verification given semi-structured data as evidence. To this end, we construct a large-scale dataset called TabFact with 16k Wikipedia tables as the evidence for 118k human-annotated natural language statements, which are labeled as either ENTAILED or REFUTED. TabFact is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning. To address these reasoning challenges, we design two different models: Table-BERT and Latent Program Algorithm (LPA). Table-BERT leverages the state-of-the-art pre-trained language model to encode the linearized tables and statements into continuous vectors for verification. LPA parses statements into programs and executes them against the tables to obtain the returned binary value for verification. Both methods achieve similar accuracy but still lag far behind human performance. We also perform a comprehensive analysis to demonstrate great future opportunities. The data and code of the dataset are provided in \\url{https://github.com/wenhuchen/Table-Fact-Checking}.|sl:tag|tag:table_based_fact_verification
Text in KG embeddings|skos:broader|Knowledge Graph Embeddings
Question Answering over Knowledge Graphs via Structural Query Patterns Natural language question answering over knowledge graphs is an important and interesting task as it enables common users to gain accurate answers in an easy and intuitive manner. However, it remains a challenge to bridge the gap between unstructured questions and structured knowledge graphs. To address the problem, a natural discipline is building a structured query to represent the input question. Searching the structured query over the knowledge graph can produce answers to the question. Distinct from the existing methods that are based on semantic parsing or templates, we propose an effective approach powered by a novel notion, structural query pattern, in this paper. Given an input question, we first generate its query sketch that is compatible with the underlying structure of the knowledge graph. Then, we complete the query graph by labeling the nodes and edges under the guidance of the structural query pattern. Finally, answers can be retrieved by executing the constructed query graph over the knowledge graph. Evaluations on three question answering benchmarks show that our proposed approach outperforms state-of-the-art methods significantly.|sl:arxiv_firstAuthor|Weiguo Zheng
GAN|skos:broader|Neural networks
About RDF|skos:broader|RDF
Google Maps|skos:broader|Carte
KD-MKB biblio|skos:broader|KD-MKB
RDFa tool|skos:broader|Dev tools
Deutsch@de|skos:broader|Langues vivantes
On Extractive and Abstractive Neural Document Summarization with Transformer Language Models  Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper. We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We show that this extractive step significantly improves summarization results. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher rouge scores. Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper.|sl:tag|tag:rigolo
Design Challenges and Misconceptions in Neural Sequence Labeling design challenges of constructing effective and efficient neural sequence labeling systems We investigate the design challenges of constructing effective and efficient neural sequence labeling systems, by reproducing twelve neural sequence labeling models, which include most of the state-of-the-art structures, and conduct a systematic model comparison on three benchmarks (i.e. NER, Chunking, and POS tagging). Misconceptions and inconsistent conclusions in existing literature are examined and clarified under statistical experiments. In the comparison and analysis process, we reach several practical conclusions which can be useful to practitioners.|sl:tag|tag:sequence_labeling
OWLED 2007|skos:broader|OWLED
Stemming|skos:broader|General NLP tasks
Deep Learning and the Information Bottleneck Principle  Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN.   Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.|sl:arxiv_author|Naftali Tishby
Seq2Seq with Attention|skos:broader|Attention mechanism
A mathematical theory of semantic development in deep neural networks  a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences?   An extensive body of empirical research has revealed remarkable regularities in the acquisition, organization, deployment, and neural representation of human semantic knowledge, thereby raising a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences? We address this question by mathematically analyzing the nonlinear dynamics of learning in deep linear networks. We find exact solutions to this learning dynamics that yield a conceptual explanation for the prevalence of many disparate phenomena in semantic cognition, including the hierarchical differentiation of concepts through rapid developmental transitions, the ubiquity of semantic illusions between such transitions, the emergence of item typicality and category coherence as factors controlling the speed of semantic processing, changing patterns of inductive projection over development, and the conservation of semantic similarity in neural representations across species. Thus, surprisingly, our simple neural model qualitatively recapitulates many diverse regularities underlying semantic development, while providing analytic insight into how the statistical structure of an environment can interact with nonlinear deep learning dynamics to give rise to these regularities.|sl:arxiv_firstAuthor|Andrew M. Saxe
A Metric Learning Reality Check Deep metric learning papers from the past four years have consistently claimed great advances in accuracy, often more than doubling the performance of decade-old methods. In this paper, we take a closer look at the field to see if this is actually true. We find flaws in the experimental setup of these papers, and propose a new way to evaluate metric learning algorithms. Finally, we present experimental results that show that the improvements over time have been marginal at best.|sl:tag|tag:metric_learning
Scalable Nearest Neighbor Search for Optimal Transport The Optimal Transport (a.k.a. Wasserstein) distance is an increasingly popular similarity measure for rich data domains, such as images or text documents. This raises the necessity for fast nearest neighbor search with respect to this distance, a problem that poses a substantial computational bottleneck for various tasks on massive datasets. In this work, we study fast tree-based approximation algorithms for searching nearest neighbors w.r.t. the Wasserstein-1 distance. A standard tree-based technique, known as Quadtree, has been previously shown to obtain good results. We introduce a variant of this algorithm, called Flowtree, and formally prove it achieves asymptotically better accuracy. Our extensive experiments, on real-world text and image datasets, show that Flowtree improves over various baselines and existing methods in either running time or accuracy. In particular, its quality of approximation is in line with previous high-accuracy methods, while its running time is much faster.|sl:arxiv_author|Arturs Backurs
NLP: Reading Comprehension|skos:broader|NLU
Paludisme|skos:broader|Grands problèmes
Les petites cases|skos:broader|Gautier Poupeau
Semantic Web Dev|skos:broader|Semantic Web
Web architecture|skos:broader|Test of independent invention
Spatial search|skos:broader|Algorithmes
Bing|skos:broader|Search Engines
Semantic Folding Theory And its Application in Semantic Fingerprinting Human language is recognized as a very complex domain since decades. No computer system has been able to reach human levels of performance so far. The only known computational system capable of proper language processing is the human brain. While we gather more and more data about the brain, its fundamental computational processes still remain obscure. The lack of a sound computational brain theory also prevents the fundamental understanding of Natural Language Processing. As always when science lacks a theoretical foundation, statistical modeling is applied to accommodate as many sampled real-world data as possible. An unsolved fundamental issue is the actual representation of language (data) within the brain, denoted as the Representational Problem. Starting with Jeff Hawkins' Hierarchical Temporal Memory (HTM) theory, a consistent computational theory of the human cortex, we have developed a corresponding theory of language data representation: The Semantic Folding Theory. The process of encoding words, by using a topographic semantic space as distributional reference frame into a sparse binary representational vector is called Semantic Folding and is the central topic of this document. Semantic Folding describes a method of converting language from its symbolic representation (text) into an explicit, semantically grounded representation that can be generically processed by Hawkins' HTM networks. As it turned out, this change in representation, by itself, can solve many complex NLP problems by applying Boolean operators and a generic similarity function like the Euclidian Distance. Many practical problems of statistical NLP systems, like the high cost of computation, the fundamental incongruity of precision and recall , the complex tuning procedures etc., can be elegantly overcome by applying Semantic Folding.|sl:tag|tag:arxiv_doc
Film de guerre|skos:broader|Film
Graph Convolutional Networks|skos:broader|Convolutional neural network
Proposed in a paper at EMLNP 2018: use Odd-Man-Out puzzles|skos:broader|[Best presentation](doc:2020/06/on_word_embeddings) about word embeddings, by [Sebastian Ruder](tag:sebastian_ruder)    Capture the idea that one can express “meaning” of words using a vector, so that the cosine of the angle between the vectors captures semantic similarity.    A set of language modeling and feature learning techniques where words from the vocabulary (and possibly phrases thereof) are mapped to vectors of real numbers in a low dimensional space, relative to the vocabulary size.     ~ Context-predicting models    ~ Latent feature representations of words    Paramaterized function mapping words in some language to vectors (perhaps 200 to 500 dimensions). Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with much lower dimension.    Plongement lexical in French    Word embedding of a word: a succinct representation of the distribution of other words around this word.    Methods to generate the mapping include neural networks, dimensionality reduction on the word co-occurrence matrix, probabilistic models, and explicit representation in terms of the context in which words appear.    In the new generation of models, the vector estimation problem is handled as a supervised task, where the weights in a word vector are set to maximize the probability of the contexts in which the word is observed in the corpus    The mapping may be generated training a neural network on a large corpus to predict a word given a context (Continuous Bag Of Words model) or to predict the context given a word (skip gram model). The context is a window of surrounding words.    The most known software to produce word embeddings is Tomas Mikolov's Word2vec. Pre-trained word embeddings are also available in the word2vec code.google page.    Applications:     - search document ranking  - boost the performance in NLP tasks such as syntactic parsing and sentiment analysis.          
Jean Rouch|skos:broader|Afrique
Museum d'Histoire Naturelle|skos:broader|Biology
Adolescents|skos:broader|Société
URI dereferencing|skos:broader|URI
Relation Extraction|skos:broader|Knowledge Extraction
Macaw: An Extensible Conversational Information Seeking Platform Conversational information seeking (CIS) has been recognized as a major emerging research area in information retrieval. Such research will require data and tools, to allow the implementation and study of conversational systems. This paper introduces Macaw, an open-source framework with a modular architecture for CIS research. Macaw supports multi-turn, multi-modal, and mixed-initiative interactions, and enables research for tasks such as document retrieval, question answering, recommendation, and structured data exploration. It has a modular design to encourage the study of new CIS algorithms, which can be evaluated in batch mode. It can also integrate with a user interface, which allows user studies and data collection in an interactive mode, where the back end can be fully algorithmic or a wizard of oz setup. Macaw is distributed under the MIT License.|sl:tag|tag:question_answering
Attention Is All You Need  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.|sl:arxiv_author|Noam Shazeer
Semi-supervised Clustering for Short Text via Deep Representation Learning semi-supervised method for short text clustering, where we represent texts as distributed vectors with neural networks, and use a small amount of labeled data to specify our intention for clustering. We design a novel objective to combine the representation learning process and the k-means clustering process together, and optimize the objective with both labeled data and unlabeled data iteratively until convergence through three steps:     1. assign each short text to its nearest centroid based on its representation from the current neural networks;  2. re-estimate the cluster centroids based on cluster assignments from step (1);  3. update neural networks according to the objective by keeping centroids and cluster assignments fixed.   In this work, we propose a semi-supervised method for short text clustering, where we represent texts as distributed vectors with neural networks, and use a small amount of labeled data to specify our intention for clustering. We design a novel objective to combine the representation learning process and the k-means clustering process together, and optimize the objective with both labeled data and unlabeled data iteratively until convergence through three steps: (1) assign each short text to its nearest centroid based on its representation from the current neural networks; (2) re-estimate the cluster centroids based on cluster assignments from step (1); (3) update neural networks according to the objective by keeping centroids and cluster assignments fixed. Experimental results on four datasets show that our method works significantly better than several other text clustering methods.|sl:tag|tag:semi_supervised_learning
Topic Models + Word embedding|skos:broader|Topic Modeling
Deep Mutual Learning  In this paper we explore a different but related idea to model distillation – that of mutual learning. Distillation starts with a powerful large and pre-trained teacher network and performs one-way knowledge transfer to a small untrained student. In contrast, in mutual learning we start with a pool of untrained students who learn simultaneously to solve the task together.    [critic here](doc:2020/06/1804_03235_large_scale_distri):     Zhang et al. (2017) reported a benefit in quality over  basic distillation, but they compare distilling model M1 into model M2 with training model M1  and model M2 using codistillation; they do not compare to distilling an ensemble of models M1  and M2 into model M3.     ...     we can achieve the 70.7% they report for online  distillation using traditional offline distillation. Model distillation is an effective and widely used technique to transfer knowledge from a teacher to a student network. The typical application is to transfer from a powerful large network or ensemble to a small network, that is better suited to low-memory or fast execution requirements. In this paper, we present a deep mutual learning (DML) strategy where, rather than one way transfer between a static pre-defined teacher and a student, an ensemble of students learn collaboratively and teach each other throughout the training process. Our experiments show that a variety of network architectures benefit from mutual learning and achieve compelling results on CIFAR-100 recognition and Market-1501 person re-identification benchmarks. Surprisingly, it is revealed that no prior powerful teacher network is necessary -- mutual learning of a collection of simple student networks works, and moreover outperforms distillation from a more powerful yet static teacher.|sl:arxiv_author|Huchuan Lu
TimBL TBL|skos:broader|Technical guys
Text mining|skos:broader|Data mining
Generalization through Memorization: Nearest Neighbor Language Models extend LMs with nearest neighbor search in embedding space We introduce $k$NN-LMs, which extend a pre-trained neural language model (LM) by linearly interpolating it with a $k$-nearest neighbors ($k$NN) model. The nearest neighbors are computed according to distance in the pre-trained LM embedding space, and can be drawn from any text collection, including the original LM training data. Applying this augmentation to a strong Wikitext-103 LM, with neighbors drawn from the original training set, our $k$NN-LM achieves a new state-of-the-art perplexity of 15.79 - a 2.9 point improvement with no additional training. We also show that this approach has implications for efficiently scaling up to larger training sets and allows for effective domain adaptation, by simply varying the nearest neighbor datastore, again without further training. Qualitatively, the model is particularly helpful in predicting rare patterns, such as factual knowledge. Together, these results strongly suggest that learning similarity between sequences of text is easier than predicting the next word, and that nearest neighbor search is an effective approach for language modeling in the long tail.|sl:tag|tag:facebook_fair
XLNet: Generalized Autoregressive Pretraining for Language Understanding a new pretraining method for NLP that significantly improves upon BERT on 20 tasks (e.g., SQuAD, GLUE, RACE) With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.|sl:arxiv_author|Quoc V. Le
Smalltalk|skos:broader|Programming language
Semantic Wiki|skos:broader|Wiki
Sud des Etats-Unis|skos:broader|USA
Self-Taught Hashing for Fast Similarity Search Emphasise following issue in Semantic Hashing: obtaining the codes for previously unseen documents. Propose following approach:  first find the optimal l-bit binary codes for all documents in  the given corpus via unsupervised learning, then train  l classifiers via supervised learning to predict the l-bit code  for any query document unseen before.    (méthode résumée [ici](https://www.semanticscholar.org/paper/Semantic-hashing-using-tags-and-topic-modeling-Wang-Zhang/1a0f660f70fd179003edc271694736baaa39dec4))       The ability of fast similarity search at large scale is of great importance to many Information Retrieval (IR) applications. A promising way to accelerate similarity search is semantic hashing which designs compact binary codes for a large number of documents so that semantically similar documents are mapped to similar codes (within a short Hamming distance). Although some recently proposed techniques are able to generate high-quality codes for documents known in advance, obtaining the codes for previously unseen documents remains to be a very challenging problem. In this paper, we emphasise this issue and propose a novel Self-Taught Hashing (STH) approach to semantic hashing: we first find the optimal $l$-bit binary codes for all documents in the given corpus via unsupervised learning, and then train $l$ classifiers via supervised learning to predict the $l$-bit code for any query document unseen before. Our experiments on three real-world text datasets show that the proposed approach using binarised Laplacian Eigenmap (LapEig) and linear Support Vector Machine (SVM) outperforms state-of-the-art techniques significantly.|sl:arxiv_author|Jinsong Lu
Swift|skos:broader|Programming language
Mussolini|skos:broader|Fascisme
Learning with Memory Embeddings Embedding learning, a.k.a. representation learning, has been shown to be able to model large-scale semantic knowledge graphs. A key concept is a mapping of the knowledge graph to a tensor representation whose entries are predicted by models using latent representations of generalized entities. Latent variable models are well suited to deal with the high dimensionality and sparsity of typical knowledge graphs. In recent publications the embedding models were extended to also consider time evolutions, time patterns and subsymbolic representations. In this paper we map embedding models, which were developed purely as solutions to technical problems for modelling temporal knowledge graphs, to various cognitive memory functions, in particular to semantic and concept memory, episodic memory, sensory memory, short-term memory, and working memory. We discuss learning, query answering, the path from sensory input to semantic decoding, and the relationship between episodic memory and semantic memory. We introduce a number of hypotheses on human memory that can be derived from the developed mathematical models.|sl:tag|tag:arxiv_doc
Cheval|skos:broader|Animal
Graph Convolutional Network GCN|skos:broader|CNN Convnet Convnets Convolutional neural networks
Continual Lifelong Learning with Neural Networks: A Review Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.|sl:arxiv_author|Jose L. Part
Paradoxe Einstein-Podolsky-Rosen|skos:broader|Einstein
SPARQL Tips|skos:broader|SPARQL
From Word to Sense Embeddings: A Survey on Vector Representations of Meaning Survey focused on semantic representation of meaning (methods that try to directly model individual meanings of words).    Pb with word embeddings: the meaning conflation deficiency (representing a word with all its possible meanings as a single vector). Can be addressed by a method for modelling unambiguous lexical meaning.    two main branches of sense representation :    - unsupervised   - knowledge-based Over the past years, distributed semantic representations have proved to be effective and flexible keepers of prior knowledge to be integrated into downstream applications. This survey focuses on the representation of meaning. We start from the theoretical background behind word vector space models and highlight one of their major limitations: the meaning conflation deficiency, which arises from representing a word with all its possible meanings as a single vector. Then, we explain how this deficiency can be addressed through a transition from the word level to the more fine-grained level of word senses (in its broader acceptation) as a method for modelling unambiguous lexical meaning. We present a comprehensive overview of the wide range of techniques in the two main branches of sense representation, i.e., unsupervised and knowledge-based. Finally, this survey covers the main evaluation procedures and applications for this type of representation, and provides an analysis of four of its important aspects: interpretability, sense granularity, adaptability to different domains and compositionality.|sl:arxiv_firstAuthor|Jose Camacho-Collados
Phishing|skos:broader|Internet
Natural Language Processing|skos:broader|favorites
Cringely|skos:broader|PBS
Deep Learning: A Critical Appraisal Although deep learning has historical roots going back decades, neither the term deep learning nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic (2012) deep network model of Imagenet. What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.|sl:arxiv_author|Gary Marcus
Catastrophe industrielle|skos:broader|Catastrophe
Vidéosurveillance|skos:broader|Big Brother
An Introduction to Conditional Random Fields Often we wish to predict a large number of variables that depend on each other as well as on other observed variables. Structured prediction methods are essentially a combination of classification and graphical modeling, combining the ability of graphical models to compactly model multivariate data with the ability of classification methods to perform prediction using large sets of input features. This tutorial describes conditional random fields, a popular probabilistic method for structured prediction. CRFs have seen wide application in natural language processing, computer vision, and bioinformatics. We describe methods for inference and parameter estimation for CRFs, including practical issues for implementing large scale CRFs. We do not assume previous knowledge of graphical modeling, so this tutorial is intended to be useful to practitioners in a wide variety of fields.|sl:tag|tag:andrew_mccallum
Named Entity Recognition with Extremely Limited Data Named Entity Search (NES)     We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.     We do not propose this as a replacement  for NER, but as something to be used for an ephemeral or contextual  class of entity, when it does not make sense to label hundreds or  thousands of instances to learn a classifier Traditional information retrieval treats named entity recognition as a pre-indexing corpus annotation task, allowing entity tags to be indexed and used during search. Named entity taggers themselves are typically trained on thousands or tens of thousands of examples labeled by humans. However, there is a long tail of named entities classes, and for these cases, labeled data may be impossible to find or justify financially. We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.|sl:arxiv_firstAuthor|John Foley
Tesla|skos:broader|Automotive
Design Challenges and Misconceptions in Neural Sequence Labeling design challenges of constructing effective and efficient neural sequence labeling systems We investigate the design challenges of constructing effective and efficient neural sequence labeling systems, by reproducing twelve neural sequence labeling models, which include most of the state-of-the-art structures, and conduct a systematic model comparison on three benchmarks (i.e. NER, Chunking, and POS tagging). Misconceptions and inconsistent conclusions in existing literature are examined and clarified under statistical experiments. In the comparison and analysis process, we reach several practical conclusions which can be useful to practitioners.|sl:tag|tag:arxiv_doc
EME|skos:broader|DRM
Detecting Potential Topics In News Using BERT, CRF and Wikipedia For a news content distribution platform like Dailyhunt, Named Entity Recognition is a pivotal task for building better user recommendation and notification algorithms. Apart from identifying names, locations, organisations from the news for 13+ Indian languages and use them in algorithms, we also need to identify n-grams which do not necessarily fit in the definition of Named-Entity, yet they are important. For example, me too movement, beef ban, alwar mob lynching. In this exercise, given an English language text, we are trying to detect case-less n-grams which convey important information and can be used as topics and/or hashtags for a news. Model is built using Wikipedia titles data, private English news corpus and BERT-Multilingual pre-trained model, Bi-GRU and CRF architecture. It shows promising results when compared with industry best Flair, Spacy and Stanford-caseless-NER in terms of F1 and especially Recall.|sl:arxiv_author|Swapnil Ashok Jadhav
Javascript tool|skos:broader|JavaScript
Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs [GitHub](https://github.com/deepakn97/relationPrediction) [Blog post](/doc/2020/04/deepak_nathani_%7C_pay_attention_) The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention based feature embedding that captures both entity and relation features in any given entity's neighborhood. Additionally, we also encapsulate relation clusters and multihop relations in our model. Our empirical study offers insights into the efficacy of our attention based model and we show marked performance gains in comparison to state of the art methods on all datasets.|sl:arxiv_author|Jatin Chauhan
Tony Blair|skos:broader|Royaume Uni
Hierarchical Memory Networks  hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory Memory networks are neural networks with an explicit memory component that can be both read and written to by the network. The memory is often addressed in a soft way using a softmax function, making end-to-end training with backpropagation possible. However, this is not computationally scalable for applications which require the network to read from extremely large memories. On the other hand, it is well known that hard attention mechanisms based on reinforcement learning are challenging to train successfully. In this paper, we explore a form of hierarchical memory network, which can be considered as a hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory. Specifically, we propose to incorporate Maximum Inner Product Search (MIPS) in the training and inference procedures for our hierarchical memory network. We explore the use of various state-of-the art approximate MIPS techniques and report results on SimpleQuestions, a challenging large scale factoid question answering task.|sl:arxiv_author|Hugo Larochelle
Squeak|skos:broader|Open Source
Cocoon|skos:broader|Dev
A Survey on Knowledge Graph Embeddings with Literals: Which model links better Literal-ly? Knowledge Graphs (KGs) are composed of structured information about a particular domain in the form of entities and relations. In addition to the structured information KGs help in facilitating interconnectivity and interoperability between different resources represented in the Linked Data Cloud. KGs have been used in a variety of applications such as entity linking, question answering, recommender systems, etc. However, KG applications suffer from high computational and storage costs. Hence, there arises the necessity for a representation able to map the high dimensional KGs into low dimensional spaces, i.e., embedding space, preserving structural as well as relational information. This paper conducts a survey of KG embedding models which not only consider the structured information contained in the form of entities and relations in a KG but also the unstructured information represented as literals such as text, numerical values, images, etc. Along with a theoretical analysis and comparison of the methods proposed so far for generating KG embeddings with literals, an empirical evaluation of the different methods under identical settings has been performed for the general task of link prediction.|sl:arxiv_firstAuthor|Genet Asefa Gesese
cross-domain data fetching|skos:broader|Web dev
Nazisme|skos:broader|Fascisme
Censure et maltraitance animale|skos:broader|Droit à l'information
Efficient Estimation of Word Representations in Vector Space We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.   We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.|sl:tag|tag:word_embedding
URI Template|skos:broader|URI
Question Answering over Knowledge Graphs via Structural Query Patterns Natural language question answering over knowledge graphs is an important and interesting task as it enables common users to gain accurate answers in an easy and intuitive manner. However, it remains a challenge to bridge the gap between unstructured questions and structured knowledge graphs. To address the problem, a natural discipline is building a structured query to represent the input question. Searching the structured query over the knowledge graph can produce answers to the question. Distinct from the existing methods that are based on semantic parsing or templates, we propose an effective approach powered by a novel notion, structural query pattern, in this paper. Given an input question, we first generate its query sketch that is compatible with the underlying structure of the knowledge graph. Then, we complete the query graph by labeling the nodes and edges under the guidance of the structural query pattern. Finally, answers can be retrieved by executing the constructed query graph over the knowledge graph. Evaluations on three question answering benchmarks show that our proposed approach outperforms state-of-the-art methods significantly.|sl:arxiv_author|Mei Zhang
dajobe Dave Beckett|skos:broader|Technical guys
Marie-Jo Pérec|skos:broader|Athlétisme
Mac dev|skos:broader|Dev
Pre-trained Models for Natural Language Processing: A Survey Recently, the emergence of pre-trained models (PTMs) has brought natural language processing (NLP) to a new era. In this survey, we provide a comprehensive review of PTMs for NLP. We first briefly introduce language representation learning and its research progress. Then we systematically categorize existing PTMs based on a taxonomy with four perspectives. Next, we describe how to adapt the knowledge of PTMs to the downstream tasks. Finally, we outline some potential directions of PTMs for future research. This survey is purposed to be a hands-on guide for understanding, using, and developing PTMs for various NLP tasks.|sl:tag|tag:pre_trained_language_models
Loi sur le voile|skos:broader|Société
Web Services for JavaScript|skos:broader|Web Services
Loropéni|skos:broader|Archéologie africaine
Knowledge-augmented language models|skos:broader|Language Models + Knowledge
Automotive AND W3C|skos:broader|Automobile
Principal component analysis|skos:broader|Dimensionality reduction
Deutsch@de|skos:broader|Allemagne
Graph-based Semi-Supervised Learning|skos:broader|Graph
Empire romain|skos:broader|Antiquité romaine
Stefan Zweig|skos:broader|Autriche
LDP @ W3C|skos:broader|W3C
Eclipse|skos:broader|Dev tools
Supervised learning techniques that also make use of unlabeled data for training – typically a small amount of labeled data with a large amount of unlabeled data.|skos:broader|Machine learning focuses on prediction, based on known properties learned from the training data. Data mining (which is the analysis step of Knowledge Discovery in Databases) focuses on the discovery of (previously) unknown properties on the data.    [Glossary (by google)](https://developers.google.com/machine-learning/glossary/)
Journaliste|skos:broader|Journalisme
Une suite de matrices symétriques en rapport avec la fonction de Mertens  we explore a class of equivalence relations over N from which is constructed a sequence of symetric matrices related to the Mertens function. From numerical experimentations we suggest a conjecture, about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may play a more important part in this classical and difficult problem. In this paper we explore a class of equivalence relations over $\\N^\\ast$ from which is constructed a sequence of symetric matrices related to the Mertens function. From numerical experimentations we suggest a conjecture, about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may play a more important part in this classical and difficult problem.|sl:arxiv_author|Jean-Paul Cardinal
New Horizons|skos:broader|Pluton
Liberté, égalité, fraternité|skos:broader|Révolution française
Efficient Contextual Representation Learning Without Softmax Layer how to accelerate contextual representation learning.     Contextual representation models are difficult to train due to the large parameter sizes and high computational complexity     We find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size.  Therefore, we redesign the learning objectiv.   Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings.  Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary.  When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.    decouples learning contexts and words     Instead of using  a softmax layer to predict the distribution of the  missing word, we utilize and extend the SEMFIT  layer (Kumar and Tsvetkov, 2018) to predict the  embedding of the missing word. Contextual representation models have achieved great success in improving various downstream tasks. However, these language-model-based encoders are difficult to train due to the large parameter sizes and high computational complexity. By carefully examining the training procedure, we find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size. Therefore, we redesign the learning objective and propose an efficient framework for training contextual representation models. Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings. Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary. When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.|sl:tag|tag:arxiv_doc
Describing a Knowledge Base We aim to automatically generate natural language descriptions about an input structured knowledge base (KB). We build our generation framework based on a pointer network which can copy facts from the input KB, and add two attention mechanisms: (i) slot-aware attention to capture the association between a slot type and its corresponding slot value; and (ii) a new \\emph{table position self-attention} to capture the inter-dependencies among related slots. For evaluation, besides standard metrics including BLEU, METEOR, and ROUGE, we propose a KB reconstruction based metric by extracting a KB from the generation output and comparing it with the input KB. We also create a new data set which includes 106,216 pairs of structured KBs and their corresponding natural language descriptions for two distinct entity types. Experiments show that our approach significantly outperforms state-of-the-art methods. The reconstructed KB achieves 68.8% - 72.6% F-score.|sl:arxiv_author|Qingyun Wang
Miriam Makeba|skos:broader|Musicien
Word Translation Without Parallel Data  we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent studies showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally describe experiments on the English-Esperanto low-resource language pair, on which there only exists a limited amount of parallel data, to show the potential impact of our method in fully unsupervised machine translation. Our code, embeddings and dictionaries are publicly available.|sl:tag|tag:nlp_facebook
Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs [GitHub](https://github.com/deepakn97/relationPrediction) [Blog post](/doc/2020/04/deepak_nathani_%7C_pay_attention_) The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention based feature embedding that captures both entity and relation features in any given entity's neighborhood. Additionally, we also encapsulate relation clusters and multihop relations in our model. Our empirical study offers insights into the efficacy of our attention based model and we show marked performance gains in comparison to state of the art methods on all datasets.|sl:tag|tag:arxiv_doc
John Sofakolle|skos:broader|Ami
Product Knowledge Graph|skos:broader|Knowledge Graphs
Provocation policière|skos:broader|Police
Topic Modeling|skos:broader|Analyse sémantique
Guerres de religion|skos:broader|Religion
Walmart|skos:broader|Entreprise
The Case for Learned Index Structures  we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs  Indexes are models: a B-Tree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term learned indexes. The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show, that by using neural nets we are able to outperform cache-optimized B-Trees by up to 70% in speed while saving an order-of-magnitude in memory over several real-world data sets. More importantly though, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work just provides a glimpse of what might be possible.|sl:tag|tag:learned_index_structures
huggingface/transformers|skos:broader|GitHub project
Obélisque|skos:broader|Sculpture
Alexandre Bertails|skos:broader|SW guys (and girls)
NLP in enterprise|skos:broader|NLP
Honda|skos:broader|Entreprise
A Primer in BERTology: What we know about how BERT works (article praised on [twitter](https://twitter.com/dennybritz/status/1233343170596917248?s=20) by D Britz and Y. Goldberg) Transformer-based models are now widely used in NLP, but we still do not understand a lot about their inner workings. This paper describes what is known to date about the famous BERT model (Devlin et al. 2019), synthesizing over 40 analysis studies. We also provide an overview of the proposed modifications to the model and its training regime. We then outline the directions for further research.|sl:arxiv_author|Olga Kovaleva
On Extractive and Abstractive Neural Document Summarization with Transformer Language Models  Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper. We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We show that this extractive step significantly improves summarization results. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher rouge scores. Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper.|sl:arxiv_author|Christopher Pal
Mars 2004|skos:broader|Exploration marsienne
Finlande|skos:broader|Europe
Scalable Nearest Neighbor Search for Optimal Transport The Optimal Transport (a.k.a. Wasserstein) distance is an increasingly popular similarity measure for rich data domains, such as images or text documents. This raises the necessity for fast nearest neighbor search with respect to this distance, a problem that poses a substantial computational bottleneck for various tasks on massive datasets. In this work, we study fast tree-based approximation algorithms for searching nearest neighbors w.r.t. the Wasserstein-1 distance. A standard tree-based technique, known as Quadtree, has been previously shown to obtain good results. We introduce a variant of this algorithm, called Flowtree, and formally prove it achieves asymptotically better accuracy. Our extensive experiments, on real-world text and image datasets, show that Flowtree improves over various baselines and existing methods in either running time or accuracy. In particular, its quality of approximation is in line with previous high-accuracy methods, while its running time is much faster.|sl:arxiv_firstAuthor|Arturs Backurs
Similarity Search for Efficient Active Learning and Search of Rare Concepts  Similarity search for Efficient Active Learning and Search (SEALS)    In [Active Learning](tag:active_learning): instead of searching globally for the optimal examples to label, leverage the fact that data is often heavily skewed and expand the candidate pool with the nearest neighbors of the labeled set.     Our work attacks both the labeling and computational costs of machine learning...SEALS dramatically reduces the barrier to machine learning, enabling small teams or individuals to  build accurate classifiers. SEALS does, however, introduce another system component, a similarity  search index, which adds some additional engineering complexity to build, tune, and maintain.  Fortunately, several highly optimized implementations like Annoy and [Faiss](doc:2020/06/facebookresearch_faiss_a_libra) work reasonably well  out of the box. Many active learning and search approaches are intractable for industrial settings with billions of unlabeled examples. Existing approaches, such as uncertainty sampling or information density, search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. However, in practice, data is often heavily skewed; only a small fraction of collected data will be relevant for a given learning task. For example, when identifying rare classes, detecting malicious content, or debugging model performance, the ratio of positive to negative examples can be 1 to 1,000 or more. In this work, we exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round by only looking at the nearest neighbors to the labeled examples. Empirically, we observe that learned representations effectively cluster unseen concepts, making active learning very effective and substantially reducing the number of viable unlabeled examples. We evaluate several active learning and search techniques in this setting on three large-scale datasets: ImageNet, Goodreads spoiler detection, and OpenImages. For rare classes, active learning methods need as little as 0.31% of the labeled data to match the average precision of full supervision. By limiting active learning methods to only consider the immediate neighbors of the labeled data as candidates for labeling, we need only process as little as 1% of the unlabeled data while achieving similar reductions in labeling costs as the traditional global approach. This process of expanding the candidate pool with the nearest neighbors of the labeled set can be done efficiently and reduces the computational complexity of selection by orders of magnitude.|sl:arxiv_author|Sean Culatana
Dictionary learning, or sparse coding, tries to learn a sparse linear code to represent the  given data succinctly.    Unsupervised learning algo. Images - edge detection (similar to primary visual cortex)    |skos:broader|In machine learning, unsupervised learning refers to the problem of trying to find hidden structure in unlabeled data
Microblogs|skos:broader|Blog
A Call for More Rigor in Unsupervised Cross-lingual Learning  a scenario without any parallel data and abundant monolingual data is unrealistic in practice We review motivations, definition, approaches, and methodology for unsupervised cross-lingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of the world's languages. However, we argue that a scenario without any parallel data and abundant monolingual data is unrealistic in practice. We also discuss different training signals that have been used in previous work, which depart from the pure unsupervised setting. We then describe common methodological issues in tuning and evaluation of unsupervised cross-lingual models and present best practices. Finally, we provide a unified outlook for different types of research in this area (i.e., cross-lingual word embeddings, deep multilingual pretraining, and unsupervised machine translation) and argue for comparable evaluation of these models.|sl:tag|tag:unsupervised_machine_translation
Detecting Potential Topics In News Using BERT, CRF and Wikipedia For a news content distribution platform like Dailyhunt, Named Entity Recognition is a pivotal task for building better user recommendation and notification algorithms. Apart from identifying names, locations, organisations from the news for 13+ Indian languages and use them in algorithms, we also need to identify n-grams which do not necessarily fit in the definition of Named-Entity, yet they are important. For example, me too movement, beef ban, alwar mob lynching. In this exercise, given an English language text, we are trying to detect case-less n-grams which convey important information and can be used as topics and/or hashtags for a news. Model is built using Wikipedia titles data, private English news corpus and BERT-Multilingual pre-trained model, Bi-GRU and CRF architecture. It shows promising results when compared with industry best Flair, Spacy and Stanford-caseless-NER in terms of F1 and especially Recall.|sl:tag|tag:bert
Samba|skos:broader|Danse
Lynn Margulis|skos:broader|Scientifique
dowhatimean.net|skos:broader|Technical guys
Intel|skos:broader|Technologie
Support vector machine|skos:broader|Supervised machine learning
Amphibiens|skos:broader|Animal
An efficient framework for learning sentence representations Quick Thoughts. Framework for learning sentence representations from unlabelled data.     we reformulate the problem of predicting the context in which a sentence appears as a classification problem.   In this work we propose a simple and efficient framework for learning sentence representations from unlabelled data. Drawing inspiration from the distributional hypothesis and recent work on learning sentence representations, we reformulate the problem of predicting the context in which a sentence appears as a classification problem. Given a sentence and its context, a classifier distinguishes context sentences from other contrastive sentences based on their vector representations. This allows us to efficiently learn different types of encoding functions, and we show that the model learns high-quality sentence representations. We demonstrate that our sentence representations outperform state-of-the-art unsupervised and supervised representation learning methods on several downstream NLP tasks that involve understanding sentence semantics while achieving an order of magnitude speedup in training time.|sl:arxiv_firstAuthor|Lajanugen Logeswaran
Eric Baetens|skos:broader|Ecole des Mines
Span Selection Pre-training for Question Answering  a new pre-training task inspired by reading  comprehension and an effort to avoid encoding general knowledge in the transformer network itself    Current transformer architectures store general knowledge - large models, long pre-training time. Better to offload the requirement of general knowledge to a sparsely activated network.    Span selection as an additional auxiliary task: the query is a sentence drawn from a corpus  with a term replaced with a special token: [BLANK]. The term replaced by the blank is the answer term. The passage is  relevant as determined by a BM25 search, and answer-bearing (containing the answer  term). Unlike BERT’s cloze task, where the answer must be drawn from the model itself, the answer is found in a passage  using language understanding.     We hope to progress to a model of general purpose language modeling that uses an indexed long  term memory to retrieve world knowledge, rather than holding it in the densely activated transformer encoder layers. BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pre-trained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension and an effort to avoid encoding general knowledge in the transformer network itself. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple reading comprehension (MRC) and paraphrasing datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also establish a new SOTA in HotpotQA, improving answer prediction F1 by 4 F1 points and supporting fact prediction by 1 F1 point. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.|sl:arxiv_firstAuthor|Michael Glass
Retrofitting Word Vectors to Semantic Lexicons Method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed.     Graph-based learning technique for using lexical relational resources to obtain higher quality semantic vectors, which we call “retrofitting.” Retrofitting is applied as a post-processing step by running belief propagation on a graph constructed from lexicon-derived relational information to update word vectors. This allows retrofitting to be used on pre-trained word vectors obtained using any vector training model.    [github](https://github.com/mfaruqui/retrofitting)     Vector space word representations are learned from distributional information of words in large corpora. Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database. This paper proposes a method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed. Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, we obtain substantial improvements starting with a variety of word vector models. Our refinement method outperforms prior techniques for incorporating semantic lexicons into the word vector training algorithms.|sl:tag|tag:manaal_faruqui
François Yvon|skos:broader|NLP girls and guys
Industrie nucléaire|skos:broader|industrie
Learning Sparse, Distributed Representations using the Hebbian Principle The \fire together, wire together\ Hebbian model is a central principle for learning in neuroscience, but surprisingly, it has found limited applicability in modern machine learning. In this paper, we take a first step towards bridging this gap, by developing flavors of competitive Hebbian learning which produce sparse, distributed neural codes using online adaptation with minimal tuning The fire together, wire together Hebbian model is a central principle for learning in neuroscience, but surprisingly, it has found limited applicability in modern machine learning. In this paper, we take a first step towards bridging this gap, by developing flavors of competitive Hebbian learning which produce sparse, distributed neural codes using online adaptation with minimal tuning. We propose an unsupervised algorithm, termed Adaptive Hebbian Learning (AHL). We illustrate the distributed nature of the learned representations via output entropy computations for synthetic data, and demonstrate superior performance, compared to standard alternatives such as autoencoders, in training a deep convolutional net on standard image datasets.|sl:tag|tag:brain_vs_deep_learning
Jamendo|skos:broader|Musique
Feynman|skos:broader|Mécanique quantique
foaf|skos:broader|RDF Vocabularies
Tag ontology|skos:broader|Tagging
Clonage|skos:broader|Genetics Génétique
Civilisation de l'Indus|skos:broader|Antiquité du Pakistan
Banksy|skos:broader|Street art
Parameter-free Sentence Embedding via Orthogonal Basis training-free approach for building sentence representations, Geometric Embedding (GEM), based on the geometric structure of word embedding space.     we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word’s novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace    [on www.groundai.com](https://www.groundai.com/project/zero-training-sentence-embedding-via-orthogonal-basis/)    [Open Revieww](/doc/?uri=https%3A%2F%2Fopenreview.net%2Fforum%3Fid%3DrJedbn0ctQ) ; [Related to this paper](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1704.05358)       We propose a simple and robust non-parameterized approach for building sentence representations. Inspired by the Gram-Schmidt Process in geometric theory, we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word's novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace. Following this motivation, we develop an innovative method based on orthogonal basis to combine pre-trained word embeddings into sentence representations. This approach requires zero parameters, along with efficient inference performance. We evaluate our approach on 11 downstream NLP tasks. Our model shows superior performance compared with non-parameterized alternatives and it is competitive to other approaches relying on either large amounts of labelled data or prolonged training time.|sl:tag|tag:arxiv_doc
Arbres remarquables|skos:broader|Arbres
Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation   An embedding method specifically designed for NED that jointly maps words and entities into the same continuous vector space.    We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words Named Entity Disambiguation (NED) refers to the task of resolving multiple named entity mentions in a document to their correct references in a knowledge base (KB) (e.g., Wikipedia). In this paper, we propose a novel embedding method specifically designed for NED. The proposed method jointly maps words and entities into the same continuous vector space. We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words. By combining contexts based on the proposed embedding with standard NED features, we achieved state-of-the-art accuracy of 93.1% on the standard CoNLL dataset and 85.2% on the TAC 2010 dataset.|sl:arxiv_author|Hiroyuki Shindo
Dark matter|skos:broader|Masse manquante
FaceNet: A Unified Embedding for Face Recognition and Clustering Learns a Euclidean embedding per image     Uses a deep CNN trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method.     state-of-the-art face recognition performance using only 128-bytes per face.      Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves 95.12%. Our system cuts the error rate in comparison to the best published result by 30% on both datasets. We also introduce the concept of harmonic embeddings, and a harmonic triplet loss, which describe different versions of face embeddings (produced by different networks) that are compatible to each other and allow for direct comparison between each other.|sl:arxiv_author|Dmitry Kalenichenko
Electric car|skos:broader|Automobile
Maladie|skos:broader|Médecine
Renato Matos|skos:broader|Brésil
Pseudo relevance feedback|skos:broader|Information retrieval
Google Colab|skos:broader|AI cloud service
Siamese networks|skos:broader|Similarity learning
Wembedder: Wikidata entity embedding web service web service for querying an embedding of entities in the Wikidata knowledge graph. The embedding is trained on the Wikidata dump using Gensim's Word2Vec implementation and a simple graph walk I present a web service for querying an embedding of entities in the Wikidata knowledge graph. The embedding is trained on the Wikidata dump using Gensim's Word2Vec implementation and a simple graph walk. A REST API is implemented. Together with the Wikidata API the web service exposes a multilingual resource for over 600'000 Wikidata items and properties.|sl:tag|tag:knowledge_graph
Calais (jungle)|skos:broader|Honteux
Volcan|skos:broader|Géologie
The Consciousness Prior consciousness seen as the formation of a low-dimensional combination of a few concepts constituting a conscious thought, i.e., consciousness as awareness at a particular time instant: the projection of a big vector (all the things conscious and unconscious in brain). Attention: additional mechanism describing what mind chooses to focus on.    [YouTube video](/doc/?uri=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYr1mOzC93xs) A new prior is proposed for learning representations of high-level concepts of the kind we manipulate with language. This prior can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by cognitive neuroscience theories of consciousness, seen as a bottleneck through which just a few elements, after having been selected by attention from a broader pool, are then broadcast and condition further processing, both in perception and decision-making. The set of recently selected elements one becomes aware of is seen as forming a low-dimensional conscious state. This conscious state is combining the few concepts constituting a conscious thought, i.e., what one is immediately conscious of at a particular moment. We claim that this architectural and information-processing constraint corresponds to assumptions about the joint distribution between high-level concepts. To the extent that these assumptions are generally true (and the form of natural language seems consistent with them), they can form a useful prior for representation learning. A low-dimensional thought or conscious state is analogous to a sentence: it involves only a few variables and yet can make a statement with very high probability of being true. This is consistent with a joint distribution (over high-level concepts) which has the form of a sparse factor graph, i.e., where the dependencies captured by each factor of the factor graph involve only very few variables while creating a strong dip in the overall energy function. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in a form similar to facts and rules, albeit capturing uncertainty as well as efficient search mechanisms implemented by attention mechanisms.|sl:arxiv_author|Yoshua Bengio
Mladic|skos:broader|Bosnie
fps' post|skos:broader|fps
Davos|skos:broader|Economie
QuickTime|skos:broader|Multimedia
Self-Taught Convolutional Neural Networks for Short Text Clustering  We propose a flexible short text clustering framework which explores the feasibility and effectiveness of combining CNN and traditional unsupervised dimensionality reduction methods.     Non-biased deep feature representations can be learned through our self- taught CNN framework which does not use any external tags/labels or complicated NLP pre-processing.     The original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations.    [conf paper, same authors](http://www.aclweb.org/anthology/W15-1509) ; [gitgub repo (matlab)](https://github.com/jacoxu/STC2)   Short text clustering is a challenging problem due to its sparseness of text representation. Here we propose a flexible Self-Taught Convolutional neural network framework for Short Text Clustering (dubbed STC^2), which can flexibly and successfully incorporate more useful semantic features and learn non-biased deep text representation in an unsupervised manner. In our framework, the original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations. Extensive experimental results demonstrate that the proposed framework is effective, flexible and outperform several popular clustering methods when tested on three public short text datasets.|sl:tag|tag:arxiv_doc
NSA spying scandal|skos:broader|NSA
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:tag|tag:knowledge_graph
DBTune|skos:broader|Yves Raymond
Écologie|skos:broader|Grands problèmes
Pubby|skos:broader|Linked Data
Unifying distillation and privileged information A framework to learn from multiple machines and data representations, unifying two techniques that enable machines to learn from other machines: [distillation](tag:knowledge_distillation) ([Hinton et al., 2015](doc:2020/04/1503_02531_distilling_the_kno)) and privileged information (Vapnik & Izmailov, 2015)   Distillation (Hinton et al., 2015) and privileged information (Vapnik & Izmailov, 2015) are two techniques that enable machines to learn from other machines. This paper unifies these two techniques into generalized distillation, a framework to learn from multiple machines and data representations. We provide theoretical and causal insight about the inner workings of generalized distillation, extend it to unsupervised, semisupervised and multitask learning scenarios, and illustrate its efficacy on a variety of numerical simulations on both synthetic and real-world data.|sl:arxiv_author|Vladimir Vapnik
PoolParty|skos:broader|SKOS editor
Samba|skos:broader|Musique
Notes on Cardinal's Matrices These notes are motivated by the work of Jean-Paul Cardinal on symmetric matrices related to the Mertens function. He showed that certain norm bounds on his matrices implied the Riemann hypothesis. Using a different matrix norm we show an equivalence of the Riemann hypothesis to suitable norm bounds on his matrices in the new norm. Then we specify a deformed version of his Mertens function matrices that unconditionally satisfies a norm bound that is of the same strength as his Riemann hypothesis bound.|sl:arxiv_author|Jeffrey C. Lagarias
Toyota|skos:broader|Automobile
Relations Europe-USA|skos:broader|USA
Topic2Vec: Learning Distributed Representations of Topics Topic2Vec aims at learning topic representations along with word representations. Considering the simplicity and efficient solution, we just follow the optimization scheme that used in Word2Vec Latent Dirichlet Allocation (LDA) mining thematic structure of documents plays an important role in nature language processing and machine learning areas. However, the probability distribution from LDA only describes the statistical relationship of occurrences in the corpus and usually in practice, probability is not the best choice for feature representations. Recently, embedding methods have been proposed to represent words and documents by learning essential concepts and representations, such as Word2Vec and Doc2Vec. The embedded representations have shown more effectiveness than LDA-style representations in many tasks. In this paper, we propose the Topic2Vec approach which can learn topic representations in the same semantic vector space with words, as an alternative to probability. The experimental results show that Topic2Vec achieves interesting and meaningful results.|sl:arxiv_author|Li-Qiang Niu
Semantic startup|skos:broader|Startups
Deep Mutual Learning  In this paper we explore a different but related idea to model distillation – that of mutual learning. Distillation starts with a powerful large and pre-trained teacher network and performs one-way knowledge transfer to a small untrained student. In contrast, in mutual learning we start with a pool of untrained students who learn simultaneously to solve the task together.    [critic here](doc:2020/06/1804_03235_large_scale_distri):     Zhang et al. (2017) reported a benefit in quality over  basic distillation, but they compare distilling model M1 into model M2 with training model M1  and model M2 using codistillation; they do not compare to distilling an ensemble of models M1  and M2 into model M3.     ...     we can achieve the 70.7% they report for online  distillation using traditional offline distillation. Model distillation is an effective and widely used technique to transfer knowledge from a teacher to a student network. The typical application is to transfer from a powerful large network or ensemble to a small network, that is better suited to low-memory or fast execution requirements. In this paper, we present a deep mutual learning (DML) strategy where, rather than one way transfer between a static pre-defined teacher and a student, an ensemble of students learn collaboratively and teach each other throughout the training process. Our experiments show that a variety of network architectures benefit from mutual learning and achieve compelling results on CIFAR-100 recognition and Market-1501 person re-identification benchmarks. Surprisingly, it is revealed that no prior powerful teacher network is necessary -- mutual learning of a collection of simple student networks works, and moreover outperforms distillation from a more powerful yet static teacher.|sl:tag|tag:kd_mkb_biblio
Alpinisme|skos:broader|Montagne
Label-Embedding for Image Classification Attributes act as intermediate representations that enable parameter sharing between classes, a must when training data is scarce. We propose to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors. We introduce a function that measures the compatibility between an image and a label embedding. The parameters of this function are learned on a training set of labeled samples to ensure that, given an image, the correct classes rank higher than the incorrect ones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasets show that the proposed framework outperforms the standard Direct Attribute Prediction baseline in a zero-shot learning scenario. Label embedding enjoys a built-in ability to leverage alternative sources of information instead of or in addition to attributes, such as e.g. class hierarchies or textual descriptions. Moreover, label embedding encompasses the whole range of learning settings from zero-shot learning to regular learning with a large number of labeled examples.|sl:arxiv_author|Zeynep Akata
Web services : critique|skos:broader|Web Services
OpenLink Ajax Toolkit (OAT)|skos:broader|Ajax
Transformers as Soft Reasoners over Language  AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. We provide the first demonstration that this is possible, and characterize the extent of this capability. To do this, we use a collection of synthetic datasets that test increasing levels of reasoning complexity (number of rules, presence of negation, and depth of chaining). We find transformers appear to learn rule-based reasoning with high (99%) accuracy on these datasets, and in a way that generalizes to test data requiring substantially deeper chaining than in the training data (95%+ scores). We also demonstrate that the models transfer well to two hand-authored rulebases, and to rulebases paraphrased into more natural language. These findings are significant as it suggests a new role for transformers, namely as a limited soft theorem prover operating over explicit theories in language. This in turn suggests new possibilities for explainability, correctability, and counterfactual reasoning in question-answering. All datasets and a live demo are available at http://rule-reasoning.apps.allenai.org/|sl:tag|tag:arxiv_doc
Privacy and internet|skos:broader|Vie privée
Séquençage du génome|skos:broader|Génome
Smoothed Inverse Frequency: a linear representation of a sentence which is better than the simple average of the embeddings of its words    2 ideas:    - assign to each word a weighting that depends on the frequency of the word it the corpus (reminiscent of TF-IDF)  - some denoising (removing the component from the top singular direction)        Todo (?): check implementation as a [sklearn Vectorizer](https://github.com/ChristophAlt/embedding_vectorizer)  |skos:broader|best known for his work on probabilistically checkable proofs and, in particular, the PCP theorem.    [Off the convex path](http://www.offconvex.org/)  
Wembedder: Wikidata entity embedding web service web service for querying an embedding of entities in the Wikidata knowledge graph. The embedding is trained on the Wikidata dump using Gensim's Word2Vec implementation and a simple graph walk I present a web service for querying an embedding of entities in the Wikidata knowledge graph. The embedding is trained on the Wikidata dump using Gensim's Word2Vec implementation and a simple graph walk. A REST API is implemented. Together with the Wikidata API the web service exposes a multilingual resource for over 600'000 Wikidata items and properties.|sl:arxiv_firstAuthor|Finn Årup Nielsen
Révolution française|skos:broader|Révolution
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Alvaro Sanchez-Gonzalez
Aho–Corasick algorithm|skos:broader|Text processing
The Limits to Growth|skos:broader|Crise écologique
Cringely|skos:broader|Technical girls and guys
Python install|skos:broader|Python
Browser : back button|skos:broader|Brouteur
Symmetric matrices related to the Mertens function In this paper we explore a family of congruences over N from which a sequence of symmetric matrices related to the Mertens function is built. From the results of numerical experiments we formulate a conjecture, about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may play a more important role in this classical and difficult problem.  In this paper we explore a family of congruences over $\\N^\\ast$ from which one builds a sequence of symmetric matrices related to the Mertens function. From the results of numerical experiments, we formulate a conjecture about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may come to play a more important role in this classical and difficult problem.|sl:tag|tag:jean_paul
Personal ontology|skos:broader|Ontologies
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:tag|tag:arxiv_doc
create.js|skos:broader|Henri Bergius
Extinction des dinosaures|skos:broader|Extinction de masse
Universal basic income|skos:broader|Travail
Distilling the Knowledge in a Neural Network  a different kind of training, which we call “distillation” to transfer the  knowledge from the cumbersome model to a small model that is more  suitable for deployment       Caruana and his collaborators have shown that it is possible to compress the knowledge in an [#ensemble](/tag/ensemble_learning.html) into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST. A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.|sl:tag|tag:knowledge_distillation
Machine Reading Comprehension Reading Comprehension|skos:broader|Natural Language Understanding
DSSM (Deep Semantic Similarity Model)|skos:broader|Web search
EDUCE: Explaining model Decisions through Unsupervised Concepts Extraction  Providing explanations along with predictions is crucial in some text processing tasks. Therefore, we propose a new self-interpretable model that performs output prediction and simultaneously provides an explanation in terms of the presence of particular concepts in the input. To do so, our model's prediction relies solely on a low-dimensional binary representation of the input, where each feature denotes the presence or absence of concepts.    Presented in these [slides](/doc/2019/12/unsupervised_learning_with_text) Providing explanations along with predictions is crucial in some text processing tasks. Therefore, we propose a new self-interpretable model that performs output prediction and simultaneously provides an explanation in terms of the presence of particular concepts in the input. To do so, our model's prediction relies solely on a low-dimensional binary representation of the input, where each feature denotes the presence or absence of concepts. The presence of a concept is decided from an excerpt i.e. a small sequence of consecutive words in the text. Relevant concepts for the prediction task at hand are automatically defined by our model, avoiding the need for concept-level annotations. To ease interpretability, we enforce that for each concept, the corresponding excerpts share similar semantics and are differentiable from each others. We experimentally demonstrate the relevance of our approach on text classification and multi-sentiment analysis tasks.|sl:tag|tag:ludovic_denoyer
Ouïgour|skos:broader|Peuples
Natural Language Processing (almost) from Scratch seminal work    Abstract:     a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements   We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.|sl:arxiv_author|Pavel Kuksa
Visualizing and Measuring the Geometry of BERT  At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.|sl:arxiv_author|Martin Wattenberg
SPARQL Update|skos:broader|SPARQL
booking.com|skos:broader|Uberisation
Délocalisations|skos:broader|Economie
jsFiddle|skos:broader|Sample code
Word Translation Without Parallel Data  we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent studies showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally describe experiments on the English-Esperanto low-resource language pair, on which there only exists a limited amount of parallel data, to show the potential impact of our method in fully unsupervised machine translation. Our code, embeddings and dictionaries are publicly available.|sl:arxiv_author|Marc'Aurelio Ranzato
A Tutorial on Distance Metric Learning: Mathematical Foundations, Algorithms and Experiments distance metric learning, a branch of machine learning that aims to learn distances from the data Distance metric learning is a branch of machine learning that aims to learn distances from the data. Distance metric learning can be useful to improve similarity learning algorithms, and also has applications in dimensionality reduction. This paper describes the distance metric learning problem and analyzes its main mathematical foundations. In addition, it also discusses some of the most popular distance metric learning techniques used in classification, showing their goals and the required information to understand and use them. Furthermore, some experiments to evaluate the performance of the different algorithms are also provided. Finally, this paper discusses several possibilities of future work in this topic.|sl:tag|tag:arxiv_doc
Differentiable Reasoning over a Virtual Knowledge Base  We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases.    [(Bhuwan Dhingra PhD Thesis)](doc:2020/07/end_to_end_learning_with_text_) We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. On HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking approach to retrieving the relevant passages required to answer a question. DrKIT is also very efficient, processing 10-100x more queries per second than existing multi-hop systems.|sl:arxiv_author|Manzil Zaheer
Watson Speech-to-Text|skos:broader|Speech-to-Text
SIMILE|skos:broader|MIT
Linked Data|skos:broader|Semantic Web
Zero-shot Entity Linking with Dense Entity Retrieval We consider the zero-shot entity-linking challenge where each entity is defined by a short textual description, and the model must read these descriptions together with the mention context to make the final linking decisions. In this setting, retrieving entity candidates can be particularly challenging, since many of the common linking cues such as entity alias tables and link popularity are not available. In this paper, we introduce a simple and effective two stage approach for zero-shot linking, based on fine-tuned BERT architectures. In the first stage, we do retrieval in a dense space defined by a bi-encoder that independently embeds the mention context and the entity descriptions. Each candidate is then examined more carefully with a cross-encoder, that concatenates the mention and entity text. Our approach achieves a nearly 5 point absolute gain on a recently introduced zero-shot entity linking benchmark, driven largely by improvements over previous IR-based candidate retrieval. We also show that it performs well in the non-zero-shot setting, obtaining the state-of-the-art result on TACKBP-2010.|sl:arxiv_author|Ledell Wu
Word Translation Without Parallel Data  we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent studies showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally describe experiments on the English-Esperanto low-resource language pair, on which there only exists a limited amount of parallel data, to show the potential impact of our method in fully unsupervised machine translation. Our code, embeddings and dictionaries are publicly available.|sl:arxiv_firstAuthor|Alexis Conneau
Knowledge Graph Embeddings|skos:broader|Knowledge Representation
Generative model|skos:broader|Machine learning: techniques
Driverless car|skos:broader|Robotique
Tchad|skos:broader|Afrique
COO|skos:broader|VW
FBI v. Apple|skos:broader|Big Brother
Deep NLP|skos:broader|Deep Learning
Patent finding|skos:broader|AI 4 IP
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:arxiv_author|Ray Kurzweil
Poincaré|skos:broader|Mathématicien
Empire colonial français|skos:broader|Histoire de France
fps blog|skos:broader|Blogger
Toyota|skos:broader|Japon
Justice américaine|skos:broader|USA
Hong Kong|skos:broader|Ville
scikit-learn|skos:broader|Machine Learning library
Technology Enhanced Learning|skos:broader|Education
Java web dev|skos:broader|Java dev
Normale Sup|skos:broader|Enseignement supérieur
A Tutorial on Distance Metric Learning: Mathematical Foundations, Algorithms and Experiments distance metric learning, a branch of machine learning that aims to learn distances from the data Distance metric learning is a branch of machine learning that aims to learn distances from the data. Distance metric learning can be useful to improve similarity learning algorithms, and also has applications in dimensionality reduction. This paper describes the distance metric learning problem and analyzes its main mathematical foundations. In addition, it also discusses some of the most popular distance metric learning techniques used in classification, showing their goals and the required information to understand and use them. Furthermore, some experiments to evaluate the performance of the different algorithms are also provided. Finally, this paper discusses several possibilities of future work in this topic.|sl:tag|tag:similarity_learning
Span Selection Pre-training for Question Answering  a new pre-training task inspired by reading  comprehension and an effort to avoid encoding general knowledge in the transformer network itself    Current transformer architectures store general knowledge - large models, long pre-training time. Better to offload the requirement of general knowledge to a sparsely activated network.    Span selection as an additional auxiliary task: the query is a sentence drawn from a corpus  with a term replaced with a special token: [BLANK]. The term replaced by the blank is the answer term. The passage is  relevant as determined by a BM25 search, and answer-bearing (containing the answer  term). Unlike BERT’s cloze task, where the answer must be drawn from the model itself, the answer is found in a passage  using language understanding.     We hope to progress to a model of general purpose language modeling that uses an indexed long  term memory to retrieve world knowledge, rather than holding it in the densely activated transformer encoder layers. BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pre-trained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension and an effort to avoid encoding general knowledge in the transformer network itself. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple reading comprehension (MRC) and paraphrasing datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also establish a new SOTA in HotpotQA, improving answer prediction F1 by 4 F1 points and supporting fact prediction by 1 F1 point. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.|sl:tag|tag:question_answering
Antilles|skos:broader|Amérique
Collaborative ontologie creation|skos:broader|Linked Data / collaborative editing
Open Education|skos:broader|Education
Information resources|skos:broader|Linked Data
iPod|skos:broader|Musique
Poésie|skos:broader|Littérature
Denny Britz|skos:broader|AI girls and guys
Apple CarPlay|skos:broader|Automobile 2.0
Building Machines That Learn and Think Like People  we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations   Recent progress in artificial intelligence (AI) has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn, and how they learn it. Specifically, we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models.|sl:arxiv_author|Samuel J. Gershman
De-extinction|skos:broader|Nous vivons une époque moderne
Vary Header|skos:broader|HTTP
Personnage historique|skos:broader|Homme célèbre
Python tips|skos:broader|Dev tips
Yoshua Bengio|skos:broader|AI girls and guys
sindice|skos:broader|Linked Data
Google Maps|skos:broader|Google
Riemann|skos:broader|Mathématicien
Scientific information extraction|skos:broader|Information extraction
Semi-supervised Clustering for Short Text via Deep Representation Learning semi-supervised method for short text clustering, where we represent texts as distributed vectors with neural networks, and use a small amount of labeled data to specify our intention for clustering. We design a novel objective to combine the representation learning process and the k-means clustering process together, and optimize the objective with both labeled data and unlabeled data iteratively until convergence through three steps:     1. assign each short text to its nearest centroid based on its representation from the current neural networks;  2. re-estimate the cluster centroids based on cluster assignments from step (1);  3. update neural networks according to the objective by keeping centroids and cluster assignments fixed.   In this work, we propose a semi-supervised method for short text clustering, where we represent texts as distributed vectors with neural networks, and use a small amount of labeled data to specify our intention for clustering. We design a novel objective to combine the representation learning process and the k-means clustering process together, and optimize the objective with both labeled data and unlabeled data iteratively until convergence through three steps: (1) assign each short text to its nearest centroid based on its representation from the current neural networks; (2) re-estimate the cluster centroids based on cluster assignments from step (1); (3) update neural networks according to the objective by keeping centroids and cluster assignments fixed. Experimental results on four datasets show that our method works significantly better than several other text clustering methods.|sl:tag|tag:nlp_short_texts
Chelsea Manning|skos:broader|Whistleblower
Active learning|skos:broader|Training data
Ranking (information retrieval)|skos:broader|Information retrieval
Jean-Jacques Annaud|skos:broader|Réalisateur
Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings (i.e. semantic representations) of word sequences as well. We present a simple but efficient unsupervised objective to train distributed representations of sentences. Our method outperforms the state-of-the-art unsupervised models on most benchmark tasks, highlighting the robustness of the produced general-purpose sentence embeddings.|sl:tag|tag:sent2vec
Séquençage du génome|skos:broader|Biotechnologies Biotechnologies
Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.|sl:tag|tag:ruslan_salakhutdinov
HttpUnit|skos:broader|JUnit
Accountable AI|skos:broader|Artificial Intelligence
OGM|skos:broader|Grands problèmes
Panama papers|skos:broader|Leaks
Norilsk|skos:broader|Industrie minière
Livre à lire|skos:broader|Livre
Autriche|skos:broader|Pays d'Europe
Entities as Experts: Sparse Memory Access with Entity Supervision   the problem of capturing declarative knowledge in the learned parameters of a language model...     Entities as Experts (EaE) can access distinct memories of the entities mentioned in a piece of text;     To understand the motivation for distinct and  independent entity representations: A traditional Transformer would need to build an internal representation  of Charles Darwin from the words “Charles”  and “Darwin”... Conversely, EAE can access  a dedicated representation of “Charles Darwin”,  which is a memory of all of the contexts in which  this entity has previously been mentioned.... Having retrieved  and re-integrated this memory it is much easier for  EAE to relate the question to the answer     EaE's entity representations are learned directly from text. Correct identification, and representation, of entities is essential to EaE's performance    Based on transformer architecture    Extension: [Facts as Experts](doc:2020/07/2007_00849_facts_as_experts_) We focus on the problem of capturing declarative knowledge in the learned parameters of a language model. We introduce a new model, Entities as Experts (EaE), that can access distinct memories of the entities mentioned in a piece of text. Unlike previous efforts to integrate entity knowledge into sequence models, EaE's entity representations are learned directly from text. These representations capture sufficient knowledge to answer TriviaQA questions such as Which Dr. Who villain has been played by Roger Delgado, Anthony Ainley, Eric Roberts?. EaE outperforms a Transformer model with $30\\times$ the parameters on this task. According to the Lama knowledge probes, EaE also contains more factual knowledge than a similar sized Bert. We show that associating parameters with specific entities means that EaE only needs to access a fraction of its parameters at inference time, and we show that the correct identification, and representation, of entities is essential to EaE's performance. We also argue that the discrete and independent entity representations in EaE make it more modular and interpretable than the Transformer architecture on which it is based.|sl:tag|tag:knowledge_augmented_language_models
James Stewart|skos:broader|Acteur
Describing a Knowledge Base We aim to automatically generate natural language descriptions about an input structured knowledge base (KB). We build our generation framework based on a pointer network which can copy facts from the input KB, and add two attention mechanisms: (i) slot-aware attention to capture the association between a slot type and its corresponding slot value; and (ii) a new \\emph{table position self-attention} to capture the inter-dependencies among related slots. For evaluation, besides standard metrics including BLEU, METEOR, and ROUGE, we propose a KB reconstruction based metric by extracting a KB from the generation output and comparing it with the input KB. We also create a new data set which includes 106,216 pairs of structured KBs and their corresponding natural language descriptions for two distinct entity types. Experiments show that our approach significantly outperforms state-of-the-art methods. The reconstructed KB achieves 68.8% - 72.6% F-score.|sl:arxiv_author|Xiaoman Pan
Leigh Dodds|skos:broader|SW guys (and girls)
WWW 2008|skos:broader|Pékin
2D-NLP|skos:broader|NLP
Ressources halieutiques|skos:broader|Pêche
Crise financière|skos:broader|Money
Internet Related Technologies|skos:broader|Internet
Deep Learning frameworks|skos:broader|Machine Learning library
Gaulois|skos:broader|Histoire de France
Government data|skos:broader|Site web gouvernemental
Bill Gates|skos:broader|Technical girls and guys
Film américain|skos:broader|Cinéma américain
Darwin|skos:broader|Explorateur
Jersey Cache-Control|skos:broader|HTTP Cache
MyCarEvent|skos:broader|Réparation automobile
Conceptual modeling|skos:broader|Knowledge Representation
A Tutorial on Distance Metric Learning: Mathematical Foundations, Algorithms and Experiments distance metric learning, a branch of machine learning that aims to learn distances from the data Distance metric learning is a branch of machine learning that aims to learn distances from the data. Distance metric learning can be useful to improve similarity learning algorithms, and also has applications in dimensionality reduction. This paper describes the distance metric learning problem and analyzes its main mathematical foundations. In addition, it also discusses some of the most popular distance metric learning techniques used in classification, showing their goals and the required information to understand and use them. Furthermore, some experiments to evaluate the performance of the different algorithms are also provided. Finally, this paper discusses several possibilities of future work in this topic.|sl:arxiv_author|Juan Luis Suárez
Egypte|skos:broader|Afrique du Nord
KD-MKB|skos:broader|Thèse IRIT-Renault NLP-KB
End-To-End Memory Networks Neural network with a recurrent attention model over a possibly large external memory.    cité par [#A. Bordes](/tag/antoine_bordes) à [#ParisIsAI conf 2018](/tag/france_is_ai_2018.html) We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network (Weston et al., 2015) but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.|sl:arxiv_firstAuthor|Sainbayar Sukhbaatar
TF-IDF|skos:broader|Vector space model
NLP techniques|skos:broader|NLP
V.S. Naipaul V. S. Naipaul|skos:broader|Prix Nobel
RSS extensions|skos:broader|RSS
Self-Taught Hashing for Fast Similarity Search Emphasise following issue in Semantic Hashing: obtaining the codes for previously unseen documents. Propose following approach:  first find the optimal l-bit binary codes for all documents in  the given corpus via unsupervised learning, then train  l classifiers via supervised learning to predict the l-bit code  for any query document unseen before.    (méthode résumée [ici](https://www.semanticscholar.org/paper/Semantic-hashing-using-tags-and-topic-modeling-Wang-Zhang/1a0f660f70fd179003edc271694736baaa39dec4))       The ability of fast similarity search at large scale is of great importance to many Information Retrieval (IR) applications. A promising way to accelerate similarity search is semantic hashing which designs compact binary codes for a large number of documents so that semantically similar documents are mapped to similar codes (within a short Hamming distance). Although some recently proposed techniques are able to generate high-quality codes for documents known in advance, obtaining the codes for previously unseen documents remains to be a very challenging problem. In this paper, we emphasise this issue and propose a novel Self-Taught Hashing (STH) approach to semantic hashing: we first find the optimal $l$-bit binary codes for all documents in the given corpus via unsupervised learning, and then train $l$ classifiers via supervised learning to predict the $l$-bit code for any query document unseen before. Our experiments on three real-world text datasets show that the proposed approach using binarised Laplacian Eigenmap (LapEig) and linear Support Vector Machine (SVM) outperforms state-of-the-art techniques significantly.|sl:tag|tag:nearest_neighbor_search
Facts as Experts: Adaptable and Interpretable Neural Memory over Symbolic Knowledge  a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge.... The model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones.     a  neural language model which learns to access information  in a symbolic knowledge graph.     This  model builds on the recently-proposed [Entities as  Experts](doc:2020/07/2004_07202_entities_as_expert) (EaE) language model (Févry et al., 2020),  which extends the same transformer (Vaswani  et al., 2017) architecture of BERT (Devlin et al., 2019) with an additional external memory for entities.     After training EaE, the embedding associated  with an entity will (ideally) capture information  about the textual context in which that  entity appears, and by inference, the entity’s semantic  properties     we include an additional  memory called a fact memory, which encodes  triples from a symbolic KB.     This combination results in a  neural language model which learns to access information  in a the symbolic knowledge graph.        TODO: read again IBM's [Span Selection Pre-training for Question Answering](doc:2019/09/_1909_04120_span_selection_pre) (an effort to avoid encoding general knowledge in the transformer network itself) Massive language models are the core of modern NLP modeling and have been shown to encode impressive amounts of commonsense and factual information. However, that knowledge exists only within the latent parameters of the model, inaccessible to inspection and interpretation, and even worse, factual information memorized from the training corpora is likely to become stale as the world changes. Knowledge stored as parameters will also inevitably exhibit all of the biases inherent in the source materials. To address these problems, we develop a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge. We show that this model dramatically improves performance on two knowledge-intensive question-answering tasks. More interestingly, the model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones in ways that are not possible for earlier models.|sl:arxiv_author|Pat Verga
Concept Bottleneck Models  We seek to learn models that we can interact with using high-level concepts... We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these concept bottleneck models by editing their predicted concept values and propagating these changes to the final prediction... These models allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time. We seek to learn models that we can interact with using high-level concepts: if the model did not think there was a bone spur in the x-ray, would it still predict severe arthritis? State-of-the-art models today do not typically support the manipulation of concepts like the existence of bone spurs, as they are trained end-to-end to go directly from raw input (e.g., pixels) to output (e.g., arthritis severity). We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these \\emph{concept bottleneck models} by editing their predicted concept values and propagating these changes to the final prediction. On x-ray grading and bird identification, concept bottleneck models achieve competitive accuracy with standard end-to-end models, while enabling interpretation in terms of high-level clinical concepts (bone spurs) or bird attributes (wing color). These models also allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time.|sl:tag|tag:ai_stanford
Elias Torres|skos:broader|Technical girls and guys
Niklas Lindström|skos:broader|SW guys (and girls)
1984|skos:broader|Big Brother
OWL|skos:broader|Semantic Web
Knowledge Enhanced Contextual Word Representations General method to embed multiple knowledge bases into pre-trained language models (KB in the   sense as fixed collection of entity nodes)     The key idea is to explicitly model  entity spans in the input text and use an entity  linker to retrieve relevant entity embeddings from  a KB to form knowledge enhanced entity-span  representations.   Then,  update contextual word representations via a form of word-to-entity attention.    In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert's runtime is comparable to BERT's and it scales to large KBs.|sl:tag|tag:nlp_using_knowledge_graphs
Knowledge Graph Embeddings|skos:broader|Embeddings
Apple-Intel|skos:broader|Apple
Gore Vidal|skos:broader|Intellectuel
Parenté à plaisanterie|skos:broader|Afrique de l'Ouest
TensorFlow|skos:broader|AI@Google
SSL|skos:broader|Access Control
Ebola|skos:broader|Épidémie
Nokia|skos:broader|Entreprise
KG Embeddings Library|skos:broader|Library (code)
Françafrique|skos:broader|France
JSONLD|skos:broader|LD
Tyrannical exploitation of nature by mankind|skos:broader|Crise écologique
Hixie|skos:broader|Technical girls and guys
Touareg|skos:broader|Peuples
Poincaré Embeddings for Learning Hierarchical Representations  While complex symbolic datasets often exhibit a latent hierarchical structure, state-of-the-art methods typically learn embeddings in Euclidean vector spaces, which do not account for this property. For this purpose, we introduce a new approach for learning hierarchical representations of symbolic data by embedding them into hyperbolic space Representation learning has become an invaluable approach for learning from symbolic data such as text and graphs. However, while complex symbolic datasets often exhibit a latent hierarchical structure, state-of-the-art methods typically learn embeddings in Euclidean vector spaces, which do not account for this property. For this purpose, we introduce a new approach for learning hierarchical representations of symbolic data by embedding them into hyperbolic space -- or more precisely into an n-dimensional Poincar\\'e ball. Due to the underlying hyperbolic geometry, this allows us to learn parsimonious representations of symbolic data by simultaneously capturing hierarchy and similarity. We introduce an efficient algorithm to learn the embeddings based on Riemannian optimization and show experimentally that Poincar\\'e embeddings outperform Euclidean embeddings significantly on data with latent hierarchies, both in terms of representation capacity and in terms of generalization ability.|sl:tag|tag:poincare_embeddings
Gene therapy|skos:broader|Manipulations génétiques
Word Embedding Compositionality|skos:broader|Word embeddings
Fourmi|skos:broader|Insecte
Marlon Brando|skos:broader|Acteur
ONU|skos:broader|Institutions internationales
Huge RDF data source|skos:broader|RDF
Aventure|skos:broader|I like I like
Humour noir|skos:broader|Humour
Ex URSS URSS|skos:broader|Asie
AI & IR|skos:broader|Information retrieval
Voir [notes](/sl/doc/2015/09/semanlink2Notes.md)  |skos:broader|Semantic Web, Semantic Me.
Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus.     In practice, some questions are best answered  using text, while others are best answered using  KBs. A natural question, then, is how to effectively  combine both types of information. Surprisingly  little prior work has looked at this problem. Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting. Source code is available at https://github.com/OceanskySun/GraftNet .|sl:arxiv_author|Haitian Sun
A Survey on Deep Learning for Named Entity Recognition mainly focus on generic NEs in English language Named entity recognition (NER) is the task to identify mentions of rigid designators from text belonging to predefined semantic types such as person, location, organization etc. NER always serves as the foundation for many natural language applications such as question answering, text summarization, and machine translation. Early NER systems got a huge success in achieving good performance with the cost of human engineering in designing domain-specific features and rules. In recent years, deep learning, empowered by continuous real-valued vector representations and semantic composition through nonlinear processing, has been employed in NER systems, yielding stat-of-the-art performance. In this paper, we provide a comprehensive review on existing deep learning techniques for NER. We first introduce NER resources, including tagged NER corpora and off-the-shelf NER tools. Then, we systematically categorize existing works based on a taxonomy along three axes: distributed representations for input, context encoder, and tag decoder. Next, we survey the most representative methods for recent applied techniques of deep learning in new NER problem settings and applications. Finally, we present readers with the challenges faced by NER systems and outline future directions in this area.|sl:tag|tag:survey
Backpropagation|skos:broader|Neural networks
A Survey on Knowledge Graph Embeddings with Literals: Which model links better Literal-ly? Knowledge Graphs (KGs) are composed of structured information about a particular domain in the form of entities and relations. In addition to the structured information KGs help in facilitating interconnectivity and interoperability between different resources represented in the Linked Data Cloud. KGs have been used in a variety of applications such as entity linking, question answering, recommender systems, etc. However, KG applications suffer from high computational and storage costs. Hence, there arises the necessity for a representation able to map the high dimensional KGs into low dimensional spaces, i.e., embedding space, preserving structural as well as relational information. This paper conducts a survey of KG embedding models which not only consider the structured information contained in the form of entities and relations in a KG but also the unstructured information represented as literals such as text, numerical values, images, etc. Along with a theoretical analysis and comparison of the methods proposed so far for generating KG embeddings with literals, an empirical evaluation of the different methods under identical settings has been performed for the general task of link prediction.|sl:arxiv_author|Harald Sack
Emerging Cross-lingual Structure in Pretrained Language Models We study the problem of multilingual masked language modeling, i.e. the training of a single model on concatenated text from multiple languages, and present a detailed study of several factors that influence why these models are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from independently trained models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these symmetries seem to be automatically discovered and aligned during the joint training process.|sl:tag|tag:cross_lingual_nlp
Categorical Metadata Representation for Customized Text Classification  We observe that current representation methods for categorical metadata... are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category The performance of text classification has improved tremendously using intelligently engineered neural-based models, especially those injecting categorical metadata as additional information, e.g., using user/product information for sentiment classification. These information have been used to modify parts of the model (e.g., word embeddings, attention mechanisms) such that results can be customized according to the metadata. We observe that current representation methods for categorical metadata, which are devised for human consumption, are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category, and even such context is often scarce (for tail category). To this end, we propose to use basis vectors to effectively incorporate categorical metadata on various parts of a neural-based model. This additionally decreases the number of parameters dramatically, especially when the number of categorical features is large. Extensive experiments on various datasets with different properties are performed and show that through our method, we can represent categorical metadata more effectively to customize parts of the model, including unexplored ones, and increase the performance of the model greatly.|sl:tag|tag:categorical_variables
Exploring the Limits of Language Modeling recent advances in Recurrent Neural Networks for large scale Language Modeling In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon.|sl:arxiv_author|Oriol Vinyals
RDF and database|skos:broader|RDF
RDF Net API|skos:broader|RDF
Knowledge Enhanced Contextual Word Representations General method to embed multiple knowledge bases into pre-trained language models (KB in the   sense as fixed collection of entity nodes)     The key idea is to explicitly model  entity spans in the input text and use an entity  linker to retrieve relevant entity embeddings from  a KB to form knowledge enhanced entity-span  representations.   Then,  update contextual word representations via a form of word-to-entity attention.    In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert's runtime is comparable to BERT's and it scales to large KBs.|sl:tag|tag:allen_institute_for_ai_a2i
IRD|skos:broader|Développement
Olivier Rossel|skos:broader|Technical girls and guys
Realistic Re-evaluation of Knowledge Graph Completion Methods: An Experimental Study data redundancy (reverse relations), Cartesian product relations     A more fundamental defect  of these models is that the link prediction scenario, given  such data, is non-existent in the real-world In the active research area of employing embedding models for knowledge graph completion, particularly for the task of link prediction, most prior studies used two benchmark datasets FB15k and WN18 in evaluating such models. Most triples in these and other datasets in such studies belong to reverse and duplicate relations which exhibit high data redundancy due to semantic duplication, correlation or data incompleteness. This is a case of excessive data leakage---a model is trained using features that otherwise would not be available when the model needs to be applied for real prediction. There are also Cartesian product relations for which every triple formed by the Cartesian product of applicable subjects and objects is a true fact. Link prediction on the aforementioned relations is easy and can be achieved with even better accuracy using straightforward rules instead of sophisticated embedding models. A more fundamental defect of these models is that the link prediction scenario, given such data, is non-existent in the real-world. This paper is the first systematic study with the main objective of assessing the true effectiveness of embedding models when the unrealistic triples are removed. Our experiment results show these models are much less accurate than what we used to perceive. Their poor accuracy renders link prediction a task without truly effective automated solution. Hence, we call for re-investigation of possible effective approaches.|sl:tag|tag:arxiv_doc
Archéologue|skos:broader|Archéologie
Catastrophe humanitaire|skos:broader|Catastrophe
Universal Language Model Fine-tuning for Text Classification code is available in the fastai lib    [blog post](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html)    [see also](/doc/?uri=https%3A%2F%2Fyashuseth.blog%2F2018%2F06%2F17%2Funderstanding-universal-language-model-fine-tuning-ulmfit%2F)             Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.|sl:tag|tag:nlp_text_classification
Yann LeCun|skos:broader|AI girls and guys
Internet of Things|skos:broader|Internet
Wikidata|skos:broader|Wikipedia
Undecidability|skos:broader|Inference
Cellule souche Stem cell|skos:broader|Médecine
Word2vec|skos:broader|NLP@Google
Hortefeux|skos:broader|Gouvernement Sarkozy
Factory farming|skos:broader|Agriculture industrielle
 Deep contextualized word representations    each word is assigned a representation which is a function of the  entire corpus sentences to which they belong. The embeddings are  computed from the internal states of a two-layers bidirectional Language  Model, hence the name “ELMo”: Embeddings from Language  Models.    [Github](https://github.com/allenai/bilm-tf)    |skos:broader|replacement of the vectorial representation of words with a matrix representation where each word’s representation includes information about its context    Embedding words through a language model    Language-model-based encoders     The key idea underneath is to train a contextual encoder with a language model objective on a large unannotated text corpus. During the training, part of the text is masked and the goal is to encode the remaining context and predict the missing part. During the training, part of the text is masked and the goal is to encode the remaining  context and predict the missing part. ([source](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1902.11269))    
Explainable AI|skos:broader|Artificial Intelligence
Ministère de l'enseignement supérieur et de la recherche|skos:broader|Gouvernement
Fukushima|skos:broader|Industrie nucléaire
Topic Modeling over Short Texts by Incorporating Word Embeddings New method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo-texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic Inferring topics from the overwhelming amount of short texts becomes a critical but challenging task for many content analysis tasks, such as content charactering, user interest profiling, and emerging topic detecting. Existing methods such as probabilistic latent semantic analysis (PLSA) and latent Dirichlet allocation (LDA) cannot solve this prob- lem very well since only very limited word co-occurrence information is available in short texts. This paper studies how to incorporate the external word correlation knowledge into short texts to improve the coherence of topic modeling. Based on recent results in word embeddings that learn se- mantically representations for words from a large corpus, we introduce a novel method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo- texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic. The experiments on real-world datasets validate the effectiveness of our model comparing with the state-of-the-art models.|sl:arxiv_author|Ping Chen
Information bottleneck method|skos:broader|Information theory
Distilling Structured Knowledge into Embeddings for Explainable and Accurate Recommendation distilling structured knowledge from a differentiable path-based recommendation model.     proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons Recently, the embedding-based recommendation models (e.g., matrix factorization and deep models) have been prevalent in both academia and industry due to their effectiveness and flexibility. However, they also have such intrinsic limitations as lacking explainability and suffering from data sparsity. In this paper, we propose an end-to-end joint learning framework to get around these limitations without introducing any extra overhead by distilling structured knowledge from a differentiable path-based recommendation model. Through extensive experiments, we show that our proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons.|sl:tag|tag:explainable_ai
Ouïgour|skos:broader|Chine
Semantic folding|skos:broader|Semantic fingerprints
Henry Story|skos:broader|SW guys (and girls)
Stacked Approximated Regression Machine: A Simple Deep Learning Approach This paper seems too good to be true! They can train a VGG-like net VERY quickly to good accuracy, without backprop. With the agreement of my coauthors, I Zhangyang Wang would like to withdraw the manuscript Stacked Approximated Regression Machine: A Simple Deep Learning Approach. Some experimental procedures were not included in the manuscript, which makes a part of important claims not meaningful. In the relevant research, I was solely responsible for carrying out the experiments; the other coauthors joined in the discussions leading to the main algorithm. Please see the updated text for more details.|sl:arxiv_firstAuthor|Zhangyang Wang
Hello Edge: Keyword Spotting on Microcontrollers Keyword spotting (KWS) is a critical component for enabling speech based user interactions on smart devices. It requires real-time response and high accuracy for good user experience. Recently, neural networks have become an attractive choice for KWS architecture because of their superior accuracy compared to traditional speech processing algorithms. Due to its always-on nature, KWS application has highly constrained power budget and typically runs on tiny microcontrollers with limited memory and compute capability. The design of neural network architecture for KWS must consider these constraints. In this work, we perform neural network architecture evaluation and exploration for running KWS on resource-constrained microcontrollers. We train various neural network architectures for keyword spotting published in literature to compare their accuracy and memory/compute requirements. We show that it is possible to optimize these neural network architectures to fit within the memory and compute constraints of microcontrollers without sacrificing accuracy. We further explore the depthwise separable convolutional neural network (DS-CNN) and compare it against other neural network architectures. DS-CNN achieves an accuracy of 95.4%, which is ~10% higher than the DNN model with similar number of parameters.|sl:arxiv_author|Liangzhen Lai
Annotation tools|skos:broader|Labeling data
BERT for Joint Intent Classification and Slot Filling  Experimental results show that our  proposed joint BERT model outperforms BERT  models modeling intent classification and slot filling  separately, demonstrating the efficacy of exploiting  the relationship between the two tasks.    Adding a CRF on top of the model doesn't improve the results. Intent classification and slot filling are two essential tasks for natural language understanding. They often suffer from small-scale human-labeled training data, resulting in poor generalization capability, especially for rare words. Recently a new language representation model, BERT (Bidirectional Encoder Representations from Transformers), facilitates pre-training deep bidirectional representations on large-scale unlabeled corpora, and has created state-of-the-art models for a wide variety of natural language processing tasks after simple fine-tuning. However, there has not been much effort on exploring BERT for natural language understanding. In this work, we propose a joint intent classification and slot filling model based on BERT. Experimental results demonstrate that our proposed model achieves significant improvement on intent classification accuracy, slot filling F1, and sentence-level semantic frame accuracy on several public benchmark datasets, compared to the attention-based recurrent neural network models and slot-gated models.|sl:arxiv_author|Wen Wang
IA: limites|skos:broader|IA AI
Nelson Mandela|skos:broader|Afrique du Sud
Still a Pain in the Neck: Evaluating Text Representations on Lexical Composition How well do contextualized word embeddings address lexical composition? They are good in recognizing meaning shift (\give in\ is different from \give\) but much worse with revealing implicit meaning (\hot tea\ is about temperature, \hot debate\ isn't). Building meaningful phrase representations is challenging because phrase meanings are not simply the sum of their constituent meanings. Lexical composition can shift the meanings of the constituent words and introduce implicit information. We tested a broad range of textual representations for their capacity to address these issues. We found that as expected, contextualized word representations perform better than static word embeddings, more so on detecting meaning shift than in recovering implicit information, in which their performance is still far from that of humans. Our evaluation suite, including 5 tasks related to lexical composition effects, can serve future research aiming to improve such representations.|sl:tag|tag:arxiv_doc
A Theoretical Analysis of Contrastive Unsupervised Representation Learning [blog post](/doc/?uri=http%3A%2F%2Fwww.offconvex.org%2F2019%2F03%2F19%2FCURL%2F) Recent empirical works have successfully used unlabeled data to learn feature representations that are broadly useful in downstream classification tasks. Several of these methods are reminiscent of the well-known word2vec embedding algorithm: leveraging availability of pairs of semantically similar data points and negative samples, the learner forces the inner product of representations of similar pairs with each other to be higher on average than with negative samples. The current paper uses the term contrastive learning for such algorithms and presents a theoretical framework for analyzing them by introducing latent classes and hypothesizing that semantically similar points are sampled from the same latent class. This framework allows us to show provable guarantees on the performance of the learned representations on the average classification task that is comprised of a subset of the same set of latent classes. Our generalization bound also shows that learned representations can reduce (labeled) sample complexity on downstream tasks. We conduct controlled experiments in both the text and image domains to support the theory.|sl:arxiv_author|Orestis Plevrakis
Differentiable Reasoning over a Virtual Knowledge Base  We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases.    [(Bhuwan Dhingra PhD Thesis)](doc:2020/07/end_to_end_learning_with_text_) We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. On HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking approach to retrieving the relevant passages required to answer a question. DrKIT is also very efficient, processing 10-100x more queries per second than existing multi-hop systems.|sl:arxiv_author|Ruslan Salakhutdinov
Mission Villani sur l'IA|skos:broader|Artificial Intelligence
On the Efficacy of Knowledge Distillation Evaluation of the efficacy  of knowledge distillation and its dependence on student  and teacher architectures. IEEE International Conference on Computer Vision (ICCV), 2019     Despite  widespread use, an understanding of when the student can  learn from the teacher is missing.     Our key finding  is that knowledge distillation is not a panacea and cannot  succeed when student capacity is too low to successfully  mimic the teacher. We have presented an approach  to mitigate this issue by stopping teacher training early In this paper, we present a thorough evaluation of the efficacy of knowledge distillation and its dependence on student and teacher architectures. Starting with the observation that more accurate teachers often don't make good teachers, we attempt to tease apart the factors that affect knowledge distillation performance. We find crucially that larger models do not often make better teachers. We show that this is a consequence of mismatched capacity, and that small students are unable to mimic large teachers. We find typical ways of circumventing this (such as performing a sequence of knowledge distillation steps) to be ineffective. Finally, we show that this effect can be mitigated by stopping the teacher's training early. Our results generalize across datasets and models.|sl:arxiv_firstAuthor|Jang Hyun Cho
Revisiting Semi-Supervised Learning with Graph Embeddings We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.|sl:arxiv_author|Ruslan Salakhutdinov
Historic images|skos:broader|Photo
Belém|skos:broader|Ville
Attention Is All You Need  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.|sl:tag|tag:attention_is_all_you_need
Semi-supervised learning|skos:broader|Supervised machine learning
Humour|skos:broader|Rigolo
Cortical.io|skos:broader|NLP tools
Coursera: Computational Neuroscience|skos:broader|Computational Neuroscience
RDFa tool|skos:broader|RDFa
Platonov|skos:broader|Ecrivain
Facts as Experts: Adaptable and Interpretable Neural Memory over Symbolic Knowledge  a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge.... The model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones.     a  neural language model which learns to access information  in a symbolic knowledge graph.     This  model builds on the recently-proposed [Entities as  Experts](doc:2020/07/2004_07202_entities_as_expert) (EaE) language model (Févry et al., 2020),  which extends the same transformer (Vaswani  et al., 2017) architecture of BERT (Devlin et al., 2019) with an additional external memory for entities.     After training EaE, the embedding associated  with an entity will (ideally) capture information  about the textual context in which that  entity appears, and by inference, the entity’s semantic  properties     we include an additional  memory called a fact memory, which encodes  triples from a symbolic KB.     This combination results in a  neural language model which learns to access information  in a the symbolic knowledge graph.        TODO: read again IBM's [Span Selection Pre-training for Question Answering](doc:2019/09/_1909_04120_span_selection_pre) (an effort to avoid encoding general knowledge in the transformer network itself) Massive language models are the core of modern NLP modeling and have been shown to encode impressive amounts of commonsense and factual information. However, that knowledge exists only within the latent parameters of the model, inaccessible to inspection and interpretation, and even worse, factual information memorized from the training corpora is likely to become stale as the world changes. Knowledge stored as parameters will also inevitably exhibit all of the biases inherent in the source materials. To address these problems, we develop a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge. We show that this model dramatically improves performance on two knowledge-intensive question-answering tasks. More interestingly, the model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones in ways that are not possible for earlier models.|sl:tag|tag:arxiv_doc
SKOS W3C document|skos:broader|SKOS
Brain vs Deep Learning|skos:broader|Deep Learning
DBpedia Mobile|skos:broader|dbpedia
Semantic Web Services vs SOAP|skos:broader|Web Services
Apache web server|skos:broader|HTTP
Musée de Niamey|skos:broader|Musées africains
NoSQL and eventual consistency|skos:broader|Distributed computing
pandas|skos:broader|Python 4 Data science
Arduino|skos:broader|Robotique
Patti Smith|skos:broader|Rock
RDF Framework|skos:broader|Frameworks
A Primer on Neural Network Models for Natural Language Processing Over the past few years, neural networks have re-emerged as powerful machine-learning models, yielding state-of-the-art results in fields such as image recognition and speech processing. More recently, neural network models started to be applied also to textual natural language signals, again with very promising results. This tutorial surveys neural network models from the perspective of natural language processing research, in an attempt to bring natural-language researchers up to speed with the neural techniques. The tutorial covers input encoding for natural language tasks, feed-forward networks, convolutional networks, recurrent networks and recursive networks, as well as the computation graph abstraction for automatic gradient computation.|sl:arxiv_firstAuthor|Yoav Goldberg
Kingsley Idehen|skos:broader|SW guys (and girls)
Keyword/keyphrase extraction|skos:broader|NLP tasks / problems
Pangloss: Fast Entity Linking in Noisy Text Environments a production system for entity disambiguation on messy tex, based  on probabilistic tokenization and context-dependent document embeddings    Probabilistic tokenization: uses the method described [here](/doc/2019/07/mining_quality_phrases_from_mas) Entity linking is the task of mapping potentially ambiguous terms in text to their constituent entities in a knowledge base like Wikipedia. This is useful for organizing content, extracting structured data from textual documents, and in machine learning relevance applications like semantic search, knowledge graph construction, and question answering. Traditionally, this work has focused on text that has been well-formed, like news articles, but in common real world datasets such as messaging, resumes, or short-form social media, non-grammatical, loosely-structured text adds a new dimension to this problem. This paper presents Pangloss, a production system for entity disambiguation on noisy text. Pangloss combines a probabilistic linear-time key phrase identification algorithm with a semantic similarity engine based on context-dependent document embeddings to achieve better than state-of-the-art results (5% in F1) compared to other research or commercially available systems. In addition, Pangloss leverages a local embedded database with a tiered architecture to house its statistics and metadata, which allows rapid disambiguation in streaming contexts and on-device disambiguation in low-memory environments such as mobile phones.|sl:arxiv_author|Sam Shah
The Matrix Calculus You Need For Deep Learning Related blog post [The Math Behind Neural Networks](https://towardsdatascience.com/step-by-step-the-math-behind-neural-networks-490dc1f3cfd9) This paper is an attempt to explain all the matrix calculus you need in order to understand the training of deep neural networks. We assume no math knowledge beyond what you learned in calculus 1, and provide links to help you refresh the necessary math where needed. Note that you do not need to understand this material before you start learning to train and use deep learning in practice; rather, this material is for those who are already familiar with the basics of neural networks, and wish to deepen their understanding of the underlying math. Don't worry if you get stuck at some point along the way---just go back and reread the previous section, and try writing down and working through some examples. And if you're still stuck, we're happy to answer your questions in the Theory category at forums.fast.ai. Note: There is a reference section at the end of the paper summarizing all the key matrix calculus rules and terminology discussed here. See related articles at http://explained.ai|sl:tag|tag:jeremy_howard
RDF Next Steps|skos:broader|RDF
WWW 2013|skos:broader|J'y étais
Attention Models in Graphs: A Survey  An attention mechanism aids a model by  allowing it to focus on the most relevant parts of the input to make decisions   Graph-structured data arise naturally in many different application domains. By representing data as graphs, we can capture entities (i.e., nodes) as well as their relationships (i.e., edges) with each other. Many useful insights can be derived from graph-structured data as demonstrated by an ever-growing body of work focused on graph mining. However, in the real-world, graphs can be both large - with many complex patterns - and noisy which can pose a problem for effective graph mining. An effective way to deal with this issue is to incorporate attention into graph mining solutions. An attention mechanism allows a method to focus on task-relevant parts of the graph, helping it to make better decisions. In this work, we conduct a comprehensive and focused survey of the literature on the emerging field of graph attention models. We introduce three intuitive taxonomies to group existing work. These are based on problem setting (type of input and output), the type of attention mechanism used, and the task (e.g., graph classification, link prediction, etc.). We motivate our taxonomies through detailed examples and use each to survey competing approaches from a unique standpoint. Finally, we highlight several challenges in the area and discuss promising directions for future work.|sl:arxiv_author|Sungchul Kim
TextRank|skos:broader|Learning to rank
Dark matter|skos:broader|Physique
One-Shot Generalization in Deep Generative Models Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our models are able to generate compelling and diverse samples---having seen new examples just once---providing an important class of general-purpose models for one-shot machine learning.|sl:arxiv_firstAuthor|Danilo Jimenez Rezende
Toutankhamon|skos:broader|Pharaon
XBRL|skos:broader|Financial Data
Taxe carbone|skos:broader|Pollueurs payeurs
Apache OpenNLP|skos:broader|apache.org
HTML Data|skos:broader|Web of data
Biohackers|skos:broader|Hackers
Do Deep Nets Really Need to be Deep? Currently, deep neural networks are the state of the art on problems such as speech recognition and computer vision. In this extended abstract, we show that shallow feed-forward networks can learn the complex functions previously learned by deep nets and achieve accuracies previously only achievable with deep models. Moreover, in some cases the shallow neural nets can learn these deep functions using a total number of parameters similar to the original deep model. We evaluate our method on the TIMIT phoneme recognition task and are able to train shallow fully-connected nets that perform similarly to complex, well-engineered, deep convolutional architectures. Our success in training shallow neural nets to mimic deeper models suggests that there probably exist better algorithms for training shallow feed-forward nets than those currently available.|sl:tag|tag:machine_learning
Entities as Experts: Sparse Memory Access with Entity Supervision   the problem of capturing declarative knowledge in the learned parameters of a language model...     Entities as Experts (EaE) can access distinct memories of the entities mentioned in a piece of text;     To understand the motivation for distinct and  independent entity representations: A traditional Transformer would need to build an internal representation  of Charles Darwin from the words “Charles”  and “Darwin”... Conversely, EAE can access  a dedicated representation of “Charles Darwin”,  which is a memory of all of the contexts in which  this entity has previously been mentioned.... Having retrieved  and re-integrated this memory it is much easier for  EAE to relate the question to the answer     EaE's entity representations are learned directly from text. Correct identification, and representation, of entities is essential to EaE's performance    Based on transformer architecture    Extension: [Facts as Experts](doc:2020/07/2007_00849_facts_as_experts_) We focus on the problem of capturing declarative knowledge in the learned parameters of a language model. We introduce a new model, Entities as Experts (EaE), that can access distinct memories of the entities mentioned in a piece of text. Unlike previous efforts to integrate entity knowledge into sequence models, EaE's entity representations are learned directly from text. These representations capture sufficient knowledge to answer TriviaQA questions such as Which Dr. Who villain has been played by Roger Delgado, Anthony Ainley, Eric Roberts?. EaE outperforms a Transformer model with $30\\times$ the parameters on this task. According to the Lama knowledge probes, EaE also contains more factual knowledge than a similar sized Bert. We show that associating parameters with specific entities means that EaE only needs to access a fraction of its parameters at inference time, and we show that the correct identification, and representation, of entities is essential to EaE's performance. We also argue that the discrete and independent entity representations in EaE make it more modular and interpretable than the Transformer architecture on which it is based.|sl:tag|tag:question_answering
JavaScript Tutorial|skos:broader|JavaScript
BAM! Born-Again Multi-Task Networks for Natural Language Understanding  knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers It can be challenging to train multi-task neural networks that outperform or even match their single-task counterparts. To help address this, we propose using knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers. We evaluate our approach by multi-task fine-tuning BERT on the GLUE benchmark. Our method consistently improves over standard single-task and multi-task training.|sl:arxiv_author|Christopher D. Manning
XLNet: Generalized Autoregressive Pretraining for Language Understanding a new pretraining method for NLP that significantly improves upon BERT on 20 tasks (e.g., SQuAD, GLUE, RACE) With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.|sl:tag|tag:arxiv_doc
Text Generation from Knowledge Graphs with Graph Transformers Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.|sl:tag|tag:arxiv_doc
FBI v. Apple|skos:broader|FBI
war on drugs|skos:broader|Prohibition des narcotiques
Attention mechanism relating different positions of a sequence in order to compute a representation of the same sequence.    Useful in machine reading, abstractive summarization, or image description generation  |skos:broader|Good explanation is this [blog post by D. Britz](/doc/?uri=http%3A%2F%2Fwww.wildml.com%2F2016%2F01%2Fattention-and-memory-in-deep-learning-and-nlp%2F). (But the best explanation related to attention is to be found in this [post](/doc/2019/08/transformers_from_scratch_%7C_pet) about Self-Attention.)     While simple Seq2Seq builds a single context vector out of the encoder’s last hidden state, attention creates  shortcuts between the context vector and the entire source input: the context vector has access to the entire input sequence.  The decoder can “attend” to different parts of the source sentence at each step of the output generation, and the model learns what to attend to based on the input sentence and what it has produced so far.    Possible to interpret what the model is doing by looking at the Attention weight matrix    Cost: We need to calculate an attention value for each combination of input and output word (D. Britz: - attention is a bit of a misnomer: we look at everything in details before deciding what to focus on)                    
Sentence Embeddings|skos:broader|Document embeddings
RBM|skos:broader|ANN NN Artificial neural network
fps ontologies|skos:broader|fps dev
Guerres coloniales|skos:broader|Colonisation
Médecins sans frontières|skos:broader|Humanitaire
A statistical model for discovering the abstract topics that occur in a collection of documents.      |skos:broader|Methods for quantifying and categorizing semantic similarities between linguistic items based on their distributional properties in large samples of language data.    Basic idea: the Distributional hypothesis: linguistic items with similar distributions have similar meanings.    Basic approach: collect distributional information in high-dimensional vectors, and define similarity in terms of vector similarity    Models: latent semantic analysis (LSA), Hyperspace Analogue to Language (HAL), syntax- or dependency-based models, random indexing, semantic folding and various variants of the topic model.      
Named Entity Disambiguation using Deep Learning on Graphs Evaluation of different deep learning techniques to create  a context vector from graphs, aimed at high-accuracy NED. (neural  approach for entity disambiguation using graphs as background  knowledge)     We tackle Named Entity Disambiguation (NED) by comparing entities  in short sentences with Wikidata graphs. Creating a context vector  from graphs through deep learning is a challenging problem that has  never been applied to NED. Our main contribution is to present an  experimental study of recent neural techniques, as well as a discussion  about which graph features are most important for the disambiguation  task...    [published paper](https://rd.springer.com/chapter/10.1007/978-3-030-15719-7_10)      In NED, the system  must be able to generate a context for an entity in a text and an entity  in a knowledge base, then correctly link the two.    Explore whether representing graphs  as triplets is more useful than using the full topological information of the graph    We tackle \\ac{NED} by comparing entities in short sentences with \\wikidata{} graphs. Creating a context vector from graphs through deep learning is a challenging problem that has never been applied to \\ac{NED}. Our main contribution is to present an experimental study of recent neural techniques, as well as a discussion about which graph features are most important for the disambiguation task. In addition, a new dataset (\\wikidatadisamb{}) is created to allow a clean and scalable evaluation of \\ac{NED} with \\wikidata{} entries, and to be used as a reference in future research. In the end our results show that a \\ac{Bi-LSTM} encoding of the graph triplets performs best, improving upon the baseline models and scoring an \ m{F1} value of $91.6\\%$ on the \\wikidatadisamb{} test set|sl:tag|tag:nlp_short_texts
Calvin|skos:broader|Fanatisme
Emerging Cross-lingual Structure in Pretrained Language Models We study the problem of multilingual masked language modeling, i.e. the training of a single model on concatenated text from multiple languages, and present a detailed study of several factors that influence why these models are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from independently trained models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these symmetries seem to be automatically discovered and aligned during the joint training process.|sl:tag|tag:nlp_facebook
Enigmes de la physique|skos:broader|Enigme
Label-Embedding for Image Classification Attributes act as intermediate representations that enable parameter sharing between classes, a must when training data is scarce. We propose to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors. We introduce a function that measures the compatibility between an image and a label embedding. The parameters of this function are learned on a training set of labeled samples to ensure that, given an image, the correct classes rank higher than the incorrect ones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasets show that the proposed framework outperforms the standard Direct Attribute Prediction baseline in a zero-shot learning scenario. Label embedding enjoys a built-in ability to leverage alternative sources of information instead of or in addition to attributes, such as e.g. class hierarchies or textual descriptions. Moreover, label embedding encompasses the whole range of learning settings from zero-shot learning to regular learning with a large number of labeled examples.|sl:tag|tag:label_embedding
Apple CarPlay|skos:broader|iphone
Espagne|skos:broader|Europe
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:arxiv_author|Zhihong Shen
Maladie contagieuse|skos:broader|Maladie
Joseki|skos:broader|SPARQL AND Jena
RDF repository|skos:broader|RDF
Apple Developer Connection|skos:broader|Dev
External memory algorithm|skos:broader|Scaling
Grèce antique|skos:broader|Antiquité
Phil Archer|skos:broader|SW guys (and girls)
Yagán|skos:broader|Amérindien
Tensor2Tensor|skos:broader|TensorFlow
Attentats 13-11-2015|skos:broader|Paris
delicious java|skos:broader|del.icio.us
Restricted Boltzmann machine|skos:broader|Neural networks
Anaconda|skos:broader|Python
Magnétisme terrestre|skos:broader|Magnétisme
DITA|skos:broader|Technical documentation
Leo Sauermann|skos:broader|SW guys (and girls)
Property Graphs|skos:broader|Graph database
Paris|skos:broader|France
Image classification|skos:broader|Statistical classification
OSEMA 2011|skos:broader|ESWC 2011
François Chollet|skos:broader|AI girls and guys
classification method that generalizes logistic regression to multiclass problems.    Assumes that a linear combination of the observed features and some problem-specific parameters can be used to determine the probability of each particular outcome of the dependent variable.     If you want to assign probabilities to an object being one of several different things, softmax is the thing to do. Even later on, when we train more sophisticated models, the final step will be a layer of softmax. [cf.](http://www.tensorflow.org/tutorials/mnist/beginners/index.md)  |skos:broader|regression model where the dependent variable is categorical.
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Justin Gilmer
MINOS Neutrino Experiment|skos:broader|Expérience scientifique
Tree of life|skos:broader|Biology
Dalai Lama|skos:broader|Tibet
Text Generation from Knowledge Graphs with Graph Transformers Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.|sl:arxiv_author|Yi Luan
classification decision based on the value of a linear combination of the feature values  |skos:broader|the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations whose category membership is known.
RDF forms|skos:broader|Linked Data
Bibliothèque numérique|skos:broader|Bibliothèque
Natural Language Processing|skos:broader|Langage
Interactive Concept Mining on Personal Data -- Bootstrapping Semantic Services Semantic services (e.g. Semantic Desktops) are still afflicted by a cold start problem: in the beginning, the user's personal information sphere, i.e. files, mails, bookmarks, etc., is not represented by the system. Information extraction tools used to kick-start the system typically create 1:1 representations of the different information items. Higher level concepts, for example found in file names, mail subjects or in the content body of these items, are not extracted. Leaving these concepts out may lead to underperformance, having to many of them (e.g. by making every found term a concept) will clutter the arising knowledge graph with non-helpful relations. In this paper, we present an interactive concept mining approach proposing concept candidates gathered by exploiting given schemata of usual personal information management applications and analysing the personal information sphere using various metrics. To heed the subjective view of the user, a graphical user interface allows to easily rank and give feedback on proposed concept candidates, thus keeping only those actually considered relevant. A prototypical implementation demonstrates major steps of our approach.|sl:arxiv_author|Andreas Dengel
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.|sl:tag|tag:dropout
Country ontologies|skos:broader|Ontologies
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:tag|tag:embeddings
Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation   An embedding method specifically designed for NED that jointly maps words and entities into the same continuous vector space.    We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words Named Entity Disambiguation (NED) refers to the task of resolving multiple named entity mentions in a document to their correct references in a knowledge base (KB) (e.g., Wikipedia). In this paper, we propose a novel embedding method specifically designed for NED. The proposed method jointly maps words and entities into the same continuous vector space. We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words. By combining contexts based on the proposed embedding with standard NED features, we achieved state-of-the-art accuracy of 93.1% on the standard CoNLL dataset and 85.2% on the TAC 2010 dataset.|sl:arxiv_author|Hideaki Takeda
Unsupervised Transfer Learning for Spoken Language Understanding in Intelligent Agents  We apply ELMo, ULMFiT (unsupervised transfer) with supervised transfer to reduce labeled data required for launching domains in Alexa by 10-15x User interaction with voice-powered agents generates large amounts of unlabeled utterances. In this paper, we explore techniques to efficiently transfer the knowledge from these unlabeled utterances to improve model performance on Spoken Language Understanding (SLU) tasks. We use Embeddings from Language Model (ELMo) to take advantage of unlabeled data by learning contextualized word representations. Additionally, we propose ELMo-Light (ELMoL), a faster and simpler unsupervised pre-training method for SLU. Our findings suggest unsupervised pre-training on a large corpora of unlabeled utterances leads to significantly better SLU performance compared to training from scratch and it can even outperform conventional supervised transfer. Additionally, we show that the gains from unsupervised transfer techniques can be further improved by supervised transfer. The improvements are more pronounced in low resource settings and when using only 1000 labeled in-domain samples, our techniques match the performance of training from scratch on 10-15x more labeled in-domain data.|sl:tag|tag:elmo
Anglais|skos:broader|Langues
LDOW2008|skos:broader|WWW 2008
Spark (Java web framework)|skos:broader|Web dev framework
AI black box|skos:broader|Artificial Intelligence
Similarity Search for Efficient Active Learning and Search of Rare Concepts  Similarity search for Efficient Active Learning and Search (SEALS)    In [Active Learning](tag:active_learning): instead of searching globally for the optimal examples to label, leverage the fact that data is often heavily skewed and expand the candidate pool with the nearest neighbors of the labeled set.     Our work attacks both the labeling and computational costs of machine learning...SEALS dramatically reduces the barrier to machine learning, enabling small teams or individuals to  build accurate classifiers. SEALS does, however, introduce another system component, a similarity  search index, which adds some additional engineering complexity to build, tune, and maintain.  Fortunately, several highly optimized implementations like Annoy and [Faiss](doc:2020/06/facebookresearch_faiss_a_libra) work reasonably well  out of the box. Many active learning and search approaches are intractable for industrial settings with billions of unlabeled examples. Existing approaches, such as uncertainty sampling or information density, search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. However, in practice, data is often heavily skewed; only a small fraction of collected data will be relevant for a given learning task. For example, when identifying rare classes, detecting malicious content, or debugging model performance, the ratio of positive to negative examples can be 1 to 1,000 or more. In this work, we exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round by only looking at the nearest neighbors to the labeled examples. Empirically, we observe that learned representations effectively cluster unseen concepts, making active learning very effective and substantially reducing the number of viable unlabeled examples. We evaluate several active learning and search techniques in this setting on three large-scale datasets: ImageNet, Goodreads spoiler detection, and OpenImages. For rare classes, active learning methods need as little as 0.31% of the labeled data to match the average precision of full supervision. By limiting active learning methods to only consider the immediate neighbors of the labeled data as candidates for labeling, we need only process as little as 1% of the unlabeled data while achieving similar reductions in labeling costs as the traditional global approach. This process of expanding the candidate pool with the nearest neighbors of the labeled set can be done efficiently and reduces the computational complexity of selection by orders of magnitude.|sl:tag|tag:active_learning
Documentaire TV|skos:broader|Documentaire
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:tag|tag:personal_assistant
Innoraise|skos:broader|Semantic Web : Application
FAO|skos:broader|Institutions internationales
Efficient Contextual Representation Learning Without Softmax Layer how to accelerate contextual representation learning.     Contextual representation models are difficult to train due to the large parameter sizes and high computational complexity     We find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size.  Therefore, we redesign the learning objectiv.   Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings.  Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary.  When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.    decouples learning contexts and words     Instead of using  a softmax layer to predict the distribution of the  missing word, we utilize and extend the SEMFIT  layer (Kumar and Tsvetkov, 2018) to predict the  embedding of the missing word. Contextual representation models have achieved great success in improving various downstream tasks. However, these language-model-based encoders are difficult to train due to the large parameter sizes and high computational complexity. By carefully examining the training procedure, we find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size. Therefore, we redesign the learning objective and propose an efficient framework for training contextual representation models. Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings. Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary. When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.|sl:tag|tag:elmo
public-lod@w3.org|skos:broader|Linked Data
TransE|skos:broader|Entity embeddings
Topic modelling for humans ; Python framework for fast Vector Space Modelling    |skos:broader|Algebraic model for representing text documents as vectors of identifiers such as index terms.br/  Documents and queries are represented as vectors.  Each dimension corresponds to a separate term. If a term occurs in the document, its value in the vector is non-zero. One way of computing the value: TD-IDF          
LDOW2008|skos:broader|Linking Open Data
A Metric Learning Reality Check Deep metric learning papers from the past four years have consistently claimed great advances in accuracy, often more than doubling the performance of decade-old methods. In this paper, we take a closer look at the field to see if this is actually true. We find flaws in the experimental setup of these papers, and propose a new way to evaluate metric learning algorithms. Finally, we present experimental results that show that the improvements over time have been marginal at best.|sl:arxiv_author|Ser-Nam Lim
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:tag|tag:ml_google
OGM|skos:broader|Biotechnologies Biotechnologies
BERT for Joint Intent Classification and Slot Filling  Experimental results show that our  proposed joint BERT model outperforms BERT  models modeling intent classification and slot filling  separately, demonstrating the efficacy of exploiting  the relationship between the two tasks.    Adding a CRF on top of the model doesn't improve the results. Intent classification and slot filling are two essential tasks for natural language understanding. They often suffer from small-scale human-labeled training data, resulting in poor generalization capability, especially for rare words. Recently a new language representation model, BERT (Bidirectional Encoder Representations from Transformers), facilitates pre-training deep bidirectional representations on large-scale unlabeled corpora, and has created state-of-the-art models for a wide variety of natural language processing tasks after simple fine-tuning. However, there has not been much effort on exploring BERT for natural language understanding. In this work, we propose a joint intent classification and slot filling model based on BERT. Experimental results demonstrate that our proposed model achieves significant improvement on intent classification accuracy, slot filling F1, and sentence-level semantic frame accuracy on several public benchmark datasets, compared to the attention-based recurrent neural network models and slot-gated models.|sl:arxiv_author|Zhu Zhuo
Phoenix Mars Lander|skos:broader|Exploration marsienne
The Description Length of Deep Learning Models  Solomonoff’s general theory of inference (Solomonoff, 1964) and the [Minimum Description Length Principle](tag:minimum_description_length_principle) (Grünwald, 2007; Rissanen, 2007) formalize [Occam's razor](tag:occam_s_razor), and hold that a good model of data is a model that is good at losslessly  compressing the data, including the cost of describing the model itself. Deep neural  networks might seem to go against this principle given the large number of  parameters to be encoded.  We demonstrate experimentally the ability of deep neural networks to compress  the training data even when accounting for parameter encoding. Solomonoff's general theory of inference and the Minimum Description Length principle formalize Occam's razor, and hold that a good model of data is a model that is good at losslessly compressing the data, including the cost of describing the model itself. Deep neural networks might seem to go against this principle given the large number of parameters to be encoded. We demonstrate experimentally the ability of deep neural networks to compress the training data even when accounting for parameter encoding. The compression viewpoint originally motivated the use of variational methods in neural networks. Unexpectedly, we found that these variational methods provide surprisingly poor compression bounds, despite being explicitly built to minimize such bounds. This might explain the relatively poor practical performance of variational methods in deep learning. On the other hand, simple incremental encoding methods yield excellent compression values on deep networks, vindicating Solomonoff's approach.|sl:tag|tag:occam_s_razor
Knowledge Graphs and NLP|skos:broader|Knowledge Graphs
Synonym URIs|skos:broader|Linked Data
ARIMA|skos:broader|Time Series
Hierarchical Memory Networks  hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory Memory networks are neural networks with an explicit memory component that can be both read and written to by the network. The memory is often addressed in a soft way using a softmax function, making end-to-end training with backpropagation possible. However, this is not computationally scalable for applications which require the network to read from extremely large memories. On the other hand, it is well known that hard attention mechanisms based on reinforcement learning are challenging to train successfully. In this paper, we explore a form of hierarchical memory network, which can be considered as a hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory. Specifically, we propose to incorporate Maximum Inner Product Search (MIPS) in the training and inference procedures for our hierarchical memory network. We explore the use of various state-of-the art approximate MIPS techniques and report results on SimpleQuestions, a challenging large scale factoid question answering task.|sl:arxiv_author|Sungjin Ahn
GoodRelations|skos:broader|Semantic SEO
similar items are clustered into classes, an n-gram language model for the class tokens is generated, and then the probabilities for words in a class are distributed according to the smoothed relative unigram frequencies of the words.|skos:broader|Language modeling: task of predicting the next word in a text given the previous words. Example of concrete practical applications: intelligent keyboards     Language model: probability distribution over sequences of words. Statistical language models try to learn the probability of the next word given its previous words.     Models rely on an auto-regressive factorization of the joint probability of a corpus using different approaches, from n-gram models to RNNs (SOTA as of 2018-01) ([source](https://arxiv.org/abs/1801.06146))
Wordnet|skos:broader|Anglais
Littérature africaine|skos:broader|Afrique
Variable Selection Methods for Model-based Clustering Model-based clustering is a popular approach for clustering multivariate data which has seen applications in numerous fields. Nowadays, high-dimensional data are more and more common and the model-based clustering approach has adapted to deal with the increasing dimensionality. In particular, the development of variable selection techniques has received a lot of attention and research effort in recent years. Even for small size problems, variable selection has been advocated to facilitate the interpretation of the clustering results. This review provides a summary of the methods developed for variable selection in model-based clustering. Existing R packages implementing the different methods are indicated and illustrated in application to two data analysis examples.|sl:tag|tag:arxiv_doc
Erreur judiciaire|skos:broader|Justice
Cory Doctorow|skos:broader|Ecrivain
Richard Socher|skos:broader|NLP girls and guys
finding clusters which are defined by only a subset of dimensions (it is not needed to have the agreement of all N features)|skos:broader|the task of grouping a set of objects in such a way that objects in the same group (cluster) are more similar (in some sense or another) to each other than to those in other groups.  
The information bottleneck method  We define the relevant information in a signal x ∈ X as being the information that this signal provides about another signal y ∈ Y. Examples include the information that face images provide about the names of the people portrayed, or the information that speech sounds provide about the words spoken. Understanding the signal x requires more than just predicting y, it also requires specifying which features of X play a role in the prediction. We formalize this problem as that of finding a short code for X that preserves the maximum information about Y. That is, we squeeze the information that X provides about Y through a ‘bottleneck’ formed by a limited set of codewords X ̃... This approach yields an exact set of self consistent equations for the coding rules X → X ̃ and X ̃ → Y .    (from the intro) : how to define meaningful / relevant information? An issue left out of information theory by Shannon (focus on the problem of transmitting information rather than judging its value to the recipient) -leads to  consider statistical and information theoretic principles as almost irrelevant  for the question of meaning.      In contrast, we argue here that information theory,  in particular lossy source compression, provides a natural quantitative  approach to the question of “relevant information.” Specifically, we formulate  a variational principle for the extraction or efficient representation of  relevant information.     We define the relevant information in a signal $x\\in X$ as being the information that this signal provides about another signal $y\\in \\Y$. Examples include the information that face images provide about the names of the people portrayed, or the information that speech sounds provide about the words spoken. Understanding the signal $x$ requires more than just predicting $y$, it also requires specifying which features of $\\X$ play a role in the prediction. We formalize this problem as that of finding a short code for $\\X$ that preserves the maximum information about $\\Y$. That is, we squeeze the information that $\\X$ provides about $\\Y$ through a `bottleneck' formed by a limited set of codewords $\\tX$. This constrained optimization problem can be seen as a generalization of rate distortion theory in which the distortion measure $d(x,\\x)$ emerges from the joint statistics of $\\X$ and $\\Y$. This approach yields an exact set of self consistent equations for the coding rules $X \\to \\tX$ and $\\tX \\to \\Y$. Solutions to these equations can be found by a convergent re-estimation method that generalizes the Blahut-Arimoto algorithm. Our variational principle provides a surprisingly rich framework for discussing a variety of problems in signal processing and learning, as will be described in detail elsewhere.|sl:arxiv_firstAuthor|Naftali Tishby Hebrew University and NEC Research Institute
Zemanta|skos:broader|Keep new
Towards Understanding Linear Word Analogies A surprising property of word vectors is that word analogies can often be solved with vector arithmetic. However, it is unclear why arithmetic operators correspond to non-linear embedding models such as skip-gram with negative sampling (SGNS). We provide a formal explanation of this phenomenon without making the strong assumptions that past theories have made about the vector space and word distribution. Our theory has several implications. Past work has conjectured that linear substructures exist in vector spaces because relations can be represented as ratios; we prove that this holds for SGNS. We provide novel justification for the addition of SGNS word vectors by showing that it automatically down-weights the more frequent word, as weighting schemes do ad hoc. Lastly, we offer an information theoretic interpretation of Euclidean distance in vector spaces, justifying its use in capturing word dissimilarity.|sl:arxiv_author|David Duvenaud
Concept Bottleneck Models  We seek to learn models that we can interact with using high-level concepts... We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these concept bottleneck models by editing their predicted concept values and propagating these changes to the final prediction... These models allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time. We seek to learn models that we can interact with using high-level concepts: if the model did not think there was a bone spur in the x-ray, would it still predict severe arthritis? State-of-the-art models today do not typically support the manipulation of concepts like the existence of bone spurs, as they are trained end-to-end to go directly from raw input (e.g., pixels) to output (e.g., arthritis severity). We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these \\emph{concept bottleneck models} by editing their predicted concept values and propagating these changes to the final prediction. On x-ray grading and bird identification, concept bottleneck models achieve competitive accuracy with standard end-to-end models, while enabling interpretation in terms of high-level clinical concepts (bone spurs) or bird attributes (wing color). These models also allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time.|sl:arxiv_author|Percy Liang
Learning to Remember Rare Events  a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training.    Our memory module can be easily added to any part of a supervised neural network Despite recent advances, memory-augmented deep neural networks are still limited when it comes to life-long and one-shot learning, especially in remembering rare events. We present a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training. Our memory module can be easily added to any part of a supervised neural network. To show its versatility we add it to a number of networks, from simple convolutional ones tested on image classification to deep sequence-to-sequence and recurrent-convolutional models. In all cases, the enhanced network gains the ability to remember and do life-long one-shot learning. Our module remembers training examples shown many thousands of steps in the past and it can successfully generalize from them. We set new state-of-the-art for one-shot learning on the Omniglot dataset and demonstrate, for the first time, life-long one-shot learning in recurrent neural networks on a large-scale machine translation task.|sl:tag|tag:k_nearest_neighbors_algorithm
Label-aware Document Representation via Hybrid Attention for Extreme Multi-Label Text Classification  This paper is motivated to better explore the semantic relationship between each document and extreme labels by taking advantage of both document content and label correlation. Our objective is to establish an explicit label-aware representation for each document with a hybrid attention deep neural network model(LAHA) Extreme multi-label text classification (XMTC) aims at tagging a document with most relevant labels from an extremely large-scale label set. It is a challenging problem especially for the tail labels because there are only few training documents to build classifier. This paper is motivated to better explore the semantic relationship between each document and extreme labels by taking advantage of both document content and label correlation. Our objective is to establish an explicit label-aware representation for each document with a hybrid attention deep neural network model(LAHA). LAHA consists of three parts. The first part adopts a multi-label self-attention mechanism to detect the contribution of each word to labels. The second part exploits the label structure and document content to determine the semantic connection between words and labels in a same latent space. An adaptive fusion strategy is designed in the third part to obtain the final label-aware document representation so that the essence of previous two parts can be sufficiently integrated. Extensive experiments have been conducted on six benchmark datasets by comparing with the state-of-the-art methods. The results show the superiority of our proposed LAHA method, especially on the tail labels.|sl:arxiv_author|Liping Jing
SPARQL Extension Functions|skos:broader|SPARQL
Word embedding: evaluation|skos:broader|Embedding evaluation
Equateur|skos:broader|Amérique du sud
Niger : festival de la jeunesse|skos:broader|Niger
CFPM|skos:broader|Niamey
Linked Data in enterprise|skos:broader|LD
Feature learning|skos:broader|Machine learning: problems
Deep Learning for Symbolic Mathematics Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.|sl:tag|tag:facebook_fair
LOD & museum|skos:broader|Culture et sem web
WWW 2008|skos:broader|TheWebConf
Société française Société française|skos:broader|France
Mur de Berlin|skos:broader|Berlin
BlackboxNLP (2018 workshop)|skos:broader|EMNLP 2018
Language Models as Knowledge Bases? an analysis of the relational knowledge present in pretrained language models shows an ability of these models to recall factual knowledge  Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as fill-in-the-blank cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.|sl:arxiv_author|Tim Rocktäschel
PCA|skos:broader|Representation learning
Prohibition des narcotiques|skos:broader|Trafic de drogue
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:tag|tag:aidan_hogan
A Comprehensive Survey on Graph Neural Networks an overview of graph neural networks (GNNs) in data mining and machine learning fields Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.|sl:tag|tag:survey
Knowledge Graph Construction|skos:broader|Knowledge Graph Completion
Swoogle|skos:broader|Semantic Web search engine
Named Entity Recognition with Extremely Limited Data Named Entity Search (NES)     We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.     We do not propose this as a replacement  for NER, but as something to be used for an ephemeral or contextual  class of entity, when it does not make sense to label hundreds or  thousands of instances to learn a classifier Traditional information retrieval treats named entity recognition as a pre-indexing corpus annotation task, allowing entity tags to be indexed and used during search. Named entity taggers themselves are typically trained on thousands or tens of thousands of examples labeled by humans. However, there is a long tail of named entities classes, and for these cases, labeled data may be impossible to find or justify financially. We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.|sl:arxiv_author|John Foley
Archéologie amazonienne|skos:broader|Amazonie
Politique économique française|skos:broader|Economie française
Unit test|skos:broader|Tests
Stanford classifier|skos:broader|NLP tools
Turing|skos:broader|Mathématicien
LibShortText|skos:broader|Text Classification
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:arxiv_author|Chenyan Xiong
Tombe d'amphipolis|skos:broader|Grèce antique
Bag of Tricks for Efficient Text Classification A simple and efficient baseline for text classification.     Our word features can  be averaged together to form good sentence representations.    Our experiments show that fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.   This paper explores a simple and efficient baseline for text classification. Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.|sl:tag|tag:arxiv_doc
Affaires de Gado à Niamey|skos:broader|Niamey
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:arxiv_author|Yousef Hindy
Hackers|skos:broader|Hack
Joint Embedding of Hierarchical Categories and Entities for Concept Categorization and Dataless Classification a framework that embeds entities and categories into a semantic space by integrating structured  knowledge and taxonomy hierarchy from large knowledge bases.    two methods:    1. Category Embedding model): it replaces the entities in the context with their directly  labeled categories to build categories’ context;   2. Hierarchical Category Embedding: it  further incorporates all ancestor categories of the context entities to utilize the hierarchical information. Due to the lack of structured knowledge applied in learning distributed representation of cate- gories, existing work cannot incorporate category hierarchies into entity information. We propose a framework that embeds entities and categories into a semantic space by integrating structured knowledge and taxonomy hierarchy from large knowledge bases. The framework allows to com- pute meaningful semantic relatedness between entities and categories. Our framework can han- dle both single-word concepts and multiple-word concepts with superior performance on concept categorization and yield state of the art results on dataless hierarchical classification.|sl:arxiv_author|Rahul Iyer
Beyond Vector Spaces: Compact Data Representation as Differentiable Weighted Graphs  In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE (Probabilistic Differentiable Graph Embeddings): a method that learns a weighted graph representation of data end-to-end by gradient descent.    [Github](https://github.com/stanis-morozov/prodige)     Learning useful representations is a key ingredient to the success of modern machine learning. Currently, representation learning mostly relies on embedding data into Euclidean space. However, recent work has shown that data in some domains is better modeled by non-euclidean metric spaces, and inappropriate geometry can result in inferior performance. In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE: a method that learns a weighted graph representation of data end-to-end by gradient descent. Greater generality and fewer model assumptions make PRODIGE more powerful than existing embedding-based approaches. We confirm the superiority of our method via extensive experiments on a wide range of tasks, including classification, compression, and collaborative filtering.|sl:tag|tag:geometry_of_language_embeddings
Benjamin Nowack|skos:broader|SW guys (and girls)
ElasticSearch: nearest neighbor(s)|skos:broader|Nearest neighbor search
Dean Allemang|skos:broader|SW guys (and girls)
Thucydide|skos:broader|Grèce antique
RDF Application|skos:broader|RDF
Honda|skos:broader|Automobile
Troubleshooting|skos:broader|J'ai un petit problème avec mon ordinateur
Scala|skos:broader|Java
PageRank|skos:broader|Google ranking
Pierre de Volvic|skos:broader|Volvic
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|Juan Sequeda
Shoah|skos:broader|Génocide
Cornell|skos:broader|Universités américaines
The Limits to Growth|skos:broader|Croissance
Cancer|skos:broader|Maladie
Barack's Wife Hillary: Using Knowledge-Graphs for Fact-Aware Language Modeling  a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset, a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark. In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language model's ability to complete sentences requiring factual knowledge, showing that the KGLM outperforms even very large language models in generating facts.|sl:tag|tag:arxiv_doc
John Sofakolle|skos:broader|CFPM
Large deviations for the perceptron model and consequences for active learning the task of choosing the subset of samples to be labeled from a fixed finite pool of samples Active learning is a branch of machine learning that deals with problems where unlabeled data is abundant yet obtaining labels is expensive. The learning algorithm has the possibility of querying a limited number of samples to obtain the corresponding labels, subsequently used for supervised learning. In this work, we consider the task of choosing the subset of samples to be labeled from a fixed finite pool of samples. We assume the pool of samples to be a random matrix and the ground truth labels to be generated by a single-layer teacher random neural network. We employ replica methods to analyze the large deviations for the accuracy achieved after supervised learning on a subset of the original pool. These large deviations then provide optimal achievable performance boundaries for any active learning algorithm. We show that the optimal learning performance can be efficiently approached by simple message-passing active learning algorithms. We also provide a comparison with the performance of some other popular active learning strategies.|sl:arxiv_firstAuthor|Hugo Cui
Seevl|skos:broader|Linked Data: application
KIWI project|skos:broader|Semantic Wiki
Turquie|skos:broader|Pays d'Europe
Tasmanian devil|skos:broader|Cancer
Natural Language Processing (almost) from Scratch seminal work    Abstract:     a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements   We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.|sl:arxiv_author|Ronan Collobert
SPARQL: sample code|skos:broader|SPARQL
Antiquité|skos:broader|Archéologie
Ranked Entities in Search Results|skos:broader|NLP and Search
Long short-term memory: recurrent neural network architecture well-suited for time series with long time lags between important events.  (cf the problem of long time dependencies, such as when you want to predict the next word in I grew up in France… I speak fluent [?]).    A solution to the vanishing gradient problem in RNNs          |skos:broader|the natural architecture of NN to deal with sequences.    NN where connections between units form a directed cycle. This creates an internal state of the network which allows it to exhibit dynamic temporal behavior. Unlike feedforward neural networks, RNNs can use their internal memory to process arbitrary sequences of inputs. This makes them applicable to tasks such as unsegmented connected handwriting recognition or speech recognition.    2 broad classes: finite impulse and infinite impulse (a finite impulse RNN can be unrolled and replaced with a strictly feedforward neural network)    Problems with RNNs:    - they suffer from the vanishing gradient problem that prevents  them from learning long-range dependencies. [#LSTMs](/tag/lstm_networks) improve upon this  by using a gating mechanism that allows for explicit memory deletes and  updates.  - inherently sequential computation which prevents parallelization across elements of the input sequence    RNN in NLP:    - Goal: reprenting a sequence of words as dense vectors  - input: seq of words (or chars)  - ouput: a seq of hidden states with each a representation of the seq from the beginning to a specific posiition  - advantages: encoding sequential relationships and dependency among words      
Virtuoso|skos:broader|Semantic Web Platform
Document embeddings|skos:broader|Text Embeddings
Peter Mika|skos:broader|SW guys (and girls)
Forms|skos:broader|HTML Dev
Pre-training via Paraphrasing We introduce MARGE, a pre-trained sequence-to-sequence model learned with an unsupervised multi-lingual multi-document paraphrasing objective. MARGE provides an alternative to the dominant masked language modeling paradigm, where we self-supervise the reconstruction of target text by retrieving a set of related texts (in many languages) and conditioning on them to maximize the likelihood of generating the original. We show it is possible to jointly learn to do retrieval and reconstruction, given only a random initialization. The objective noisily captures aspects of paraphrase, translation, multi-document summarization, and information retrieval, allowing for strong zero-shot performance on several tasks. For example, with no additional task-specific training we achieve BLEU scores of up to 35.8 for document translation. We further show that fine-tuning gives strong performance on a range of discriminative and generative tasks in many languages, making MARGE the most generally applicable pre-training method to date.|sl:arxiv_author|Gargi Ghosh
On Extractive and Abstractive Neural Document Summarization with Transformer Language Models  Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper. We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We show that this extractive step significantly improves summarization results. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher rouge scores. Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper.|sl:arxiv_firstAuthor|Sandeep Subramanian
Linked Data in enterprise|skos:broader|Enterprise Semantic Web Semantic Web in the enterprise Corporate Semantic Web
VoCamp|skos:broader|Semantic Web
TouchGraph|skos:broader|Applet
A machine learning model that models some of the structural and algorithmic properties of the neocortex. HTM is a biomimetic model based on the memory-prediction theory of brain function described by Jeff Hawkins. HTM is a method for discovering and inferring the high-level causes of observed input patterns and sequences, thus building an increasingly complex model of the world.  |skos:broader|a theory of brain function created by Jeff Hawkins about mammalian neocortex. Role of the mammalian neocortex in matching sensory inputs to stored memory patterns, and how this process leads to predictions of what will happen in the future.
France : dysfonctionnement administratif|skos:broader|France : dysfonctionnement des institutions
David Ricardo|skos:broader|Capitalisme
gensim|skos:broader|Vector space model
BBC semantic publishing|skos:broader|RDF Application
Le Pen|skos:broader|FN
Deep Patent Landscaping Model Using Transformer and Graph Embedding a transformer encoder  for analyzing textual data present in patent documents  and a graph convolutional network for analyzing  patent metadata.    A benchmarking dataset for patent landscaping  based on patent trends reports published by the  Korean Patent Office. Data acquisition using Google's BigQuery public datasets.    10% improvement comparing to Google’s proposed Automated Patent Landscaping.    Empirical analysis of the importance of features (text vs metadata, citations vs classification)     Patent landscaping is a method used for searching related patents during a research and development (R&D) project. To avoid the risk of patent infringement and to follow current trends in technology, patent landscaping is a crucial task required during the early stages of an R&D project. As the process of patent landscaping requires advanced resources and can be tedious, the demand for automated patent landscaping has been gradually increasing. However, a shortage of well-defined benchmark datasets and comparable models makes it difficult to find related research studies. In this paper, we propose an automated patent landscaping model based on deep learning. To analyze the text of patents, the proposed model uses a modified transformer structure. To analyze the metadata of patents, we propose a graph embedding method that uses a diffusion graph called Diff2Vec. Furthermore, we introduce four benchmark datasets for comparing related research studies in patent landscaping. The datasets are produced by querying Google BigQuery, based on a search formula from a Korean patent attorney. The obtained results indicate that the proposed model and datasets can attain state-of-the-art performance, as compared with current patent landscaping models.|sl:arxiv_author|Seokkyu Choi
Fast.ai course|skos:broader|MOOC
UNIX Tips|skos:broader|Unix
Label-aware Document Representation via Hybrid Attention for Extreme Multi-Label Text Classification  This paper is motivated to better explore the semantic relationship between each document and extreme labels by taking advantage of both document content and label correlation. Our objective is to establish an explicit label-aware representation for each document with a hybrid attention deep neural network model(LAHA) Extreme multi-label text classification (XMTC) aims at tagging a document with most relevant labels from an extremely large-scale label set. It is a challenging problem especially for the tail labels because there are only few training documents to build classifier. This paper is motivated to better explore the semantic relationship between each document and extreme labels by taking advantage of both document content and label correlation. Our objective is to establish an explicit label-aware representation for each document with a hybrid attention deep neural network model(LAHA). LAHA consists of three parts. The first part adopts a multi-label self-attention mechanism to detect the contribution of each word to labels. The second part exploits the label structure and document content to determine the semantic connection between words and labels in a same latent space. An adaptive fusion strategy is designed in the third part to obtain the final label-aware document representation so that the essence of previous two parts can be sufficiently integrated. Extensive experiments have been conducted on six benchmark datasets by comparing with the state-of-the-art methods. The results show the superiority of our proposed LAHA method, especially on the tail labels.|sl:arxiv_firstAuthor|Xin Huang
SDMX-RDF|skos:broader|RDF
Google Colab|skos:broader|Google Research
Hymne à la joie|skos:broader|Beethoven
todo à voir :  https://www.researchgate.net/publication/315590093_Cost-sensitive_sequential_three-way_decision_modeling_using_a_deep_neural_network  https://arxiv.org/pdf/1611.05134.pdf  https://www.researchgate.net/publication/261379944_Three-way_decisions_with_artificial_neural_networks  |skos:broader|the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations whose category membership is known.
Taxe carbone|skos:broader|Économie écologique
Topic Modeling over Short Texts by Incorporating Word Embeddings New method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo-texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic Inferring topics from the overwhelming amount of short texts becomes a critical but challenging task for many content analysis tasks, such as content charactering, user interest profiling, and emerging topic detecting. Existing methods such as probabilistic latent semantic analysis (PLSA) and latent Dirichlet allocation (LDA) cannot solve this prob- lem very well since only very limited word co-occurrence information is available in short texts. This paper studies how to incorporate the external word correlation knowledge into short texts to improve the coherence of topic modeling. Based on recent results in word embeddings that learn se- mantically representations for words from a large corpus, we introduce a novel method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo- texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic. The experiments on real-world datasets validate the effectiveness of our model comparing with the state-of-the-art models.|sl:tag|tag:topic_modeling_over_short_texts
WWW 2018|skos:broader|WWW Conference
Javascript RDF Parser in IE|skos:broader|Javascript RDF Parser
Data Augmentation|skos:broader|Machine learning: techniques
EDUCE: Explaining model Decisions through Unsupervised Concepts Extraction  Providing explanations along with predictions is crucial in some text processing tasks. Therefore, we propose a new self-interpretable model that performs output prediction and simultaneously provides an explanation in terms of the presence of particular concepts in the input. To do so, our model's prediction relies solely on a low-dimensional binary representation of the input, where each feature denotes the presence or absence of concepts.    Presented in these [slides](/doc/2019/12/unsupervised_learning_with_text) Providing explanations along with predictions is crucial in some text processing tasks. Therefore, we propose a new self-interpretable model that performs output prediction and simultaneously provides an explanation in terms of the presence of particular concepts in the input. To do so, our model's prediction relies solely on a low-dimensional binary representation of the input, where each feature denotes the presence or absence of concepts. The presence of a concept is decided from an excerpt i.e. a small sequence of consecutive words in the text. Relevant concepts for the prediction task at hand are automatically defined by our model, avoiding the need for concept-level annotations. To ease interpretability, we enforce that for each concept, the corresponding excerpts share similar semantics and are differentiable from each others. We experimentally demonstrate the relevance of our approach on text classification and multi-sentiment analysis tasks.|sl:tag|tag:arxiv_doc
Graph Attention Networks |skos:broader|Attention in Graphs
Internet Explorer|skos:broader|Microsoft
Replace or Retrieve Keywords In Documents at Scale For a document of size N (characters) and a dictionary of M keywords, the time complexity is O(N) (compared to O(MxN) with regex). FlashText is designed to only match complete words (words with boundary characters on both sides). Different from Aho Corasick Algorithm, as it doesn't match substrings. This algorithm is also designed to go for the longest match first. For an input dictionary {Machine, Learning, Machine learning} on a string 'I like Machine learning', it will only consider the longest match, which is Machine Learning    [Github](https://github.com/vi3k6i5/flashtext) In this paper we introduce, the FlashText algorithm for replacing keywords or finding keywords in a given text. FlashText can search or replace keywords in one pass over a document. The time complexity of this algorithm is not dependent on the number of terms being searched or replaced. For a document of size N (characters) and a dictionary of M keywords, the time complexity will be O(N). This algorithm is much faster than Regex, because regex time complexity is O(MxN). It is also different from Aho Corasick Algorithm, as it doesn't match substrings. FlashText is designed to only match complete words (words with boundary characters on both sides). For an input dictionary of {Apple}, this algorithm won't match it to 'I like Pineapple'. This algorithm is also designed to go for the longest match first. For an input dictionary {Machine, Learning, Machine learning} on a string 'I like Machine learning', it will only consider the longest match, which is Machine Learning. We have made python implementation of this algorithm available as open-source on GitHub, released under the permissive MIT License.|sl:tag|tag:string_searching_algorithm
jersey/RDF|skos:broader|jersey
A Survey Of Cross-lingual Word Embedding Models Cross-lingual representations of words enable us to reason about word meaning in multilingual contexts and are a key facilitator of cross-lingual transfer when developing natural language processing models for low-resource languages. In this survey, we provide a comprehensive typology of cross-lingual word embedding models. We compare their data requirements and objective functions. The recurring theme of the survey is that many of the models presented in the literature optimize for the same objectives, and that seemingly different models are often equivalent modulo optimization strategies, hyper-parameters, and such. We also discuss the different ways cross-lingual word embeddings are evaluated, as well as future challenges and research horizons.|sl:arxiv_author|Anders Søgaard
Semantic Vector Encoding and Similarity Search Using Fulltext Search Engines  The ubiquity of semantic vector space modeling raises the challenge of efficient searching in dense, high-dimensional vector spaces. We would naturally want to take advantage of the design and optimizations behind modern fulltext engines like Elasticsearch so as to meet the scalability and robustness demands of modern IR applications. This is the research challenge addressed in this paper.   The paper describes novel ways of encoding dense vectors into text documents, allowing the use of traditional inverted index engines.    [blog post](https://rare-technologies.com/semantic-search-fulltext-engine-acl-2017/)   Vector representations and vector space modeling (VSM) play a central role in modern machine learning. We propose a novel approach to `vector similarity searching' over dense semantic representations of words and documents that can be deployed on top of traditional inverted-index-based fulltext engines, taking advantage of their robustness, stability, scalability and ubiquity. We show that this approach allows the indexing and querying of dense vectors in text domains. This opens up exciting avenues for major efficiency gains, along with simpler deployment, scaling and monitoring. The end result is a fast and scalable vector database with a tunable trade-off between vector search performance and quality, backed by a standard fulltext engine such as Elasticsearch. We empirically demonstrate its querying performance and quality by applying this solution to the task of semantic searching over a dense vector representation of the entire English Wikipedia.|sl:tag|tag:elasticsearch
Moyen-âge|skos:broader|Histoire
A La Carte Embedding|skos:broader|N-grams
Ontology|skos:broader|Web sémantique sw
JSON 2 JSON-LD|skos:broader|JSON-LD
Read-Write Secure Data Web|skos:broader|Read-Write Linked Data
A mathematical theory of semantic development in deep neural networks  a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences?   An extensive body of empirical research has revealed remarkable regularities in the acquisition, organization, deployment, and neural representation of human semantic knowledge, thereby raising a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences? We address this question by mathematically analyzing the nonlinear dynamics of learning in deep linear networks. We find exact solutions to this learning dynamics that yield a conceptual explanation for the prevalence of many disparate phenomena in semantic cognition, including the hierarchical differentiation of concepts through rapid developmental transitions, the ubiquity of semantic illusions between such transitions, the emergence of item typicality and category coherence as factors controlling the speed of semantic processing, changing patterns of inductive projection over development, and the conservation of semantic similarity in neural representations across species. Thus, surprisingly, our simple neural model qualitatively recapitulates many diverse regularities underlying semantic development, while providing analytic insight into how the statistical structure of an environment can interact with nonlinear deep learning dynamics to give rise to these regularities.|sl:tag|tag:arxiv_doc
Poète|skos:broader|Ecrivain
WWW 2012|skos:broader|J'y étais
Missions spatiales|skos:broader|Exploration spatiale
Hierarchical Memory Networks  hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory Memory networks are neural networks with an explicit memory component that can be both read and written to by the network. The memory is often addressed in a soft way using a softmax function, making end-to-end training with backpropagation possible. However, this is not computationally scalable for applications which require the network to read from extremely large memories. On the other hand, it is well known that hard attention mechanisms based on reinforcement learning are challenging to train successfully. In this paper, we explore a form of hierarchical memory network, which can be considered as a hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory. Specifically, we propose to incorporate Maximum Inner Product Search (MIPS) in the training and inference procedures for our hierarchical memory network. We explore the use of various state-of-the art approximate MIPS techniques and report results on SimpleQuestions, a challenging large scale factoid question answering task.|sl:arxiv_author|Gerald Tesauro
data.gouv.fr|skos:broader|Gouvernement français
Wikipedia|skos:broader|Encyclopédie collaborative
Aldous Huxley|skos:broader|Ecrivain
Snorkel|skos:broader|Weak supervision
CommonTag|skos:broader|RDF/A
m2eclipse|skos:broader|Maven
LIME|skos:broader|AI black box
LDP|skos:broader|RW Linked Data
Iguane|skos:broader|Reptile
StarSpace: Embed All The Things! We present StarSpace, a general-purpose neural embedding model that can solve a wide variety of problems: labeling tasks such as text classification, ranking tasks such as information retrieval/web search, collaborative filtering-based or content-based recommendation, embedding of multi-relational graphs, and learning word, sentence or document level embeddings. In each case the model works by embedding those entities comprised of discrete features and comparing them against each other -- learning similarities dependent on the task. Empirical results on a number of tasks show that StarSpace is highly competitive with existing methods, whilst also being generally applicable to new cases where those methods are not.|sl:arxiv_author|Jason Weston
Corruption|skos:broader|Grands problèmes
Learning by Abstraction: The Neural State Machine  Given an image, we first predict a probabilistic graph  that represents its underlying semantics and serves as a structured world model.  Then, we perform sequential reasoning over the graph, iteratively traversing its  nodes to answer a given question or draw a new inference. In contrast to most  neural architectures that are designed to closely interact with the raw sensory  data, our model operates instead in an abstract latent space, by transforming both  the visual and linguistic modalities into semantic concept-based representations,  thereby achieving enhanced transparency and modularity.     Drawing inspiration from [Bengio’s consciousness prior](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1709.08568)... We introduce the Neural State Machine, seeking to bridge the gap between the neural and symbolic views of AI and integrate their complementary strengths for the task of visual reasoning. Given an image, we first predict a probabilistic graph that represents its underlying semantics and serves as a structured world model. Then, we perform sequential reasoning over the graph, iteratively traversing its nodes to answer a given question or draw a new inference. In contrast to most neural architectures that are designed to closely interact with the raw sensory data, our model operates instead in an abstract latent space, by transforming both the visual and linguistic modalities into semantic concept-based representations, thereby achieving enhanced transparency and modularity. We evaluate our model on VQA-CP and GQA, two recent VQA datasets that involve compositionality, multi-step inference and diverse reasoning skills, achieving state-of-the-art results in both cases. We provide further experiments that illustrate the model's strong generalization capacity across multiple dimensions, including novel compositions of concepts, changes in the answer distribution, and unseen linguistic structures, demonstrating the qualities and efficacy of our approach.|sl:tag|tag:nn_symbolic_ai_hybridation
Large scale distributed neural network training through online distillation   we use codistillation to refer to distillation performed:   1. using the same architecture for all the models;   2. using the same dataset to train all the models; and   3. using the distillation loss during training before any model has fully converged.     In general, we believe the quality gains of codistillation over well-tuned offline distillation will be  minor in practice and the more interesting research direction is exploring codistillation as a distributed  training algorithm     Codistillation with  the same data seems to be slightly better than the baseline, but codistillation using different data  gets much better results. These results show that the codistilling models are indeed successfully  transmitting useful information about different parts of the training data to each other.    Related to [Deep mutual learning](doc:2020/05/1706_00384_deep_mutual_learni) paper Techniques such as ensembling and distillation promise model quality improvements when paired with almost any base model. However, due to increased test-time cost (for ensembles) and increased complexity of the training pipeline (for distillation), these techniques are challenging to use in industrial settings. In this paper we explore a variant of distillation which is relatively straightforward to use as it does not require a complicated multi-stage setup or many new hyperparameters. Our first claim is that online distillation enables us to use extra parallelism to fit very large datasets about twice as fast. Crucially, we can still speed up training even after we have already reached the point at which additional parallelism provides no benefit for synchronous or asynchronous stochastic gradient descent. Two neural networks trained on disjoint subsets of the data can share knowledge by encouraging each model to agree with the predictions the other model would have made. These predictions can come from a stale version of the other model so they can be safely computed using weights that only rarely get transmitted. Our second claim is that online distillation is a cost-effective way to make the exact predictions of a model dramatically more reproducible. We support our claims using experiments on the Criteo Display Ad Challenge dataset, ImageNet, and the largest to-date dataset used for neural language modeling, containing $6\\times 10^{11}$ tokens and based on the Common Crawl repository of web data.|sl:tag|tag:ml_google
Docker-Volumes|skos:broader|Docker
Bitcoin|skos:broader|Cryptocurrency
Film|skos:broader|Cinéma
Eglise catholique|skos:broader|Catholicisme
Von Mises-Fisher Loss for Training Sequence to Sequence Models with Continuous Outputs predicting embeddings instead of word IDs (avoids a discrete softmax, using a new loss)    [@honnibal](https://twitter.com/honnibal/status/1073513114468081664)     The Softmax function is used in the final layer of nearly all existing sequence-to-sequence models for language generation. However, it is usually the slowest layer to compute which limits the vocabulary size to a subset of most frequent types; and it has a large memory footprint. We propose a general technique for replacing the softmax layer with a continuous embedding layer. Our primary innovations are a novel probabilistic loss, and a training and inference procedure in which we generate a probability distribution over pre-trained word embeddings, instead of a multinomial distribution over the vocabulary obtained via softmax. We evaluate this new class of sequence-to-sequence models with continuous outputs on the task of neural machine translation. We show that our models obtain upto 2.5x speed-up in training time while performing on par with the state-of-the-art models in terms of translation quality. These models are capable of handling very large vocabularies without compromising on translation quality. They also produce more meaningful errors than in the softmax-based models, as these errors typically lie in a subspace of the vector space of the reference translations.|sl:arxiv_author|Yulia Tsvetkov
ML Engineering|skos:broader|Machine learning
Querying Remote SPARQL Services|skos:broader|SPARQL
Antisémitisme|skos:broader|Racisme
Large Memory Layers with Product Keys  a structured memory which can be easily integrated into a neural network. The memory is very large by design and therefore significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time.     a key-value memory layer that can increase model capacity for a negligible computational cost. A 12-layer transformer with a memory outperforms a 24-layer transformer, and is 2x faster!     [Implementation](/doc/2019/08/product_key_memory_pkm_minima) This paper introduces a structured memory which can be easily integrated into a neural network. The memory is very large by design and significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time. This memory layer allows us to tackle very large scale language modeling tasks. In our experiments we consider a dataset with up to 30 billion words, and we plug our memory layer in a state-of-the-art transformer-based architecture. In particular, we found that a memory augmented model with only 12 layers outperforms a baseline transformer model with 24 layers, while being twice faster at inference time. We release our code for reproducibility purposes.|sl:tag|tag:memory_networks
Education and Linked Data|skos:broader|Technology Enhanced Learning
Recurrent Memory Networks for Language Modeling  Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge.     In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data.     We demonstrate the power of RMN on language modeling and sentence completion tasks.     On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.   Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge. In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data. We demonstrate the power of RMN on language modeling and sentence completion tasks. On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.|sl:arxiv_firstAuthor|Ke Tran
Portland (OR)|skos:broader|Oregon
iPod|skos:broader|Digital entertainment
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Nicolas Heess
Apache Spark|skos:broader|jma
OWL|skos:broader|Knowledge Representation
IJCAI|skos:broader|AI Conference
Stephen Wolfram|skos:broader|Technical girls and guys
IBM SPSS Text Analytics for Surveys|skos:broader|Survey analysis
Meaning in NLP|skos:broader|NLP tasks / problems
Large Memory Layers with Product Keys  a structured memory which can be easily integrated into a neural network. The memory is very large by design and therefore significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time.     a key-value memory layer that can increase model capacity for a negligible computational cost. A 12-layer transformer with a memory outperforms a 24-layer transformer, and is 2x faster!     [Implementation](/doc/2019/08/product_key_memory_pkm_minima) This paper introduces a structured memory which can be easily integrated into a neural network. The memory is very large by design and significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time. This memory layer allows us to tackle very large scale language modeling tasks. In our experiments we consider a dataset with up to 30 billion words, and we plug our memory layer in a state-of-the-art transformer-based architecture. In particular, we found that a memory augmented model with only 12 layers outperforms a baseline transformer model with 24 layers, while being twice faster at inference time. We release our code for reproducibility purposes.|sl:tag|tag:guillaume_lample
Norilsk|skos:broader|Pollution
Similarity Search for Efficient Active Learning and Search of Rare Concepts  Similarity search for Efficient Active Learning and Search (SEALS)    In [Active Learning](tag:active_learning): instead of searching globally for the optimal examples to label, leverage the fact that data is often heavily skewed and expand the candidate pool with the nearest neighbors of the labeled set.     Our work attacks both the labeling and computational costs of machine learning...SEALS dramatically reduces the barrier to machine learning, enabling small teams or individuals to  build accurate classifiers. SEALS does, however, introduce another system component, a similarity  search index, which adds some additional engineering complexity to build, tune, and maintain.  Fortunately, several highly optimized implementations like Annoy and [Faiss](doc:2020/06/facebookresearch_faiss_a_libra) work reasonably well  out of the box. Many active learning and search approaches are intractable for industrial settings with billions of unlabeled examples. Existing approaches, such as uncertainty sampling or information density, search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. However, in practice, data is often heavily skewed; only a small fraction of collected data will be relevant for a given learning task. For example, when identifying rare classes, detecting malicious content, or debugging model performance, the ratio of positive to negative examples can be 1 to 1,000 or more. In this work, we exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round by only looking at the nearest neighbors to the labeled examples. Empirically, we observe that learned representations effectively cluster unseen concepts, making active learning very effective and substantially reducing the number of viable unlabeled examples. We evaluate several active learning and search techniques in this setting on three large-scale datasets: ImageNet, Goodreads spoiler detection, and OpenImages. For rare classes, active learning methods need as little as 0.31% of the labeled data to match the average precision of full supervision. By limiting active learning methods to only consider the immediate neighbors of the labeled data as candidates for labeling, we need only process as little as 1% of the unlabeled data while achieving similar reductions in labeling costs as the traditional global approach. This process of expanding the candidate pool with the nearest neighbors of the labeled set can be done efficiently and reduces the computational complexity of selection by orders of magnitude.|sl:arxiv_author|Edward Chou
A Call for More Rigor in Unsupervised Cross-lingual Learning  a scenario without any parallel data and abundant monolingual data is unrealistic in practice We review motivations, definition, approaches, and methodology for unsupervised cross-lingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of the world's languages. However, we argue that a scenario without any parallel data and abundant monolingual data is unrealistic in practice. We also discuss different training signals that have been used in previous work, which depart from the pure unsupervised setting. We then describe common methodological issues in tuning and evaluation of unsupervised cross-lingual models and present best practices. Finally, we provide a unified outlook for different types of research in this area (i.e., cross-lingual word embeddings, deep multilingual pretraining, and unsupervised machine translation) and argue for comparable evaluation of these models.|sl:tag|tag:arxiv_doc
Mike Bergman|skos:broader|SW guys (and girls)
LDP|skos:broader|LD
Areva|skos:broader|Industrie nucléaire
R2RML|skos:broader|Database to RDF mapping
Flask|skos:broader|Python tools
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|Axel Polleres
Google Structured Data Testing Tool|skos:broader|Web tools
Document embeddings|skos:broader|Embeddings
Security and REST|skos:broader|REST
NTIC|skos:broader|Technologie
A Little Annotation does a Lot of Good: A Study in Bootstrapping Low-resource Named Entity Recognizers Most state-of-the-art models for named entity recognition (NER) rely on the availability of large amounts of labeled data, making them challenging to extend to new, lower-resourced languages. However, there are now several proposed approaches involving either cross-lingual transfer learning, which learns from other highly resourced languages, or active learning, which efficiently selects effective training data based on model predictions. This paper poses the question: given this recent progress, and limited human annotation, what is the most effective method for efficiently creating high-quality entity recognizers in under-resourced languages? Based on extensive experimentation using both simulated and real human annotation, we find a dual-strategy approach best, starting with a cross-lingual transferred model, then performing targeted annotation of only uncertain entity spans in the target language, minimizing annotator effort. Results demonstrate that cross-lingual transfer is a powerful tool when very little data can be annotated, but an entity-targeted annotation strategy can achieve competitive accuracy quickly, with just one-tenth of training data.|sl:tag|tag:named_entity_recognition
Fado tropical|skos:broader|Chanson
The HSIC Bottleneck: Deep Learning without Back-Propagation  we show that it is possible to learn classification tasks at near competitive accuracy without  backpropagation, by maximizing a surrogate of the mutual information between hidden representations and labels and  simultaneously minimizing the mutual dependency between hidden representations and the inputs...  the hidden units of a network trained in this way form useful representations. Specifically, fully competitive accuracy  can be obtained by freezing the network trained without backpropagation and appending and training a one-layer  network using conventional SGD to convert convert the representation to the desired format.    The training method uses an approximation of the [#information bottleneck](/tag/information_bottleneck_method).    Advantages:     - The method facilitates parallel processing and requires significantly less operations.    - It does not suffer from exploding or vanishing gradients.   - It is biologically more plausible than Backpropagation     We introduce the HSIC (Hilbert-Schmidt independence criterion) bottleneck for training deep neural networks. The HSIC bottleneck is an alternative to the conventional cross-entropy loss and backpropagation that has a number of distinct advantages. It mitigates exploding and vanishing gradients, resulting in the ability to learn very deep networks without skip connections. There is no requirement for symmetric feedback or update locking. We find that the HSIC bottleneck provides performance on MNIST/FashionMNIST/CIFAR10 classification comparable to backpropagation with a cross-entropy target, even when the system is not encouraged to make the output resemble the classification labels. Appending a single layer trained with SGD (without backpropagation) to reformat the information further improves performance.|sl:tag|tag:information_bottleneck_method
Recommender Systems|skos:broader|Machine learning: problems
Jiroft|skos:broader|Antiquité iranienne
Supraconductivité|skos:broader|Mécanique quantique
fastai: A Layered API for Deep Learning Paper describing the fast.ai v2 API fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes: a new type dispatch system for Python along with a semantic type hierarchy for tensors; a GPU-optimized computer vision library which can be extended in pure Python; an optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 4-5 lines of code; a novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training; a new data block API; and much more. We have used this library to successfully create a complete deep learning course, which we were able to write more quickly than using previous approaches, and the code was more clear. The library is already in wide use in research, industry, and teaching. NB: This paper covers fastai v2, which is currently in pre-release at http://dev.fast.ai/|sl:tag|tag:jeremy_howard
Stanbol|skos:broader|Interactive Knowledge Stack
Blogs Le Monde|skos:broader|Journal Le Monde
Jean-Paul Cardinal|skos:broader|Mathématicien
Mladic|skos:broader|Guerre de Yougoslavie
Paradoxe Einstein-Podolsky-Rosen|skos:broader|Photons corrélés
AutoML-Zero: Evolving Machine Learning Algorithms From Scratch  Fun AutoML-Zero experiments: Evolutionary search discovers fundamental ML algorithms from scratch, e.g., small neural nets with backprop.   Can evolution be the “Master Algorithm”? ;) Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.|sl:arxiv_author|Esteban Real
Écologie|skos:broader|Nature
Nike|skos:broader|Entreprise
Joint Embedding of Hierarchical Categories and Entities for Concept Categorization and Dataless Classification a framework that embeds entities and categories into a semantic space by integrating structured  knowledge and taxonomy hierarchy from large knowledge bases.    two methods:    1. Category Embedding model): it replaces the entities in the context with their directly  labeled categories to build categories’ context;   2. Hierarchical Category Embedding: it  further incorporates all ancestor categories of the context entities to utilize the hierarchical information. Due to the lack of structured knowledge applied in learning distributed representation of cate- gories, existing work cannot incorporate category hierarchies into entity information. We propose a framework that embeds entities and categories into a semantic space by integrating structured knowledge and taxonomy hierarchy from large knowledge bases. The framework allows to com- pute meaningful semantic relatedness between entities and categories. Our framework can han- dle both single-word concepts and multiple-word concepts with superior performance on concept categorization and yield state of the art results on dataless hierarchical classification.|sl:arxiv_author|Yuezhang Li
Saturne|skos:broader|Système solaire
OwlSight|skos:broader|Clark and Parsia
Makolab Semantic Day|skos:broader|Makolab
Neural Architectures for Named Entity Recognition Neural architectures for NER that use no language-specific resources or features beyond a small amount of supervised training data and unlabeled corpora.      Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.|sl:tag|tag:nlp_facebook
A Little Annotation does a Lot of Good: A Study in Bootstrapping Low-resource Named Entity Recognizers Most state-of-the-art models for named entity recognition (NER) rely on the availability of large amounts of labeled data, making them challenging to extend to new, lower-resourced languages. However, there are now several proposed approaches involving either cross-lingual transfer learning, which learns from other highly resourced languages, or active learning, which efficiently selects effective training data based on model predictions. This paper poses the question: given this recent progress, and limited human annotation, what is the most effective method for efficiently creating high-quality entity recognizers in under-resourced languages? Based on extensive experimentation using both simulated and real human annotation, we find a dual-strategy approach best, starting with a cross-lingual transferred model, then performing targeted annotation of only uncertain entity spans in the target language, minimizing annotator effort. Results demonstrate that cross-lingual transfer is a powerful tool when very little data can be annotated, but an entity-targeted annotation strategy can achieve competitive accuracy quickly, with just one-tenth of training data.|sl:tag|tag:arxiv_doc
RAKE|skos:broader|Python-NLP
KGAT: Knowledge Graph Attention Network for Recommendation To provide more accurate, diverse, and explainable recommendation, it is compulsory to go beyond modeling user-item interactions and take side information into account. Traditional methods like factorization machine (FM) cast it as a supervised learning problem, which assumes each interaction as an independent instance with side information encoded. Due to the overlook of the relations among instances or items (e.g., the director of a movie is also an actor of another movie), these methods are insufficient to distill the collaborative signal from the collective behaviors of users. In this work, we investigate the utility of knowledge graph (KG), which breaks down the independent interaction assumption by linking items with their attributes. We argue that in such a hybrid structure of KG and user-item graph, high-order relations --- which connect two items with one or multiple linked attributes --- are an essential factor for successful recommendation. We propose a new method named Knowledge Graph Attention Network (KGAT) which explicitly models the high-order connectivities in KG in an end-to-end fashion. It recursively propagates the embeddings from a node's neighbors (which can be users, items, or attributes) to refine the node's embedding, and employs an attention mechanism to discriminate the importance of the neighbors. Our KGAT is conceptually advantageous to existing KG-based recommendation methods, which either exploit high-order relations by extracting paths or implicitly modeling them with regularization. Empirical results on three public benchmarks show that KGAT significantly outperforms state-of-the-art methods like Neural FM and RippleNet. Further studies verify the efficacy of embedding propagation for high-order relation modeling and the interpretability benefits brought by the attention mechanism.|sl:tag|tag:recommender_systems
Primate|skos:broader|Animal
Amour|skos:broader|Sentiment
AI risks|skos:broader|IA AI
KnowBert|skos:broader|Contextualized word representations
RDA|skos:broader|Communisme
Social bookmarking|skos:broader|Tagging
Scandinavie|skos:broader|Europe
Markets are efficient if and only if P = NP Hmm wow I prove that if markets are weak-form efficient, meaning current prices fully reflect all information available in past prices, then P = NP, meaning every computational problem whose solution can be verified in polynomial time can also be solved in polynomial time. I also prove the converse by showing how we can program the market to solve NP-complete problems. Since P probably does not equal NP, markets are probably not efficient. Specifically, markets become increasingly inefficient as the time series lengthens or becomes more frequent. An illustration by way of partitioning the excess returns to momentum strategies based on data availability confirms this prediction.|sl:arxiv_firstAuthor|Philip Maymin
Knowledge Graphs and NLP|skos:broader|AI + Knowledge Bases
Déforestation|skos:broader|Écologie
EC-Web'14|skos:broader|EC-Web
Civilisations précolombiennes|skos:broader|Amérindien
Emerging Cross-lingual Structure in Pretrained Language Models We study the problem of multilingual masked language modeling, i.e. the training of a single model on concatenated text from multiple languages, and present a detailed study of several factors that influence why these models are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from independently trained models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these symmetries seem to be automatically discovered and aligned during the joint training process.|sl:tag|tag:bertology
ATerm|skos:broader|Dev tools
Coursera: NLP class|skos:broader|Stanford
Patent|skos:broader|Propriété intellectuelle
JavaScript librairies|skos:broader|Web dev framework
Neo4j|skos:broader|Graph database
Censure et maltraitance animale|skos:broader|Animal rights
Femme célèbre (où qui mérite de l'être)|skos:broader|Femme
Musique du Niger|skos:broader|Niger
Category Embedding|skos:broader|Entity embeddings
Bag of Tricks for Efficient Text Classification A simple and efficient baseline for text classification.     Our word features can  be averaged together to form good sentence representations.    Our experiments show that fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.   This paper explores a simple and efficient baseline for text classification. Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.|sl:tag|tag:sentence_embeddings
The Case for Learned Index Structures  we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs  Indexes are models: a B-Tree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term learned indexes. The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show, that by using neural nets we are able to outperform cache-optimized B-Trees by up to 70% in speed while saving an order-of-magnitude in memory over several real-world data sets. More importantly though, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work just provides a glimpse of what might be possible.|sl:arxiv_author|Tim Kraska
GitHub project|skos:broader|GitHub
Mussolini|skos:broader|Dictature
Google Web Toolkit|skos:broader|JavaScript librairies
Pre-training via Paraphrasing We introduce MARGE, a pre-trained sequence-to-sequence model learned with an unsupervised multi-lingual multi-document paraphrasing objective. MARGE provides an alternative to the dominant masked language modeling paradigm, where we self-supervise the reconstruction of target text by retrieving a set of related texts (in many languages) and conditioning on them to maximize the likelihood of generating the original. We show it is possible to jointly learn to do retrieval and reconstruction, given only a random initialization. The objective noisily captures aspects of paraphrase, translation, multi-document summarization, and information retrieval, allowing for strong zero-shot performance on several tasks. For example, with no additional task-specific training we achieve BLEU scores of up to 35.8 for document translation. We further show that fine-tuning gives strong performance on a range of discriminative and generative tasks in many languages, making MARGE the most generally applicable pre-training method to date.|sl:arxiv_author|Marjan Ghazvininejad
Large Memory Layers with Product Keys  a structured memory which can be easily integrated into a neural network. The memory is very large by design and therefore significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time.     a key-value memory layer that can increase model capacity for a negligible computational cost. A 12-layer transformer with a memory outperforms a 24-layer transformer, and is 2x faster!     [Implementation](/doc/2019/08/product_key_memory_pkm_minima) This paper introduces a structured memory which can be easily integrated into a neural network. The memory is very large by design and significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time. This memory layer allows us to tackle very large scale language modeling tasks. In our experiments we consider a dataset with up to 30 billion words, and we plug our memory layer in a state-of-the-art transformer-based architecture. In particular, we found that a memory augmented model with only 12 layers outperforms a baseline transformer model with 24 layers, while being twice faster at inference time. We release our code for reproducibility purposes.|sl:arxiv_author|Ludovic Denoyer
Towards a Seamless Integration of Word Senses into Downstream NLP Applications Lexical ambiguity can impede NLP systems from accurate understanding of semantics. Despite its potential benefits, the integration of sense-level information into NLP systems has remained understudied. By incorporating a novel disambiguation algorithm into a state-of-the-art classification model, we create a pipeline to integrate sense-level information into downstream NLP applications. We show that a simple disambiguation of the input text can lead to consistent performance improvement on multiple topic categorization and polarity detection datasets, particularly when the fine granularity of the underlying sense inventory is reduced and the document is sufficiently large. Our results also point to the need for sense representation research to focus more on in vivo evaluations which target the performance in downstream NLP applications rather than artificial benchmarks.|sl:arxiv_firstAuthor|Mohammad Taher Pilehvar
Covid19|skos:broader|Virus
Representation learning for very short texts using weighted word embedding aggregation A method based on word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. a href=https://github.com/cedricdeboom/RepresentationLearningGithub/a (hmm...) (python code)     Short text messages such as tweets are very noisy and sparse in their use of vocabulary. Traditional textual representations, such as tf-idf, have difficulty grasping the semantic meaning of such texts, which is important in applications such as event detection, opinion mining, news recommendation, etc. We constructed a method based on semantic word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. For this purpose we designed a weight-based model and a learning procedure based on a novel median-based loss function. This paper discusses the details of our model and the optimization methods, together with the experimental results on both Wikipedia and Twitter data. We find that our method outperforms the baseline approaches in the experiments, and that it generalizes well on different word embeddings without retraining. Our method is therefore capable of retaining most of the semantic information in the text, and is applicable out-of-the-box.|sl:arxiv_author|Cedric De Boom
Docker-Python|skos:broader|Docker
Plantation d'arbres|skos:broader|Arbres
Categorical Metadata Representation for Customized Text Classification  We observe that current representation methods for categorical metadata... are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category The performance of text classification has improved tremendously using intelligently engineered neural-based models, especially those injecting categorical metadata as additional information, e.g., using user/product information for sentiment classification. These information have been used to modify parts of the model (e.g., word embeddings, attention mechanisms) such that results can be customized according to the metadata. We observe that current representation methods for categorical metadata, which are devised for human consumption, are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category, and even such context is often scarce (for tail category). To this end, we propose to use basis vectors to effectively incorporate categorical metadata on various parts of a neural-based model. This additionally decreases the number of parameters dramatically, especially when the number of categorical features is large. Extensive experiments on various datasets with different properties are performed and show that through our method, we can represent categorical metadata more effectively to customize parts of the model, including unexplored ones, and increase the performance of the model greatly.|sl:tag|tag:nlp_text_classification
Caroline Fourest|skos:broader|Journaliste
Information theory AND Deep Learning|skos:broader|Information theory
C2GWeb and Product description|skos:broader|Product description
Génétique + Histoire|skos:broader|ADN
Attention mechanism|skos:broader|Deep Learning
Attention Is All You Need  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.|sl:arxiv_author|Illia Polosukhin
Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus.     In practice, some questions are best answered  using text, while others are best answered using  KBs. A natural question, then, is how to effectively  combine both types of information. Surprisingly  little prior work has looked at this problem. Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting. Source code is available at https://github.com/OceanskySun/GraftNet .|sl:tag|tag:ruslan_salakhutdinov
ERNIE: Enhanced Language Representation with Informative Entities  We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.|sl:tag|tag:arxiv_doc
Google Cloud|skos:broader|Google
Philosophe|skos:broader|Philosophie
Google Rich Snippets|skos:broader|SEO
A mathematical theory of semantic development in deep neural networks  a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences?   An extensive body of empirical research has revealed remarkable regularities in the acquisition, organization, deployment, and neural representation of human semantic knowledge, thereby raising a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences? We address this question by mathematically analyzing the nonlinear dynamics of learning in deep linear networks. We find exact solutions to this learning dynamics that yield a conceptual explanation for the prevalence of many disparate phenomena in semantic cognition, including the hierarchical differentiation of concepts through rapid developmental transitions, the ubiquity of semantic illusions between such transitions, the emergence of item typicality and category coherence as factors controlling the speed of semantic processing, changing patterns of inductive projection over development, and the conservation of semantic similarity in neural representations across species. Thus, surprisingly, our simple neural model qualitatively recapitulates many diverse regularities underlying semantic development, while providing analytic insight into how the statistical structure of an environment can interact with nonlinear deep learning dynamics to give rise to these regularities.|sl:arxiv_author|Surya Ganguli
Thucydide|skos:broader|Historien
Cafard|skos:broader|Insecte
Cosmologie|skos:broader|Science
Amazon Alexa|skos:broader|Enceintes connectées
Antiquité de l'Inde|skos:broader|Inde
Introduced in the early 1990s by Bromley and LeCun to solve signature verification as an image matching problem|skos:broader|The goal is to learn from examples a similarity function that measures how similar or related two objects are.    Distance metric learning: the task of learning a distance function over objects consistent with a notion of similarity.     Distance metric learning is a major tool for a variety  of problems in computer vision. It has successfully  been employed for image retrieval, near duplicate detection, clustering and zero-shot learning. ([src](doc/2020/02/_1703_07464_no_fuss_distance_m))
Neural Ranking Models with Weak Supervision Main Idea: To leverage large amounts of unsupervised data to infer “weak” labels and use that signal for learning supervised models as if we had the ground truth labels. See [blog post](/doc/?uri=http%3A%2F%2Fmostafadehghani.com%2F2017%2F04%2F23%2Fbeating-the-teacher-neural-ranking-models-with-weak-supervision%2F):     This is truly awesome since we have only used  BM25 as the supervisor to train a model which performs better than BM25 itself!   Despite the impressive improvements achieved by unsupervised deep neural networks in computer vision and NLP tasks, such improvements have not yet been observed in ranking for information retrieval. The reason may be the complexity of the ranking problem, as it is not obvious how to learn from queries and documents when no supervised signal is available. Hence, in this paper, we propose to train a neural ranking model using weak supervision, where labels are obtained automatically without human annotators or any external resources (e.g., click data). To this aim, we use the output of an unsupervised ranking model, such as BM25, as a weak supervision signal. We further train a set of simple yet effective ranking models based on feed-forward neural networks. We study their effectiveness under various learning scenarios (point-wise and pair-wise models) and using different input representations (i.e., from encoding query-document pairs into dense/sparse vectors to using word embedding representation). We train our networks using tens of millions of training instances and evaluate it on two standard collections: a homogeneous news collection(Robust) and a heterogeneous large-scale web collection (ClueWeb). Our experiments indicate that employing proper objective functions and letting the networks to learn the input representation based on weakly supervised data leads to impressive performance, with over 13% and 35% MAP improvements over the BM25 model on the Robust and the ClueWeb collections. Our findings also suggest that supervised neural ranking models can greatly benefit from pre-training on large amounts of weakly labeled data that can be easily obtained from unsupervised IR models.|sl:arxiv_author|W. Bruce Croft
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:arxiv_author|Aleksandr Nisnevich
Chine / Afrique|skos:broader|Chine
Fado tropical|skos:broader|Poésie
Google Patents|skos:broader|Patent finding
Semantic indexing|skos:broader|Semantic Web
Word2Bits - Quantized Word Vectors We show that high quality quantized word vectors using 1-2 bits per parameter can be learned by introducing a quantization function into Word2Vec. We furthermore show that training with the quantization function acts as a regularizer Word vectors require significant amounts of memory and storage, posing issues to resource limited devices like mobile phones and GPUs. We show that high quality quantized word vectors using 1-2 bits per parameter can be learned by introducing a quantization function into Word2Vec. We furthermore show that training with the quantization function acts as a regularizer. We train word vectors on English Wikipedia (2017) and evaluate them on standard word similarity and analogy tasks and on question answering (SQuAD). Our quantized word vectors not only take 8-16x less space than full precision (32 bit) word vectors but also outperform them on word similarity tasks and question answering.|sl:arxiv_firstAuthor|Maximilian Lam
Deep Learning and the Information Bottleneck Principle  Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN.   Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.|sl:tag|tag:naftali_tishby
Lobby nucléaire|skos:broader|Industrie nucléaire
AI: startups|skos:broader|Startups
Maroc|skos:broader|Afrique du Nord
Replace or Retrieve Keywords In Documents at Scale For a document of size N (characters) and a dictionary of M keywords, the time complexity is O(N) (compared to O(MxN) with regex). FlashText is designed to only match complete words (words with boundary characters on both sides). Different from Aho Corasick Algorithm, as it doesn't match substrings. This algorithm is also designed to go for the longest match first. For an input dictionary {Machine, Learning, Machine learning} on a string 'I like Machine learning', it will only consider the longest match, which is Machine Learning    [Github](https://github.com/vi3k6i5/flashtext) In this paper we introduce, the FlashText algorithm for replacing keywords or finding keywords in a given text. FlashText can search or replace keywords in one pass over a document. The time complexity of this algorithm is not dependent on the number of terms being searched or replaced. For a document of size N (characters) and a dictionary of M keywords, the time complexity will be O(N). This algorithm is much faster than Regex, because regex time complexity is O(MxN). It is also different from Aho Corasick Algorithm, as it doesn't match substrings. FlashText is designed to only match complete words (words with boundary characters on both sides). For an input dictionary of {Apple}, this algorithm won't match it to 'I like Pineapple'. This algorithm is also designed to go for the longest match first. For an input dictionary {Machine, Learning, Machine learning} on a string 'I like Machine learning', it will only consider the longest match, which is Machine Learning. We have made python implementation of this algorithm available as open-source on GitHub, released under the permissive MIT License.|sl:tag|tag:arxiv_doc
Recurrent Memory Networks for Language Modeling  Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge.     In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data.     We demonstrate the power of RMN on language modeling and sentence completion tasks.     On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.   Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge. In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data. We demonstrate the power of RMN on language modeling and sentence completion tasks. On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.|sl:tag|tag:rnn_based_language_model
Hierarchical tags|skos:broader|Tagging
sindice|skos:broader|Linking Open Data
semantic-web@w3.org|skos:broader|Semantic Web
Concise Bounded Description|skos:broader|SPARQL
Économie écologique|skos:broader|Economie
SPARQL Demo|skos:broader|SW demo
Vint Cerf|skos:broader|Technical girls and guys
The Description Length of Deep Learning Models  Solomonoff’s general theory of inference (Solomonoff, 1964) and the [Minimum Description Length Principle](tag:minimum_description_length_principle) (Grünwald, 2007; Rissanen, 2007) formalize [Occam's razor](tag:occam_s_razor), and hold that a good model of data is a model that is good at losslessly  compressing the data, including the cost of describing the model itself. Deep neural  networks might seem to go against this principle given the large number of  parameters to be encoded.  We demonstrate experimentally the ability of deep neural networks to compress  the training data even when accounting for parameter encoding. Solomonoff's general theory of inference and the Minimum Description Length principle formalize Occam's razor, and hold that a good model of data is a model that is good at losslessly compressing the data, including the cost of describing the model itself. Deep neural networks might seem to go against this principle given the large number of parameters to be encoded. We demonstrate experimentally the ability of deep neural networks to compress the training data even when accounting for parameter encoding. The compression viewpoint originally motivated the use of variational methods in neural networks. Unexpectedly, we found that these variational methods provide surprisingly poor compression bounds, despite being explicitly built to minimize such bounds. This might explain the relatively poor practical performance of variational methods in deep learning. On the other hand, simple incremental encoding methods yield excellent compression values on deep networks, vindicating Solomonoff's approach.|sl:tag|tag:normale_sup
Astrophysique|skos:broader|Science
HTTP|skos:broader|Internet
Large deviations for the perceptron model and consequences for active learning the task of choosing the subset of samples to be labeled from a fixed finite pool of samples Active learning is a branch of machine learning that deals with problems where unlabeled data is abundant yet obtaining labels is expensive. The learning algorithm has the possibility of querying a limited number of samples to obtain the corresponding labels, subsequently used for supervised learning. In this work, we consider the task of choosing the subset of samples to be labeled from a fixed finite pool of samples. We assume the pool of samples to be a random matrix and the ground truth labels to be generated by a single-layer teacher random neural network. We employ replica methods to analyze the large deviations for the accuracy achieved after supervised learning on a subset of the original pool. These large deviations then provide optimal achievable performance boundaries for any active learning algorithm. We show that the optimal learning performance can be efficiently approached by simple message-passing active learning algorithms. We also provide a comparison with the performance of some other popular active learning strategies.|sl:arxiv_author|Luca Saglietti
Dinosaures|skos:broader|Paléontologie
Real-Time Communications|skos:broader|Real-Time
Solid|skos:broader|Linked Data: application
IRD|skos:broader|Zones intertropicales
Harry Halpin|skos:broader|Technical girls and guys
Amazon|skos:broader|Entreprise
Chimie|skos:broader|Science
Knowledge Graphs|skos:broader|Knowledge bases
Learning Semantic Similarity for Very Short Texts In order to pair short text  fragments—as a concatenation of separate words—an adequate  distributed sentence representation is needed. Main contribution: a first step towards a hybrid method that  combines the strength of dense distributed representations—  as opposed to sparse term matching—with the strength of  tf-idf based methods. The combination of word embeddings and tf-idf  information might lead to a better model for semantic content  within very short text fragments. Levering data on social media, such as Twitter and Facebook, requires information retrieval algorithms to become able to relate very short text fragments to each other. Traditional text similarity methods such as tf-idf cosine-similarity, based on word overlap, mostly fail to produce good results in this case, since word overlap is little or non-existent. Recently, distributed word representations, or word embeddings, have been shown to successfully allow words to match on the semantic level. In order to pair short text fragments - as a concatenation of separate words - an adequate distributed sentence representation is needed, in existing literature often obtained by naively combining the individual word representations. We therefore investigated several text representations as a combination of word embeddings in the context of semantic pair matching. This paper investigates the effectiveness of several such naive techniques, as well as traditional tf-idf similarity, for fragments of different lengths. Our main contribution is a first step towards a hybrid method that combines the strength of dense distributed representations - as opposed to sparse term matching - with the strength of tf-idf based methods to automatically reduce the impact of less informative terms. Our new approach outperforms the existing techniques in a toy experimental set-up, leading to the conclusion that the combination of word embeddings and tf-idf information might lead to a better model for semantic content within very short text fragments.|sl:arxiv_firstAuthor|Cedric De Boom
predicting a single label among mutually exclusive labels.|skos:broader|the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations whose category membership is known.
One-Shot Generalization in Deep Generative Models Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our models are able to generate compelling and diverse samples---having seen new examples just once---providing an important class of general-purpose models for one-shot machine learning.|sl:arxiv_author|Daan Wierstra
SparqlPress|skos:broader|SPARQL
Towards Understanding Linear Word Analogies A surprising property of word vectors is that word analogies can often be solved with vector arithmetic. However, it is unclear why arithmetic operators correspond to non-linear embedding models such as skip-gram with negative sampling (SGNS). We provide a formal explanation of this phenomenon without making the strong assumptions that past theories have made about the vector space and word distribution. Our theory has several implications. Past work has conjectured that linear substructures exist in vector spaces because relations can be represented as ratios; we prove that this holds for SGNS. We provide novel justification for the addition of SGNS word vectors by showing that it automatically down-weights the more frequent word, as weighting schemes do ad hoc. Lastly, we offer an information theoretic interpretation of Euclidean distance in vector spaces, justifying its use in capturing word dissimilarity.|sl:arxiv_author|Kawin Ethayarajh
Genome editing|skos:broader|Gene editing
Chine : écologie|skos:broader|Chine
Espace|skos:broader|Astronomie
Pangloss: Fast Entity Linking in Noisy Text Environments a production system for entity disambiguation on messy tex, based  on probabilistic tokenization and context-dependent document embeddings    Probabilistic tokenization: uses the method described [here](/doc/2019/07/mining_quality_phrases_from_mas) Entity linking is the task of mapping potentially ambiguous terms in text to their constituent entities in a knowledge base like Wikipedia. This is useful for organizing content, extracting structured data from textual documents, and in machine learning relevance applications like semantic search, knowledge graph construction, and question answering. Traditionally, this work has focused on text that has been well-formed, like news articles, but in common real world datasets such as messaging, resumes, or short-form social media, non-grammatical, loosely-structured text adds a new dimension to this problem. This paper presents Pangloss, a production system for entity disambiguation on noisy text. Pangloss combines a probabilistic linear-time key phrase identification algorithm with a semantic similarity engine based on context-dependent document embeddings to achieve better than state-of-the-art results (5% in F1) compared to other research or commercially available systems. In addition, Pangloss leverages a local embedded database with a tiered architecture to house its statistics and metadata, which allows rapid disambiguation in streaming contexts and on-device disambiguation in low-memory environments such as mobile phones.|sl:tag|tag:entity_linking
Linked Data / collaborative editing|skos:broader|Collaborative editing
XLNet: Generalized Autoregressive Pretraining for Language Understanding a new pretraining method for NLP that significantly improves upon BERT on 20 tasks (e.g., SQuAD, GLUE, RACE) With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.|sl:tag|tag:xlnet
Voyager|skos:broader|Exploit
Ecrivain|skos:broader|Littérature
Virus|skos:broader|Biology
Un ivrogne dans la brousse|skos:broader|Littérature africaine
Semantic Web: Life Sciences|skos:broader|Semantic web : Use cases
CoKE: Contextualized Knowledge Graph Embedding A method to build contextualized entity and relation embeddings. Entities and relations may appear in different graph contexts. Edges and paths, both formulated as sequences of entities and relations, are passed as input to a Transformer encoder to learn the contextualized representations..    [Github](https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE) Knowledge graph embedding, which projects symbolic entities and relations into continuous vector spaces, is gaining increasing attention. Previous methods allow a single static embedding for each entity or relation, ignoring their intrinsic contextual nature, i.e., entities and relations may appear in different graph contexts, and accordingly, exhibit different properties. This work presents Contextualized Knowledge Graph Embedding (CoKE), a novel paradigm that takes into account such contextual nature, and learns dynamic, flexible, and fully contextualized entity and relation embeddings. Two types of graph contexts are studied: edges and paths, both formulated as sequences of entities and relations. CoKE takes a sequence as input and uses a Transformer encoder to obtain contextualized representations. These representations are hence naturally adaptive to the input, capturing contextual meanings of entities and relations therein. Evaluation on a wide variety of public benchmarks verifies the superiority of CoKE in link prediction and path query answering. It performs consistently better than, or at least equally well as current state-of-the-art in almost every case, in particular offering an absolute improvement of 21.0% in H@10 on path query answering. Our code is available at \\url{https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE}.|sl:arxiv_firstAuthor|Quan Wang
Knowledge Graph KG|skos:broader|KR
Semanlink|skos:broader|Favoris
Universal Language Model Fine-tuning for Text Classification code is available in the fastai lib    [blog post](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html)    [see also](/doc/?uri=https%3A%2F%2Fyashuseth.blog%2F2018%2F06%2F17%2Funderstanding-universal-language-model-fine-tuning-ulmfit%2F)             Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.|sl:tag|tag:good
Multi-language support|skos:broader|Language
Automating the search for a patent's prior art with a full text similarity search [github](https://github.com/helmersl/patent_similarity_search)    mouais     More than ever, technical inventions are the symbol of our society's advance. Patents guarantee their creators protection against infringement. For an invention being patentable, its novelty and inventiveness have to be assessed. Therefore, a search for published work that describes similar inventions to a given patent application needs to be performed. Currently, this so-called search for prior art is executed with semi-automatically composed keyword queries, which is not only time consuming, but also prone to errors. In particular, errors may systematically arise by the fact that different keywords for the same technical concepts may exist across disciplines. In this paper, a novel approach is proposed, where the full text of a given patent application is compared to existing patents using machine learning and natural language processing techniques to automatically detect inventions that are similar to the one described in the submitted document. Various state-of-the-art approaches for feature extraction and document comparison are evaluated. In addition to that, the quality of the current search process is assessed based on ratings of a domain expert. The evaluation results show that our automated approach, besides accelerating the search process, also improves the search results for prior art with respect to their quality.|sl:arxiv_firstAuthor|Lea Helmers
Musicien|skos:broader|Musique
Stacked Approximated Regression Machine: A Simple Deep Learning Approach This paper seems too good to be true! They can train a VGG-like net VERY quickly to good accuracy, without backprop. With the agreement of my coauthors, I Zhangyang Wang would like to withdraw the manuscript Stacked Approximated Regression Machine: A Simple Deep Learning Approach. Some experimental procedures were not included in the manuscript, which makes a part of important claims not meaningful. In the relevant research, I was solely responsible for carrying out the experiments; the other coauthors joined in the discussions leading to the main algorithm. Please see the updated text for more details.|sl:arxiv_author|Shuai Huang
Self-Taught Hashing for Fast Similarity Search Emphasise following issue in Semantic Hashing: obtaining the codes for previously unseen documents. Propose following approach:  first find the optimal l-bit binary codes for all documents in  the given corpus via unsupervised learning, then train  l classifiers via supervised learning to predict the l-bit code  for any query document unseen before.    (méthode résumée [ici](https://www.semanticscholar.org/paper/Semantic-hashing-using-tags-and-topic-modeling-Wang-Zhang/1a0f660f70fd179003edc271694736baaa39dec4))       The ability of fast similarity search at large scale is of great importance to many Information Retrieval (IR) applications. A promising way to accelerate similarity search is semantic hashing which designs compact binary codes for a large number of documents so that semantically similar documents are mapped to similar codes (within a short Hamming distance). Although some recently proposed techniques are able to generate high-quality codes for documents known in advance, obtaining the codes for previously unseen documents remains to be a very challenging problem. In this paper, we emphasise this issue and propose a novel Self-Taught Hashing (STH) approach to semantic hashing: we first find the optimal $l$-bit binary codes for all documents in the given corpus via unsupervised learning, and then train $l$ classifiers via supervised learning to predict the $l$-bit code for any query document unseen before. Our experiments on three real-world text datasets show that the proposed approach using binarised Laplacian Eigenmap (LapEig) and linear Support Vector Machine (SVM) outperforms state-of-the-art techniques significantly.|sl:tag|tag:arxiv_doc
Bidirectional LSTM-CRF Models for Sequence Tagging In this paper, we propose a variety of Long Short-Term Memory (LSTM) based models for sequence tagging. These models include LSTM networks, bidirectional LSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer (LSTM-CRF) and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work is the first to apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model to NLP benchmark sequence tagging data sets. We show that the BI-LSTM-CRF model can efficiently use both past and future input features thanks to a bidirectional LSTM component. It can also use sentence level tag information thanks to a CRF layer. The BI-LSTM-CRF model can produce state of the art (or close to) accuracy on POS, chunking and NER data sets. In addition, it is robust and has less dependence on word embedding as compared to previous observations.|sl:tag|tag:sequence_labeling
Richard Stallman|skos:broader|Logiciel libre
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|Anisa Rula
Data mining tools|skos:broader|Data mining
spaCy|skos:broader|Python-NLP
Zika|skos:broader|Maladie
Einstein|skos:broader|Physicien
Egypte antique|skos:broader|Egypte
RapidMiner|skos:broader|NLP tools
Inference|skos:broader|Artificial Intelligence
NLP: use cases|skos:broader|NLP
RDF vs XML|skos:broader|RDF
TF1|skos:broader|Télévision
Bio inspired computing devices|skos:broader|Nous vivons une époque moderne
Capitalisme|skos:broader|Economie
Unifying distillation and privileged information A framework to learn from multiple machines and data representations, unifying two techniques that enable machines to learn from other machines: [distillation](tag:knowledge_distillation) ([Hinton et al., 2015](doc:2020/04/1503_02531_distilling_the_kno)) and privileged information (Vapnik & Izmailov, 2015)   Distillation (Hinton et al., 2015) and privileged information (Vapnik & Izmailov, 2015) are two techniques that enable machines to learn from other machines. This paper unifies these two techniques into generalized distillation, a framework to learn from multiple machines and data representations. We provide theoretical and causal insight about the inner workings of generalized distillation, extend it to unsupervised, semisupervised and multitask learning scenarios, and illustrate its efficacy on a variety of numerical simulations on both synthetic and real-world data.|sl:arxiv_author|Léon Bottou
Text processing|skos:broader|NLP techniques
Word embeddings with lexical resources|skos:broader|Word embeddings
Reporters sans frontières|skos:broader|Liberté de la presse
Fukushima|skos:broader|Catastrophe industrielle
Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation   An embedding method specifically designed for NED that jointly maps words and entities into the same continuous vector space.    We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words Named Entity Disambiguation (NED) refers to the task of resolving multiple named entity mentions in a document to their correct references in a knowledge base (KB) (e.g., Wikipedia). In this paper, we propose a novel embedding method specifically designed for NED. The proposed method jointly maps words and entities into the same continuous vector space. We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words. By combining contexts based on the proposed embedding with standard NED features, we achieved state-of-the-art accuracy of 93.1% on the standard CoNLL dataset and 85.2% on the TAC 2010 dataset.|sl:tag|tag:named_entity_recognition
Facts as Experts: Adaptable and Interpretable Neural Memory over Symbolic Knowledge  a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge.... The model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones.     a  neural language model which learns to access information  in a symbolic knowledge graph.     This  model builds on the recently-proposed [Entities as  Experts](doc:2020/07/2004_07202_entities_as_expert) (EaE) language model (Févry et al., 2020),  which extends the same transformer (Vaswani  et al., 2017) architecture of BERT (Devlin et al., 2019) with an additional external memory for entities.     After training EaE, the embedding associated  with an entity will (ideally) capture information  about the textual context in which that  entity appears, and by inference, the entity’s semantic  properties     we include an additional  memory called a fact memory, which encodes  triples from a symbolic KB.     This combination results in a  neural language model which learns to access information  in a the symbolic knowledge graph.        TODO: read again IBM's [Span Selection Pre-training for Question Answering](doc:2019/09/_1909_04120_span_selection_pre) (an effort to avoid encoding general knowledge in the transformer network itself) Massive language models are the core of modern NLP modeling and have been shown to encode impressive amounts of commonsense and factual information. However, that knowledge exists only within the latent parameters of the model, inaccessible to inspection and interpretation, and even worse, factual information memorized from the training corpora is likely to become stale as the world changes. Knowledge stored as parameters will also inevitably exhibit all of the biases inherent in the source materials. To address these problems, we develop a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge. We show that this model dramatically improves performance on two knowledge-intensive question-answering tasks. More interestingly, the model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones in ways that are not possible for earlier models.|sl:arxiv_author|Livio Baldini Soares
FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence [github](https://github.com/google-research/fixmatch)     we demonstrate the power of a  simple combination of two common Semi-Supervised Learning methods: consistency  regularization and pseudo-labeling.    1. First generates pseudo-labels using the model’s  predictions on weakly-augmented unlabeled images. For a  given image, the pseudo-label is only retained if the model  produces a high-confidence prediction.   2. The model is then  trained to predict the pseudo-label when fed a strongly augmented  version of the same image. Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. In this paper, we demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling. Our algorithm, FixMatch, first generates pseudo-labels using the model's predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just 4 labels per class. Since FixMatch bears many similarities to existing SSL methods that achieve worse performance, we carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. We make our code available at https://github.com/google-research/fixmatch.|sl:arxiv_firstAuthor|Kihyuk Sohn
Miriam Makeba|skos:broader|Music of Africa
Hérodote|skos:broader|Géographie
Differentiable Top-k Operator with Optimal Transport  if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator   ...   We apply the proposed operator to the [k-nearest neighbors](tag:k_nearest_neighbors_algorithm) and [beam search](tag:beam_search) algorithms, and demonstrate improved performance The top-k operation, i.e., finding the k largest or smallest elements from a collection of scores, is an important model component, which is widely used in information retrieval, machine learning, and data mining. However, if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator. Specifically, our SOFT top-k operator approximates the output of the top-k operation as the solution of an Entropic Optimal Transport (EOT) problem. The gradient of the SOFT operator can then be efficiently approximated based on the optimality conditions of EOT problem. We apply the proposed operator to the k-nearest neighbors and beam search algorithms, and demonstrate improved performance.|sl:arxiv_author|Tuo Zhao
RDF embeddings|skos:broader|Knowledge Graph Embeddings
Structured Knowledge Distillation for Dense Prediction In this paper, we consider transferring the structure information from large networks to small ones for dense prediction tasks. Previous knowledge distillation strategies used for dense prediction tasks often directly borrow the distillation scheme for image classification and perform knowledge distillation for each pixel separately, leading to sub-optimal performance. Here we propose to distill structured knowledge from large networks to small networks, taking into account the fact that dense prediction is a structured prediction problem. Specifically, we study two structured distillation schemes: i)pair-wise distillation that distills the pairwise similarities by building a static graph, and ii)holistic distillation that uses adversarial training to distill holistic knowledge. The effectiveness of our knowledge distillation approaches is demonstrated by extensive experiments on three dense prediction tasks: semantic segmentation, depth estimation, and object detection.|sl:arxiv_author|Chunhua Shen
semblog|skos:broader|Semantic Blog
Erta Ale|skos:broader|Volcan
A Hierarchical Multi-task Approach for Learning Embeddings from Semantic Tasks [Blog post](https://medium.com/dair-ai/hmtl-multi-task-learning-for-state-of-the-art-nlp-245572bbb601), [GitHub repo](https://github.com/huggingface/hmtl)   Much effort has been devoted to evaluate whether multi-task learning can be leveraged to learn rich representations that can be used in various Natural Language Processing (NLP) down-stream applications. However, there is still a lack of understanding of the settings in which multi-task learning has a significant effect. In this work, we introduce a hierarchical model trained in a multi-task learning setup on a set of carefully selected semantic tasks. The model is trained in a hierarchical fashion to introduce an inductive bias by supervising a set of low level tasks at the bottom layers of the model and more complex tasks at the top layers of the model. This model achieves state-of-the-art results on a number of tasks, namely Named Entity Recognition, Entity Mention Detection and Relation Extraction without hand-engineered features or external NLP tools like syntactic parsers. The hierarchical training supervision induces a set of shared semantic representations at lower layers of the model. We show that as we move from the bottom to the top layers of the model, the hidden states of the layers tend to represent more complex semantic information.|sl:tag|tag:embeddings
Zune|skos:broader|Microsoft
Separation of man and ape|skos:broader|Grands Singes
Dave Winer|skos:broader|Technical girls and guys
Réalisateur|skos:broader|Cinéma
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|Sabrina Kirrane
Lutte traditionnelle|skos:broader|Sport de combat
ESWC 2012|skos:broader|ESWC
Nikolai Vavilov|skos:broader|Genetics Génétique
No Fuss Distance Metric Learning using Proxies  We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity...   Traditionnaly, supervision is expressed in the form of sets of points that follow  an ordinal relationship – an anchor point x is similar to  a set of positive points Y , and dissimilar to a set of negative  points Z, and a loss defined over these distances is minimized.   Triplet-Based methods are challenging to optimize (a main issue is the need for finding informative triplets).     We propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss.    Mentioned in this [blog post](/doc/2020/01/training_a_speaker_embedding_fr):     Proxy based triplet learning: instead of generating triplets, we learn an embedding for each class and use the learnt embedding as a proxy for triplets as part of the training. In other words, we can train end to end without the computationally expensive step of resampling triplets after each network update.    Near the conclusion:     Our formulation of Proxy-NCA loss produces a loss very  similar to the standard cross-entropy loss used in classification.  However, we arrive at our formulation from a different  direction: we are not interested in the actual classifier and  indeed discard the proxies once the model has been trained.  Instead, the proxies are auxiliary variables, enabling more  effective optimization of the embedding model parameters.  As such, our formulation not only enables us to surpass the  state of the art in zero-shot learning, but also offers an explanation  to the effectiveness of the standard trick of training  a classifier, and using its penultimate layer’s output as the  embedding. We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity. Traditionally, for this problem supervision is expressed in the form of sets of points that follow an ordinal relationship -- an anchor point $x$ is similar to a set of positive points $Y$, and dissimilar to a set of negative points $Z$, and a loss defined over these distances is minimized. While the specifics of the optimization differ, in this work we collectively call this type of supervision Triplets and all methods that follow this pattern Triplet-Based methods. These methods are challenging to optimize. A main issue is the need for finding informative triplets, which is usually achieved by a variety of tricks such as increasing the batch size, hard or semi-hard triplet mining, etc. Even with these tricks, the convergence rate of such methods is slow. In this paper we propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss. This proxy-based loss is empirically better behaved. As a result, the proxy-loss improves on state-of-art results for three standard zero-shot learning datasets, by up to 15% points, while converging three times as fast as other triplet-based losses.|sl:tag|tag:triplet_loss
DSSM (Deep Semantic Similarity Model)|skos:broader|Microsoft Research
Venus Express|skos:broader|esa
DocBERT: BERT for Document Classification We present, to our knowledge, the first application of BERT to document classification. A few characteristics of the task might lead one to think that BERT is not the most appropriate model: syntactic structures matter less for content categories, documents can often be longer than typical BERT input, and documents often have multiple labels. Nevertheless, we show that a straightforward classification model using BERT is able to achieve the state of the art across four popular datasets. To address the computational expense associated with BERT inference, we distill knowledge from BERT-large to small bidirectional LSTMs, reaching BERT-base parity on multiple datasets using 30x fewer parameters. The primary contribution of our paper is improved baselines that can provide the foundation for future work.|sl:tag|tag:arxiv_doc
foaf|skos:broader|Social Semantic Web
SPARQL Clipboard|skos:broader|Live Clipboard
R|skos:broader|Data science
Edvige|skos:broader|Etat policier
Latent Dirichlet allocation|skos:broader|Topic Modeling
SVD|skos:broader|Algèbre linéaire
(LOV) Linked Open Vocabularies|skos:broader|Mondeca
Artificial neurons|skos:broader|Bio inspired computing devices
Layered Graph Embedding for Entity Recommendation using Wikipedia in the Yahoo! Knowledge Graph an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia In this paper, we describe an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia. Through offline and online evaluations, we show that the resulting embeddings and recommendations perform well in terms of quality and user engagement. Balancing simplicity and quality, this framework provides default entity recommendations for English and other languages in the Yahoo! Knowledge Graph, which Wikipedia is a core subset of.|sl:tag|tag:entity_recommendation
NTIC et développement|skos:broader|NTIC
David Peterson|skos:broader|Technical girls and guys
Evaluation of sentence embeddings in downstream and linguistic probing tasks a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets     We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.           Despite the fast developmental pace of new sentence embedding methods, it is still challenging to find comprehensive evaluations of these different techniques. In the past years, we saw significant improvements in the field of sentence embeddings and especially towards the development of universal sentence encoders that could provide inductive transfer to a wide variety of downstream tasks. In this work, we perform a comprehensive evaluation of recent methods using a wide variety of downstream and linguistic feature probing tasks. We show that a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets. We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.|sl:tag|tag:sentence_embeddings
Pape François|skos:broader|Pape
SemTechBiz Berlin 2012|skos:broader|SemTechBiz
The HSIC Bottleneck: Deep Learning without Back-Propagation  we show that it is possible to learn classification tasks at near competitive accuracy without  backpropagation, by maximizing a surrogate of the mutual information between hidden representations and labels and  simultaneously minimizing the mutual dependency between hidden representations and the inputs...  the hidden units of a network trained in this way form useful representations. Specifically, fully competitive accuracy  can be obtained by freezing the network trained without backpropagation and appending and training a one-layer  network using conventional SGD to convert convert the representation to the desired format.    The training method uses an approximation of the [#information bottleneck](/tag/information_bottleneck_method).    Advantages:     - The method facilitates parallel processing and requires significantly less operations.    - It does not suffer from exploding or vanishing gradients.   - It is biologically more plausible than Backpropagation     We introduce the HSIC (Hilbert-Schmidt independence criterion) bottleneck for training deep neural networks. The HSIC bottleneck is an alternative to the conventional cross-entropy loss and backpropagation that has a number of distinct advantages. It mitigates exploding and vanishing gradients, resulting in the ability to learn very deep networks without skip connections. There is no requirement for symmetric feedback or update locking. We find that the HSIC bottleneck provides performance on MNIST/FashionMNIST/CIFAR10 classification comparable to backpropagation with a cross-entropy target, even when the system is not encouraged to make the output resemble the classification labels. Appending a single layer trained with SGD (without backpropagation) to reformat the information further improves performance.|sl:tag|tag:backpropagation_vs_biology
Mussolini|skos:broader|Italie
The information bottleneck method  We define the relevant information in a signal x ∈ X as being the information that this signal provides about another signal y ∈ Y. Examples include the information that face images provide about the names of the people portrayed, or the information that speech sounds provide about the words spoken. Understanding the signal x requires more than just predicting y, it also requires specifying which features of X play a role in the prediction. We formalize this problem as that of finding a short code for X that preserves the maximum information about Y. That is, we squeeze the information that X provides about Y through a ‘bottleneck’ formed by a limited set of codewords X ̃... This approach yields an exact set of self consistent equations for the coding rules X → X ̃ and X ̃ → Y .    (from the intro) : how to define meaningful / relevant information? An issue left out of information theory by Shannon (focus on the problem of transmitting information rather than judging its value to the recipient) -leads to  consider statistical and information theoretic principles as almost irrelevant  for the question of meaning.      In contrast, we argue here that information theory,  in particular lossy source compression, provides a natural quantitative  approach to the question of “relevant information.” Specifically, we formulate  a variational principle for the extraction or efficient representation of  relevant information.     We define the relevant information in a signal $x\\in X$ as being the information that this signal provides about another signal $y\\in \\Y$. Examples include the information that face images provide about the names of the people portrayed, or the information that speech sounds provide about the words spoken. Understanding the signal $x$ requires more than just predicting $y$, it also requires specifying which features of $\\X$ play a role in the prediction. We formalize this problem as that of finding a short code for $\\X$ that preserves the maximum information about $\\Y$. That is, we squeeze the information that $\\X$ provides about $\\Y$ through a `bottleneck' formed by a limited set of codewords $\\tX$. This constrained optimization problem can be seen as a generalization of rate distortion theory in which the distortion measure $d(x,\\x)$ emerges from the joint statistics of $\\X$ and $\\Y$. This approach yields an exact set of self consistent equations for the coding rules $X \\to \\tX$ and $\\tX \\to \\Y$. Solutions to these equations can be found by a convergent re-estimation method that generalizes the Blahut-Arimoto algorithm. Our variational principle provides a surprisingly rich framework for discussing a variety of problems in signal processing and learning, as will be described in detail elsewhere.|sl:arxiv_author|William Bialek NEC Research Institute
Manuscrits de Tombouctou|skos:broader|Manuscrits
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:arxiv_author|Yonatan Bisk
Multi-Task Deep Neural Networks for Natural Language Understanding outperforms BERT in nine of eleven benchmark NLP tasks In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations in order to adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7% (2.2% absolute improvement). We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. The code and pre-trained models are publicly available at https://github.com/namisan/mt-dnn.|sl:tag|tag:arxiv_doc
Photons corrélés|skos:broader|Photon
Encoding Categorical Variables with Conjugate Bayesian Models for WeWork Lead Scoring Engine  To encode high-cardinality categorical variables, we introduce a technique based on traditional Bayesian statistics. This technique is a paradigm for ensemble modeling, specifically stacking, where the base learner consists of a problem- specific conjugate Bayesian model (CBM)   Applied Data Scientists throughout various industries are commonly faced with the challenging task of encoding high-cardinality categorical features into digestible inputs for machine learning algorithms. This paper describes a Bayesian encoding technique developed for WeWork's lead scoring engine which outputs the probability of a person touring one of our office spaces based on interaction, enrichment, and geospatial data. We present a paradigm for ensemble modeling which mitigates the need to build complicated preprocessing and encoding schemes for categorical variables. In particular, domain-specific conjugate Bayesian models are employed as base learners for features in a stacked ensemble model. For each column of a categorical feature matrix we fit a problem-specific prior distribution, for example, the Beta distribution for a binary classification problem. In order to analytically derive the moments of the posterior distribution, we update the prior with the conjugate likelihood of the corresponding target variable for each unique value of the given categorical feature. This function of column and value encodes the categorical feature matrix so that the final learner in the ensemble model ingests low-dimensional numerical input. Experimental results on both curated and real world datasets demonstrate impressive accuracy and computational efficiency on a variety of problem archetypes. Particularly, for the lead scoring engine at WeWork -- where some categorical features have as many as 300,000 levels -- we have seen an AUC improvement from 0.87 to 0.97 through implementing conjugate Bayesian model encoding.|sl:tag|tag:stacking_ensemble_learning
Entity linking with Wikipedia as the target knowledge base|skos:broader|= named entity disambiguation: the task of resolving multiple named entity mentions in a document to their correct references in a knowledge base.
 Deep contextualized word representations    each word is assigned a representation which is a function of the  entire corpus sentences to which they belong. The embeddings are  computed from the internal states of a two-layers bidirectional Language  Model, hence the name “ELMo”: Embeddings from Language  Models.    [Github](https://github.com/allenai/bilm-tf)    |skos:broader|open-source NLP research library, built on PyTorch
Droit d'auteur|skos:broader|Propriété intellectuelle
KnowBert|skos:broader|Knowledge Graphs in NLP
Slime mold|skos:broader|Biology
Poincaré|skos:broader|Scientifique
How can we use knowledge graph in computing?    A knowledge graph is a symbolic and logical system but applications often involve numerical computing in continuous spaces.  Formal logic is neither tractable nor robust when dealing with knowledge graph. Hence the idea of Knowledge graph embeddings.    Generally, each entity is represented  as a point in that space while each relation is interpreted as an operation over entity embeddings (eg. in Bordes et al. transE, a translation). The embedding representations are usually learnt by minimizing a global loss function involving all entities and relations so that each entity  embedding encodes both local and global connectivity patterns of the original graph.  |skos:broader|[Surveys](/tag/?and=knowledge_graph&and=survey) (see also [surveys about graphs](/tag/?and=graph&and=survey))
James Hendler|skos:broader|SW guys (and girls)
Ivan Herman|skos:broader|Technical girls and guys
Slot filling|skos:broader|Natural Language Understanding
Rumba|skos:broader|Musique
AngularJS|skos:broader|Google
SIMILE Exhibit|skos:broader|JSON
DocBERT: BERT for Document Classification We present, to our knowledge, the first application of BERT to document classification. A few characteristics of the task might lead one to think that BERT is not the most appropriate model: syntactic structures matter less for content categories, documents can often be longer than typical BERT input, and documents often have multiple labels. Nevertheless, we show that a straightforward classification model using BERT is able to achieve the state of the art across four popular datasets. To address the computational expense associated with BERT inference, we distill knowledge from BERT-large to small bidirectional LSTMs, reaching BERT-base parity on multiple datasets using 30x fewer parameters. The primary contribution of our paper is improved baselines that can provide the foundation for future work.|sl:arxiv_author|Achyudh Ram
Topic2Vec: Learning Distributed Representations of Topics Topic2Vec aims at learning topic representations along with word representations. Considering the simplicity and efficient solution, we just follow the optimization scheme that used in Word2Vec Latent Dirichlet Allocation (LDA) mining thematic structure of documents plays an important role in nature language processing and machine learning areas. However, the probability distribution from LDA only describes the statistical relationship of occurrences in the corpus and usually in practice, probability is not the best choice for feature representations. Recently, embedding methods have been proposed to represent words and documents by learning essential concepts and representations, such as Word2Vec and Doc2Vec. The embedded representations have shown more effectiveness than LDA-style representations in many tasks. In this paper, we propose the Topic2Vec approach which can learn topic representations in the same semantic vector space with words, as an alternative to probability. The experimental results show that Topic2Vec achieves interesting and meaningful results.|sl:tag|tag:arxiv_doc
Ours|skos:broader|Animal
Safari|skos:broader|Apple Software
Médecine|skos:broader|Santé
Extrémisme islamique|skos:broader|Grands problèmes
BERT for Joint Intent Classification and Slot Filling  Experimental results show that our  proposed joint BERT model outperforms BERT  models modeling intent classification and slot filling  separately, demonstrating the efficacy of exploiting  the relationship between the two tasks.    Adding a CRF on top of the model doesn't improve the results. Intent classification and slot filling are two essential tasks for natural language understanding. They often suffer from small-scale human-labeled training data, resulting in poor generalization capability, especially for rare words. Recently a new language representation model, BERT (Bidirectional Encoder Representations from Transformers), facilitates pre-training deep bidirectional representations on large-scale unlabeled corpora, and has created state-of-the-art models for a wide variety of natural language processing tasks after simple fine-tuning. However, there has not been much effort on exploring BERT for natural language understanding. In this work, we propose a joint intent classification and slot filling model based on BERT. Experimental results demonstrate that our proposed model achieves significant improvement on intent classification accuracy, slot filling F1, and sentence-level semantic frame accuracy on several public benchmark datasets, compared to the attention-based recurrent neural network models and slot-gated models.|sl:tag|tag:bert
Nokia|skos:broader|Finlande
Multitask Learning in NLP|skos:broader|NLP tasks / problems
LOD2|skos:broader|Linking Open Data
AI cloud service|skos:broader|Artificial Intelligence
AI3:::Adaptive Information|skos:broader|Technical guys
Bayesian Deep Learning|skos:broader|Uncertainty in Deep Learning
Database to RDF mapping|skos:broader|RDF and database
Similarity Search for Efficient Active Learning and Search of Rare Concepts  Similarity search for Efficient Active Learning and Search (SEALS)    In [Active Learning](tag:active_learning): instead of searching globally for the optimal examples to label, leverage the fact that data is often heavily skewed and expand the candidate pool with the nearest neighbors of the labeled set.     Our work attacks both the labeling and computational costs of machine learning...SEALS dramatically reduces the barrier to machine learning, enabling small teams or individuals to  build accurate classifiers. SEALS does, however, introduce another system component, a similarity  search index, which adds some additional engineering complexity to build, tune, and maintain.  Fortunately, several highly optimized implementations like Annoy and [Faiss](doc:2020/06/facebookresearch_faiss_a_libra) work reasonably well  out of the box. Many active learning and search approaches are intractable for industrial settings with billions of unlabeled examples. Existing approaches, such as uncertainty sampling or information density, search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. However, in practice, data is often heavily skewed; only a small fraction of collected data will be relevant for a given learning task. For example, when identifying rare classes, detecting malicious content, or debugging model performance, the ratio of positive to negative examples can be 1 to 1,000 or more. In this work, we exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round by only looking at the nearest neighbors to the labeled examples. Empirically, we observe that learned representations effectively cluster unseen concepts, making active learning very effective and substantially reducing the number of viable unlabeled examples. We evaluate several active learning and search techniques in this setting on three large-scale datasets: ImageNet, Goodreads spoiler detection, and OpenImages. For rare classes, active learning methods need as little as 0.31% of the labeled data to match the average precision of full supervision. By limiting active learning methods to only consider the immediate neighbors of the labeled data as candidates for labeling, we need only process as little as 1% of the unlabeled data while achieving similar reductions in labeling costs as the traditional global approach. This process of expanding the candidate pool with the nearest neighbors of the labeled set can be done efficiently and reduces the computational complexity of selection by orders of magnitude.|sl:tag|tag:imbalanced_data
Archéologie|skos:broader|Favoris
Integrating Tomcat with Apache|skos:broader|Tomcat
SIgnets|skos:broader|Browser
Critique du libéralisme|skos:broader|Critique du capitalisme
Representation Learning with Contrastive Predictive Coding  a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful [autoregressive models](/tag/autoregressive_model). We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using [negative sampling](/tag/negative_sampling).    a contrastive method that can be applied to any form of data that can be expressed in an ordered sequence: text, speech, video... While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.|sl:tag|tag:google_deepmind
Linked Data Fragments|skos:broader|Linked Data
Royaume Uni|skos:broader|Europe
Search Engines|skos:broader|Informatique
Dialogs in javascript|skos:broader|JavaScript
J'ai un petit problème|skos:broader|Howto
Semantic Vector Encoding and Similarity Search Using Fulltext Search Engines  The ubiquity of semantic vector space modeling raises the challenge of efficient searching in dense, high-dimensional vector spaces. We would naturally want to take advantage of the design and optimizations behind modern fulltext engines like Elasticsearch so as to meet the scalability and robustness demands of modern IR applications. This is the research challenge addressed in this paper.   The paper describes novel ways of encoding dense vectors into text documents, allowing the use of traditional inverted index engines.    [blog post](https://rare-technologies.com/semantic-search-fulltext-engine-acl-2017/)   Vector representations and vector space modeling (VSM) play a central role in modern machine learning. We propose a novel approach to `vector similarity searching' over dense semantic representations of words and documents that can be deployed on top of traditional inverted-index-based fulltext engines, taking advantage of their robustness, stability, scalability and ubiquity. We show that this approach allows the indexing and querying of dense vectors in text domains. This opens up exciting avenues for major efficiency gains, along with simpler deployment, scaling and monitoring. The end result is a fast and scalable vector database with a tunable trade-off between vector search performance and quality, backed by a standard fulltext engine such as Elasticsearch. We empirically demonstrate its querying performance and quality by applying this solution to the task of semantic searching over a dense vector representation of the entire English Wikipedia.|sl:arxiv_firstAuthor|Jan Rygl
Assemblée nationale|skos:broader|France
NoSQL pour les nuls|skos:broader|NOSQL
Rare events|skos:broader|Imbalanced Data
Information retrieval|skos:broader|Technologie
Extinction des dinosaures|skos:broader|Météorite
Pre-trained Models for Natural Language Processing: A Survey Recently, the emergence of pre-trained models (PTMs) has brought natural language processing (NLP) to a new era. In this survey, we provide a comprehensive review of PTMs for NLP. We first briefly introduce language representation learning and its research progress. Then we systematically categorize existing PTMs based on a taxonomy with four perspectives. Next, we describe how to adapt the knowledge of PTMs to the downstream tasks. Finally, we outline some potential directions of PTMs for future research. This survey is purposed to be a hands-on guide for understanding, using, and developing PTMs for various NLP tasks.|sl:arxiv_author|Yunfan Shao
Economie française|skos:broader|France
Pre-Trained Language Models|skos:broader|Unsupervised deep pre-training
Neural Architectures for Named Entity Recognition Neural architectures for NER that use no language-specific resources or features beyond a small amount of supervised training data and unlabeled corpora.      Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.|sl:arxiv_author|Chris Dyer
IKS|skos:broader|LD
Julian Assange|skos:broader|Wikileaks
RDFa 1.1 Lite|skos:broader|RDFa 1.1
MyFaces|skos:broader|apache.org
Wiki|skos:broader|Social Networks
Question Answering over Knowledge Graphs via Structural Query Patterns Natural language question answering over knowledge graphs is an important and interesting task as it enables common users to gain accurate answers in an easy and intuitive manner. However, it remains a challenge to bridge the gap between unstructured questions and structured knowledge graphs. To address the problem, a natural discipline is building a structured query to represent the input question. Searching the structured query over the knowledge graph can produce answers to the question. Distinct from the existing methods that are based on semantic parsing or templates, we propose an effective approach powered by a novel notion, structural query pattern, in this paper. Given an input question, we first generate its query sketch that is compatible with the underlying structure of the knowledge graph. Then, we complete the query graph by labeling the nodes and edges under the guidance of the structural query pattern. Finally, answers can be retrieved by executing the constructed query graph over the knowledge graph. Evaluations on three question answering benchmarks show that our proposed approach outperforms state-of-the-art methods significantly.|sl:tag|tag:knowledge_graph
DAO attack|skos:broader|Hack
SPARQL en javascript|skos:broader|Javascript RDF
Interactive Concept Mining on Personal Data -- Bootstrapping Semantic Services Semantic services (e.g. Semantic Desktops) are still afflicted by a cold start problem: in the beginning, the user's personal information sphere, i.e. files, mails, bookmarks, etc., is not represented by the system. Information extraction tools used to kick-start the system typically create 1:1 representations of the different information items. Higher level concepts, for example found in file names, mail subjects or in the content body of these items, are not extracted. Leaving these concepts out may lead to underperformance, having to many of them (e.g. by making every found term a concept) will clutter the arising knowledge graph with non-helpful relations. In this paper, we present an interactive concept mining approach proposing concept candidates gathered by exploiting given schemata of usual personal information management applications and analysing the personal information sphere using various metrics. To heed the subjective view of the user, a graphical user interface allows to easily rank and give feedback on proposed concept candidates, thus keeping only those actually considered relevant. A prototypical implementation demonstrates major steps of our approach.|sl:arxiv_author|Markus Schröder
Beyond Vector Spaces: Compact Data Representation as Differentiable Weighted Graphs  In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE (Probabilistic Differentiable Graph Embeddings): a method that learns a weighted graph representation of data end-to-end by gradient descent.    [Github](https://github.com/stanis-morozov/prodige)     Learning useful representations is a key ingredient to the success of modern machine learning. Currently, representation learning mostly relies on embedding data into Euclidean space. However, recent work has shown that data in some domains is better modeled by non-euclidean metric spaces, and inappropriate geometry can result in inferior performance. In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE: a method that learns a weighted graph representation of data end-to-end by gradient descent. Greater generality and fewer model assumptions make PRODIGE more powerful than existing embedding-based approaches. We confirm the superiority of our method via extensive experiments on a wide range of tasks, including classification, compression, and collaborative filtering.|sl:arxiv_author|Denis Mazur
IHM|skos:broader|Informatique
"Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One We propose to reinterpret a standard discriminative classifier of p(y|x) as an energy based model for the joint distribution p(x,y). In this setting, the standard class probabilities can be easily computed as well as unnormalized values of p(x) and p(x|y). Within this framework, standard discriminative architectures may beused and the model can also be trained on unlabeled data. We demonstrate that energy based training of the joint distribution improves calibration, robustness, andout-of-distribution detection while also enabling our models to generate samplesrivaling the quality of recent GAN approaches. We improve upon recently proposed techniques for scaling up the training of energy based models and presentan approach which adds little overhead compared to standard classification training. Our approach is the first to achieve performance rivaling the state-of-the-artin both generative and discriminative learning within one hybrid model."|sl:arxiv_author|Kevin Swersky
Approach to machine translation in which a large neural network is trained to maximize translation performance. It is a radical departure from the phrase-based statistical translation approaches, in which a translation system consists of subcomponents that are separately optimized.    A bidirectional recurrent neural network (RNN), known as an encoder, is used by the neural network to encode a source sentence for a second RNN, known as a decoder, that is used to predict words in the target language    |skos:broader|sub-field of computational linguistics that investigates the use of software to translate text or speech from one language to another
[#Word sense disambiguation](/tag/word_sense_disambiguation) algorithm based on the assumption that words in a given neighborhood (section of text) tend to share a common topic  |skos:broader|Methods for quantifying and categorizing semantic similarities between linguistic items based on their distributional properties in large samples of language data.    Basic idea: the Distributional hypothesis: linguistic items with similar distributions have similar meanings.    Basic approach: collect distributional information in high-dimensional vectors, and define similarity in terms of vector similarity    Models: latent semantic analysis (LSA), Hyperspace Analogue to Language (HAL), syntax- or dependency-based models, random indexing, semantic folding and various variants of the topic model.      
NLP girls and guys|skos:broader|NLP
EC-Web|skos:broader|Conférences
QOTD|skos:broader|Citation
Relation Extraction|skos:broader|Entities
A Hierarchical Multi-task Approach for Learning Embeddings from Semantic Tasks [Blog post](https://medium.com/dair-ai/hmtl-multi-task-learning-for-state-of-the-art-nlp-245572bbb601), [GitHub repo](https://github.com/huggingface/hmtl)   Much effort has been devoted to evaluate whether multi-task learning can be leveraged to learn rich representations that can be used in various Natural Language Processing (NLP) down-stream applications. However, there is still a lack of understanding of the settings in which multi-task learning has a significant effect. In this work, we introduce a hierarchical model trained in a multi-task learning setup on a set of carefully selected semantic tasks. The model is trained in a hierarchical fashion to introduce an inductive bias by supervising a set of low level tasks at the bottom layers of the model and more complex tasks at the top layers of the model. This model achieves state-of-the-art results on a number of tasks, namely Named Entity Recognition, Entity Mention Detection and Relation Extraction without hand-engineered features or external NLP tools like syntactic parsers. The hierarchical training supervision induces a set of shared semantic representations at lower layers of the model. We show that as we move from the bottom to the top layers of the model, the hidden states of the layers tend to represent more complex semantic information.|sl:arxiv_author|Thomas Wolf
Same architecture as autoencoder, but make strong assumptions concerning the distribution of latent variables. They use variational approach for latent representation learning (\Stochastic Gradient Variational Bayes\ (SGVB) training algorithm)|skos:broader|Deep latent variable models assume a generative process whereby a simple random variable is transformed from the latent space to the observed, output space through a deep neural network. Generative Adversarial Networks (GAN) and Variational Autoencoders (VAE) are two of the most popular variants of this approach
Land Degradation|skos:broader|Crise écologique
GUI|skos:broader|UI
Geoffrey Hinton|skos:broader|AI girls and guys
Mars|skos:broader|Système solaire
Subword Semantic Hashing for Intent Classification on Small Datasets In this paper, we introduce the use of Semantic Hashing as embedding for the task of Intent Classification and achieve state-of-the-art performance on three frequently used benchmarks. Intent Classification on a small dataset is a challenging task for data-hungry state-of-the-art Deep Learning based systems. Semantic Hashing is an attempt to overcome such a challenge and learn robust text classification. Current word embedding based are dependent on vocabularies. One of the major drawbacks of such methods is out-of-vocabulary terms, especially when having small training datasets and using a wider vocabulary. This is the case in Intent Classification for chatbots, where typically small datasets are extracted from internet communication. Two problems arise by the use of internet communication. First, such datasets miss a lot of terms in the vocabulary to use word embeddings efficiently. Second, users frequently make spelling errors. Typically, the models for intent classification are not trained with spelling errors and it is difficult to think about ways in which users will make mistakes. Models depending on a word vocabulary will always face such issues. An ideal classifier should handle spelling errors inherently. With Semantic Hashing, we overcome these challenges and achieve state-of-the-art results on three datasets: AskUbuntu, Chatbot, and Web Application. Our benchmarks are available online: https://github.com/kumar-shridhar/Know-Your-Intent|sl:arxiv_author|Foteini Simistira
Stacked Approximated Regression Machine: A Simple Deep Learning Approach This paper seems too good to be true! They can train a VGG-like net VERY quickly to good accuracy, without backprop. With the agreement of my coauthors, I Zhangyang Wang would like to withdraw the manuscript Stacked Approximated Regression Machine: A Simple Deep Learning Approach. Some experimental procedures were not included in the manuscript, which makes a part of important claims not meaningful. In the relevant research, I was solely responsible for carrying out the experiments; the other coauthors joined in the discussions leading to the main algorithm. Please see the updated text for more details.|sl:tag|tag:arxiv_doc
Web Pollution|skos:broader|Web
Ghana Empire|skos:broader|Histoire de l'Afrique
Linked Data Cache|skos:broader|Cache
Grounded Language Learning|skos:broader|NLU
FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence [github](https://github.com/google-research/fixmatch)     we demonstrate the power of a  simple combination of two common Semi-Supervised Learning methods: consistency  regularization and pseudo-labeling.    1. First generates pseudo-labels using the model’s  predictions on weakly-augmented unlabeled images. For a  given image, the pseudo-label is only retained if the model  produces a high-confidence prediction.   2. The model is then  trained to predict the pseudo-label when fed a strongly augmented  version of the same image. Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. In this paper, we demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling. Our algorithm, FixMatch, first generates pseudo-labels using the model's predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just 4 labels per class. Since FixMatch bears many similarities to existing SSL methods that achieve worse performance, we carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. We make our code available at https://github.com/google-research/fixmatch.|sl:arxiv_author|David Berthelot
Automating the search for a patent's prior art with a full text similarity search [github](https://github.com/helmersl/patent_similarity_search)    mouais     More than ever, technical inventions are the symbol of our society's advance. Patents guarantee their creators protection against infringement. For an invention being patentable, its novelty and inventiveness have to be assessed. Therefore, a search for published work that describes similar inventions to a given patent application needs to be performed. Currently, this so-called search for prior art is executed with semi-automatically composed keyword queries, which is not only time consuming, but also prone to errors. In particular, errors may systematically arise by the fact that different keywords for the same technical concepts may exist across disciplines. In this paper, a novel approach is proposed, where the full text of a given patent application is compared to existing patents using machine learning and natural language processing techniques to automatically detect inventions that are similar to the one described in the submitted document. Various state-of-the-art approaches for feature extraction and document comparison are evaluated. In addition to that, the quality of the current search process is assessed based on ratings of a domain expert. The evaluation results show that our automated approach, besides accelerating the search process, also improves the search results for prior art with respect to their quality.|sl:arxiv_author|Franziska Horn
Mobile apps dev|skos:broader|Dev
GAO|skos:broader|Automotive ontologies
HATEOAS|skos:broader|REST
Bringing Light Into the Dark: A Large-scale Evaluation of Knowledge Graph Embedding Models Under a Unified Framework The heterogeneity in recently published knowledge graph embedding models' implementations, training, and evaluation has made fair and thorough comparisons difficult. In order to assess the reproducibility of previously published results, we re-implemented and evaluated 19 interaction models in the PyKEEN software package. Here, we outline which results could be reproduced with their reported hyper-parameters, which could only be reproduced with alternate hyper-parameters, and which could not be reproduced at all as well as provide insight as to why this might be the case. We then performed a large-scale benchmarking on four datasets with several thousands of experiments and 21,246 GPU hours of computation time. We present insights gained as to best practices, best configurations for each model, and where improvements could be made over previously published best configurations. Our results highlight that the combination of model architecture, training approach, loss function, and the explicit modeling of inverse relations is crucial for a model's performances, and not only determined by the model architecture. We provide evidence that several architectures can obtain results competitive to the state-of-the-art when configured carefully. We have made all code, experimental configurations, results, and analyses that lead to our interpretations available at https://github.com/pykeen/pykeen and https://github.com/pykeen/benchmarking|sl:arxiv_author|Asja Fischer
Enswers|skos:broader|Digital Video
"Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One We propose to reinterpret a standard discriminative classifier of p(y|x) as an energy based model for the joint distribution p(x,y). In this setting, the standard class probabilities can be easily computed as well as unnormalized values of p(x) and p(x|y). Within this framework, standard discriminative architectures may beused and the model can also be trained on unlabeled data. We demonstrate that energy based training of the joint distribution improves calibration, robustness, andout-of-distribution detection while also enabling our models to generate samplesrivaling the quality of recent GAN approaches. We improve upon recently proposed techniques for scaling up the training of energy based models and presentan approach which adds little overhead compared to standard classification training. Our approach is the first to achieve performance rivaling the state-of-the-artin both generative and discriminative learning within one hybrid model."|sl:arxiv_author|Jörn-Henrik Jacobsen
Word Representations via Gaussian Embedding  Current work in lexical distributed representations maps each word to a point vector in low-dimensional space. Mapping instead to a density provides many interesting advantages     Novel word embedding algorithms that embed words directly as Gaussian distributional potential functions in an infinite dimensional function space. This allows us to map word types not only to vectors but to soft regions in space, modeling uncertainty, inclusion, and entailment, as well as providing a rich geometry of the latent space. Current work in lexical distributed representations maps each word to a point vector in low-dimensional space. Mapping instead to a density provides many interesting advantages, including better capturing uncertainty about a representation and its relationships, expressing asymmetries more naturally than dot product or cosine similarity, and enabling more expressive parameterization of decision boundaries. This paper advocates for density-based distributed embeddings and presents a method for learning representations in the space of Gaussian distributions. We compare performance on various word embedding benchmarks, investigate the ability of these embeddings to model entailment and other asymmetric relationships, and explore novel properties of the representation.|sl:arxiv_author|Luke Vilnis
Archéologie|skos:broader|Histoire
Ecocide|skos:broader|Écologie
BERT-of-Theseus: Compressing BERT by Progressive Module Replacing approach to compress BERT by progressive module replacing.     Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter    [Github](https://github.com/JetRunner/BERT-of-Theseus) In this paper, we propose a novel model compression approach to effectively compress BERT by progressive module replacing. Our approach first divides the original BERT into several modules and builds their compact substitutes. Then, we randomly replace the original modules with their substitutes to train the compact modules to mimic the behavior of the original modules. We progressively increase the probability of replacement through the training. In this way, our approach brings a deeper level of interaction between the original and compact models, and smooths the training process. Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter, liberating human effort from hyper-parameter tuning. Our approach outperforms existing knowledge distillation approaches on GLUE benchmark, showing a new perspective of model compression.|sl:arxiv_author|Wangchunshu Zhou
The HSIC Bottleneck: Deep Learning without Back-Propagation  we show that it is possible to learn classification tasks at near competitive accuracy without  backpropagation, by maximizing a surrogate of the mutual information between hidden representations and labels and  simultaneously minimizing the mutual dependency between hidden representations and the inputs...  the hidden units of a network trained in this way form useful representations. Specifically, fully competitive accuracy  can be obtained by freezing the network trained without backpropagation and appending and training a one-layer  network using conventional SGD to convert convert the representation to the desired format.    The training method uses an approximation of the [#information bottleneck](/tag/information_bottleneck_method).    Advantages:     - The method facilitates parallel processing and requires significantly less operations.    - It does not suffer from exploding or vanishing gradients.   - It is biologically more plausible than Backpropagation     We introduce the HSIC (Hilbert-Schmidt independence criterion) bottleneck for training deep neural networks. The HSIC bottleneck is an alternative to the conventional cross-entropy loss and backpropagation that has a number of distinct advantages. It mitigates exploding and vanishing gradients, resulting in the ability to learn very deep networks without skip connections. There is no requirement for symmetric feedback or update locking. We find that the HSIC bottleneck provides performance on MNIST/FashionMNIST/CIFAR10 classification comparable to backpropagation with a cross-entropy target, even when the system is not encouraged to make the output resemble the classification labels. Appending a single layer trained with SGD (without backpropagation) to reformat the information further improves performance.|sl:tag|tag:arxiv_doc
Representing Sentences as Low-Rank Subspaces  We observe a simple geometry of sentences -- the word representations of a given sentence roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors.    A sentence of N words is a matrix (300, N) (if 300 is the dim of the word embeddings space). We take the eg. 4 (hyperparam) heaviest singular values - a subspace with dim 4    Similarity between docs: principal angle between the subspaces (reminiscent of cosine similarity)     Sentences are important semantic units of natural language. A generic, distributional representation of sentences that can capture the latent semantics is beneficial to multiple downstream applications. We observe a simple geometry of sentences -- the word representations of a given sentence (on average 10.23 words in all SemEval datasets with a standard deviation 4.84) roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors. Such an unsupervised representation is empirically validated via semantic textual similarity tasks on 19 different datasets, where it outperforms the sophisticated neural network models, including skip-thought vectors, by 15% on average.|sl:tag|tag:sentence_embeddings
Bayesian networks bayesian Réseaux bayésiens|skos:broader|IA AI
Union européenne|skos:broader|Institutions européennes
RDF Framework|skos:broader|Semantic Web : Tools
Ranked Entities in Search Results|skos:broader|Search Engines
PlaNet - Photo Geolocation with Convolutional Neural Networks Is it possible to build a system to determine the location where a photo was taken using just its pixels? In general, the problem seems exceptionally difficult: it is trivial to construct situations where no location can be inferred. Yet images often contain informative cues such as landmarks, weather patterns, vegetation, road markings, and architectural details, which in combination may allow one to determine an approximate location and occasionally an exact location. Websites such as GeoGuessr and View from your Window suggest that humans are relatively good at integrating these cues to geolocate images, especially en-masse. In computer vision, the photo geolocation problem is usually approached using image retrieval methods. In contrast, we pose the problem as one of classification by subdividing the surface of the earth into thousands of multi-scale geographic cells, and train a deep network using millions of geotagged images. While previous approaches only recognize landmarks or perform approximate matching using global image descriptors, our model is able to use and integrate multiple visible cues. We show that the resulting model, called PlaNet, outperforms previous approaches and even attains superhuman levels of accuracy in some cases. Moreover, we extend our model to photo albums by combining it with a long short-term memory (LSTM) architecture. By learning to exploit temporal coherence to geolocate uncertain photos, we demonstrate that this model achieves a 50% performance improvement over the single-image model.|sl:tag|tag:convolutional_neural_network
Bruxelles|skos:broader|Ville
Deep Learning and the Information Bottleneck Principle  Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN.   Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.|sl:tag|tag:information_bottleneck_method
Ouzbékistan|skos:broader|Ex URSS URSS
ESWC 2007|skos:broader|ESWC
Europe|skos:broader|Géographie
Language Models as Knowledge Bases? an analysis of the relational knowledge present in pretrained language models shows an ability of these models to recall factual knowledge  Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as fill-in-the-blank cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.|sl:tag|tag:nlp_facebook
Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call fooling images (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.|sl:arxiv_author|Jason Yosinski
Sculpture|skos:broader|Art
Guha|skos:broader|Technical girls and guys
Jena: assembler|skos:broader|Jena dev
Knowledge Graph Embeddings Library|skos:broader|KGE KG embedding Knowledge graph embedding
Differentiable Top-k Operator with Optimal Transport  if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator   ...   We apply the proposed operator to the [k-nearest neighbors](tag:k_nearest_neighbors_algorithm) and [beam search](tag:beam_search) algorithms, and demonstrate improved performance The top-k operation, i.e., finding the k largest or smallest elements from a collection of scores, is an important model component, which is widely used in information retrieval, machine learning, and data mining. However, if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator. Specifically, our SOFT top-k operator approximates the output of the top-k operation as the solution of an Entropic Optimal Transport (EOT) problem. The gradient of the SOFT operator can then be efficiently approximated based on the optimality conditions of EOT problem. We apply the proposed operator to the k-nearest neighbors and beam search algorithms, and demonstrate improved performance.|sl:arxiv_author|Bo Dai
Blackbox NLP|skos:broader|AI black box
LODr|skos:broader|Tagging
Javascript RDF Parser|skos:broader|JavaScript
A Survey on Knowledge Graph Embeddings with Literals: Which model links better Literal-ly? Knowledge Graphs (KGs) are composed of structured information about a particular domain in the form of entities and relations. In addition to the structured information KGs help in facilitating interconnectivity and interoperability between different resources represented in the Linked Data Cloud. KGs have been used in a variety of applications such as entity linking, question answering, recommender systems, etc. However, KG applications suffer from high computational and storage costs. Hence, there arises the necessity for a representation able to map the high dimensional KGs into low dimensional spaces, i.e., embedding space, preserving structural as well as relational information. This paper conducts a survey of KG embedding models which not only consider the structured information contained in the form of entities and relations in a KG but also the unstructured information represented as literals such as text, numerical values, images, etc. Along with a theoretical analysis and comparison of the methods proposed so far for generating KG embeddings with literals, an empirical evaluation of the different methods under identical settings has been performed for the general task of link prediction.|sl:arxiv_author|Genet Asefa Gesese
Kingsley Idehen|skos:broader|OpenLink Software
Still a Pain in the Neck: Evaluating Text Representations on Lexical Composition How well do contextualized word embeddings address lexical composition? They are good in recognizing meaning shift (\give in\ is different from \give\) but much worse with revealing implicit meaning (\hot tea\ is about temperature, \hot debate\ isn't). Building meaningful phrase representations is challenging because phrase meanings are not simply the sum of their constituent meanings. Lexical composition can shift the meanings of the constituent words and introduce implicit information. We tested a broad range of textual representations for their capacity to address these issues. We found that as expected, contextualized word representations perform better than static word embeddings, more so on detecting meaning shift than in recovering implicit information, in which their performance is still far from that of humans. Our evaluation suite, including 5 tasks related to lexical composition effects, can serve future research aiming to improve such representations.|sl:tag|tag:word_embedding_compositionality
Censure et maltraitance animale|skos:broader|Vive le capitalisme !
Bioterrorisme|skos:broader|Terrorisme
Feedly|skos:broader|RSS
An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks For most deep learning practitioners, sequence modeling is synonymous with recurrent networks. Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation. Given a new sequence modeling task or dataset, which architecture should one use? We conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling. The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks. Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as LSTMs across a diverse range of tasks and datasets, while demonstrating longer effective memory. We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks. To assist related work, we have made code available at http://github.com/locuslab/TCN .|sl:arxiv_author|Vladlen Koltun
Enterprise Semantic Web Semantic Web in the enterprise Corporate Semantic Web|skos:broader|Web sémantique sw
InceptionTime: Finding AlexNet for Time Series Classification Time series classification (TSC) is the area of machine learning interested in learning how to assign labels to time series. The last few decades of work in this area have led to significant progress in the accuracy of classifiers, with the state of the art now represented by the HIVE-COTE algorithm. While extremely accurate, HIVE-COTE is infeasible to use in many applications because of its very high training time complexity in O(N^2T^4) for a dataset with N time series of length T. For example, it takes HIVE-COTE more than 72,000s to learn from a small dataset with N=700 time series of short length T=46. Deep learning, on the other hand, has now received enormous attention because of its high scalability and state-of-the-art accuracy in computer vision and natural language processing tasks. Deep learning for TSC has only very recently started to be explored, with the first few architectures developed over the last 3 years only. The accuracy of deep learning for TSC has been raised to a competitive level, but has not quite reached the level of HIVE-COTE. This is what this paper achieves: outperforming HIVE-COTE's accuracy together with scalability. We take an important step towards finding the AlexNet network for TSC by presenting InceptionTime---an ensemble of deep Convolutional Neural Network (CNN) models, inspired by the Inception-v4 architecture. Our experiments show that InceptionTime slightly outperforms HIVE-COTE with a win/draw/loss on the UCR archive of 40/6/39. Not only is InceptionTime more accurate, but it is much faster: InceptionTime learns from that same dataset with 700 time series in 2,300s but can also learn from a dataset with 8M time series in 13 hours, a quantity of data that is fully out of reach of HIVE-COTE.|sl:arxiv_author|Daniel F. Schmidt
Cognition|skos:broader|Divers
Distilling the Knowledge in a Neural Network  a different kind of training, which we call “distillation” to transfer the  knowledge from the cumbersome model to a small model that is more  suitable for deployment       Caruana and his collaborators have shown that it is possible to compress the knowledge in an [#ensemble](/tag/ensemble_learning.html) into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST. A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.|sl:tag|tag:arxiv_doc
Contextualized word representations|skos:broader|NLP techniques
BAM! Born-Again Multi-Task Networks for Natural Language Understanding  knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers It can be challenging to train multi-task neural networks that outperform or even match their single-task counterparts. To help address this, we propose using knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers. We evaluate our approach by multi-task fine-tuning BERT on the GLUE benchmark. Our method consistently improves over standard single-task and multi-task training.|sl:tag|tag:chris_manning
Javadoc|skos:broader|Documentation tool
Text feature extraction|skos:broader|NLP techniques
Genetic data|skos:broader|Genetics Génétique
- Siamese network with two deep sub-models  - Projects input and candidate texts into embedding space  - Trained by maximizing cosine similarity between correct input-output pairs    [source](/doc/2019/08/neural_models_for_information_r)|skos:broader|Finding items that are similar to a given query is the core  aspect of search and retrieval systems, as well as of  recommendation engines.
Lobby agroalimentaire|skos:broader|Agriculture
Schema.org roles|skos:broader|schema.org
Linking Open Data|skos:broader|Open Data
Categorical Metadata Representation for Customized Text Classification  We observe that current representation methods for categorical metadata... are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category The performance of text classification has improved tremendously using intelligently engineered neural-based models, especially those injecting categorical metadata as additional information, e.g., using user/product information for sentiment classification. These information have been used to modify parts of the model (e.g., word embeddings, attention mechanisms) such that results can be customized according to the metadata. We observe that current representation methods for categorical metadata, which are devised for human consumption, are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category, and even such context is often scarce (for tail category). To this end, we propose to use basis vectors to effectively incorporate categorical metadata on various parts of a neural-based model. This additionally decreases the number of parameters dramatically, especially when the number of categorical features is large. Extensive experiments on various datasets with different properties are performed and show that through our method, we can represent categorical metadata more effectively to customize parts of the model, including unexplored ones, and increase the performance of the model greatly.|sl:arxiv_author|Reinald Kim Amplayo
Angela Merkel|skos:broader|Homme politique
IBM|skos:broader|NTIC
Doc2Vec|skos:broader|Word2vec
the bottleneck of getting labeled training data|skos:broader|Machine learning focuses on prediction, based on known properties learned from the training data. Data mining (which is the analysis step of Knowledge Discovery in Databases) focuses on the discovery of (previously) unknown properties on the data.    [Glossary (by google)](https://developers.google.com/machine-learning/glossary/)
Science fiction|skos:broader|Fiction
Guerres puniques|skos:broader|Antiquité romaine
Question Answering for complex questions is often modeled as a graph construction or traversal task, where a solver must build or traverse a graph of facts that answer and explain a given question.|skos:broader|For a description of the variants of this task, see this [paper](/doc/2020/02/how_much_knowledge_can_you_pack)    - reading comprehesion  - open-domain QA      - open-book exam      - open-book exam
iTunes|skos:broader|Music store
Biologie|skos:broader|sciences
gensim|skos:broader|Topic Modeling
Fado tropical|skos:broader|Chico Buarque
Rébellion touarègue|skos:broader|Niger
CIMBA|skos:broader|Personal data
Learning Semantic Similarity for Very Short Texts In order to pair short text  fragments—as a concatenation of separate words—an adequate  distributed sentence representation is needed. Main contribution: a first step towards a hybrid method that  combines the strength of dense distributed representations—  as opposed to sparse term matching—with the strength of  tf-idf based methods. The combination of word embeddings and tf-idf  information might lead to a better model for semantic content  within very short text fragments. Levering data on social media, such as Twitter and Facebook, requires information retrieval algorithms to become able to relate very short text fragments to each other. Traditional text similarity methods such as tf-idf cosine-similarity, based on word overlap, mostly fail to produce good results in this case, since word overlap is little or non-existent. Recently, distributed word representations, or word embeddings, have been shown to successfully allow words to match on the semantic level. In order to pair short text fragments - as a concatenation of separate words - an adequate distributed sentence representation is needed, in existing literature often obtained by naively combining the individual word representations. We therefore investigated several text representations as a combination of word embeddings in the context of semantic pair matching. This paper investigates the effectiveness of several such naive techniques, as well as traditional tf-idf similarity, for fragments of different lengths. Our main contribution is a first step towards a hybrid method that combines the strength of dense distributed representations - as opposed to sparse term matching - with the strength of tf-idf based methods to automatically reduce the impact of less informative terms. Our new approach outperforms the existing techniques in a toy experimental set-up, leading to the conclusion that the combination of word embeddings and tf-idf information might lead to a better model for semantic content within very short text fragments.|sl:arxiv_author|Steven Bohez
Reformer: The Efficient Transformer Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O($L^2$) to O($L\\log L$), where $L$ is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of $N$ times, where $N$ is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.|sl:arxiv_author|Nikita Kitaev
AI Chip|skos:broader|Chip
Regroupement familial et test ADN de filiation|skos:broader|Test ADN de filiation
Snippet Manager|skos:broader|Semanlink related
Subword Semantic Hashing for Intent Classification on Small Datasets In this paper, we introduce the use of Semantic Hashing as embedding for the task of Intent Classification and achieve state-of-the-art performance on three frequently used benchmarks. Intent Classification on a small dataset is a challenging task for data-hungry state-of-the-art Deep Learning based systems. Semantic Hashing is an attempt to overcome such a challenge and learn robust text classification. Current word embedding based are dependent on vocabularies. One of the major drawbacks of such methods is out-of-vocabulary terms, especially when having small training datasets and using a wider vocabulary. This is the case in Intent Classification for chatbots, where typically small datasets are extracted from internet communication. Two problems arise by the use of internet communication. First, such datasets miss a lot of terms in the vocabulary to use word embeddings efficiently. Second, users frequently make spelling errors. Typically, the models for intent classification are not trained with spelling errors and it is difficult to think about ways in which users will make mistakes. Models depending on a word vocabulary will always face such issues. An ideal classifier should handle spelling errors inherently. With Semantic Hashing, we overcome these challenges and achieve state-of-the-art results on three datasets: AskUbuntu, Chatbot, and Web Application. Our benchmarks are available online: https://github.com/kumar-shridhar/Know-Your-Intent|sl:arxiv_firstAuthor|Kumar Shridhar
Explainable AI|skos:broader|Accountable AI
Silicon Valley|skos:broader|Californie
Semantic Statistics|skos:broader|Semantic Web
Restful semantic web services|skos:broader|REST
Reformer: The Efficient Transformer Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O($L^2$) to O($L\\log L$), where $L$ is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of $N$ times, where $N$ is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.|sl:tag|tag:arxiv_doc
Soleil|skos:broader|Système solaire
Microsoft Concept Graph|skos:broader|Knowledge Extraction
DNA nanotechnology|skos:broader|ADN
Learning to Remember Rare Events  a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training.    Our memory module can be easily added to any part of a supervised neural network Despite recent advances, memory-augmented deep neural networks are still limited when it comes to life-long and one-shot learning, especially in remembering rare events. We present a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training. Our memory module can be easily added to any part of a supervised neural network. To show its versatility we add it to a number of networks, from simple convolutional ones tested on image classification to deep sequence-to-sequence and recurrent-convolutional models. In all cases, the enhanced network gains the ability to remember and do life-long one-shot learning. Our module remembers training examples shown many thousands of steps in the past and it can successfully generalize from them. We set new state-of-the-art for one-shot learning on the Omniglot dataset and demonstrate, for the first time, life-long one-shot learning in recurrent neural networks on a large-scale machine translation task.|sl:tag|tag:rare_events
Google Refine|skos:broader|OpenRefine
Liberté d'expression|skos:broader|Liberté
1ere guerre mondiale|skos:broader|Histoire
Newton|skos:broader|Physique
Manu Dibango|skos:broader|Jazz
Differentiable Top-k Operator with Optimal Transport  if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator   ...   We apply the proposed operator to the [k-nearest neighbors](tag:k_nearest_neighbors_algorithm) and [beam search](tag:beam_search) algorithms, and demonstrate improved performance The top-k operation, i.e., finding the k largest or smallest elements from a collection of scores, is an important model component, which is widely used in information retrieval, machine learning, and data mining. However, if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator. Specifically, our SOFT top-k operator approximates the output of the top-k operation as the solution of an Entropic Optimal Transport (EOT) problem. The gradient of the SOFT operator can then be efficiently approximated based on the optimality conditions of EOT problem. We apply the proposed operator to the k-nearest neighbors and beam search algorithms, and demonstrate improved performance.|sl:arxiv_firstAuthor|Yujia Xie
Croisade des enfants|skos:broader|Croisades
Antiquité du Pakistan|skos:broader|Pakistan
Construction européenne|skos:broader|Europe
Triple-store powered site|skos:broader|TripleStore
Linked Learning|skos:broader|Online Learning
Wikipedia page to concept|skos:broader|Information resources
Sida|skos:broader|Grands problèmes
Sônia Braga|skos:broader|Actrice
C2GWeb|skos:broader|SW at Renault
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:arxiv_author|Mario Guajardo-Cespedes
Conjecture de Goldbach|skos:broader|Grands problèmes mathématiques
Louis Jouvet|skos:broader|Cinéma français
KD-MKR biblio|skos:broader|KD-MKR
Mésopotamie|skos:broader|Antiquité
Pre-training via Paraphrasing We introduce MARGE, a pre-trained sequence-to-sequence model learned with an unsupervised multi-lingual multi-document paraphrasing objective. MARGE provides an alternative to the dominant masked language modeling paradigm, where we self-supervise the reconstruction of target text by retrieving a set of related texts (in many languages) and conditioning on them to maximize the likelihood of generating the original. We show it is possible to jointly learn to do retrieval and reconstruction, given only a random initialization. The objective noisily captures aspects of paraphrase, translation, multi-document summarization, and information retrieval, allowing for strong zero-shot performance on several tasks. For example, with no additional task-specific training we achieve BLEU scores of up to 35.8 for document translation. We further show that fine-tuning gives strong performance on a range of discriminative and generative tasks in many languages, making MARGE the most generally applicable pre-training method to date.|sl:tag|tag:sequence_to_sequence_learning
Tanis-KT|skos:broader|Extinction des dinosaures
A Little Annotation does a Lot of Good: A Study in Bootstrapping Low-resource Named Entity Recognizers Most state-of-the-art models for named entity recognition (NER) rely on the availability of large amounts of labeled data, making them challenging to extend to new, lower-resourced languages. However, there are now several proposed approaches involving either cross-lingual transfer learning, which learns from other highly resourced languages, or active learning, which efficiently selects effective training data based on model predictions. This paper poses the question: given this recent progress, and limited human annotation, what is the most effective method for efficiently creating high-quality entity recognizers in under-resourced languages? Based on extensive experimentation using both simulated and real human annotation, we find a dual-strategy approach best, starting with a cross-lingual transferred model, then performing targeted annotation of only uncertain entity spans in the target language, minimizing annotator effort. Results demonstrate that cross-lingual transfer is a powerful tool when very little data can be annotated, but an entity-targeted annotation strategy can achieve competitive accuracy quickly, with just one-tenth of training data.|sl:tag|tag:cross_lingual_nlp
Macaw: An Extensible Conversational Information Seeking Platform Conversational information seeking (CIS) has been recognized as a major emerging research area in information retrieval. Such research will require data and tools, to allow the implementation and study of conversational systems. This paper introduces Macaw, an open-source framework with a modular architecture for CIS research. Macaw supports multi-turn, multi-modal, and mixed-initiative interactions, and enables research for tasks such as document retrieval, question answering, recommendation, and structured data exploration. It has a modular design to encourage the study of new CIS algorithms, which can be evaluated in batch mode. It can also integrate with a user interface, which allows user studies and data collection in an interactive mode, where the back end can be fully algorithmic or a wizard of oz setup. Macaw is distributed under the MIT License.|sl:tag|tag:arxiv_doc
Similarity Search for Efficient Active Learning and Search of Rare Concepts  Similarity search for Efficient Active Learning and Search (SEALS)    In [Active Learning](tag:active_learning): instead of searching globally for the optimal examples to label, leverage the fact that data is often heavily skewed and expand the candidate pool with the nearest neighbors of the labeled set.     Our work attacks both the labeling and computational costs of machine learning...SEALS dramatically reduces the barrier to machine learning, enabling small teams or individuals to  build accurate classifiers. SEALS does, however, introduce another system component, a similarity  search index, which adds some additional engineering complexity to build, tune, and maintain.  Fortunately, several highly optimized implementations like Annoy and [Faiss](doc:2020/06/facebookresearch_faiss_a_libra) work reasonably well  out of the box. Many active learning and search approaches are intractable for industrial settings with billions of unlabeled examples. Existing approaches, such as uncertainty sampling or information density, search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. However, in practice, data is often heavily skewed; only a small fraction of collected data will be relevant for a given learning task. For example, when identifying rare classes, detecting malicious content, or debugging model performance, the ratio of positive to negative examples can be 1 to 1,000 or more. In this work, we exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round by only looking at the nearest neighbors to the labeled examples. Empirically, we observe that learned representations effectively cluster unseen concepts, making active learning very effective and substantially reducing the number of viable unlabeled examples. We evaluate several active learning and search techniques in this setting on three large-scale datasets: ImageNet, Goodreads spoiler detection, and OpenImages. For rare classes, active learning methods need as little as 0.31% of the labeled data to match the average precision of full supervision. By limiting active learning methods to only consider the immediate neighbors of the labeled data as candidates for labeling, we need only process as little as 1% of the unlabeled data while achieving similar reductions in labeling costs as the traditional global approach. This process of expanding the candidate pool with the nearest neighbors of the labeled set can be done efficiently and reduces the computational complexity of selection by orders of magnitude.|sl:arxiv_firstAuthor|Cody Coleman
Ben Adida|skos:broader|SW guys (and girls)
Shelley Powers|skos:broader|Technical girls and guys
Discounted cumulative gain|skos:broader|Ranking (information retrieval)
HATEOAS|skos:broader|Hypermedia
Geometry of language embeddings|skos:broader|Text Embeddings
Guerre de Yougoslavie|skos:broader|War
Language Models as Knowledge Bases? an analysis of the relational knowledge present in pretrained language models shows an ability of these models to recall factual knowledge  Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as fill-in-the-blank cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.|sl:tag|tag:arxiv_doc
Afrique de l'Est|skos:broader|Afrique
Coupe du monde 2010|skos:broader|Coupe du monde de football
Net Neutrality|skos:broader|Internet
Mirek Sopek|skos:broader|SW guys (and girls)
Facebook Open Graph|skos:broader|Facebook
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:tag|tag:knowledge_graph_completion
NLP@Google|skos:broader|AI@Google
Abeille|skos:broader|Insecte
Conditional random fields|skos:broader|Probabilistic Graphical Models
Information resources|skos:broader|URI
Backpropagation vs Biology|skos:broader|Brain vs Deep Learning
Bringing Light Into the Dark: A Large-scale Evaluation of Knowledge Graph Embedding Models Under a Unified Framework The heterogeneity in recently published knowledge graph embedding models' implementations, training, and evaluation has made fair and thorough comparisons difficult. In order to assess the reproducibility of previously published results, we re-implemented and evaluated 19 interaction models in the PyKEEN software package. Here, we outline which results could be reproduced with their reported hyper-parameters, which could only be reproduced with alternate hyper-parameters, and which could not be reproduced at all as well as provide insight as to why this might be the case. We then performed a large-scale benchmarking on four datasets with several thousands of experiments and 21,246 GPU hours of computation time. We present insights gained as to best practices, best configurations for each model, and where improvements could be made over previously published best configurations. Our results highlight that the combination of model architecture, training approach, loss function, and the explicit modeling of inverse relations is crucial for a model's performances, and not only determined by the model architecture. We provide evidence that several architectures can obtain results competitive to the state-of-the-art when configured carefully. We have made all code, experimental configurations, results, and analyses that lead to our interpretations available at https://github.com/pykeen/pykeen and https://github.com/pykeen/benchmarking|sl:arxiv_author|Volker Tresp
Realistic Re-evaluation of Knowledge Graph Completion Methods: An Experimental Study data redundancy (reverse relations), Cartesian product relations     A more fundamental defect  of these models is that the link prediction scenario, given  such data, is non-existent in the real-world In the active research area of employing embedding models for knowledge graph completion, particularly for the task of link prediction, most prior studies used two benchmark datasets FB15k and WN18 in evaluating such models. Most triples in these and other datasets in such studies belong to reverse and duplicate relations which exhibit high data redundancy due to semantic duplication, correlation or data incompleteness. This is a case of excessive data leakage---a model is trained using features that otherwise would not be available when the model needs to be applied for real prediction. There are also Cartesian product relations for which every triple formed by the Cartesian product of applicable subjects and objects is a true fact. Link prediction on the aforementioned relations is easy and can be achieved with even better accuracy using straightforward rules instead of sophisticated embedding models. A more fundamental defect of these models is that the link prediction scenario, given such data, is non-existent in the real-world. This paper is the first systematic study with the main objective of assessing the true effectiveness of embedding models when the unrealistic triples are removed. Our experiment results show these models are much less accurate than what we used to perceive. Their poor accuracy renders link prediction a task without truly effective automated solution. Hence, we call for re-investigation of possible effective approaches.|sl:arxiv_author|Wei Hu State Key Laboratory for Novel Software Technology, Nanjing University
Publishing RDF Vocabularies|skos:broader|RDF Vocabularies
Shelley Powers|skos:broader|SW guys (and girls)
Smartphone|skos:broader|Mobile device
Coursera: Deep Learning|skos:broader|Andrew Ng
Bricolage Mac|skos:broader|Bricolage
Clustering of text documents|skos:broader|NLP tasks / problems
Film argentin|skos:broader|Argentine
Linux hosting|skos:broader|Linux
Hierarchical text classification|skos:broader|Hierarchical Categories
Transfer learning|skos:broader|Machine learning
Learning Sparse, Distributed Representations using the Hebbian Principle The \fire together, wire together\ Hebbian model is a central principle for learning in neuroscience, but surprisingly, it has found limited applicability in modern machine learning. In this paper, we take a first step towards bridging this gap, by developing flavors of competitive Hebbian learning which produce sparse, distributed neural codes using online adaptation with minimal tuning The fire together, wire together Hebbian model is a central principle for learning in neuroscience, but surprisingly, it has found limited applicability in modern machine learning. In this paper, we take a first step towards bridging this gap, by developing flavors of competitive Hebbian learning which produce sparse, distributed neural codes using online adaptation with minimal tuning. We propose an unsupervised algorithm, termed Adaptive Hebbian Learning (AHL). We illustrate the distributed nature of the learned representations via output entropy computations for synthetic data, and demonstrate superior performance, compared to standard alternatives such as autoencoders, in training a deep convolutional net on standard image datasets.|sl:tag|tag:neuroscience_and_machine_learning
Attention Models in Graphs: A Survey  An attention mechanism aids a model by  allowing it to focus on the most relevant parts of the input to make decisions   Graph-structured data arise naturally in many different application domains. By representing data as graphs, we can capture entities (i.e., nodes) as well as their relationships (i.e., edges) with each other. Many useful insights can be derived from graph-structured data as demonstrated by an ever-growing body of work focused on graph mining. However, in the real-world, graphs can be both large - with many complex patterns - and noisy which can pose a problem for effective graph mining. An effective way to deal with this issue is to incorporate attention into graph mining solutions. An attention mechanism allows a method to focus on task-relevant parts of the graph, helping it to make better decisions. In this work, we conduct a comprehensive and focused survey of the literature on the emerging field of graph attention models. We introduce three intuitive taxonomies to group existing work. These are based on problem setting (type of input and output), the type of attention mechanism used, and the task (e.g., graph classification, link prediction, etc.). We motivate our taxonomies through detailed examples and use each to survey competing approaches from a unique standpoint. Finally, we highlight several challenges in the area and discuss promising directions for future work.|sl:arxiv_author|Eunyee Koh
Paul Graham|skos:broader|Technical girls and guys
Principal component analysis|skos:broader|Unsupervised machine learning
Industrie textile|skos:broader|industrie
Disque à retrouver|skos:broader|Souvenirs
The Description Length of Deep Learning Models  Solomonoff’s general theory of inference (Solomonoff, 1964) and the [Minimum Description Length Principle](tag:minimum_description_length_principle) (Grünwald, 2007; Rissanen, 2007) formalize [Occam's razor](tag:occam_s_razor), and hold that a good model of data is a model that is good at losslessly  compressing the data, including the cost of describing the model itself. Deep neural  networks might seem to go against this principle given the large number of  parameters to be encoded.  We demonstrate experimentally the ability of deep neural networks to compress  the training data even when accounting for parameter encoding. Solomonoff's general theory of inference and the Minimum Description Length principle formalize Occam's razor, and hold that a good model of data is a model that is good at losslessly compressing the data, including the cost of describing the model itself. Deep neural networks might seem to go against this principle given the large number of parameters to be encoded. We demonstrate experimentally the ability of deep neural networks to compress the training data even when accounting for parameter encoding. The compression viewpoint originally motivated the use of variational methods in neural networks. Unexpectedly, we found that these variational methods provide surprisingly poor compression bounds, despite being explicitly built to minimize such bounds. This might explain the relatively poor practical performance of variational methods in deep learning. On the other hand, simple incremental encoding methods yield excellent compression values on deep networks, vindicating Solomonoff's approach.|sl:tag|tag:arxiv_doc
Word sense / Lexical ambiguity|skos:broader|Ambiguity (NLP)
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:arxiv_author|Chris Tar
Word2vec|skos:broader|Word embeddings
DRM in HTML 5|skos:broader|DRM
Automating the search for a patent's prior art with a full text similarity search [github](https://github.com/helmersl/patent_similarity_search)    mouais     More than ever, technical inventions are the symbol of our society's advance. Patents guarantee their creators protection against infringement. For an invention being patentable, its novelty and inventiveness have to be assessed. Therefore, a search for published work that describes similar inventions to a given patent application needs to be performed. Currently, this so-called search for prior art is executed with semi-automatically composed keyword queries, which is not only time consuming, but also prone to errors. In particular, errors may systematically arise by the fact that different keywords for the same technical concepts may exist across disciplines. In this paper, a novel approach is proposed, where the full text of a given patent application is compared to existing patents using machine learning and natural language processing techniques to automatically detect inventions that are similar to the one described in the submitted document. Various state-of-the-art approaches for feature extraction and document comparison are evaluated. In addition to that, the quality of the current search process is assessed based on ratings of a domain expert. The evaluation results show that our automated approach, besides accelerating the search process, also improves the search results for prior art with respect to their quality.|sl:arxiv_author|Franziska Biegler
jQuery|skos:broader|JavaScript librairies
Government data as Linked Data|skos:broader|Government data
Distilling Structured Knowledge into Embeddings for Explainable and Accurate Recommendation distilling structured knowledge from a differentiable path-based recommendation model.     proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons Recently, the embedding-based recommendation models (e.g., matrix factorization and deep models) have been prevalent in both academia and industry due to their effectiveness and flexibility. However, they also have such intrinsic limitations as lacking explainability and suffering from data sparsity. In this paper, we propose an end-to-end joint learning framework to get around these limitations without introducing any extra overhead by distilling structured knowledge from a differentiable path-based recommendation model. Through extensive experiments, we show that our proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons.|sl:arxiv_author|Yuan Zhang
BERT Rediscovers the Classical NLP Pipeline  We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.   Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.|sl:arxiv_author|Ian Tenney
Silk Road|skos:broader|Dark Web
Protection de la nature|skos:broader|Nature
Maven tips|skos:broader|Tips
Pre-Trained Language Models|skos:broader|Language model
Memory requirements in NN|skos:broader|Mémoire (informatique)
RDF and social networks|skos:broader|RDF Application
Pologne|skos:broader|Pays d'Europe
Categorical Metadata Representation for Customized Text Classification  We observe that current representation methods for categorical metadata... are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category The performance of text classification has improved tremendously using intelligently engineered neural-based models, especially those injecting categorical metadata as additional information, e.g., using user/product information for sentiment classification. These information have been used to modify parts of the model (e.g., word embeddings, attention mechanisms) such that results can be customized according to the metadata. We observe that current representation methods for categorical metadata, which are devised for human consumption, are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category, and even such context is often scarce (for tail category). To this end, we propose to use basis vectors to effectively incorporate categorical metadata on various parts of a neural-based model. This additionally decreases the number of parameters dramatically, especially when the number of categorical features is large. Extensive experiments on various datasets with different properties are performed and show that through our method, we can represent categorical metadata more effectively to customize parts of the model, including unexplored ones, and increase the performance of the model greatly.|sl:tag|tag:category_embedding
Dictionary learning, or sparse coding, tries to learn a sparse linear code to represent the  given data succinctly.    Unsupervised learning algo. Images - edge detection (similar to primary visual cortex)    |skos:broader|techniques (mostly unsupervised learning algorithms) that learn a feature: a transformation of raw data input to a representation that can be effectively exploited in machine learning tasks    (= aim at discovering better representations of the inputs provided during training. Classical examples include principal components analysis and cluster analysis. Representation learning algorithms often attempt to preserve the information in their input but transform it in a way that makes it useful)  
Subword Semantic Hashing for Intent Classification on Small Datasets In this paper, we introduce the use of Semantic Hashing as embedding for the task of Intent Classification and achieve state-of-the-art performance on three frequently used benchmarks. Intent Classification on a small dataset is a challenging task for data-hungry state-of-the-art Deep Learning based systems. Semantic Hashing is an attempt to overcome such a challenge and learn robust text classification. Current word embedding based are dependent on vocabularies. One of the major drawbacks of such methods is out-of-vocabulary terms, especially when having small training datasets and using a wider vocabulary. This is the case in Intent Classification for chatbots, where typically small datasets are extracted from internet communication. Two problems arise by the use of internet communication. First, such datasets miss a lot of terms in the vocabulary to use word embeddings efficiently. Second, users frequently make spelling errors. Typically, the models for intent classification are not trained with spelling errors and it is difficult to think about ways in which users will make mistakes. Models depending on a word vocabulary will always face such issues. An ideal classifier should handle spelling errors inherently. With Semantic Hashing, we overcome these challenges and achieve state-of-the-art results on three datasets: AskUbuntu, Chatbot, and Web Application. Our benchmarks are available online: https://github.com/kumar-shridhar/Know-Your-Intent|sl:arxiv_author|Kumar Shridhar
Thèse IRIT-Renault: biblio initiale|skos:broader|Thèse IRIT-Renault: biblio
Calais|skos:broader|Thomson Reuters
aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (Most k-means-type algorithms require the number of clusters – k – to be specified in advance)|skos:broader|In machine learning, unsupervised learning refers to the problem of trying to find hidden structure in unlabeled data
Compressive Transformers for Long-Range Sequence Modelling  the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning.    [Blog post](/doc/2020/02/a_new_model_and_dataset_for_lon) We present the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning. We find the Compressive Transformer obtains state-of-the-art language modelling results in the WikiText-103 and Enwik8 benchmarks, achieving 17.1 ppl and 0.97 bpc respectively. We also find it can model high-frequency speech effectively and can be used as a memory mechanism for RL, demonstrated on an object matching task. To promote the domain of long-range sequence learning, we propose a new open-vocabulary language modelling benchmark derived from books, PG-19.|sl:arxiv_author|Anna Potapenko
TopBraid|skos:broader|Semantic Web : Tools
(aka paragraph2vec, aka sentence embeddings) extends word2vec algorithm to larger blocks of text (sentences, paragraphs or entire documents). Represents each document by a dense vector which is trained to predict words in the document.    Paragraph Vectors is the name of the model proposed by Le and Mikolov to generate unsupervised representations of sentences, paragraphs, or entire documents without losing local word order.    Implemented in [gensim](/tag/gensim)            |skos:broader|In practice, many NLP applications rely on a simple sentence embedding: the average of the  embeddings of the words in it. We can do better.    Ex of use (besides trivial ones such as classification and similarity): use sentence embeddings to cluster  sentences in documents, which aids in the automatic extraction  of key information from large bodies of text.  
Millennium Goal|skos:broader|Pauvreté
RDFJS|skos:broader|Javascript RDF
Enseignement scientifique|skos:broader|Education
Multi-hop reasonning|skos:broader|Question Answering
Plastic|skos:broader|Grands problèmes
VIE Vienna IKS Editables|skos:broader|JavaScript librairies
Boube Gado|skos:broader|Archéologue
RNN|skos:broader|ANN NN Artificial neural network
Littérature russe|skos:broader|Littérature
Sorbonne|skos:broader|Universités françaises
DeepWalk|skos:broader|Node Embeddings
delicious api|skos:broader|del.icio.us
Google Refine|skos:broader|Google
EMNLP 2018|skos:broader|NLP conference
Differentiable Reasoning over a Virtual Knowledge Base  We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases.    [(Bhuwan Dhingra PhD Thesis)](doc:2020/07/end_to_end_learning_with_text_) We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. On HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking approach to retrieving the relevant passages required to answer a question. DrKIT is also very efficient, processing 10-100x more queries per second than existing multi-hop systems.|sl:arxiv_author|William W. Cohen
The HSIC Bottleneck: Deep Learning without Back-Propagation  we show that it is possible to learn classification tasks at near competitive accuracy without  backpropagation, by maximizing a surrogate of the mutual information between hidden representations and labels and  simultaneously minimizing the mutual dependency between hidden representations and the inputs...  the hidden units of a network trained in this way form useful representations. Specifically, fully competitive accuracy  can be obtained by freezing the network trained without backpropagation and appending and training a one-layer  network using conventional SGD to convert convert the representation to the desired format.    The training method uses an approximation of the [#information bottleneck](/tag/information_bottleneck_method).    Advantages:     - The method facilitates parallel processing and requires significantly less operations.    - It does not suffer from exploding or vanishing gradients.   - It is biologically more plausible than Backpropagation     We introduce the HSIC (Hilbert-Schmidt independence criterion) bottleneck for training deep neural networks. The HSIC bottleneck is an alternative to the conventional cross-entropy loss and backpropagation that has a number of distinct advantages. It mitigates exploding and vanishing gradients, resulting in the ability to learn very deep networks without skip connections. There is no requirement for symmetric feedback or update locking. We find that the HSIC bottleneck provides performance on MNIST/FashionMNIST/CIFAR10 classification comparable to backpropagation with a cross-entropy target, even when the system is not encouraged to make the output resemble the classification labels. Appending a single layer trained with SGD (without backpropagation) to reformat the information further improves performance.|sl:tag|tag:neuroscience_and_machine_learning
Google Cloud Platform|skos:broader|Google Cloud
Large Memory Layers with Product Keys  a structured memory which can be easily integrated into a neural network. The memory is very large by design and therefore significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time.     a key-value memory layer that can increase model capacity for a negligible computational cost. A 12-layer transformer with a memory outperforms a 24-layer transformer, and is 2x faster!     [Implementation](/doc/2019/08/product_key_memory_pkm_minima) This paper introduces a structured memory which can be easily integrated into a neural network. The memory is very large by design and significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time. This memory layer allows us to tackle very large scale language modeling tasks. In our experiments we consider a dataset with up to 30 billion words, and we plug our memory layer in a state-of-the-art transformer-based architecture. In particular, we found that a memory augmented model with only 12 layers outperforms a baseline transformer model with 24 layers, while being twice faster at inference time. We release our code for reproducibility purposes.|sl:tag|tag:nlp_facebook
TV advertising|skos:broader|Publicité
Shallow parsing (Chunking)|skos:broader|NLP tasks / problems
Linked Learning 2012|skos:broader|WWW 2012
Traders|skos:broader|Finance
Semantic markup in HTML|skos:broader|Semantic Web
Bijan Parsia|skos:broader|Clark and Parsia
Fossile vivant|skos:broader|Paléontologie
Wikipedia page to concept|skos:broader|dbpedia
GRDDL|skos:broader|XSLT
Knowledge Graphs in NLP|skos:broader|Knowledge Graphs and NLP
Ouzbékistan|skos:broader|Asie centrale
Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks  Sentence-BERT  (SBERT), a modification of the pretrained  BERT network that use siamese and triplet network  structures to derive semantically meaningful  sentence embeddings that can be compared  using cosine-similarity.    Important because     - BERT ist unsuitable for semantic similarity  search as well as for unsupervised tasks  like clustering.  - simple methods such as using the CLS token give low quality sentence embeddings    However, the purpose of SBERT sentence embeddings  are not to be used for transfer learning for other  tasks.    [Related blog post](/doc/2020/01/richer_sentence_embeddings_usin); [Github](https://github.com/UKPLab/sentence-transformers) BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.|sl:arxiv_author|Iryna Gurevych
Facebook FAIR|skos:broader|AI@Facebook
Insectes fossiles|skos:broader|Insecte
Virtuoso Open-Source Edition|skos:broader|OpenLink Software
Brown Corpus|skos:broader|Text Corpora and Lexical Resources
Integrating Tomcat with Apache|skos:broader|Apache web server
A Survey on Deep Learning for Named Entity Recognition mainly focus on generic NEs in English language Named entity recognition (NER) is the task to identify mentions of rigid designators from text belonging to predefined semantic types such as person, location, organization etc. NER always serves as the foundation for many natural language applications such as question answering, text summarization, and machine translation. Early NER systems got a huge success in achieving good performance with the cost of human engineering in designing domain-specific features and rules. In recent years, deep learning, empowered by continuous real-valued vector representations and semantic composition through nonlinear processing, has been employed in NER systems, yielding stat-of-the-art performance. In this paper, we provide a comprehensive review on existing deep learning techniques for NER. We first introduce NER resources, including tagged NER corpora and off-the-shelf NER tools. Then, we systematically categorize existing works based on a taxonomy along three axes: distributed representations for input, context encoder, and tag decoder. Next, we survey the most representative methods for recent applied techniques of deep learning in new NER problem settings and applications. Finally, we present readers with the challenges faced by NER systems and outline future directions in this area.|sl:arxiv_author|Jianglei Han
Cinéma américain|skos:broader|Cinéma
EventKG: A Multilingual Event-Centric Temporal Knowledge Graph 690 thousand contemporary and historical events and over 2.3 million temporal relations One of the key requirements to facilitate semantic analytics of information regarding contemporary and historical events on the Web, in the news and in social media is the availability of reference knowledge repositories containing comprehensive representations of events and temporal relations. Existing knowledge graphs, with popular examples including DBpedia, YAGO and Wikidata, focus mostly on entity-centric information and are insufficient in terms of their coverage and completeness with respect to events and temporal relations. EventKG presented in this paper is a multilingual event-centric temporal knowledge graph that addresses this gap. EventKG incorporates over 690 thousand contemporary and historical events and over 2.3 million temporal relations extracted from several large-scale knowledge graphs and semi-structured sources and makes them available through a canonical representation.|sl:arxiv_author|Simon Gottschalk
PIMO|skos:broader|gnowsis
Poincaré Embeddings for Learning Hierarchical Representations  While complex symbolic datasets often exhibit a latent hierarchical structure, state-of-the-art methods typically learn embeddings in Euclidean vector spaces, which do not account for this property. For this purpose, we introduce a new approach for learning hierarchical representations of symbolic data by embedding them into hyperbolic space Representation learning has become an invaluable approach for learning from symbolic data such as text and graphs. However, while complex symbolic datasets often exhibit a latent hierarchical structure, state-of-the-art methods typically learn embeddings in Euclidean vector spaces, which do not account for this property. For this purpose, we introduce a new approach for learning hierarchical representations of symbolic data by embedding them into hyperbolic space -- or more precisely into an n-dimensional Poincar\\'e ball. Due to the underlying hyperbolic geometry, this allows us to learn parsimonious representations of symbolic data by simultaneously capturing hierarchy and similarity. We introduce an efficient algorithm to learn the embeddings based on Riemannian optimization and show experimentally that Poincar\\'e embeddings outperform Euclidean embeddings significantly on data with latent hierarchies, both in terms of representation capacity and in terms of generalization ability.|sl:arxiv_author|Maximilian Nickel
Sursauts gamma|skos:broader|Explosions cosmiques
Quoc V. Le|skos:broader|AI girls and guys
Pompe à eau|skos:broader|Irrigation
Faim|skos:broader|Alimentation
Deep Patent Landscaping Model Using Transformer and Graph Embedding a transformer encoder  for analyzing textual data present in patent documents  and a graph convolutional network for analyzing  patent metadata.    A benchmarking dataset for patent landscaping  based on patent trends reports published by the  Korean Patent Office. Data acquisition using Google's BigQuery public datasets.    10% improvement comparing to Google’s proposed Automated Patent Landscaping.    Empirical analysis of the importance of features (text vs metadata, citations vs classification)     Patent landscaping is a method used for searching related patents during a research and development (R&D) project. To avoid the risk of patent infringement and to follow current trends in technology, patent landscaping is a crucial task required during the early stages of an R&D project. As the process of patent landscaping requires advanced resources and can be tedious, the demand for automated patent landscaping has been gradually increasing. However, a shortage of well-defined benchmark datasets and comparable models makes it difficult to find related research studies. In this paper, we propose an automated patent landscaping model based on deep learning. To analyze the text of patents, the proposed model uses a modified transformer structure. To analyze the metadata of patents, we propose a graph embedding method that uses a diffusion graph called Diff2Vec. Furthermore, we introduce four benchmark datasets for comparing related research studies in patent landscaping. The datasets are produced by querying Google BigQuery, based on a search formula from a Korean patent attorney. The obtained results indicate that the proposed model and datasets can attain state-of-the-art performance, as compared with current patent landscaping models.|sl:arxiv_author|Eunjeong Lucy Park
Bourse|skos:broader|Economie
Volkswagen|skos:broader|Automobile
Relational Databases and the Semantic Web|skos:broader|RDF
Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks Current machine learning systems operate, almost exclusively, in a statistical, or model-free mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks. To demonstrate the essential role of such models, I will present a summary of seven tasks which are beyond reach of current machine learning systems and which have been accomplished using the tools of causal modeling.|sl:tag|tag:human_level_ai
Sécheresse|skos:broader|Eau
New Yorker|skos:broader|Presse
Universités américaines|skos:broader|Université
A Dual Embedding Space Model for Document Ranking Investigate neural word embeddings as a source of evidence in document ranking.    Presented in [this Stanford course on IR](/doc/?uri=https%3A%2F%2Fweb.stanford.edu%2Fclass%2Fcs276%2Fhandouts%2Flecture20-distributed-representations.pdf) by Chris Manning (starting slide 44)    They train a word2vec model, but retain both the input and the output projections.     During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs.      However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives A fundamental goal of search engines is to identify, given a query, documents that have relevant text. This is intrinsically difficult because the query and the document may use different vocabulary, or the document may contain query words without being relevant. We investigate neural word embeddings as a source of evidence in document ranking. We train a word2vec embedding model on a large unlabelled query corpus, but in contrast to how the model is commonly used, we retain both the input and the output projections, allowing us to leverage both the embedding spaces to derive richer distributional relationships. During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs. We postulate that the proposed Dual Embedding Space Model (DESM) captures evidence on whether a document is about a query term in addition to what is modelled by traditional term-frequency based approaches. Our experiments show that the DESM can re-rank top documents returned by a commercial Web search engine, like Bing, better than a term-matching based signal like TF-IDF. However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives, retrieving documents that are only loosely related to the query. We demonstrate that this problem can be solved effectively by ranking based on a linear mixture of the DESM and the word counting features.|sl:tag|tag:arxiv_doc
Ronan Collobert|skos:broader|NLP girls and guys
Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.|sl:tag|tag:acl_2019
Bookmarks|skos:broader|Brouteur
Stardust|skos:broader|Comet Wild 2
A La Carte Embedding|skos:broader|Rare words (NLP)
SW in Technical Automotive Documentation|skos:broader|Semantic Web : Application
Entity alignment@de|skos:broader|Entities
Hierarchical linear model|skos:broader|Regression analysis
DAO attack|skos:broader|The DAO
Knowledge Enhanced Contextual Word Representations General method to embed multiple knowledge bases into pre-trained language models (KB in the   sense as fixed collection of entity nodes)     The key idea is to explicitly model  entity spans in the input text and use an entity  linker to retrieve relevant entity embeddings from  a KB to form knowledge enhanced entity-span  representations.   Then,  update contextual word representations via a form of word-to-entity attention.    In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert's runtime is comparable to BERT's and it scales to large KBs.|sl:arxiv_author|Noah A. Smith
DANs (Deep Averaging Neural Networks)|skos:broader|Neural Bag of Words
ElasticSearch|skos:broader|Text Search
Flickr|skos:broader|photos online
Spotlight (OSX)|skos:broader|Mac OS X
A Strong Baseline for Learning Cross-Lingual Word Embeddings from Sentence Alignments While cross-lingual word embeddings have been studied extensively in recent years, the qualitative differences between the different algorithms remain vague. We observe that whether or not an algorithm uses a particular feature set (sentence IDs) accounts for a significant performance gap among these algorithms. This feature set is also used by traditional alignment algorithms, such as IBM Model-1, which demonstrate similar performance to state-of-the-art embedding algorithms on a variety of benchmarks. Overall, we observe that different algorithmic approaches for utilizing the sentence ID feature space result in similar performance. This paper draws both empirical and theoretical parallels between the embedding and alignment literature, and suggests that adding additional sources of information, which go beyond the traditional signal of bilingual sentence-aligned corpora, may substantially improve cross-lingual word embeddings, and that future baselines should at least take such features into account.|sl:arxiv_author|Yoav Goldberg
Turing test|skos:broader|Turing
Java 5|skos:broader|Java
Google Knowledge Graph|skos:broader|Semantic Web
A Tutorial on Distance Metric Learning: Mathematical Foundations, Algorithms and Experiments distance metric learning, a branch of machine learning that aims to learn distances from the data Distance metric learning is a branch of machine learning that aims to learn distances from the data. Distance metric learning can be useful to improve similarity learning algorithms, and also has applications in dimensionality reduction. This paper describes the distance metric learning problem and analyzes its main mathematical foundations. In addition, it also discusses some of the most popular distance metric learning techniques used in classification, showing their goals and the required information to understand and use them. Furthermore, some experiments to evaluate the performance of the different algorithms are also provided. Finally, this paper discusses several possibilities of future work in this topic.|sl:arxiv_firstAuthor|Juan Luis Suárez
Linked Data demo|skos:broader|Linked Data
CamemBERT|skos:broader|INRIA
Voice recognition Speech recognition|skos:broader|Sequence Modeling Seq2Seq
Dave Reynolds|skos:broader|Technical girls and guys
Peter Mika|skos:broader|Yahoo!
RDF graphs|skos:broader|RDF
Tchernobyl|skos:broader|Catastrophe écologique
The Case for Learned Index Structures  we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs  Indexes are models: a B-Tree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term learned indexes. The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show, that by using neural nets we are able to outperform cache-optimized B-Trees by up to 70% in speed while saving an order-of-magnitude in memory over several real-world data sets. More importantly though, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work just provides a glimpse of what might be possible.|sl:arxiv_author|Neoklis Polyzotis
A Comparative Study of Word Embeddings for Reading Comprehension abstract:   The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on    1.  the use of pre-trained word embeddings, and  2. the representation of out-of-vocabulary tokens at test time,     can turn out to have a larger impact than architectural choices on the final performance         The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on (1) the use of pre-trained word embeddings, and (2) the representation of out-of-vocabulary tokens at test time, can turn out to have a larger impact than architectural choices on the final performance. We systematically explore several options for these choices, and provide recommendations to researchers working in this area.|sl:tag|tag:nlp_reading_comprehension
summly|skos:broader|iphone app
Self-driving car|skos:broader|Automotive
css/html templates|skos:broader|css
Barack's Wife Hillary: Using Knowledge-Graphs for Fact-Aware Language Modeling  a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset, a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark. In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language model's ability to complete sentences requiring factual knowledge, showing that the KGLM outperforms even very large language models in generating facts.|sl:tag|tag:language_model
iPod|skos:broader|Apple
Ranked Entities in Search Results|skos:broader|Entities
Cassini|skos:broader|NASA
A Theoretical Analysis of Contrastive Unsupervised Representation Learning [blog post](/doc/?uri=http%3A%2F%2Fwww.offconvex.org%2F2019%2F03%2F19%2FCURL%2F) Recent empirical works have successfully used unlabeled data to learn feature representations that are broadly useful in downstream classification tasks. Several of these methods are reminiscent of the well-known word2vec embedding algorithm: leveraging availability of pairs of semantically similar data points and negative samples, the learner forces the inner product of representations of similar pairs with each other to be higher on average than with negative samples. The current paper uses the term contrastive learning for such algorithms and presents a theoretical framework for analyzing them by introducing latent classes and hypothesizing that semantically similar points are sampled from the same latent class. This framework allows us to show provable guarantees on the performance of the learned representations on the average classification task that is comprised of a subset of the same set of latent classes. Our generalization bound also shows that learned representations can reduce (labeled) sample complexity on downstream tasks. We conduct controlled experiments in both the text and image domains to support the theory.|sl:tag|tag:embeddings
Philae|skos:broader|Rosetta
Datao|skos:broader|Semantic Web search engine
Phrase embeddings|skos:broader|Phrases (NLP)
data.gouv.fr|skos:broader|Open Data
Hello Edge: Keyword Spotting on Microcontrollers Keyword spotting (KWS) is a critical component for enabling speech based user interactions on smart devices. It requires real-time response and high accuracy for good user experience. Recently, neural networks have become an attractive choice for KWS architecture because of their superior accuracy compared to traditional speech processing algorithms. Due to its always-on nature, KWS application has highly constrained power budget and typically runs on tiny microcontrollers with limited memory and compute capability. The design of neural network architecture for KWS must consider these constraints. In this work, we perform neural network architecture evaluation and exploration for running KWS on resource-constrained microcontrollers. We train various neural network architectures for keyword spotting published in literature to compare their accuracy and memory/compute requirements. We show that it is possible to optimize these neural network architectures to fit within the memory and compute constraints of microcontrollers without sacrificing accuracy. We further explore the depthwise separable convolutional neural network (DS-CNN) and compare it against other neural network architectures. DS-CNN achieves an accuracy of 95.4%, which is ~10% higher than the DNN model with similar number of parameters.|sl:arxiv_firstAuthor|Yundong Zhang
Histropedia|skos:broader|Histoire
Zero-shot Entity Linking with Dense Entity Retrieval We consider the zero-shot entity-linking challenge where each entity is defined by a short textual description, and the model must read these descriptions together with the mention context to make the final linking decisions. In this setting, retrieving entity candidates can be particularly challenging, since many of the common linking cues such as entity alias tables and link popularity are not available. In this paper, we introduce a simple and effective two stage approach for zero-shot linking, based on fine-tuned BERT architectures. In the first stage, we do retrieval in a dense space defined by a bi-encoder that independently embeds the mention context and the entity descriptions. Each candidate is then examined more carefully with a cross-encoder, that concatenates the mention and entity text. Our approach achieves a nearly 5 point absolute gain on a recently introduced zero-shot entity linking benchmark, driven largely by improvements over previous IR-based candidate retrieval. We also show that it performs well in the non-zero-shot setting, obtaining the state-of-the-art result on TACKBP-2010.|sl:tag|tag:blink
Minoen|skos:broader|Langues
Named Entity Disambiguation using Deep Learning on Graphs Evaluation of different deep learning techniques to create  a context vector from graphs, aimed at high-accuracy NED. (neural  approach for entity disambiguation using graphs as background  knowledge)     We tackle Named Entity Disambiguation (NED) by comparing entities  in short sentences with Wikidata graphs. Creating a context vector  from graphs through deep learning is a challenging problem that has  never been applied to NED. Our main contribution is to present an  experimental study of recent neural techniques, as well as a discussion  about which graph features are most important for the disambiguation  task...    [published paper](https://rd.springer.com/chapter/10.1007/978-3-030-15719-7_10)      In NED, the system  must be able to generate a context for an entity in a text and an entity  in a knowledge base, then correctly link the two.    Explore whether representing graphs  as triplets is more useful than using the full topological information of the graph    We tackle \\ac{NED} by comparing entities in short sentences with \\wikidata{} graphs. Creating a context vector from graphs through deep learning is a challenging problem that has never been applied to \\ac{NED}. Our main contribution is to present an experimental study of recent neural techniques, as well as a discussion about which graph features are most important for the disambiguation task. In addition, a new dataset (\\wikidatadisamb{}) is created to allow a clean and scalable evaluation of \\ac{NED} with \\wikidata{} entries, and to be used as a reference in future research. In the end our results show that a \\ac{Bi-LSTM} encoding of the graph triplets performs best, improving upon the baseline models and scoring an \ m{F1} value of $91.6\\%$ on the \\wikidatadisamb{} test set|sl:tag|tag:entity_linking
Docker-Mac|skos:broader|Docker
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.|sl:arxiv_firstAuthor|Yarin Gal
Java 8 lambdas|skos:broader|Lambda calculus
KDE|skos:broader|Linux
SWRL|skos:broader|Rules
Musique en ligne|skos:broader|Digital Media
LDA|skos:broader|Topic model
LD-PATCH|skos:broader|HTTP PATCH
Evaluation of sentence embeddings in downstream and linguistic probing tasks a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets     We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.           Despite the fast developmental pace of new sentence embedding methods, it is still challenging to find comprehensive evaluations of these different techniques. In the past years, we saw significant improvements in the field of sentence embeddings and especially towards the development of universal sentence encoders that could provide inductive transfer to a wide variety of downstream tasks. In this work, we perform a comprehensive evaluation of recent methods using a wide variety of downstream and linguistic feature probing tasks. We show that a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets. We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.|sl:arxiv_author|Christian S. Perone
Roosevelt|skos:broader|Président des USA
Censure et maltraitance animale|skos:broader|Justice
Uriqr|skos:broader|Linking Open Data
Latent Semantic Analysis|skos:broader|NLP techniques
PyDev|skos:broader|Python
Semantic Vector Encoding and Similarity Search Using Fulltext Search Engines  The ubiquity of semantic vector space modeling raises the challenge of efficient searching in dense, high-dimensional vector spaces. We would naturally want to take advantage of the design and optimizations behind modern fulltext engines like Elasticsearch so as to meet the scalability and robustness demands of modern IR applications. This is the research challenge addressed in this paper.   The paper describes novel ways of encoding dense vectors into text documents, allowing the use of traditional inverted index engines.    [blog post](https://rare-technologies.com/semantic-search-fulltext-engine-acl-2017/)   Vector representations and vector space modeling (VSM) play a central role in modern machine learning. We propose a novel approach to `vector similarity searching' over dense semantic representations of words and documents that can be deployed on top of traditional inverted-index-based fulltext engines, taking advantage of their robustness, stability, scalability and ubiquity. We show that this approach allows the indexing and querying of dense vectors in text domains. This opens up exciting avenues for major efficiency gains, along with simpler deployment, scaling and monitoring. The end result is a fast and scalable vector database with a tunable trade-off between vector search performance and quality, backed by a standard fulltext engine such as Elasticsearch. We empirically demonstrate its querying performance and quality by applying this solution to the task of semantic searching over a dense vector representation of the entire English Wikipedia.|sl:tag|tag:arxiv_doc
Specializing Word Embeddings (for Parsing) by Information Bottleneck EMNLP best paper award. [Related blog post](doc:2020/06/information_bottleneck_for_nlp_) Pre-trained word embeddings like ELMo and BERT contain rich syntactic and semantic information, resulting in state-of-the-art performance on various tasks. We propose a very fast variational information bottleneck (VIB) method to nonlinearly compress these embeddings, keeping only the information that helps a discriminative parser. We compress each word embedding to either a discrete tag or a continuous vector. In the discrete version, our automatically compressed tags form an alternative tag set: we show experimentally that our tags capture most of the information in traditional POS tag annotations, but our tag sequences can be parsed more accurately at the same level of tag granularity. In the continuous version, we show experimentally that moderately compressing the word embeddings by our method yields a more accurate parser in 8 of 9 languages, unlike simple dimensionality reduction.|sl:tag|tag:emnlp_2019
Good explanation is this [blog post by D. Britz](/doc/?uri=http%3A%2F%2Fwww.wildml.com%2F2016%2F01%2Fattention-and-memory-in-deep-learning-and-nlp%2F). (But the best explanation related to attention is to be found in this [post](/doc/2019/08/transformers_from_scratch_%7C_pet) about Self-Attention.)     While simple Seq2Seq builds a single context vector out of the encoder’s last hidden state, attention creates  shortcuts between the context vector and the entire source input: the context vector has access to the entire input sequence.  The decoder can “attend” to different parts of the source sentence at each step of the output generation, and the model learns what to attend to based on the input sentence and what it has produced so far.    Possible to interpret what the model is doing by looking at the Attention weight matrix    Cost: We need to calculate an attention value for each combination of input and output word (D. Britz: - attention is a bit of a misnomer: we look at everything in details before deciding what to focus on)                    |skos:broader|a set of algorithms in machine learning that attempt to model high-level abstractions in data by using architectures composed of multiple non-linear transformations. Deep learning is part of a broader family of machine learning methods based on learning representations of data.    One of the promises of deep learning is replacing handcrafted features with efficient algorithms for unsupervised or semi-supervised feature learning and hierarchical feature extraction    With Deep Learning, Ng says, you just give the system a lot of data so it can discover by itself what some of the concepts in the world are ([cf.](http://www.wired.com/2013/05/neuro-artificial-intelligence/all/))  
Dependency Injection|skos:broader|Inversion of Control
GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden unit), or embedding-free units such as image pixels.|sl:tag|tag:transfer_learning
URIs within URIs|skos:broader|URI
The Case for Learned Index Structures  we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs  Indexes are models: a B-Tree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term learned indexes. The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show, that by using neural nets we are able to outperform cache-optimized B-Trees by up to 70% in speed while saving an order-of-magnitude in memory over several real-world data sets. More importantly though, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work just provides a glimpse of what might be possible.|sl:tag|tag:ml_google
Brain-computer interface|skos:broader|Nous vivons une époque moderne
AI: dangers|skos:broader|Artificial Intelligence
A practical tutorial on autoencoders for nonlinear feature fusion: Taxonomy, models, software and guidelines Many of the existing machine learning algorithms, both supervised and unsupervised, depend on the quality of the input characteristics to generate a good model. The amount of these variables is also important, since performance tends to decline as the input dimensionality increases, hence the interest in using feature fusion techniques, able to produce feature sets that are more compact and higher level. A plethora of procedures to fuse original variables for producing new ones has been developed in the past decades. The most basic ones use linear combinations of the original variables, such as PCA (Principal Component Analysis) and LDA (Linear Discriminant Analysis), while others find manifold embeddings of lower dimensionality based on non-linear combinations, such as Isomap or LLE (Linear Locally Embedding) techniques. More recently, autoencoders (AEs) have emerged as an alternative to manifold learning for conducting nonlinear feature fusion. Dozens of AE models have been proposed lately, each with its own specific traits. Although many of them can be used to generate reduced feature sets through the fusion of the original ones, there also AEs designed with other applications in mind. The goal of this paper is to provide the reader with a broad view of what an AE is, how they are used for feature fusion, a taxonomy gathering a broad range of models, and how they relate to other classical techniques. In addition, a set of didactic guidelines on how to choose the proper AE for a given task is supplied, together with a discussion of the software tools available. Finally, two case studies illustrate the usage of AEs with datasets of handwritten digits and breast cancer.|sl:arxiv_author|Salvador García
Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data Word embeddings are a popular approach to unsupervised learning of word relationships that are widely used in natural language processing. In this article, we present a new set of embeddings for medical concepts learned using an extremely large collection of multimodal medical data. Leaning on recent theoretical insights, we demonstrate how an insurance claims database of 60 million members, a collection of 20 million clinical notes, and 1.7 million full text biomedical journal articles can be combined to embed concepts into a common space, resulting in the largest ever set of embeddings for 108,477 medical concepts. To evaluate our approach, we present a new benchmark methodology based on statistical power specifically designed to test embeddings of medical concepts. Our approach, called cui2vec, attains state-of-the-art performance relative to previous methods in most instances. Finally, we provide a downloadable set of pre-trained embeddings for other researchers to use, as well as an online tool for interactive exploration of the cui2vec embeddings|sl:arxiv_author|Xu Shi
Knowledge Graph + Deep Learning|skos:broader|AI + Knowledge Bases
Extrémophiles|skos:broader|Curiosité naturelle
KIWI project|skos:broader|Commission européenne
A Theoretical Analysis of Contrastive Unsupervised Representation Learning [blog post](/doc/?uri=http%3A%2F%2Fwww.offconvex.org%2F2019%2F03%2F19%2FCURL%2F) Recent empirical works have successfully used unlabeled data to learn feature representations that are broadly useful in downstream classification tasks. Several of these methods are reminiscent of the well-known word2vec embedding algorithm: leveraging availability of pairs of semantically similar data points and negative samples, the learner forces the inner product of representations of similar pairs with each other to be higher on average than with negative samples. The current paper uses the term contrastive learning for such algorithms and presents a theoretical framework for analyzing them by introducing latent classes and hypothesizing that semantically similar points are sampled from the same latent class. This framework allows us to show provable guarantees on the performance of the learned representations on the average classification task that is comprised of a subset of the same set of latent classes. Our generalization bound also shows that learned representations can reduce (labeled) sample complexity on downstream tasks. We conduct controlled experiments in both the text and image domains to support the theory.|sl:tag|tag:noise_contrastive_estimation
Économie écologique|skos:broader|Écologie
Learning by Abstraction: The Neural State Machine  Given an image, we first predict a probabilistic graph  that represents its underlying semantics and serves as a structured world model.  Then, we perform sequential reasoning over the graph, iteratively traversing its  nodes to answer a given question or draw a new inference. In contrast to most  neural architectures that are designed to closely interact with the raw sensory  data, our model operates instead in an abstract latent space, by transforming both  the visual and linguistic modalities into semantic concept-based representations,  thereby achieving enhanced transparency and modularity.     Drawing inspiration from [Bengio’s consciousness prior](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1709.08568)... We introduce the Neural State Machine, seeking to bridge the gap between the neural and symbolic views of AI and integrate their complementary strengths for the task of visual reasoning. Given an image, we first predict a probabilistic graph that represents its underlying semantics and serves as a structured world model. Then, we perform sequential reasoning over the graph, iteratively traversing its nodes to answer a given question or draw a new inference. In contrast to most neural architectures that are designed to closely interact with the raw sensory data, our model operates instead in an abstract latent space, by transforming both the visual and linguistic modalities into semantic concept-based representations, thereby achieving enhanced transparency and modularity. We evaluate our model on VQA-CP and GQA, two recent VQA datasets that involve compositionality, multi-step inference and diverse reasoning skills, achieving state-of-the-art results in both cases. We provide further experiments that illustrate the model's strong generalization capacity across multiple dimensions, including novel compositions of concepts, changes in the answer distribution, and unseen linguistic structures, demonstrating the qualities and efficacy of our approach.|sl:arxiv_author|Drew A. Hudson
XLNet: Generalized Autoregressive Pretraining for Language Understanding a new pretraining method for NLP that significantly improves upon BERT on 20 tasks (e.g., SQuAD, GLUE, RACE) With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.|sl:arxiv_author|Zihang Dai
Brains in silicon Neuromorphique Neuromorphic engineering|skos:broader|Cerveau
String theory|skos:broader|Physics
Leonardo da Vinci|skos:broader|Scientifique
Question Answering over Knowledge Graphs via Structural Query Patterns Natural language question answering over knowledge graphs is an important and interesting task as it enables common users to gain accurate answers in an easy and intuitive manner. However, it remains a challenge to bridge the gap between unstructured questions and structured knowledge graphs. To address the problem, a natural discipline is building a structured query to represent the input question. Searching the structured query over the knowledge graph can produce answers to the question. Distinct from the existing methods that are based on semantic parsing or templates, we propose an effective approach powered by a novel notion, structural query pattern, in this paper. Given an input question, we first generate its query sketch that is compatible with the underlying structure of the knowledge graph. Then, we complete the query graph by labeling the nodes and edges under the guidance of the structural query pattern. Finally, answers can be retrieved by executing the constructed query graph over the knowledge graph. Evaluations on three question answering benchmarks show that our proposed approach outperforms state-of-the-art methods significantly.|sl:tag|tag:question_answering
Katie Portwin|skos:broader|Technical girls and guys
Hierarchical clustering of text documents|skos:broader|Clustering of text documents
HTTPS|skos:broader|Cybersecurity Sécurité informatique
OSEMA/DERI-Renault paper|skos:broader|OSEMA 2011
Londres|skos:broader|Royaume Uni
Extracting Tables from Documents using Conditional Generative Adversarial Networks and Genetic Algorithms Extracting information from tables in documents presents a significant challenge in many industries and in academic research. Existing methods which take a bottom-up approach of integrating lines into cells and rows or columns neglect the available prior information relating to table structure. Our proposed method takes a top-down approach, first using a generative adversarial network to map a table image into a standardised `skeleton' table form denoting the approximate row and column borders without table content, then fitting renderings of candidate latent table structures to the skeleton structure using a distance measure optimised by a genetic algorithm.|sl:arxiv_author|Nataliya Le Vine
Film danois|skos:broader|Film
CWL|skos:broader|Web sémantique sw
Pre-trained Models for Natural Language Processing: A Survey Recently, the emergence of pre-trained models (PTMs) has brought natural language processing (NLP) to a new era. In this survey, we provide a comprehensive review of PTMs for NLP. We first briefly introduce language representation learning and its research progress. Then we systematically categorize existing PTMs based on a taxonomy with four perspectives. Next, we describe how to adapt the knowledge of PTMs to the downstream tasks. Finally, we outline some potential directions of PTMs for future research. This survey is purposed to be a hands-on guide for understanding, using, and developing PTMs for various NLP tasks.|sl:arxiv_author|Tianxiang Sun
RDF Access to Relational Databases|skos:broader|RDF and database
Matière noire|skos:broader|Physics
Mauritanie|skos:broader|Afrique de l'Ouest
Describing a Knowledge Base We aim to automatically generate natural language descriptions about an input structured knowledge base (KB). We build our generation framework based on a pointer network which can copy facts from the input KB, and add two attention mechanisms: (i) slot-aware attention to capture the association between a slot type and its corresponding slot value; and (ii) a new \\emph{table position self-attention} to capture the inter-dependencies among related slots. For evaluation, besides standard metrics including BLEU, METEOR, and ROUGE, we propose a KB reconstruction based metric by extracting a KB from the generation output and comparing it with the input KB. We also create a new data set which includes 106,216 pairs of structured KBs and their corresponding natural language descriptions for two distinct entity types. Experiments show that our approach significantly outperforms state-of-the-art methods. The reconstructed KB achieves 68.8% - 72.6% F-score.|sl:tag|tag:arxiv_doc
Aaron Swartz|skos:broader|Technical girls and guys
Photo numérique|skos:broader|Photo
DocBERT: BERT for Document Classification We present, to our knowledge, the first application of BERT to document classification. A few characteristics of the task might lead one to think that BERT is not the most appropriate model: syntactic structures matter less for content categories, documents can often be longer than typical BERT input, and documents often have multiple labels. Nevertheless, we show that a straightforward classification model using BERT is able to achieve the state of the art across four popular datasets. To address the computational expense associated with BERT inference, we distill knowledge from BERT-large to small bidirectional LSTMs, reaching BERT-base parity on multiple datasets using 30x fewer parameters. The primary contribution of our paper is improved baselines that can provide the foundation for future work.|sl:tag|tag:bert
Cambridge Analytica|skos:broader|DeleteFB
Cross-Origin Resource Sharing|skos:broader|JavaScript
Mac OS X|skos:broader|OS
Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs [GitHub](https://github.com/deepakn97/relationPrediction) [Blog post](/doc/2020/04/deepak_nathani_%7C_pay_attention_) The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention based feature embedding that captures both entity and relation features in any given entity's neighborhood. Additionally, we also encapsulate relation clusters and multihop relations in our model. Our empirical study offers insights into the efficacy of our attention based model and we show marked performance gains in comparison to state of the art methods on all datasets.|sl:tag|tag:knowledge_graph_embeddings
Pape|skos:broader|Catholicisme
Layered Graph Embedding for Entity Recommendation using Wikipedia in the Yahoo! Knowledge Graph an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia In this paper, we describe an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia. Through offline and online evaluations, we show that the resulting embeddings and recommendations perform well in terms of quality and user engagement. Balancing simplicity and quality, this framework provides default entity recommendations for English and other languages in the Yahoo! Knowledge Graph, which Wikipedia is a core subset of.|sl:arxiv_author|Kin Sum Liu
Abel Prize|skos:broader|Mathématiques
Street art|skos:broader|Art
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:tag|tag:arxiv_doc
Exploring the Limits of Language Modeling recent advances in Recurrent Neural Networks for large scale Language Modeling In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon.|sl:tag|tag:arxiv_doc
Semanlink|skos:broader|Dev
RDF123|skos:broader|Excel and SW
JSONP|skos:broader|cross-domain data fetching
Virtual knowledge graph|skos:broader|Knowledge Graphs
NLP Teams|skos:broader|NLP
Knowledge Enhanced Contextual Word Representations General method to embed multiple knowledge bases into pre-trained language models (KB in the   sense as fixed collection of entity nodes)     The key idea is to explicitly model  entity spans in the input text and use an entity  linker to retrieve relevant entity embeddings from  a KB to form knowledge enhanced entity-span  representations.   Then,  update contextual word representations via a form of word-to-entity attention.    In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert's runtime is comparable to BERT's and it scales to large KBs.|sl:tag|tag:knowbert
Classification under the  restriction that we may only observe a single example of  each possible class before making a prediction about a test  instance.|skos:broader|Machine learning focuses on prediction, based on known properties learned from the training data. Data mining (which is the analysis step of Knowledge Discovery in Databases) focuses on the discovery of (previously) unknown properties on the data.    [Glossary (by google)](https://developers.google.com/machine-learning/glossary/)
Guillaume Lample|skos:broader|NLP girls and guys
Fascisme|skos:broader|Extrème droite
CERN|skos:broader|Recherche
DNA nanotechnology|skos:broader|Nanotechnologies
Aïchi|skos:broader|Exposition universelle
Covid19: incompétence gouvernementale|skos:broader|Covid19
Stacked Approximated Regression Machine: A Simple Deep Learning Approach This paper seems too good to be true! They can train a VGG-like net VERY quickly to good accuracy, without backprop. With the agreement of my coauthors, I Zhangyang Wang would like to withdraw the manuscript Stacked Approximated Regression Machine: A Simple Deep Learning Approach. Some experimental procedures were not included in the manuscript, which makes a part of important claims not meaningful. In the relevant research, I was solely responsible for carrying out the experiments; the other coauthors joined in the discussions leading to the main algorithm. Please see the updated text for more details.|sl:arxiv_author|Honghui Shi
Entity alignment@de|skos:broader|Combining knowledge graphs
Antiquité romaine|skos:broader|Rome
SOAP|skos:broader|XML
Part Of Speech Tagging|skos:broader|Sequence labeling
Similarity Search for Efficient Active Learning and Search of Rare Concepts  Similarity search for Efficient Active Learning and Search (SEALS)    In [Active Learning](tag:active_learning): instead of searching globally for the optimal examples to label, leverage the fact that data is often heavily skewed and expand the candidate pool with the nearest neighbors of the labeled set.     Our work attacks both the labeling and computational costs of machine learning...SEALS dramatically reduces the barrier to machine learning, enabling small teams or individuals to  build accurate classifiers. SEALS does, however, introduce another system component, a similarity  search index, which adds some additional engineering complexity to build, tune, and maintain.  Fortunately, several highly optimized implementations like Annoy and [Faiss](doc:2020/06/facebookresearch_faiss_a_libra) work reasonably well  out of the box. Many active learning and search approaches are intractable for industrial settings with billions of unlabeled examples. Existing approaches, such as uncertainty sampling or information density, search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. However, in practice, data is often heavily skewed; only a small fraction of collected data will be relevant for a given learning task. For example, when identifying rare classes, detecting malicious content, or debugging model performance, the ratio of positive to negative examples can be 1 to 1,000 or more. In this work, we exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round by only looking at the nearest neighbors to the labeled examples. Empirically, we observe that learned representations effectively cluster unseen concepts, making active learning very effective and substantially reducing the number of viable unlabeled examples. We evaluate several active learning and search techniques in this setting on three large-scale datasets: ImageNet, Goodreads spoiler detection, and OpenImages. For rare classes, active learning methods need as little as 0.31% of the labeled data to match the average precision of full supervision. By limiting active learning methods to only consider the immediate neighbors of the labeled data as candidates for labeling, we need only process as little as 1% of the unlabeled data while achieving similar reductions in labeling costs as the traditional global approach. This process of expanding the candidate pool with the nearest neighbors of the labeled set can be done efficiently and reduces the computational complexity of selection by orders of magnitude.|sl:tag|tag:ai_stanford
Rosée|skos:broader|Eau
Text Generation from Knowledge Graphs with Graph Transformers Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.|sl:arxiv_author|Hannaneh Hajishirzi
Bricolage Mac|skos:broader|Macintosh
RDF/binary|skos:broader|RDF
Document Embedding with Paragraph Vectors Paragraph Vectors has been recently proposed as an unsupervised method for learning distributed representations for pieces of texts. In their work, the authors showed that the method can learn an embedding of movie review texts which can be leveraged for sentiment analysis. That proof of concept, while encouraging, was rather narrow. Here we consider tasks other than sentiment analysis, provide a more thorough comparison of Paragraph Vectors to other document modelling algorithms such as Latent Dirichlet Allocation, and evaluate performance of the method as we vary the dimensionality of the learned representation. We benchmarked the models on two document similarity data sets, one from Wikipedia, one from arXiv. We observe that the Paragraph Vector method performs significantly better than other methods, and propose a simple improvement to enhance embedding quality. Somewhat surprisingly, we also show that much like word embeddings, vector operations on Paragraph Vectors can perform useful semantic results.|sl:tag|tag:christopher_olah
Cinéma africain|skos:broader|Cinéma
My old things|skos:broader|fps
Word Translation Without Parallel Data  we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent studies showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally describe experiments on the English-Esperanto low-resource language pair, on which there only exists a limited amount of parallel data, to show the potential impact of our method in fully unsupervised machine translation. Our code, embeddings and dictionaries are publicly available.|sl:tag|tag:arxiv_doc
A La Carte Embedding|skos:broader|Sentence Embeddings
Richard Cyganiak|skos:broader|SW guys (and girls)
TabFact: A Large-scale Dataset for Table-based Fact Verification fact verification given semi-structured data as evidence The problem of verifying whether a textual hypothesis holds based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation. However, existing studies are mainly restricted to dealing with unstructured evidence (e.g., natural language sentences and documents, news, etc), while verification under structured evidence, such as tables, graphs, and databases, remains under-explored. This paper specifically aims to study the fact verification given semi-structured data as evidence. To this end, we construct a large-scale dataset called TabFact with 16k Wikipedia tables as the evidence for 118k human-annotated natural language statements, which are labeled as either ENTAILED or REFUTED. TabFact is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning. To address these reasoning challenges, we design two different models: Table-BERT and Latent Program Algorithm (LPA). Table-BERT leverages the state-of-the-art pre-trained language model to encode the linearized tables and statements into continuous vectors for verification. LPA parses statements into programs and executes them against the tables to obtain the returned binary value for verification. Both methods achieve similar accuracy but still lag far behind human performance. We also perform a comprehensive analysis to demonstrate great future opportunities. The data and code of the dataset are provided in \\url{https://github.com/wenhuchen/Table-Fact-Checking}.|sl:arxiv_author|Shiyang Li
Bidirectional LSTM-CRF Models for Sequence Tagging In this paper, we propose a variety of Long Short-Term Memory (LSTM) based models for sequence tagging. These models include LSTM networks, bidirectional LSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer (LSTM-CRF) and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work is the first to apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model to NLP benchmark sequence tagging data sets. We show that the BI-LSTM-CRF model can efficiently use both past and future input features thanks to a bidirectional LSTM component. It can also use sentence level tag information thanks to a CRF layer. The BI-LSTM-CRF model can produce state of the art (or close to) accuracy on POS, chunking and NER data sets. In addition, it is robust and has less dependence on word embedding as compared to previous observations.|sl:tag|tag:arxiv_doc
Wiki markup|skos:broader|Text tools
Lesk algorithm|skos:broader|Distributional semantics
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:arxiv_author|Braden Hancock
SPARQL Update|skos:broader|Read-Write Linked Data
foaf|skos:broader|RDF and social networks
hyperdoc2vec: Distributed Representations of Hypertext Documents Hypertext documents, such as web pages and academic papers, are of great importance in delivering information in our daily life. Although being effective on plain documents, conventional text embedding methods suffer from information loss if directly adapted to hyper-documents. In this paper, we propose a general embedding approach for hyper-documents, namely, hyperdoc2vec, along with four criteria characterizing necessary information that hyper-document embedding models should preserve. Systematic comparisons are conducted between hyperdoc2vec and several competitors on two tasks, i.e., paper classification and citation recommendation, in the academic paper domain. Analyses and experiments both validate the superiority of hyperdoc2vec to other models w.r.t. the four criteria.|sl:tag|tag:arxiv_doc
Yahoo - My Web 2.0|skos:broader|Yahoo!
D2RQ|skos:broader|SQL to RDF mapping
[Best presentation](doc:2020/06/on_word_embeddings) about word embeddings, by [Sebastian Ruder](tag:sebastian_ruder)    Capture the idea that one can express “meaning” of words using a vector, so that the cosine of the angle between the vectors captures semantic similarity.    A set of language modeling and feature learning techniques where words from the vocabulary (and possibly phrases thereof) are mapped to vectors of real numbers in a low dimensional space, relative to the vocabulary size.     ~ Context-predicting models    ~ Latent feature representations of words    Paramaterized function mapping words in some language to vectors (perhaps 200 to 500 dimensions). Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with much lower dimension.    Plongement lexical in French    Word embedding of a word: a succinct representation of the distribution of other words around this word.    Methods to generate the mapping include neural networks, dimensionality reduction on the word co-occurrence matrix, probabilistic models, and explicit representation in terms of the context in which words appear.    In the new generation of models, the vector estimation problem is handled as a supervised task, where the weights in a word vector are set to maximize the probability of the contexts in which the word is observed in the corpus    The mapping may be generated training a neural network on a large corpus to predict a word given a context (Continuous Bag Of Words model) or to predict the context given a word (skip gram model). The context is a window of surrounding words.    The most known software to produce word embeddings is Tomas Mikolov's Word2vec. Pre-trained word embeddings are also available in the word2vec code.google page.    Applications:     - search document ranking  - boost the performance in NLP tasks such as syntactic parsing and sentiment analysis.          |skos:broader|Methods for quantifying and categorizing semantic similarities between linguistic items based on their distributional properties in large samples of language data.    Basic idea: the Distributional hypothesis: linguistic items with similar distributions have similar meanings.    Basic approach: collect distributional information in high-dimensional vectors, and define similarity in terms of vector similarity    Models: latent semantic analysis (LSA), Hyperspace Analogue to Language (HAL), syntax- or dependency-based models, random indexing, semantic folding and various variants of the topic model.      
KnowBert|skos:broader|Knowledge-driven embeddings
Semantic Web project|skos:broader|Semantic Web
Ludovic Denoyer|skos:broader|NLP girls and guys
Python-NLP|skos:broader|NLP tools
Darwin|skos:broader|Evolution
Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data Word embeddings are a popular approach to unsupervised learning of word relationships that are widely used in natural language processing. In this article, we present a new set of embeddings for medical concepts learned using an extremely large collection of multimodal medical data. Leaning on recent theoretical insights, we demonstrate how an insurance claims database of 60 million members, a collection of 20 million clinical notes, and 1.7 million full text biomedical journal articles can be combined to embed concepts into a common space, resulting in the largest ever set of embeddings for 108,477 medical concepts. To evaluate our approach, we present a new benchmark methodology based on statistical power specifically designed to test embeddings of medical concepts. Our approach, called cui2vec, attains state-of-the-art performance relative to previous methods in most instances. Finally, we provide a downloadable set of pre-trained embeddings for other researchers to use, as well as an online tool for interactive exploration of the cui2vec embeddings|sl:tag|tag:medical_data
GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden unit), or embedding-free units such as image pixels.|sl:arxiv_author|Kaiming He
SWEO: Renault use case|skos:broader|SW in Technical Automotive Documentation
Phrase embeddings|skos:broader|Embeddings in NLP
Philippe Cudré-Mauroux|skos:broader|SW guys (and girls)
Configuration ontology|skos:broader|fps ontologies
Cinéma africain|skos:broader|Art d'Afrique
Galileo (spacecraft)|skos:broader|Missions spatiales
Attention + Knowledge Graphs|skos:broader|Attention in Graphs
Knowledge Graphs in NLP|skos:broader|NLP: using Knowledge
A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efficient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximally preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We first introduce the formal definition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work address these challenges in their solutions. Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efficiency, problem settings, techniques and application scenarios.|sl:tag|tag:graph_embeddings
Zero-shot Entity Linking with Dense Entity Retrieval We consider the zero-shot entity-linking challenge where each entity is defined by a short textual description, and the model must read these descriptions together with the mention context to make the final linking decisions. In this setting, retrieving entity candidates can be particularly challenging, since many of the common linking cues such as entity alias tables and link popularity are not available. In this paper, we introduce a simple and effective two stage approach for zero-shot linking, based on fine-tuned BERT architectures. In the first stage, we do retrieval in a dense space defined by a bi-encoder that independently embeds the mention context and the entity descriptions. Each candidate is then examined more carefully with a cross-encoder, that concatenates the mention and entity text. Our approach achieves a nearly 5 point absolute gain on a recently introduced zero-shot entity linking benchmark, driven largely by improvements over previous IR-based candidate retrieval. We also show that it performs well in the non-zero-shot setting, obtaining the state-of-the-art result on TACKBP-2010.|sl:arxiv_author|Martin Josifoski
Reagan|skos:broader|Chef d'état
The Consciousness Prior consciousness seen as the formation of a low-dimensional combination of a few concepts constituting a conscious thought, i.e., consciousness as awareness at a particular time instant: the projection of a big vector (all the things conscious and unconscious in brain). Attention: additional mechanism describing what mind chooses to focus on.    [YouTube video](/doc/?uri=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYr1mOzC93xs) A new prior is proposed for learning representations of high-level concepts of the kind we manipulate with language. This prior can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by cognitive neuroscience theories of consciousness, seen as a bottleneck through which just a few elements, after having been selected by attention from a broader pool, are then broadcast and condition further processing, both in perception and decision-making. The set of recently selected elements one becomes aware of is seen as forming a low-dimensional conscious state. This conscious state is combining the few concepts constituting a conscious thought, i.e., what one is immediately conscious of at a particular moment. We claim that this architectural and information-processing constraint corresponds to assumptions about the joint distribution between high-level concepts. To the extent that these assumptions are generally true (and the form of natural language seems consistent with them), they can form a useful prior for representation learning. A low-dimensional thought or conscious state is analogous to a sentence: it involves only a few variables and yet can make a statement with very high probability of being true. This is consistent with a joint distribution (over high-level concepts) which has the form of a sparse factor graph, i.e., where the dependencies captured by each factor of the factor graph involve only very few variables while creating a strong dip in the overall energy function. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in a form similar to facts and rules, albeit capturing uncertainty as well as efficient search mechanisms implemented by attention mechanisms.|sl:arxiv_firstAuthor|Yoshua Bengio
Cyc|skos:broader|Artificial Intelligence
Java profiling|skos:broader|Java dev
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.|sl:tag|tag:uncertainty_in_deep_learning
Bidirectional LSTM-CRF Models for Sequence Tagging In this paper, we propose a variety of Long Short-Term Memory (LSTM) based models for sequence tagging. These models include LSTM networks, bidirectional LSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer (LSTM-CRF) and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work is the first to apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model to NLP benchmark sequence tagging data sets. We show that the BI-LSTM-CRF model can efficiently use both past and future input features thanks to a bidirectional LSTM component. It can also use sentence level tag information thanks to a CRF layer. The BI-LSTM-CRF model can produce state of the art (or close to) accuracy on POS, chunking and NER data sets. In addition, it is robust and has less dependence on word embedding as compared to previous observations.|sl:tag|tag:named_entity_recognition
Cloud based LOD platform|skos:broader|Cloud and Linked Data
AI 4 IP|skos:broader|NLP: use cases
Knowledge Vault|skos:broader|Google
Freedom Box|skos:broader|Internet libre
SL|skos:broader|favorites
Ténéré|skos:broader|Désert
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:tag|tag:survey
Large Memory Layers with Product Keys  a structured memory which can be easily integrated into a neural network. The memory is very large by design and therefore significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time.     a key-value memory layer that can increase model capacity for a negligible computational cost. A 12-layer transformer with a memory outperforms a 24-layer transformer, and is 2x faster!     [Implementation](/doc/2019/08/product_key_memory_pkm_minima) This paper introduces a structured memory which can be easily integrated into a neural network. The memory is very large by design and significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time. This memory layer allows us to tackle very large scale language modeling tasks. In our experiments we consider a dataset with up to 30 billion words, and we plug our memory layer in a state-of-the-art transformer-based architecture. In particular, we found that a memory augmented model with only 12 layers outperforms a baseline transformer model with 24 layers, while being twice faster at inference time. We release our code for reproducibility purposes.|sl:tag|tag:attention_is_all_you_need
HTTP Redirect|skos:broader|HTTP
Marklogic|skos:broader|NOSQL
Dev|skos:broader|Technologie
faiss|skos:broader|Machine Learning library
Chômage|skos:broader|Economie
Disco Hyperdata Browser|skos:broader|RDF browser
Publicité Internet|skos:broader|Publicité
NLP + Sem web|skos:broader|NLP
Président des USA|skos:broader|Chef d'état
YouTube video|skos:broader|YouTube
Génocide|skos:broader|Crime contre l'Humanité
Ontologies: use cases|skos:broader|Ontologies
Neural Ranking Models with Weak Supervision Main Idea: To leverage large amounts of unsupervised data to infer “weak” labels and use that signal for learning supervised models as if we had the ground truth labels. See [blog post](/doc/?uri=http%3A%2F%2Fmostafadehghani.com%2F2017%2F04%2F23%2Fbeating-the-teacher-neural-ranking-models-with-weak-supervision%2F):     This is truly awesome since we have only used  BM25 as the supervisor to train a model which performs better than BM25 itself!   Despite the impressive improvements achieved by unsupervised deep neural networks in computer vision and NLP tasks, such improvements have not yet been observed in ranking for information retrieval. The reason may be the complexity of the ranking problem, as it is not obvious how to learn from queries and documents when no supervised signal is available. Hence, in this paper, we propose to train a neural ranking model using weak supervision, where labels are obtained automatically without human annotators or any external resources (e.g., click data). To this aim, we use the output of an unsupervised ranking model, such as BM25, as a weak supervision signal. We further train a set of simple yet effective ranking models based on feed-forward neural networks. We study their effectiveness under various learning scenarios (point-wise and pair-wise models) and using different input representations (i.e., from encoding query-document pairs into dense/sparse vectors to using word embedding representation). We train our networks using tens of millions of training instances and evaluate it on two standard collections: a homogeneous news collection(Robust) and a heterogeneous large-scale web collection (ClueWeb). Our experiments indicate that employing proper objective functions and letting the networks to learn the input representation based on weakly supervised data leads to impressive performance, with over 13% and 35% MAP improvements over the BM25 model on the Robust and the ClueWeb collections. Our findings also suggest that supervised neural ranking models can greatly benefit from pre-training on large amounts of weakly labeled data that can be easily obtained from unsupervised IR models.|sl:arxiv_author|Aliaksei Severyn
Differentiable Reasoning over a Virtual Knowledge Base  We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases.    [(Bhuwan Dhingra PhD Thesis)](doc:2020/07/end_to_end_learning_with_text_) We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. On HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking approach to retrieving the relevant passages required to answer a question. DrKIT is also very efficient, processing 10-100x more queries per second than existing multi-hop systems.|sl:arxiv_author|Graham Neubig
Folksonomies vs ontologies|skos:broader|Folksonomy
SDMX-RDF|skos:broader|SDMX
China's Social Credit System|skos:broader|Big Brother
Large-scale Multi-label Learning with Missing Labels The multi-label classification problem has generated significant interest in recent years. However, existing approaches do not adequately address two key challenges: (a) the ability to tackle problems with a large number (say millions) of labels, and (b) the ability to handle data with missing labels. In this paper, we directly address both these problems by studying the multi-label problem in a generic empirical risk minimization (ERM) framework. Our framework, despite being simple, is surprisingly able to encompass several recent label-compression based methods which can be derived as special cases of our method. To optimize the ERM problem, we develop techniques that exploit the structure of specific loss functions - such as the squared loss function - to offer efficient algorithms. We further show that our learning framework admits formal excess risk bounds even in the presence of missing labels. Our risk bounds are tight and demonstrate better generalization performance for low-rank promoting trace-norm regularization when compared to (rank insensitive) Frobenius norm regularization. Finally, we present extensive empirical results on a variety of benchmark datasets and show that our methods perform significantly better than existing label compression based methods and can scale up to very large datasets such as the Wikipedia dataset.|sl:arxiv_author|Prateek Jain
Lord's Resistance Army|skos:broader|Ouganda
Mobile phone|skos:broader|Téléphone
Antibiotic resistance|skos:broader|Antibiotiques
JAX-RS|skos:broader|Java
Extinction de masse de la fin du permien|skos:broader|Paléontologie
Genetic Programming|skos:broader|Evolution
Semantic Web Services|skos:broader|Semantic Web
NMT|skos:broader|Traduction automatique
Energies renouvelables|skos:broader|Energie
Improving Entity Linking by Modeling Latent Entity Type Information Existing state of the art neural entity linking models employ attention-based bag-of-words context model and pre-trained entity embeddings bootstrapped from word embeddings to assess topic level context compatibility. However, the latent entity type information in the immediate context of the mention is neglected, which causes the models often link mentions to incorrect entities with incorrect type. To tackle this problem, we propose to inject latent entity type information into the entity embeddings based on pre-trained BERT. In addition, we integrate a BERT-based entity similarity score into the local context model of a state-of-the-art model to better capture latent entity type information. Our model significantly outperforms the state-of-the-art entity linking models on standard benchmark (AIDA-CoNLL). Detailed experiment analysis demonstrates that our model corrects most of the type errors produced by the direct baseline.|sl:arxiv_author|Chin-Yew Lin
Monsanto|skos:broader|Entreprise
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|Sabbir M. Rashid
Private wiki|skos:broader|Wiki
KGE KG embedding Knowledge graph embedding|skos:broader|KR
Bookmarks|skos:broader|Tagging
Google Visualization API|skos:broader|API
Learning Semantic Similarity for Very Short Texts In order to pair short text  fragments—as a concatenation of separate words—an adequate  distributed sentence representation is needed. Main contribution: a first step towards a hybrid method that  combines the strength of dense distributed representations—  as opposed to sparse term matching—with the strength of  tf-idf based methods. The combination of word embeddings and tf-idf  information might lead to a better model for semantic content  within very short text fragments. Levering data on social media, such as Twitter and Facebook, requires information retrieval algorithms to become able to relate very short text fragments to each other. Traditional text similarity methods such as tf-idf cosine-similarity, based on word overlap, mostly fail to produce good results in this case, since word overlap is little or non-existent. Recently, distributed word representations, or word embeddings, have been shown to successfully allow words to match on the semantic level. In order to pair short text fragments - as a concatenation of separate words - an adequate distributed sentence representation is needed, in existing literature often obtained by naively combining the individual word representations. We therefore investigated several text representations as a combination of word embeddings in the context of semantic pair matching. This paper investigates the effectiveness of several such naive techniques, as well as traditional tf-idf similarity, for fragments of different lengths. Our main contribution is a first step towards a hybrid method that combines the strength of dense distributed representations - as opposed to sparse term matching - with the strength of tf-idf based methods to automatically reduce the impact of less informative terms. Our new approach outperforms the existing techniques in a toy experimental set-up, leading to the conclusion that the combination of word embeddings and tf-idf information might lead to a better model for semantic content within very short text fragments.|sl:arxiv_author|Bart Dhoedt
Tim Cook|skos:broader|Apple
ERNIE: Enhanced Language Representation with Informative Entities  We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.|sl:tag|tag:nlp_using_knowledge_graphs
LinkNBed: Multi-Graph Representation Learning with Entity Linkage   a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure     We posit that combining  graph alignment task with deep representation  learning across multi-relational graphs has potential  to induce a synergistic effect on both tasks Knowledge graphs have emerged as an important model for studying complex multi-relational data. This has given rise to the construction of numerous large scale but incomplete knowledge graphs encoding information extracted from various resources. An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledge-based inference for many downstream applications. To this end, we propose LinkNBed, a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure. Experiments on link prediction and entity linkage demonstrate substantial improvements over the state-of-the-art relational learning approaches.|sl:tag|tag:arxiv_doc
Eric Schmidt|skos:broader|Google
Configuration and SW|skos:broader|Constraints in the SW
VoCamp|skos:broader|Barcamp
(aka paragraph2vec, aka sentence embeddings) extends word2vec algorithm to larger blocks of text (sentences, paragraphs or entire documents). Represents each document by a dense vector which is trained to predict words in the document.    Paragraph Vectors is the name of the model proposed by Le and Mikolov to generate unsupervised representations of sentences, paragraphs, or entire documents without losing local word order.    Implemented in [gensim](/tag/gensim)            |skos:broader|group of related models that are used to produce word embeddings
Mécanique quantique|skos:broader|Physique
Kaguya|skos:broader|Lune
Court métrage|skos:broader|Cinéma
Googling|skos:broader|Google
Improving Entity Linking by Modeling Latent Entity Type Information Existing state of the art neural entity linking models employ attention-based bag-of-words context model and pre-trained entity embeddings bootstrapped from word embeddings to assess topic level context compatibility. However, the latent entity type information in the immediate context of the mention is neglected, which causes the models often link mentions to incorrect entities with incorrect type. To tackle this problem, we propose to inject latent entity type information into the entity embeddings based on pre-trained BERT. In addition, we integrate a BERT-based entity similarity score into the local context model of a state-of-the-art model to better capture latent entity type information. Our model significantly outperforms the state-of-the-art entity linking models on standard benchmark (AIDA-CoNLL). Detailed experiment analysis demonstrates that our model corrects most of the type errors produced by the direct baseline.|sl:tag|tag:arxiv_doc
CIMBA|skos:broader|Linked Data Platform
Redland|skos:broader|RDF Tools
Magie noire|skos:broader|Magie
Europe écologie|skos:broader|Verts
Grands Singes|skos:broader|Singe
Extrème droite|skos:broader|Politique
Auvergne|skos:broader|France
Einstein|skos:broader|Physique
LDA2vec|skos:broader|Latent Dirichlet allocation
Graph-based Text Representations|skos:broader|Graph
Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call fooling images (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.|sl:tag|tag:image_recognition
TF-IDF|skos:broader|Probabilistic relevance model
HTML Dev|skos:broader|Dev
Requin|skos:broader|Poisson
Automotive AND W3C|skos:broader|Automobile 2.0
Transfer Learning for Sequence Labeling Using Source Model and Target Data use-case ex: NER when the target data contains new categories In this paper, we propose an approach for transferring the knowledge of a neural model for sequence labeling, learned from the source domain, to a new model trained on a target domain, where new label categories appear. Our transfer learning (TL) techniques enable to adapt the source model using the target data and new categories, without accessing to the source data. Our solution consists in adding new neurons in the output layer of the target model and transferring parameters from the source model, which are then fine-tuned with the target data. Additionally, we propose a neural adapter to learn the difference between the source and the target label distribution, which provides additional important information to the target model. Our experiments on Named Entity Recognition show that (i) the learned knowledge in the source model can be effectively transferred when the target data contains new categories and (ii) our neural adapter further improves such transfer.|sl:arxiv_author|Alessandro Moschitti
Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks Current machine learning systems operate, almost exclusively, in a statistical, or model-free mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks. To demonstrate the essential role of such models, I will present a summary of seven tasks which are beyond reach of current machine learning systems and which have been accomplished using the tools of causal modeling.|sl:tag|tag:judea_pearl
fps AND LDOW2008|skos:broader|Linking Enterprise Data
Île Maurice|skos:broader|Afrique
On Extractive and Abstractive Neural Document Summarization with Transformer Language Models  Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper. We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We show that this extractive step significantly improves summarization results. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher rouge scores. Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper.|sl:tag|tag:attention_is_all_you_need
CoKE: Contextualized Knowledge Graph Embedding A method to build contextualized entity and relation embeddings. Entities and relations may appear in different graph contexts. Edges and paths, both formulated as sequences of entities and relations, are passed as input to a Transformer encoder to learn the contextualized representations..    [Github](https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE) Knowledge graph embedding, which projects symbolic entities and relations into continuous vector spaces, is gaining increasing attention. Previous methods allow a single static embedding for each entity or relation, ignoring their intrinsic contextual nature, i.e., entities and relations may appear in different graph contexts, and accordingly, exhibit different properties. This work presents Contextualized Knowledge Graph Embedding (CoKE), a novel paradigm that takes into account such contextual nature, and learns dynamic, flexible, and fully contextualized entity and relation embeddings. Two types of graph contexts are studied: edges and paths, both formulated as sequences of entities and relations. CoKE takes a sequence as input and uses a Transformer encoder to obtain contextualized representations. These representations are hence naturally adaptive to the input, capturing contextual meanings of entities and relations therein. Evaluation on a wide variety of public benchmarks verifies the superiority of CoKE in link prediction and path query answering. It performs consistently better than, or at least equally well as current state-of-the-art in almost every case, in particular offering an absolute improvement of 21.0% in H@10 on path query answering. Our code is available at \\url{https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE}.|sl:arxiv_author|Haifeng Wang
Boucle ferroviaire d’Afrique de l’Ouest|skos:broader|Train
Mur de Berlin|skos:broader|Communisme
Sem web: context|skos:broader|Semantic Web Dev
Piggy Bank|skos:broader|Ajax
SPARQL Tutorial|skos:broader|Tutorial
Alexandre le Grand|skos:broader|Grèce antique
Film japonais|skos:broader|Film
Burkina Faso|skos:broader|Afrique de l'Ouest
BERT-of-Theseus: Compressing BERT by Progressive Module Replacing approach to compress BERT by progressive module replacing.     Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter    [Github](https://github.com/JetRunner/BERT-of-Theseus) In this paper, we propose a novel model compression approach to effectively compress BERT by progressive module replacing. Our approach first divides the original BERT into several modules and builds their compact substitutes. Then, we randomly replace the original modules with their substitutes to train the compact modules to mimic the behavior of the original modules. We progressively increase the probability of replacement through the training. In this way, our approach brings a deeper level of interaction between the original and compact models, and smooths the training process. Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter, liberating human effort from hyper-parameter tuning. Our approach outperforms existing knowledge distillation approaches on GLUE benchmark, showing a new perspective of model compression.|sl:arxiv_author|Ming Zhou
Thought alone controlled device|skos:broader|Pensée
Fujitsu|skos:broader|Entreprise
NLTK|skos:broader|NLP tools
Inverse-functional properties|skos:broader|OWL
Apache Hive|skos:broader|Big Data Tools
Spark (Java web framework)|skos:broader|RESTful Web Services
Pédagogie numérique|skos:broader|Enseignement
Axoum|skos:broader|Archéologie africaine
Ivan Herman|skos:broader|W3C
ARQ|skos:broader|Andy Seaborne
Music source separation|skos:broader|IA/ML: domaines d'application
Linking Enterprise Data|skos:broader|Enterprise Data
Linear Algebraic Structure of Word Senses, with Applications to Polysemy  Here it is shown that multiple word senses reside  in linear superposition within the word  embedding and simple sparse coding can recover  vectors that approximately capture the  senses     Each extracted word sense is accompanied by one of about  2000 “discourse atoms” that gives a succinct description of which other words co-occur with that word sense.     The success of the approach is mathematically explained using a variant of  the random walk on discourses model    (random walk: a generative model for language). Under the assumptions of this model,  there  exists a linear relationship between the vector of a  word w and the vectors of the words in its contexts (It is not the average of the words in w's context, but in a given corpus the matrix of the linear relationship does not depend on w. It can be estimated, and so we can compute the embedding of a word from the contexts it belongs to)    [Related blog post](/doc/?uri=https%3A%2F%2Fwww.offconvex.org%2F2016%2F07%2F10%2Fembeddingspolysemy%2F)   Word embeddings are ubiquitous in NLP and information retrieval, but it is unclear what they represent when the word is polysemous. Here it is shown that multiple word senses reside in linear superposition within the word embedding and simple sparse coding can recover vectors that approximately capture the senses. The success of our approach, which applies to several embedding methods, is mathematically explained using a variant of the random walk on discourses model (Arora et al., 2016). A novel aspect of our technique is that each extracted word sense is accompanied by one of about 2000 discourse atoms that gives a succinct description of which other words co-occur with that word sense. Discourse atoms can be of independent interest, and make the method potentially more useful. Empirical tests are used to verify and support the theory.|sl:tag|tag:emnlp_2018
Evaluation of sentence embeddings in downstream and linguistic probing tasks a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets     We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.           Despite the fast developmental pace of new sentence embedding methods, it is still challenging to find comprehensive evaluations of these different techniques. In the past years, we saw significant improvements in the field of sentence embeddings and especially towards the development of universal sentence encoders that could provide inductive transfer to a wide variety of downstream tasks. In this work, we perform a comprehensive evaluation of recent methods using a wide variety of downstream and linguistic feature probing tasks. We show that a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets. We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.|sl:arxiv_author|Thomas S. Paula
Australia's evolutionary history|skos:broader|Evolution
\Better entity LINKing\, @facebookai open-source entity linker. [GitHub](https://github.com/facebookresearch/BLINK)|skos:broader|each entity is defined by a short textual description, and the model must read these descriptions together with the mention context to make the linking decisions. 
Panama papers|skos:broader|Paradis fiscaux
Anzo|skos:broader|TripleStore
Building Machines That Learn and Think Like People  we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations   Recent progress in artificial intelligence (AI) has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn, and how they learn it. Specifically, we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models.|sl:arxiv_author|Tomer D. Ullman
BERT-of-Theseus: Compressing BERT by Progressive Module Replacing approach to compress BERT by progressive module replacing.     Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter    [Github](https://github.com/JetRunner/BERT-of-Theseus) In this paper, we propose a novel model compression approach to effectively compress BERT by progressive module replacing. Our approach first divides the original BERT into several modules and builds their compact substitutes. Then, we randomly replace the original modules with their substitutes to train the compact modules to mimic the behavior of the original modules. We progressively increase the probability of replacement through the training. In this way, our approach brings a deeper level of interaction between the original and compact models, and smooths the training process. Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter, liberating human effort from hyper-parameter tuning. Our approach outperforms existing knowledge distillation approaches on GLUE benchmark, showing a new perspective of model compression.|sl:tag|tag:bert
Semantic Web: Life Sciences|skos:broader|Biology
Chimpanzé|skos:broader|Grands Singes
Darwin|skos:broader|Scientifique
Chico Buarque|skos:broader|Musicien
Semantic SEO|skos:broader|SEO
Glue|skos:broader|Firefox extension
Mexique|skos:broader|Amérique
Juliana Rotich|skos:broader|Afrique
Java Server Faces|skos:broader|Java
GloVe|skos:broader|Global Semantic Context
AI@Amazon|skos:broader|Artificial Intelligence
delicious java|skos:broader|Tagging
TabFact: A Large-scale Dataset for Table-based Fact Verification fact verification given semi-structured data as evidence The problem of verifying whether a textual hypothesis holds based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation. However, existing studies are mainly restricted to dealing with unstructured evidence (e.g., natural language sentences and documents, news, etc), while verification under structured evidence, such as tables, graphs, and databases, remains under-explored. This paper specifically aims to study the fact verification given semi-structured data as evidence. To this end, we construct a large-scale dataset called TabFact with 16k Wikipedia tables as the evidence for 118k human-annotated natural language statements, which are labeled as either ENTAILED or REFUTED. TabFact is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning. To address these reasoning challenges, we design two different models: Table-BERT and Latent Program Algorithm (LPA). Table-BERT leverages the state-of-the-art pre-trained language model to encode the linearized tables and statements into continuous vectors for verification. LPA parses statements into programs and executes them against the tables to obtain the returned binary value for verification. Both methods achieve similar accuracy but still lag far behind human performance. We also perform a comprehensive analysis to demonstrate great future opportunities. The data and code of the dataset are provided in \\url{https://github.com/wenhuchen/Table-Fact-Checking}.|sl:arxiv_author|Hongmin Wang
A Comparative Study of Word Embeddings for Reading Comprehension abstract:   The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on    1.  the use of pre-trained word embeddings, and  2. the representation of out-of-vocabulary tokens at test time,     can turn out to have a larger impact than architectural choices on the final performance         The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on (1) the use of pre-trained word embeddings, and (2) the representation of out-of-vocabulary tokens at test time, can turn out to have a larger impact than architectural choices on the final performance. We systematically explore several options for these choices, and provide recommendations to researchers working in this area.|sl:arxiv_author|Ruslan Salakhutdinov
Attention Models in Graphs: A Survey  An attention mechanism aids a model by  allowing it to focus on the most relevant parts of the input to make decisions   Graph-structured data arise naturally in many different application domains. By representing data as graphs, we can capture entities (i.e., nodes) as well as their relationships (i.e., edges) with each other. Many useful insights can be derived from graph-structured data as demonstrated by an ever-growing body of work focused on graph mining. However, in the real-world, graphs can be both large - with many complex patterns - and noisy which can pose a problem for effective graph mining. An effective way to deal with this issue is to incorporate attention into graph mining solutions. An attention mechanism allows a method to focus on task-relevant parts of the graph, helping it to make better decisions. In this work, we conduct a comprehensive and focused survey of the literature on the emerging field of graph attention models. We introduce three intuitive taxonomies to group existing work. These are based on problem setting (type of input and output), the type of attention mechanism used, and the task (e.g., graph classification, link prediction, etc.). We motivate our taxonomies through detailed examples and use each to survey competing approaches from a unique standpoint. Finally, we highlight several challenges in the area and discuss promising directions for future work.|sl:tag|tag:arxiv_doc
Andrew Ng|skos:broader|Technical girls and guys
Grèce|skos:broader|Pays d'Europe
K-BERT: Enabling Language Representation with Knowledge Graph a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by equipped with a KG without pre-training by-self because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts.|sl:tag|tag:arxiv_doc
Russie|skos:broader|Pays d'Europe
CoKE: Contextualized Knowledge Graph Embedding A method to build contextualized entity and relation embeddings. Entities and relations may appear in different graph contexts. Edges and paths, both formulated as sequences of entities and relations, are passed as input to a Transformer encoder to learn the contextualized representations..    [Github](https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE) Knowledge graph embedding, which projects symbolic entities and relations into continuous vector spaces, is gaining increasing attention. Previous methods allow a single static embedding for each entity or relation, ignoring their intrinsic contextual nature, i.e., entities and relations may appear in different graph contexts, and accordingly, exhibit different properties. This work presents Contextualized Knowledge Graph Embedding (CoKE), a novel paradigm that takes into account such contextual nature, and learns dynamic, flexible, and fully contextualized entity and relation embeddings. Two types of graph contexts are studied: edges and paths, both formulated as sequences of entities and relations. CoKE takes a sequence as input and uses a Transformer encoder to obtain contextualized representations. These representations are hence naturally adaptive to the input, capturing contextual meanings of entities and relations therein. Evaluation on a wide variety of public benchmarks verifies the superiority of CoKE in link prediction and path query answering. It performs consistently better than, or at least equally well as current state-of-the-art in almost every case, in particular offering an absolute improvement of 21.0% in H@10 on path query answering. Our code is available at \\url{https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE}.|sl:arxiv_author|Jing Liu
Multi-Task Deep Neural Networks for Natural Language Understanding outperforms BERT in nine of eleven benchmark NLP tasks In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations in order to adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7% (2.2% absolute improvement). We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. The code and pre-trained models are publicly available at https://github.com/namisan/mt-dnn.|sl:arxiv_author|Jianfeng Gao
Ajax|skos:broader|XML
ANN NN Artificial neural network|skos:broader|IA AI
Nicolas Hulot|skos:broader|Télévision
Commission européenne|skos:broader|Europe
localization|skos:broader|Dev
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|David Raposo
Tesla, Inc|skos:broader|Automobile
Chris Manning|skos:broader|AI girls and guys
Singular value decomposition|skos:broader|Linear algebra
Visualizing and Measuring the Geometry of BERT  At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.|sl:tag|tag:bertology
Logistic regression|skos:broader|Machine learning: techniques
Large scale distributed neural network training through online distillation   we use codistillation to refer to distillation performed:   1. using the same architecture for all the models;   2. using the same dataset to train all the models; and   3. using the distillation loss during training before any model has fully converged.     In general, we believe the quality gains of codistillation over well-tuned offline distillation will be  minor in practice and the more interesting research direction is exploring codistillation as a distributed  training algorithm     Codistillation with  the same data seems to be slightly better than the baseline, but codistillation using different data  gets much better results. These results show that the codistilling models are indeed successfully  transmitting useful information about different parts of the training data to each other.    Related to [Deep mutual learning](doc:2020/05/1706_00384_deep_mutual_learni) paper Techniques such as ensembling and distillation promise model quality improvements when paired with almost any base model. However, due to increased test-time cost (for ensembles) and increased complexity of the training pipeline (for distillation), these techniques are challenging to use in industrial settings. In this paper we explore a variant of distillation which is relatively straightforward to use as it does not require a complicated multi-stage setup or many new hyperparameters. Our first claim is that online distillation enables us to use extra parallelism to fit very large datasets about twice as fast. Crucially, we can still speed up training even after we have already reached the point at which additional parallelism provides no benefit for synchronous or asynchronous stochastic gradient descent. Two neural networks trained on disjoint subsets of the data can share knowledge by encouraging each model to agree with the predictions the other model would have made. These predictions can come from a stale version of the other model so they can be safely computed using weights that only rarely get transmitted. Our second claim is that online distillation is a cost-effective way to make the exact predictions of a model dramatically more reproducible. We support our claims using experiments on the Criteo Display Ad Challenge dataset, ImageNet, and the largest to-date dataset used for neural language modeling, containing $6\\times 10^{11}$ tokens and based on the Common Crawl repository of web data.|sl:arxiv_author|Rohan Anil
or grammatical tagging, or word-category disambiguation: the process of marking up a word in a text as corresponding to a particular part of speech|skos:broader|pattern recognition task that involves the assignment of a categorical label to each member of a sequence of observed values. Eg: POS tagging
Self-Taught Hashing for Fast Similarity Search Emphasise following issue in Semantic Hashing: obtaining the codes for previously unseen documents. Propose following approach:  first find the optimal l-bit binary codes for all documents in  the given corpus via unsupervised learning, then train  l classifiers via supervised learning to predict the l-bit code  for any query document unseen before.    (méthode résumée [ici](https://www.semanticscholar.org/paper/Semantic-hashing-using-tags-and-topic-modeling-Wang-Zhang/1a0f660f70fd179003edc271694736baaa39dec4))       The ability of fast similarity search at large scale is of great importance to many Information Retrieval (IR) applications. A promising way to accelerate similarity search is semantic hashing which designs compact binary codes for a large number of documents so that semantically similar documents are mapped to similar codes (within a short Hamming distance). Although some recently proposed techniques are able to generate high-quality codes for documents known in advance, obtaining the codes for previously unseen documents remains to be a very challenging problem. In this paper, we emphasise this issue and propose a novel Self-Taught Hashing (STH) approach to semantic hashing: we first find the optimal $l$-bit binary codes for all documents in the given corpus via unsupervised learning, and then train $l$ classifiers via supervised learning to predict the $l$-bit code for any query document unseen before. Our experiments on three real-world text datasets show that the proposed approach using binarised Laplacian Eigenmap (LapEig) and linear Support Vector Machine (SVM) outperforms state-of-the-art techniques significantly.|sl:arxiv_author|Dell Zhang
Gautier Poupeau|skos:broader|Technical girls and guys
Business case: semantic web|skos:broader|Semantic Web : Business
Building Machines That Learn and Think Like People  we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations   Recent progress in artificial intelligence (AI) has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn, and how they learn it. Specifically, we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models.|sl:arxiv_firstAuthor|Brenden M. Lake
Physicien|skos:broader|Physique
Traversing Knowledge Graphs in Vector Space Knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new \compositional\ training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. Path queries on a knowledge graph can be used to answer compositional questions such as What languages are spoken by people living in Lisbon?. However, knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new compositional training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. On a standard knowledge base completion task, we also demonstrate that compositional training acts as a novel form of structural regularization, reliably improving performance across all base models (reducing errors by up to 43%) and achieving new state-of-the-art results.|sl:arxiv_author|Kelvin Guu
Subword embeddings|skos:broader|Word embeddings
Machine Learning Course|skos:broader|Machine learning
Censure et maltraitance animale|skos:broader|Maltraitance animale
Graphviz|skos:broader|Graph visualization
Smartphone|skos:broader|Mobile phone
Canal+|skos:broader|Télévision
David Ricardo|skos:broader|Economiste
OWL ontology browser|skos:broader|OWL
Entities as Experts: Sparse Memory Access with Entity Supervision   the problem of capturing declarative knowledge in the learned parameters of a language model...     Entities as Experts (EaE) can access distinct memories of the entities mentioned in a piece of text;     To understand the motivation for distinct and  independent entity representations: A traditional Transformer would need to build an internal representation  of Charles Darwin from the words “Charles”  and “Darwin”... Conversely, EAE can access  a dedicated representation of “Charles Darwin”,  which is a memory of all of the contexts in which  this entity has previously been mentioned.... Having retrieved  and re-integrated this memory it is much easier for  EAE to relate the question to the answer     EaE's entity representations are learned directly from text. Correct identification, and representation, of entities is essential to EaE's performance    Based on transformer architecture    Extension: [Facts as Experts](doc:2020/07/2007_00849_facts_as_experts_) We focus on the problem of capturing declarative knowledge in the learned parameters of a language model. We introduce a new model, Entities as Experts (EaE), that can access distinct memories of the entities mentioned in a piece of text. Unlike previous efforts to integrate entity knowledge into sequence models, EaE's entity representations are learned directly from text. These representations capture sufficient knowledge to answer TriviaQA questions such as Which Dr. Who villain has been played by Roger Delgado, Anthony Ainley, Eric Roberts?. EaE outperforms a Transformer model with $30\\times$ the parameters on this task. According to the Lama knowledge probes, EaE also contains more factual knowledge than a similar sized Bert. We show that associating parameters with specific entities means that EaE only needs to access a fraction of its parameters at inference time, and we show that the correct identification, and representation, of entities is essential to EaE's performance. We also argue that the discrete and independent entity representations in EaE make it more modular and interpretable than the Transformer architecture on which it is based.|sl:arxiv_author|Livio Baldini Soares
Coursera: R Programming|skos:broader|Coursera
Insectes fossiles|skos:broader|Fossile
Pakistan|skos:broader|Asie
Frederick Giasson|skos:broader|SW guys (and girls)
Apple|skos:broader|Technologie
 Create delightful python projects using Jupyter Notebooks|skos:broader|- shift-tab (de 1 à 3 fois)  - ?xxx eg. ?learn.predict - doc  - ??xxx eg. `??learn.predict - source code  - H - liste des raccourcis    
IKS Workshop Salzburg 2012|skos:broader|Salzburg
Backpropagation vs Biology|skos:broader|Backpropagation
Nikolai Vavilov|skos:broader|Ex URSS URSS
Bidirectional LSTM-CRF Models for Sequence Tagging In this paper, we propose a variety of Long Short-Term Memory (LSTM) based models for sequence tagging. These models include LSTM networks, bidirectional LSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer (LSTM-CRF) and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work is the first to apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model to NLP benchmark sequence tagging data sets. We show that the BI-LSTM-CRF model can efficiently use both past and future input features thanks to a bidirectional LSTM component. It can also use sentence level tag information thanks to a CRF layer. The BI-LSTM-CRF model can produce state of the art (or close to) accuracy on POS, chunking and NER data sets. In addition, it is robust and has less dependence on word embedding as compared to previous observations.|sl:arxiv_firstAuthor|Zhiheng Huang
Linear Algebraic Structure of Word Senses, with Applications to Polysemy  Here it is shown that multiple word senses reside  in linear superposition within the word  embedding and simple sparse coding can recover  vectors that approximately capture the  senses     Each extracted word sense is accompanied by one of about  2000 “discourse atoms” that gives a succinct description of which other words co-occur with that word sense.     The success of the approach is mathematically explained using a variant of  the random walk on discourses model    (random walk: a generative model for language). Under the assumptions of this model,  there  exists a linear relationship between the vector of a  word w and the vectors of the words in its contexts (It is not the average of the words in w's context, but in a given corpus the matrix of the linear relationship does not depend on w. It can be estimated, and so we can compute the embedding of a word from the contexts it belongs to)    [Related blog post](/doc/?uri=https%3A%2F%2Fwww.offconvex.org%2F2016%2F07%2F10%2Fembeddingspolysemy%2F)   Word embeddings are ubiquitous in NLP and information retrieval, but it is unclear what they represent when the word is polysemous. Here it is shown that multiple word senses reside in linear superposition within the word embedding and simple sparse coding can recover vectors that approximately capture the senses. The success of our approach, which applies to several embedding methods, is mathematically explained using a variant of the random walk on discourses model (Arora et al., 2016). A novel aspect of our technique is that each extracted word sense is accompanied by one of about 2000 discourse atoms that gives a succinct description of which other words co-occur with that word sense. Discourse atoms can be of independent interest, and make the method potentially more useful. Empirical tests are used to verify and support the theory.|sl:arxiv_author|Tengyu Ma
Continual Lifelong Learning with Neural Networks: A Review Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.|sl:tag|tag:continual_learning
Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call fooling images (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.|sl:tag|tag:artificial_neural_network
Wiki Software|skos:broader|Wiki
Rock|skos:broader|Musique
African languages|skos:broader|Langues
Explosion cambrienne|skos:broader|Histoire de la vie
SemTechBiz Berlin 2012|skos:broader|Berlin
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:tag|tag:thewebconf_2020
A Little Annotation does a Lot of Good: A Study in Bootstrapping Low-resource Named Entity Recognizers Most state-of-the-art models for named entity recognition (NER) rely on the availability of large amounts of labeled data, making them challenging to extend to new, lower-resourced languages. However, there are now several proposed approaches involving either cross-lingual transfer learning, which learns from other highly resourced languages, or active learning, which efficiently selects effective training data based on model predictions. This paper poses the question: given this recent progress, and limited human annotation, what is the most effective method for efficiently creating high-quality entity recognizers in under-resourced languages? Based on extensive experimentation using both simulated and real human annotation, we find a dual-strategy approach best, starting with a cross-lingual transferred model, then performing targeted annotation of only uncertain entity spans in the target language, minimizing annotator effort. Results demonstrate that cross-lingual transfer is a powerful tool when very little data can be annotated, but an entity-targeted annotation strategy can achieve competitive accuracy quickly, with just one-tenth of training data.|sl:arxiv_author|Graham Neubig
URI Reference|skos:broader|URI
Newton|skos:broader|Physicien
Synonymy|skos:broader|NLP tasks / problems
Zhang Qian|skos:broader|Explorateur
Lumières|skos:broader|Philosophie
RDF Schema querying|skos:broader|RDF Schema
ExoMars|skos:broader|Exploration marsienne
Relativité|skos:broader|Physique
Embeddings in IR|skos:broader|embedding
Cour européenne de justice|skos:broader|Institutions européennes
Sparse coding|skos:broader|Representation learning
Slot tagging|skos:broader|NLU
Large Memory Layers with Product Keys  a structured memory which can be easily integrated into a neural network. The memory is very large by design and therefore significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time.     a key-value memory layer that can increase model capacity for a negligible computational cost. A 12-layer transformer with a memory outperforms a 24-layer transformer, and is 2x faster!     [Implementation](/doc/2019/08/product_key_memory_pkm_minima) This paper introduces a structured memory which can be easily integrated into a neural network. The memory is very large by design and significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time. This memory layer allows us to tackle very large scale language modeling tasks. In our experiments we consider a dataset with up to 30 billion words, and we plug our memory layer in a state-of-the-art transformer-based architecture. In particular, we found that a memory augmented model with only 12 layers outperforms a baseline transformer model with 24 layers, while being twice faster at inference time. We release our code for reproducibility purposes.|sl:tag|tag:arxiv_doc
Attentats 13-11-2015|skos:broader|Etat islamique
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:tag|tag:weak_supervision
Global brain|skos:broader|NTIC
Layered Graph Embedding for Entity Recommendation using Wikipedia in the Yahoo! Knowledge Graph an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia In this paper, we describe an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia. Through offline and online evaluations, we show that the resulting embeddings and recommendations perform well in terms of quality and user engagement. Balancing simplicity and quality, this framework provides default entity recommendations for English and other languages in the Yahoo! Knowledge Graph, which Wikipedia is a core subset of.|sl:tag|tag:recommender_systems
Deep Learning for Symbolic Mathematics Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.|sl:arxiv_author|François Charton
Reformer: The Efficient Transformer Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O($L^2$) to O($L\\log L$), where $L$ is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of $N$ times, where $N$ is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.|sl:tag|tag:google_research
Clint Eastwood|skos:broader|Acteur
Elliotte Rusty Harold|skos:broader|Technical girls and guys
FBI v. Apple|skos:broader|Terrorisme
AJAR|skos:broader|Ajax
Novartis|skos:broader|Entreprise
Universal Language Model Fine-tuning for Text Classification code is available in the fastai lib    [blog post](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html)    [see also](/doc/?uri=https%3A%2F%2Fyashuseth.blog%2F2018%2F06%2F17%2Funderstanding-universal-language-model-fine-tuning-ulmfit%2F)             Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.|sl:tag|tag:ulmfit
rdfQuery|skos:broader|jQuery
Graph visualization|skos:broader|Graph
A Call for More Rigor in Unsupervised Cross-lingual Learning  a scenario without any parallel data and abundant monolingual data is unrealistic in practice We review motivations, definition, approaches, and methodology for unsupervised cross-lingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of the world's languages. However, we argue that a scenario without any parallel data and abundant monolingual data is unrealistic in practice. We also discuss different training signals that have been used in previous work, which depart from the pure unsupervised setting. We then describe common methodological issues in tuning and evaluation of unsupervised cross-lingual models and present best practices. Finally, we provide a unified outlook for different types of research in this area (i.e., cross-lingual word embeddings, deep multilingual pretraining, and unsupervised machine translation) and argue for comparable evaluation of these models.|sl:arxiv_author|Sebastian Ruder
Hash Embeddings for Efficient Word Representations  A hash embedding may be seen as an interpolation between  a standard word embedding and a word embedding created using a random hash  function (the hashing trick).    recommandé par [Raphaël Sourty](tag:raphaelsty) We present hash embeddings, an efficient method for representing words in a continuous vector form. A hash embedding may be seen as an interpolation between a standard word embedding and a word embedding created using a random hash function (the hashing trick). In hash embeddings each token is represented by $k$ $d$-dimensional embeddings vectors and one $k$ dimensional weight vector. The final $d$ dimensional representation of the token is the product of the two. Rather than fitting the embedding vectors for each token these are selected by the hashing trick from a shared pool of $B$ embedding vectors. Our experiments show that hash embeddings can easily deal with huge vocabularies consisting of millions of tokens. When using a hash embedding there is no need to create a dictionary before training nor to perform any kind of vocabulary pruning after training. We show that models trained using hash embeddings exhibit at least the same level of performance as models trained using regular embeddings across a wide range of tasks. Furthermore, the number of parameters needed by such an embedding is only a fraction of what is required by a regular embedding. Since standard embeddings and embeddings constructed using the hashing trick are actually just special cases of a hash embedding, hash embeddings can be considered an extension and improvement over the existing regular embedding types.|sl:tag|tag:arxiv_doc
Thought alone controlled device|skos:broader|Robotique
Pays-Bas|skos:broader|Pays d'Europe
DRM|skos:broader|Content industries
InceptionTime: Finding AlexNet for Time Series Classification Time series classification (TSC) is the area of machine learning interested in learning how to assign labels to time series. The last few decades of work in this area have led to significant progress in the accuracy of classifiers, with the state of the art now represented by the HIVE-COTE algorithm. While extremely accurate, HIVE-COTE is infeasible to use in many applications because of its very high training time complexity in O(N^2T^4) for a dataset with N time series of length T. For example, it takes HIVE-COTE more than 72,000s to learn from a small dataset with N=700 time series of short length T=46. Deep learning, on the other hand, has now received enormous attention because of its high scalability and state-of-the-art accuracy in computer vision and natural language processing tasks. Deep learning for TSC has only very recently started to be explored, with the first few architectures developed over the last 3 years only. The accuracy of deep learning for TSC has been raised to a competitive level, but has not quite reached the level of HIVE-COTE. This is what this paper achieves: outperforming HIVE-COTE's accuracy together with scalability. We take an important step towards finding the AlexNet network for TSC by presenting InceptionTime---an ensemble of deep Convolutional Neural Network (CNN) models, inspired by the Inception-v4 architecture. Our experiments show that InceptionTime slightly outperforms HIVE-COTE with a win/draw/loss on the UCR archive of 40/6/39. Not only is InceptionTime more accurate, but it is much faster: InceptionTime learns from that same dataset with 700 time series in 2,300s but can also learn from a dataset with 8M time series in 13 hours, a quantity of data that is fully out of reach of HIVE-COTE.|sl:arxiv_author|Jonathan Weber
Personal Archive|skos:broader|PIM
A Primer in BERTology: What we know about how BERT works (article praised on [twitter](https://twitter.com/dennybritz/status/1233343170596917248?s=20) by D Britz and Y. Goldberg) Transformer-based models are now widely used in NLP, but we still do not understand a lot about their inner workings. This paper describes what is known to date about the famous BERT model (Devlin et al. 2019), synthesizing over 40 analysis studies. We also provide an overview of the proposed modifications to the model and its training regime. We then outline the directions for further research.|sl:tag|tag:bertology
Nuxeo|skos:broader|Enterprise Content Management
Resources-Oriented Web Services|skos:broader|Linked Data
An ontology for linking product descriptions and business entities on the Web|skos:broader|An ontology is a specification of a conceptualization.
Evolutionary algorithm|skos:broader|Evolutionary computation
A Tutorial on Network Embeddings Network embedding methods aim at learning low-dimensional latent representation of nodes in a network. These representations can be used as features for a wide range of tasks on graphs such as classification, clustering, link prediction, and visualization. In this survey, we give an overview of network embeddings by summarizing and categorizing recent advancements in this research field. We first discuss the desirable properties of network embeddings and briefly introduce the history of network embedding algorithms. Then, we discuss network embedding methods under different scenarios, such as supervised versus unsupervised learning, learning embeddings for homogeneous networks versus for heterogeneous networks, etc. We further demonstrate the applications of network embeddings, and conclude the survey with future work in this area.|sl:arxiv_author|Steven Skiena
Cognition-as-a-Service|skos:broader|Cognition
Apache Spark|skos:broader|In-memory computing
JAX-RS|skos:broader|REST
Manu Sporny|skos:broader|SW guys (and girls)
Stemming|skos:broader|Text preprocessing
Internet tool|skos:broader|Tools
RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space  We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.|sl:arxiv_author|Zhi-Hong Deng
Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data Word embeddings are a popular approach to unsupervised learning of word relationships that are widely used in natural language processing. In this article, we present a new set of embeddings for medical concepts learned using an extremely large collection of multimodal medical data. Leaning on recent theoretical insights, we demonstrate how an insurance claims database of 60 million members, a collection of 20 million clinical notes, and 1.7 million full text biomedical journal articles can be combined to embed concepts into a common space, resulting in the largest ever set of embeddings for 108,477 medical concepts. To evaluate our approach, we present a new benchmark methodology based on statistical power specifically designed to test embeddings of medical concepts. Our approach, called cui2vec, attains state-of-the-art performance relative to previous methods in most instances. Finally, we provide a downloadable set of pre-trained embeddings for other researchers to use, as well as an online tool for interactive exploration of the cui2vec embeddings|sl:arxiv_author|Nathan P. Palmer
blojsom|skos:broader|Blog software
Civilisation de l'Indus|skos:broader|Antiquité de l'Inde
Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data Word embeddings are a popular approach to unsupervised learning of word relationships that are widely used in natural language processing. In this article, we present a new set of embeddings for medical concepts learned using an extremely large collection of multimodal medical data. Leaning on recent theoretical insights, we demonstrate how an insurance claims database of 60 million members, a collection of 20 million clinical notes, and 1.7 million full text biomedical journal articles can be combined to embed concepts into a common space, resulting in the largest ever set of embeddings for 108,477 medical concepts. To evaluate our approach, we present a new benchmark methodology based on statistical power specifically designed to test embeddings of medical concepts. Our approach, called cui2vec, attains state-of-the-art performance relative to previous methods in most instances. Finally, we provide a downloadable set of pre-trained embeddings for other researchers to use, as well as an online tool for interactive exploration of the cui2vec embeddings|sl:arxiv_author|Andrew L. Beam
OS X Unix|skos:broader|Mac OS X
Knowledge bases|skos:broader|Knowledge
Advances in Pre-Training Distributed Word Representations  we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks Many Natural Language Processing applications nowadays rely on pre-trained word representations estimated from large text corpora such as news collections, Wikipedia and Web Crawl. In this paper, we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks.|sl:tag|tag:fasttext
Boris Johnson|skos:broader|Royaume Uni
Paradise Papers|skos:broader|Paradis fiscaux
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:tag|tag:grounded_language_learning
Recurrent Memory Networks for Language Modeling  Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge.     In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data.     We demonstrate the power of RMN on language modeling and sentence completion tasks.     On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.   Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge. In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data. We demonstrate the power of RMN on language modeling and sentence completion tasks. On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.|sl:tag|tag:recurrent_neural_network
Detroit|skos:broader|USA
Excel and SW|skos:broader|Excel
Intent classification and slot filling|skos:broader|Slot tagging
Web services: document vs RPC Style|skos:broader|Web Services
Longformer: The Long-Document Transformer  Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Following prior work on long-sequence transformers, we evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8. In contrast to most prior work, we also pretrain Longformer and finetune it on a variety of downstream tasks. Our pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA.|sl:arxiv_author|Iz Beltagy
Graph database and NLP|skos:broader|Graph database
Photon|skos:broader|Physique des particules
Knowledge Compilation|skos:broader|Artificial Intelligence
A Comparative Study of Word Embeddings for Reading Comprehension abstract:   The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on    1.  the use of pre-trained word embeddings, and  2. the representation of out-of-vocabulary tokens at test time,     can turn out to have a larger impact than architectural choices on the final performance         The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on (1) the use of pre-trained word embeddings, and (2) the representation of out-of-vocabulary tokens at test time, can turn out to have a larger impact than architectural choices on the final performance. We systematically explore several options for these choices, and provide recommendations to researchers working in this area.|sl:arxiv_author|Bhuwan Dhingra
Word2vec: howto|skos:broader|Word2vec
Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data Word embeddings are a popular approach to unsupervised learning of word relationships that are widely used in natural language processing. In this article, we present a new set of embeddings for medical concepts learned using an extremely large collection of multimodal medical data. Leaning on recent theoretical insights, we demonstrate how an insurance claims database of 60 million members, a collection of 20 million clinical notes, and 1.7 million full text biomedical journal articles can be combined to embed concepts into a common space, resulting in the largest ever set of embeddings for 108,477 medical concepts. To evaluate our approach, we present a new benchmark methodology based on statistical power specifically designed to test embeddings of medical concepts. Our approach, called cui2vec, attains state-of-the-art performance relative to previous methods in most instances. Finally, we provide a downloadable set of pre-trained embeddings for other researchers to use, as well as an online tool for interactive exploration of the cui2vec embeddings|sl:arxiv_author|Isaac S. Kohane
Language Models as Knowledge Bases? an analysis of the relational knowledge present in pretrained language models shows an ability of these models to recall factual knowledge  Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as fill-in-the-blank cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.|sl:arxiv_author|Fabio Petroni
Histoire de la vie|skos:broader|Evolution
Reformer|skos:broader|AI@Google
Word + Entity embeddings|skos:broader|Word embeddings
scikit-learn|skos:broader|Python
Musées africains|skos:broader|Musée
Fossile|skos:broader|Histoire de la vie
[Vaswani, et al. 2017 paper](https://arxiv.org/abs/1706.03762): Attention is all you need.    [#seq2seq](/tag/sequence_to_sequence_learning) using only improved self-attention units (multi-head self-attention  mechanism), without any RNN.  |skos:broader|Attention mechanism relating different positions of a sequence in order to compute a representation of the same sequence.    Useful in machine reading, abstractive summarization, or image description generation  
GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden unit), or embedding-free units such as image pixels.|sl:tag|tag:graph_embeddings
paggr|skos:broader|SPARQL
Russie|skos:broader|Europe
Reformer: The Efficient Transformer Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O($L^2$) to O($L\\log L$), where $L$ is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of $N$ times, where $N$ is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.|sl:arxiv_author|Łukasz Kaiser
A Review of Relational Machine Learning for Knowledge Graphs Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be trained on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive datasets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Google's Knowledge Vault project as an example of such combination.|sl:arxiv_author|Volker Tresp
Self-Taught Convolutional Neural Networks for Short Text Clustering  We propose a flexible short text clustering framework which explores the feasibility and effectiveness of combining CNN and traditional unsupervised dimensionality reduction methods.     Non-biased deep feature representations can be learned through our self- taught CNN framework which does not use any external tags/labels or complicated NLP pre-processing.     The original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations.    [conf paper, same authors](http://www.aclweb.org/anthology/W15-1509) ; [gitgub repo (matlab)](https://github.com/jacoxu/STC2)   Short text clustering is a challenging problem due to its sparseness of text representation. Here we propose a flexible Self-Taught Convolutional neural network framework for Short Text Clustering (dubbed STC^2), which can flexibly and successfully incorporate more useful semantic features and learn non-biased deep text representation in an unsupervised manner. In our framework, the original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations. Extensive experimental results demonstrate that the proposed framework is effective, flexible and outperform several popular clustering methods when tested on three public short text datasets.|sl:arxiv_author|Jiaming Xu
Rosetta Project|skos:broader|Disparition de langues vivantes
Justice internationale|skos:broader|Justice
NLP sample code|skos:broader|Sample code
Nanotechnologies|skos:broader|Technologie
Carrot2|skos:broader|Open Source
OSEMA/DERI-Renault paper|skos:broader|Fadi Badra
UNIX Tips|skos:broader|Howto
Denny Britz|skos:broader|NLP girls and guys
Pangolin|skos:broader|Espèces menacées
Generative adversarial networks Generative adversarial network|skos:broader|ANN NN Artificial neural network
Sense embeddings|skos:broader|Embeddings
Mémoire (informatique)|skos:broader|Mémoire
OpenLink Software|skos:broader|Semantic Web
Jena|skos:broader|apache.org
W3C Incubator Group Report|skos:broader|W3C
Zitgist|skos:broader|RDF browser
H5N1|skos:broader|Grippe aviaire
Graphs+Machine Learning|skos:broader|Machine learning
Afrique équatoriale|skos:broader|Afrique
A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efficient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximally preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We first introduce the formal definition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work address these challenges in their solutions. Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efficiency, problem settings, techniques and application scenarios.|sl:tag|tag:arxiv_doc
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:tag|tag:snorkel
Yahoo!|skos:broader|Search Engines
Hash Embeddings for Efficient Word Representations  A hash embedding may be seen as an interpolation between  a standard word embedding and a word embedding created using a random hash  function (the hashing trick).    recommandé par [Raphaël Sourty](tag:raphaelsty) We present hash embeddings, an efficient method for representing words in a continuous vector form. A hash embedding may be seen as an interpolation between a standard word embedding and a word embedding created using a random hash function (the hashing trick). In hash embeddings each token is represented by $k$ $d$-dimensional embeddings vectors and one $k$ dimensional weight vector. The final $d$ dimensional representation of the token is the product of the two. Rather than fitting the embedding vectors for each token these are selected by the hashing trick from a shared pool of $B$ embedding vectors. Our experiments show that hash embeddings can easily deal with huge vocabularies consisting of millions of tokens. When using a hash embedding there is no need to create a dictionary before training nor to perform any kind of vocabulary pruning after training. We show that models trained using hash embeddings exhibit at least the same level of performance as models trained using regular embeddings across a wide range of tasks. Furthermore, the number of parameters needed by such an embedding is only a fraction of what is required by a regular embedding. Since standard embeddings and embeddings constructed using the hashing trick are actually just special cases of a hash embedding, hash embeddings can be considered an extension and improvement over the existing regular embedding types.|sl:tag|tag:feature_hashing
Ofir|skos:broader|Gastronomie
Dan Brickley|skos:broader|SW guys (and girls)
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:arxiv_author|Alexander Ratner
Large scale distributed neural network training through online distillation   we use codistillation to refer to distillation performed:   1. using the same architecture for all the models;   2. using the same dataset to train all the models; and   3. using the distillation loss during training before any model has fully converged.     In general, we believe the quality gains of codistillation over well-tuned offline distillation will be  minor in practice and the more interesting research direction is exploring codistillation as a distributed  training algorithm     Codistillation with  the same data seems to be slightly better than the baseline, but codistillation using different data  gets much better results. These results show that the codistilling models are indeed successfully  transmitting useful information about different parts of the training data to each other.    Related to [Deep mutual learning](doc:2020/05/1706_00384_deep_mutual_learni) paper Techniques such as ensembling and distillation promise model quality improvements when paired with almost any base model. However, due to increased test-time cost (for ensembles) and increased complexity of the training pipeline (for distillation), these techniques are challenging to use in industrial settings. In this paper we explore a variant of distillation which is relatively straightforward to use as it does not require a complicated multi-stage setup or many new hyperparameters. Our first claim is that online distillation enables us to use extra parallelism to fit very large datasets about twice as fast. Crucially, we can still speed up training even after we have already reached the point at which additional parallelism provides no benefit for synchronous or asynchronous stochastic gradient descent. Two neural networks trained on disjoint subsets of the data can share knowledge by encouraging each model to agree with the predictions the other model would have made. These predictions can come from a stale version of the other model so they can be safely computed using weights that only rarely get transmitted. Our second claim is that online distillation is a cost-effective way to make the exact predictions of a model dramatically more reproducible. We support our claims using experiments on the Criteo Display Ad Challenge dataset, ImageNet, and the largest to-date dataset used for neural language modeling, containing $6\\times 10^{11}$ tokens and based on the Common Crawl repository of web data.|sl:tag|tag:arxiv_doc
Topic Modeling|skos:broader|Distributional semantics
A Dual Embedding Space Model for Document Ranking Investigate neural word embeddings as a source of evidence in document ranking.    Presented in [this Stanford course on IR](/doc/?uri=https%3A%2F%2Fweb.stanford.edu%2Fclass%2Fcs276%2Fhandouts%2Flecture20-distributed-representations.pdf) by Chris Manning (starting slide 44)    They train a word2vec model, but retain both the input and the output projections.     During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs.      However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives A fundamental goal of search engines is to identify, given a query, documents that have relevant text. This is intrinsically difficult because the query and the document may use different vocabulary, or the document may contain query words without being relevant. We investigate neural word embeddings as a source of evidence in document ranking. We train a word2vec embedding model on a large unlabelled query corpus, but in contrast to how the model is commonly used, we retain both the input and the output projections, allowing us to leverage both the embedding spaces to derive richer distributional relationships. During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs. We postulate that the proposed Dual Embedding Space Model (DESM) captures evidence on whether a document is about a query term in addition to what is modelled by traditional term-frequency based approaches. Our experiments show that the DESM can re-rank top documents returned by a commercial Web search engine, like Bing, better than a term-matching based signal like TF-IDF. However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives, retrieving documents that are only loosely related to the query. We demonstrate that this problem can be solved effectively by ranking based on a linear mixture of the DESM and the word counting features.|sl:arxiv_author|Rich Caruana
Musique brésilienne|skos:broader|Brésil
Samba|skos:broader|Brésil
Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.|sl:arxiv_author|Zihang Dai
Talis RDF/JSON|skos:broader|RDF-in-JSON
\Why Should I Trust You?\: Explaining the Predictions of Any Classifier technique that explains the predictions of any classifier by learning an interpretable model locally around the prediction Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.|sl:arxiv_author|Marco Tulio Ribeiro
Traduction automatique|skos:broader|Natural Language Processing
Eléphant|skos:broader|Animal
Transnets|skos:broader|NTIC
Gaulois|skos:broader|Antiquité
The HSIC Bottleneck: Deep Learning without Back-Propagation  we show that it is possible to learn classification tasks at near competitive accuracy without  backpropagation, by maximizing a surrogate of the mutual information between hidden representations and labels and  simultaneously minimizing the mutual dependency between hidden representations and the inputs...  the hidden units of a network trained in this way form useful representations. Specifically, fully competitive accuracy  can be obtained by freezing the network trained without backpropagation and appending and training a one-layer  network using conventional SGD to convert convert the representation to the desired format.    The training method uses an approximation of the [#information bottleneck](/tag/information_bottleneck_method).    Advantages:     - The method facilitates parallel processing and requires significantly less operations.    - It does not suffer from exploding or vanishing gradients.   - It is biologically more plausible than Backpropagation     We introduce the HSIC (Hilbert-Schmidt independence criterion) bottleneck for training deep neural networks. The HSIC bottleneck is an alternative to the conventional cross-entropy loss and backpropagation that has a number of distinct advantages. It mitigates exploding and vanishing gradients, resulting in the ability to learn very deep networks without skip connections. There is no requirement for symmetric feedback or update locking. We find that the HSIC bottleneck provides performance on MNIST/FashionMNIST/CIFAR10 classification comparable to backpropagation with a cross-entropy target, even when the system is not encouraged to make the output resemble the classification labels. Appending a single layer trained with SGD (without backpropagation) to reformat the information further improves performance.|sl:arxiv_author|J. P. Lewis
Building Machines That Learn and Think Like People  we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations   Recent progress in artificial intelligence (AI) has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn, and how they learn it. Specifically, we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models.|sl:tag|tag:arxiv_doc
Binary classification models with \Uncertain\ predictions Binary classification models which can assign probabilities to categories such as the tissue is 75% likely to be tumorous or the chemical is 25% likely to be toxic are well understood statistically, but their utility as an input to decision making is less well explored. We argue that users need to know which is the most probable outcome, how likely that is to be true and, in addition, whether the model is capable enough to provide an answer. It is the last case, where the potential outcomes of the model explicitly include don't know that is addressed in this paper. Including this outcome would better separate those predictions that can lead directly to a decision from those where more data is needed. Where models produce an Uncertain answer similar to a human reply of don't know or 50:50 in the examples we refer to earlier, this would translate to actions such as operate on tumour or remove compound from use where the models give a more true than not answer. Where the models judge the result Uncertain the practical decision might be carry out more detailed laboratory testing of compound or commission new tissue analyses. The paper presents several examples where we first analyse the effect of its introduction, then present a methodology for separating Uncertain from binary predictions and finally, we provide arguments for its use in practice.|sl:arxiv_author|Damjan Krstajic
Poincaré Embeddings|skos:broader|Poincaré
535|skos:broader|Eruption volcanique
Zune|skos:broader|Musique en ligne
Watson IBM's Watson|skos:broader|IA AI
Towards Understanding Linear Word Analogies A surprising property of word vectors is that word analogies can often be solved with vector arithmetic. However, it is unclear why arithmetic operators correspond to non-linear embedding models such as skip-gram with negative sampling (SGNS). We provide a formal explanation of this phenomenon without making the strong assumptions that past theories have made about the vector space and word distribution. Our theory has several implications. Past work has conjectured that linear substructures exist in vector spaces because relations can be represented as ratios; we prove that this holds for SGNS. We provide novel justification for the addition of SGNS word vectors by showing that it automatically down-weights the more frequent word, as weighting schemes do ad hoc. Lastly, we offer an information theoretic interpretation of Euclidean distance in vector spaces, justifying its use in capturing word dissimilarity.|sl:arxiv_firstAuthor|Kawin Ethayarajh
BERT|skos:broader|NLP@Google
KD-MKB related|skos:broader|KD-MKB
HypiosVoCampParisMay2010|skos:broader|Hypios
Semantic Web|skos:broader|Semantic technology
Biodiversité : effondrement|skos:broader|Grands problèmes
Word2vec: howto|skos:broader|Using word embeddings
Jena and database|skos:broader|Semantic Web: databases
Trust in the Web of Data|skos:broader|Trust
Image recognition|skos:broader|Machine learning: problems
Politique française|skos:broader|Politique
Label Embedding|skos:broader|Embeddings
KGAT: Knowledge Graph Attention Network for Recommendation To provide more accurate, diverse, and explainable recommendation, it is compulsory to go beyond modeling user-item interactions and take side information into account. Traditional methods like factorization machine (FM) cast it as a supervised learning problem, which assumes each interaction as an independent instance with side information encoded. Due to the overlook of the relations among instances or items (e.g., the director of a movie is also an actor of another movie), these methods are insufficient to distill the collaborative signal from the collective behaviors of users. In this work, we investigate the utility of knowledge graph (KG), which breaks down the independent interaction assumption by linking items with their attributes. We argue that in such a hybrid structure of KG and user-item graph, high-order relations --- which connect two items with one or multiple linked attributes --- are an essential factor for successful recommendation. We propose a new method named Knowledge Graph Attention Network (KGAT) which explicitly models the high-order connectivities in KG in an end-to-end fashion. It recursively propagates the embeddings from a node's neighbors (which can be users, items, or attributes) to refine the node's embedding, and employs an attention mechanism to discriminate the importance of the neighbors. Our KGAT is conceptually advantageous to existing KG-based recommendation methods, which either exploit high-order relations by extracting paths or implicitly modeling them with regularization. Empirical results on three public benchmarks show that KGAT significantly outperforms state-of-the-art methods like Neural FM and RippleNet. Further studies verify the efficacy of embedding propagation for high-order relation modeling and the interpretability benefits brought by the attention mechanism.|sl:arxiv_author|Xiang Wang
Learning Semantic Similarity for Very Short Texts In order to pair short text  fragments—as a concatenation of separate words—an adequate  distributed sentence representation is needed. Main contribution: a first step towards a hybrid method that  combines the strength of dense distributed representations—  as opposed to sparse term matching—with the strength of  tf-idf based methods. The combination of word embeddings and tf-idf  information might lead to a better model for semantic content  within very short text fragments. Levering data on social media, such as Twitter and Facebook, requires information retrieval algorithms to become able to relate very short text fragments to each other. Traditional text similarity methods such as tf-idf cosine-similarity, based on word overlap, mostly fail to produce good results in this case, since word overlap is little or non-existent. Recently, distributed word representations, or word embeddings, have been shown to successfully allow words to match on the semantic level. In order to pair short text fragments - as a concatenation of separate words - an adequate distributed sentence representation is needed, in existing literature often obtained by naively combining the individual word representations. We therefore investigated several text representations as a combination of word embeddings in the context of semantic pair matching. This paper investigates the effectiveness of several such naive techniques, as well as traditional tf-idf similarity, for fragments of different lengths. Our main contribution is a first step towards a hybrid method that combines the strength of dense distributed representations - as opposed to sparse term matching - with the strength of tf-idf based methods to automatically reduce the impact of less informative terms. Our new approach outperforms the existing techniques in a toy experimental set-up, leading to the conclusion that the combination of word embeddings and tf-idf information might lead to a better model for semantic content within very short text fragments.|sl:tag|tag:arxiv_doc
Lexicon Infused Phrase Embeddings for Named Entity Resolution Employs lexicons as part of the word embedding training:      The skip-gram model can be trained to  predict not only neighboring words but also lexicon  membership of the central word (or phrase).    Quickly demonstrates how we can plug phrase embeddings  into an existing log-linear CRF System.     Most state-of-the-art approaches for named-entity recognition (NER) use semi supervised information in the form of word clusters and lexicons. Recently neural network-based language models have been explored, as they as a byproduct generate highly informative vector representations for words, known as word embeddings. In this paper we present two contributions: a new form of learning word embeddings that can leverage information from relevant lexicons to improve the representations, and the first system to use neural word embeddings to achieve state-of-the-art results on named-entity recognition in both CoNLL and Ontonotes NER. Our system achieves an F1 score of 90.90 on the test set for CoNLL 2003---significantly better than any previous system trained on public data, and matching a system employing massive private industrial query-log data.|sl:arxiv_author|Alexandre Passos
Brains in silicon Neuromorphique Neuromorphic engineering|skos:broader|C'est déjà demain
Generalization through Memorization: Nearest Neighbor Language Models extend LMs with nearest neighbor search in embedding space We introduce $k$NN-LMs, which extend a pre-trained neural language model (LM) by linearly interpolating it with a $k$-nearest neighbors ($k$NN) model. The nearest neighbors are computed according to distance in the pre-trained LM embedding space, and can be drawn from any text collection, including the original LM training data. Applying this augmentation to a strong Wikitext-103 LM, with neighbors drawn from the original training set, our $k$NN-LM achieves a new state-of-the-art perplexity of 15.79 - a 2.9 point improvement with no additional training. We also show that this approach has implications for efficiently scaling up to larger training sets and allows for effective domain adaptation, by simply varying the nearest neighbor datastore, again without further training. Qualitatively, the model is particularly helpful in predicting rare patterns, such as factual knowledge. Together, these results strongly suggest that learning similarity between sequences of text is easier than predicting the next word, and that nearest neighbor search is an effective approach for language modeling in the long tail.|sl:tag|tag:k_nearest_neighbors_algorithm
Pollution|skos:broader|Grands problèmes
Bidirectional LSTM-CRF Models for Sequence Tagging In this paper, we propose a variety of Long Short-Term Memory (LSTM) based models for sequence tagging. These models include LSTM networks, bidirectional LSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer (LSTM-CRF) and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work is the first to apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model to NLP benchmark sequence tagging data sets. We show that the BI-LSTM-CRF model can efficiently use both past and future input features thanks to a bidirectional LSTM component. It can also use sentence level tag information thanks to a CRF layer. The BI-LSTM-CRF model can produce state of the art (or close to) accuracy on POS, chunking and NER data sets. In addition, it is robust and has less dependence on word embedding as compared to previous observations.|sl:arxiv_author|Zhiheng Huang
AI & IR|skos:broader|Artificial Intelligence
Toutankhamon|skos:broader|Egypte antique
Javascript tips|skos:broader|JavaScript
Rocard|skos:broader|Politique française
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:arxiv_author|Joyce Chai
Cache buster|skos:broader|Cache
Gravitation|skos:broader|Physique
Alphago|skos:broader|Deep Learning
The Case for Learned Index Structures  we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs  Indexes are models: a B-Tree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term learned indexes. The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show, that by using neural nets we are able to outperform cache-optimized B-Trees by up to 70% in speed while saving an order-of-magnitude in memory over several real-world data sets. More importantly though, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work just provides a glimpse of what might be possible.|sl:arxiv_author|Alex Beutel
Semantic framework|skos:broader|Semantic Web Dev
Cour européenne de justice|skos:broader|Union européenne
"Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One We propose to reinterpret a standard discriminative classifier of p(y|x) as an energy based model for the joint distribution p(x,y). In this setting, the standard class probabilities can be easily computed as well as unnormalized values of p(x) and p(x|y). Within this framework, standard discriminative architectures may beused and the model can also be trained on unlabeled data. We demonstrate that energy based training of the joint distribution improves calibration, robustness, andout-of-distribution detection while also enabling our models to generate samplesrivaling the quality of recent GAN approaches. We improve upon recently proposed techniques for scaling up the training of energy based models and presentan approach which adds little overhead compared to standard classification training. Our approach is the first to achieve performance rivaling the state-of-the-artin both generative and discriminative learning within one hybrid model."|sl:arxiv_author|David Duvenaud
Learning by Abstraction: The Neural State Machine  Given an image, we first predict a probabilistic graph  that represents its underlying semantics and serves as a structured world model.  Then, we perform sequential reasoning over the graph, iteratively traversing its  nodes to answer a given question or draw a new inference. In contrast to most  neural architectures that are designed to closely interact with the raw sensory  data, our model operates instead in an abstract latent space, by transforming both  the visual and linguistic modalities into semantic concept-based representations,  thereby achieving enhanced transparency and modularity.     Drawing inspiration from [Bengio’s consciousness prior](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1709.08568)... We introduce the Neural State Machine, seeking to bridge the gap between the neural and symbolic views of AI and integrate their complementary strengths for the task of visual reasoning. Given an image, we first predict a probabilistic graph that represents its underlying semantics and serves as a structured world model. Then, we perform sequential reasoning over the graph, iteratively traversing its nodes to answer a given question or draw a new inference. In contrast to most neural architectures that are designed to closely interact with the raw sensory data, our model operates instead in an abstract latent space, by transforming both the visual and linguistic modalities into semantic concept-based representations, thereby achieving enhanced transparency and modularity. We evaluate our model on VQA-CP and GQA, two recent VQA datasets that involve compositionality, multi-step inference and diverse reasoning skills, achieving state-of-the-art results in both cases. We provide further experiments that illustrate the model's strong generalization capacity across multiple dimensions, including novel compositions of concepts, changes in the answer distribution, and unseen linguistic structures, demonstrating the qualities and efficacy of our approach.|sl:tag|tag:arxiv_doc
XTech|skos:broader|NTIC
Retrofitting Word Vectors to Semantic Lexicons Method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed.     Graph-based learning technique for using lexical relational resources to obtain higher quality semantic vectors, which we call “retrofitting.” Retrofitting is applied as a post-processing step by running belief propagation on a graph constructed from lexicon-derived relational information to update word vectors. This allows retrofitting to be used on pre-trained word vectors obtained using any vector training model.    [github](https://github.com/mfaruqui/retrofitting)     Vector space word representations are learned from distributional information of words in large corpora. Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database. This paper proposes a method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed. Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, we obtain substantial improvements starting with a variety of word vector models. Our refinement method outperforms prior techniques for incorporating semantic lexicons into the word vector training algorithms.|sl:tag|tag:these_irit_renault_biblio_initiale
Film danois|skos:broader|Danemark
Ajax|skos:broader|Dev
Global brain|skos:broader|Conscience artificielle
Virtuoso Open-Source Edition|skos:broader|Open Source
Graph database|skos:broader|Graph
Unsupervised Transfer Learning for Spoken Language Understanding in Intelligent Agents  We apply ELMo, ULMFiT (unsupervised transfer) with supervised transfer to reduce labeled data required for launching domains in Alexa by 10-15x User interaction with voice-powered agents generates large amounts of unlabeled utterances. In this paper, we explore techniques to efficiently transfer the knowledge from these unlabeled utterances to improve model performance on Spoken Language Understanding (SLU) tasks. We use Embeddings from Language Model (ELMo) to take advantage of unlabeled data by learning contextualized word representations. Additionally, we propose ELMo-Light (ELMoL), a faster and simpler unsupervised pre-training method for SLU. Our findings suggest unsupervised pre-training on a large corpora of unlabeled utterances leads to significantly better SLU performance compared to training from scratch and it can even outperform conventional supervised transfer. Additionally, we show that the gains from unsupervised transfer techniques can be further improved by supervised transfer. The improvements are more pronounced in low resource settings and when using only 1000 labeled in-domain samples, our techniques match the performance of training from scratch on 10-15x more labeled in-domain data.|sl:tag|tag:ulmfit
K-BERT: Enabling Language Representation with Knowledge Graph a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by equipped with a KG without pre-training by-self because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts.|sl:arxiv_author|Zhiruo Wang
Credit card|skos:broader|Banque
Oum Kalsoum|skos:broader|Musicien
Text Editor|skos:broader|Text tools
Comet Wild 2|skos:broader|Comète
Design Challenges and Misconceptions in Neural Sequence Labeling design challenges of constructing effective and efficient neural sequence labeling systems We investigate the design challenges of constructing effective and efficient neural sequence labeling systems, by reproducing twelve neural sequence labeling models, which include most of the state-of-the-art structures, and conduct a systematic model comparison on three benchmarks (i.e. NER, Chunking, and POS tagging). Misconceptions and inconsistent conclusions in existing literature are examined and clarified under statistical experiments. In the comparison and analysis process, we reach several practical conclusions which can be useful to practitioners.|sl:arxiv_author|Yue Zhang
Large Memory Layers with Product Keys  a structured memory which can be easily integrated into a neural network. The memory is very large by design and therefore significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time.     a key-value memory layer that can increase model capacity for a negligible computational cost. A 12-layer transformer with a memory outperforms a 24-layer transformer, and is 2x faster!     [Implementation](/doc/2019/08/product_key_memory_pkm_minima) This paper introduces a structured memory which can be easily integrated into a neural network. The memory is very large by design and significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time. This memory layer allows us to tackle very large scale language modeling tasks. In our experiments we consider a dataset with up to 30 billion words, and we plug our memory layer in a state-of-the-art transformer-based architecture. In particular, we found that a memory augmented model with only 12 layers outperforms a baseline transformer model with 24 layers, while being twice faster at inference time. We release our code for reproducibility purposes.|sl:arxiv_author|Alexandre Sablayrolles
Périclès|skos:broader|Grand Homme
Génétique et Évolution|skos:broader|Genetics Génétique
Earth map|skos:broader|Carte
Digital Audio|skos:broader|Musique
SIMILE Exhibit|skos:broader|SIMILE
Macaw: An Extensible Conversational Information Seeking Platform Conversational information seeking (CIS) has been recognized as a major emerging research area in information retrieval. Such research will require data and tools, to allow the implementation and study of conversational systems. This paper introduces Macaw, an open-source framework with a modular architecture for CIS research. Macaw supports multi-turn, multi-modal, and mixed-initiative interactions, and enables research for tasks such as document retrieval, question answering, recommendation, and structured data exploration. It has a modular design to encourage the study of new CIS algorithms, which can be evaluated in batch mode. It can also integrate with a user interface, which allows user studies and data collection in an interactive mode, where the back end can be fully algorithmic or a wizard of oz setup. Macaw is distributed under the MIT License.|sl:tag|tag:nlp_tools
InceptionTime: Finding AlexNet for Time Series Classification Time series classification (TSC) is the area of machine learning interested in learning how to assign labels to time series. The last few decades of work in this area have led to significant progress in the accuracy of classifiers, with the state of the art now represented by the HIVE-COTE algorithm. While extremely accurate, HIVE-COTE is infeasible to use in many applications because of its very high training time complexity in O(N^2T^4) for a dataset with N time series of length T. For example, it takes HIVE-COTE more than 72,000s to learn from a small dataset with N=700 time series of short length T=46. Deep learning, on the other hand, has now received enormous attention because of its high scalability and state-of-the-art accuracy in computer vision and natural language processing tasks. Deep learning for TSC has only very recently started to be explored, with the first few architectures developed over the last 3 years only. The accuracy of deep learning for TSC has been raised to a competitive level, but has not quite reached the level of HIVE-COTE. This is what this paper achieves: outperforming HIVE-COTE's accuracy together with scalability. We take an important step towards finding the AlexNet network for TSC by presenting InceptionTime---an ensemble of deep Convolutional Neural Network (CNN) models, inspired by the Inception-v4 architecture. Our experiments show that InceptionTime slightly outperforms HIVE-COTE with a win/draw/loss on the UCR archive of 40/6/39. Not only is InceptionTime more accurate, but it is much faster: InceptionTime learns from that same dataset with 700 time series in 2,300s but can also learn from a dataset with 8M time series in 13 hours, a quantity of data that is fully out of reach of HIVE-COTE.|sl:arxiv_author|Geoffrey I. Webb
Regroupement familial et test ADN de filiation|skos:broader|Sarkozy : immigration
Text Generation from Knowledge Graphs with Graph Transformers Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.|sl:arxiv_author|Rik Koncel-Kedziorski
Bura|skos:broader|African art
Solr documentation|skos:broader|Solr
Flask|skos:broader|Web dev
RDC|skos:broader|Afrique Centrale
JCS - Java Caching System|skos:broader|Java dev
Relations franco-américaines|skos:broader|USA
SourceForge|skos:broader|Software
When a learning algorithm is able to interactively query the user to obtain the label of a data point (pb: estimate which points are more valable to sollicit labels for)    Active learning deals with problems where unlabeled data is abundant yet obtaining labels is expensive. The learning algorithm has the possibility of querying a limited number of samples to obtain the corresponding labels, subsequently used for supervised learning.    The goal of active learning: to reduce the cost of labeling. To this end, the learning algorithm is  allowed to choose which data to label based on uncertainty (e.g., the entropy of predicted class  probabilities) or other heuristics ([src](doc:2020/07/2007_00077_similarity_search_))|skos:broader|the bottleneck of getting labeled training data
J'ai un petit problème avec mon ordinateur|skos:broader|Ca craint
Saudade@pt|skos:broader|Souvenirs
Alexandria|skos:broader|Ville
Herschel telescope|skos:broader|Télescope
Louvre|skos:broader|Musée
Variational Bayesian methods|skos:broader|Bayesian Reasoning
Critique du capitalisme|skos:broader|Capitalisme
Kingsley Idehen|skos:broader|Technical girls and guys
Learning by Abstraction: The Neural State Machine  Given an image, we first predict a probabilistic graph  that represents its underlying semantics and serves as a structured world model.  Then, we perform sequential reasoning over the graph, iteratively traversing its  nodes to answer a given question or draw a new inference. In contrast to most  neural architectures that are designed to closely interact with the raw sensory  data, our model operates instead in an abstract latent space, by transforming both  the visual and linguistic modalities into semantic concept-based representations,  thereby achieving enhanced transparency and modularity.     Drawing inspiration from [Bengio’s consciousness prior](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1709.08568)... We introduce the Neural State Machine, seeking to bridge the gap between the neural and symbolic views of AI and integrate their complementary strengths for the task of visual reasoning. Given an image, we first predict a probabilistic graph that represents its underlying semantics and serves as a structured world model. Then, we perform sequential reasoning over the graph, iteratively traversing its nodes to answer a given question or draw a new inference. In contrast to most neural architectures that are designed to closely interact with the raw sensory data, our model operates instead in an abstract latent space, by transforming both the visual and linguistic modalities into semantic concept-based representations, thereby achieving enhanced transparency and modularity. We evaluate our model on VQA-CP and GQA, two recent VQA datasets that involve compositionality, multi-step inference and diverse reasoning skills, achieving state-of-the-art results in both cases. We provide further experiments that illustrate the model's strong generalization capacity across multiple dimensions, including novel compositions of concepts, changes in the answer distribution, and unseen linguistic structures, demonstrating the qualities and efficacy of our approach.|sl:arxiv_author|Christopher D. Manning
Subventions agricoles|skos:broader|Agriculture
Dean Allemang|skos:broader|TopQuadrant
France Télécom|skos:broader|Entreprise
Unsupervised Deep Embedding for Clustering Analysis Relatively little work has focused on learning representations for clustering. In this paper, we propose Deep Embedded Clustering (DEC), a method that simultaneously learns feature representations and cluster assignments using deep neural networks. DEC learns a mapping from the data space to a lower-dimensional feature space in which it iteratively optimizes a clustering objective Clustering is central to many data-driven application domains and has been studied extensively in terms of distance functions and grouping algorithms. Relatively little work has focused on learning representations for clustering. In this paper, we propose Deep Embedded Clustering (DEC), a method that simultaneously learns feature representations and cluster assignments using deep neural networks. DEC learns a mapping from the data space to a lower-dimensional feature space in which it iteratively optimizes a clustering objective. Our experimental evaluations on image and text corpora show significant improvement over state-of-the-art methods.|sl:arxiv_author|Ross Girshick
RDF data visualization|skos:broader|RDF
Egypte antique|skos:broader|Antiquité
CIA|skos:broader|USA
BAM! Born-Again Multi-Task Networks for Natural Language Understanding  knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers It can be challenging to train multi-task neural networks that outperform or even match their single-task counterparts. To help address this, we propose using knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers. We evaluate our approach by multi-task fine-tuning BERT on the GLUE benchmark. Our method consistently improves over standard single-task and multi-task training.|sl:tag|tag:knowledge_distillation
Joint Embedding of Hierarchical Categories and Entities for Concept Categorization and Dataless Classification a framework that embeds entities and categories into a semantic space by integrating structured  knowledge and taxonomy hierarchy from large knowledge bases.    two methods:    1. Category Embedding model): it replaces the entities in the context with their directly  labeled categories to build categories’ context;   2. Hierarchical Category Embedding: it  further incorporates all ancestor categories of the context entities to utilize the hierarchical information. Due to the lack of structured knowledge applied in learning distributed representation of cate- gories, existing work cannot incorporate category hierarchies into entity information. We propose a framework that embeds entities and categories into a semantic space by integrating structured knowledge and taxonomy hierarchy from large knowledge bases. The framework allows to com- pute meaningful semantic relatedness between entities and categories. Our framework can han- dle both single-word concepts and multiple-word concepts with superior performance on concept categorization and yield state of the art results on dataless hierarchical classification.|sl:arxiv_author|Zhiting Hu
Obélisque d'Axoum|skos:broader|Obélisque
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|Antoine Zimmermann
Test of independent invention|skos:broader|Web architecture
Markets are efficient if and only if P = NP Hmm wow I prove that if markets are weak-form efficient, meaning current prices fully reflect all information available in past prices, then P = NP, meaning every computational problem whose solution can be verified in polynomial time can also be solved in polynomial time. I also prove the converse by showing how we can program the market to solve NP-complete problems. Since P probably does not equal NP, markets are probably not efficient. Specifically, markets become increasingly inefficient as the time series lengthens or becomes more frequent. An illustration by way of partitioning the excess returns to momentum strategies based on data availability confirms this prediction.|sl:tag|tag:p_np
log4j|skos:broader|apache.org
RDF search engine|skos:broader|Moteur de recherche
Multi-Task Deep Neural Networks for Natural Language Understanding outperforms BERT in nine of eleven benchmark NLP tasks In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations in order to adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7% (2.2% absolute improvement). We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. The code and pre-trained models are publicly available at https://github.com/namisan/mt-dnn.|sl:arxiv_author|Xiaodong Liu
Bayesian analysis|skos:broader|Probabilistic Graphical Models
Combining Statistics and Semantics|skos:broader|Semantics
Paul Krugman|skos:broader|Economiste
Jean Rouch|skos:broader|Ethnologie
Plante|skos:broader|Nature
Read-Write Secure Data Web|skos:broader|Security and REST
Thèse IRIT-Renault NLP-KB|skos:broader|Knowledge Graph + Deep Learning
End-To-End Memory Networks Neural network with a recurrent attention model over a possibly large external memory.    cité par [#A. Bordes](/tag/antoine_bordes) à [#ParisIsAI conf 2018](/tag/france_is_ai_2018.html) We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network (Weston et al., 2015) but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.|sl:tag|tag:france_is_ai_2018
Do Deep Nets Really Need to be Deep? Currently, deep neural networks are the state of the art on problems such as speech recognition and computer vision. In this extended abstract, we show that shallow feed-forward networks can learn the complex functions previously learned by deep nets and achieve accuracies previously only achievable with deep models. Moreover, in some cases the shallow neural nets can learn these deep functions using a total number of parameters similar to the original deep model. We evaluate our method on the TIMIT phoneme recognition task and are able to train shallow fully-connected nets that perform similarly to complex, well-engineered, deep convolutional architectures. Our success in training shallow neural nets to mimic deeper models suggests that there probably exist better algorithms for training shallow feed-forward nets than those currently available.|sl:tag|tag:arxiv_doc
Lalibela|skos:broader|Ethiopie
Mladic|skos:broader|Crime contre l'Humanité
End-to-End Neural Entity Linking  We presented the first neural end-to-end entity linking  model and show the benefit of jointly optimizing  entity recognition and linking. Leveraging key  components, namely word, entity and mention embeddings,  we prove that engineered features can  be almost completely replaced by modern neural  networks. Entity Linking (EL) is an essential task for semantic text understanding and information extraction. Popular methods separately address the Mention Detection (MD) and Entity Disambiguation (ED) stages of EL, without leveraging their mutual dependency. We here propose the first neural end-to-end EL system that jointly discovers and links entities in a text document. The main idea is to consider all possible spans as potential mentions and learn contextual similarity scores over their entity candidates that are useful for both MD and ED decisions. Key components are context-aware mention embeddings, entity embeddings and a probabilistic mention - entity map, without demanding other engineered features. Empirically, we show that our end-to-end method significantly outperforms popular systems on the Gerbil platform when enough training data is available. Conversely, if testing datasets follow different annotation conventions compared to the training set (e.g. queries/ tweets vs news documents), our ED model coupled with a traditional NER system offers the best or second best EL accuracy.|sl:arxiv_author|Nikolaos Kolitsas
Property Graphs|skos:broader|Graph
Automotive Ontology Working Group|skos:broader|Ontologies
Enhancing the Power of Cardinal's Algorithm Cardinal's factorization algorithm of 1996 splits a univariate polynomial into two factors with root sets separated by the imaginary axis, which is an important goal itself and a basic step toward root-finding. The novelty of the algorithm and its potential power have been well recognized by experts immediately, but by 2016, that is, two decades later, its practical value still remains nil, particularly because of the high computational cost of performing its final stage by means of computing approximate greatest common divisor of two polynomials. We briefly recall Cardinal's algorithm and its difficulties, amend it based on some works performed since 1996, extend its power to splitting out factors of a more general class, and reduce the final stage of the algorithm to quite manageable computations with structured matrices. Some of our techniques can be of independent interest for matrix computations.|sl:tag|tag:jean_paul
gnowsis|skos:broader|Semantic Web project
AutoML-Zero: Evolving Machine Learning Algorithms From Scratch  Fun AutoML-Zero experiments: Evolutionary search discovers fundamental ML algorithms from scratch, e.g., small neural nets with backprop.   Can evolution be the “Master Algorithm”? ;) Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.|sl:arxiv_author|David R. So
Bag of Tricks for Efficient Text Classification A simple and efficient baseline for text classification.     Our word features can  be averaged together to form good sentence representations.    Our experiments show that fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.   This paper explores a simple and efficient baseline for text classification. Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.|sl:tag|tag:nlp_text_classification
Efficient Contextual Representation Learning Without Softmax Layer how to accelerate contextual representation learning.     Contextual representation models are difficult to train due to the large parameter sizes and high computational complexity     We find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size.  Therefore, we redesign the learning objectiv.   Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings.  Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary.  When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.    decouples learning contexts and words     Instead of using  a softmax layer to predict the distribution of the  missing word, we utilize and extend the SEMFIT  layer (Kumar and Tsvetkov, 2018) to predict the  embedding of the missing word. Contextual representation models have achieved great success in improving various downstream tasks. However, these language-model-based encoders are difficult to train due to the large parameter sizes and high computational complexity. By carefully examining the training procedure, we find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size. Therefore, we redesign the learning objective and propose an efficient framework for training contextual representation models. Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings. Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary. When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.|sl:arxiv_author|Cho-Jui Hsieh
Canada|skos:broader|Amérique
Constitution européenne|skos:broader|Europe
Machine Learning + Semantic Web|skos:broader|Semantic Web
Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective reviews the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. Neural-symbolic computing has now become the subject of interest of both academic and industry research laboratories. Graph Neural Networks (GNN) have been widely used in relational and symbolic domains, with widespread application of GNNs in combinatorial optimization, constraint satisfaction, relational reasoning and other scientific domains. The need for improved explainability, interpretability and trust of AI systems in general demands principled methodologies, as suggested by neural-symbolic computing. In this paper, we review the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. This includes the application of GNNs in several domains as well as its relationship to current developments in neural-symbolic computing.|sl:tag|tag:neural_symbolic_computing
Tabulator|skos:broader|Linked Data
InceptionTime: Finding AlexNet for Time Series Classification Time series classification (TSC) is the area of machine learning interested in learning how to assign labels to time series. The last few decades of work in this area have led to significant progress in the accuracy of classifiers, with the state of the art now represented by the HIVE-COTE algorithm. While extremely accurate, HIVE-COTE is infeasible to use in many applications because of its very high training time complexity in O(N^2T^4) for a dataset with N time series of length T. For example, it takes HIVE-COTE more than 72,000s to learn from a small dataset with N=700 time series of short length T=46. Deep learning, on the other hand, has now received enormous attention because of its high scalability and state-of-the-art accuracy in computer vision and natural language processing tasks. Deep learning for TSC has only very recently started to be explored, with the first few architectures developed over the last 3 years only. The accuracy of deep learning for TSC has been raised to a competitive level, but has not quite reached the level of HIVE-COTE. This is what this paper achieves: outperforming HIVE-COTE's accuracy together with scalability. We take an important step towards finding the AlexNet network for TSC by presenting InceptionTime---an ensemble of deep Convolutional Neural Network (CNN) models, inspired by the Inception-v4 architecture. Our experiments show that InceptionTime slightly outperforms HIVE-COTE with a win/draw/loss on the UCR archive of 40/6/39. Not only is InceptionTime more accurate, but it is much faster: InceptionTime learns from that same dataset with 700 time series in 2,300s but can also learn from a dataset with 8M time series in 13 hours, a quantity of data that is fully out of reach of HIVE-COTE.|sl:tag|tag:time_series
Transfer Learning for Sequence Labeling Using Source Model and Target Data use-case ex: NER when the target data contains new categories In this paper, we propose an approach for transferring the knowledge of a neural model for sequence labeling, learned from the source domain, to a new model trained on a target domain, where new label categories appear. Our transfer learning (TL) techniques enable to adapt the source model using the target data and new categories, without accessing to the source data. Our solution consists in adding new neurons in the output layer of the target model and transferring parameters from the source model, which are then fine-tuned with the target data. Additionally, we propose a neural adapter to learn the difference between the source and the target label distribution, which provides additional important information to the target model. Our experiments on Named Entity Recognition show that (i) the learned knowledge in the source model can be effectively transferred when the target data contains new categories and (ii) our neural adapter further improves such transfer.|sl:tag|tag:arxiv_doc
Privacy and internet|skos:broader|Cybersecurity Sécurité informatique
Poincaré Embeddings|skos:broader|Embeddings
Paraphrase identification|skos:broader|Identification of similar documents
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Ryan Faulkner
Beyond Vector Spaces: Compact Data Representation as Differentiable Weighted Graphs  In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE (Probabilistic Differentiable Graph Embeddings): a method that learns a weighted graph representation of data end-to-end by gradient descent.    [Github](https://github.com/stanis-morozov/prodige)     Learning useful representations is a key ingredient to the success of modern machine learning. Currently, representation learning mostly relies on embedding data into Euclidean space. However, recent work has shown that data in some domains is better modeled by non-euclidean metric spaces, and inappropriate geometry can result in inferior performance. In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE: a method that learns a weighted graph representation of data end-to-end by gradient descent. Greater generality and fewer model assumptions make PRODIGE more powerful than existing embedding-based approaches. We confirm the superiority of our method via extensive experiments on a wide range of tasks, including classification, compression, and collaborative filtering.|sl:tag|tag:graphs_machine_learning
Mike Bergman|skos:broader|Technical girls and guys
Pará|skos:broader|Brésil
Zero-shot Entity Linking with Dense Entity Retrieval We consider the zero-shot entity-linking challenge where each entity is defined by a short textual description, and the model must read these descriptions together with the mention context to make the final linking decisions. In this setting, retrieving entity candidates can be particularly challenging, since many of the common linking cues such as entity alias tables and link popularity are not available. In this paper, we introduce a simple and effective two stage approach for zero-shot linking, based on fine-tuned BERT architectures. In the first stage, we do retrieval in a dense space defined by a bi-encoder that independently embeds the mention context and the entity descriptions. Each candidate is then examined more carefully with a cross-encoder, that concatenates the mention and entity text. Our approach achieves a nearly 5 point absolute gain on a recently introduced zero-shot entity linking benchmark, driven largely by improvements over previous IR-based candidate retrieval. We also show that it performs well in the non-zero-shot setting, obtaining the state-of-the-art result on TACKBP-2010.|sl:arxiv_firstAuthor|Ledell Wu
Handwriting recognition|skos:broader|OCR
Clandestins|skos:broader|Immigration
Neural machine translation|skos:broader|Neural networks
StarSpace|skos:broader|Entity embeddings
Seq2Seq Encoder-Decoder|skos:broader|Sequence Modeling Seq2Seq
Pêche|skos:broader|Poisson
Large deviations for the perceptron model and consequences for active learning the task of choosing the subset of samples to be labeled from a fixed finite pool of samples Active learning is a branch of machine learning that deals with problems where unlabeled data is abundant yet obtaining labels is expensive. The learning algorithm has the possibility of querying a limited number of samples to obtain the corresponding labels, subsequently used for supervised learning. In this work, we consider the task of choosing the subset of samples to be labeled from a fixed finite pool of samples. We assume the pool of samples to be a random matrix and the ground truth labels to be generated by a single-layer teacher random neural network. We employ replica methods to analyze the large deviations for the accuracy achieved after supervised learning on a subset of the original pool. These large deviations then provide optimal achievable performance boundaries for any active learning algorithm. We show that the optimal learning performance can be efficiently approached by simple message-passing active learning algorithms. We also provide a comparison with the performance of some other popular active learning strategies.|sl:arxiv_author|Lenka Zdeborová
Pangloss: Fast Entity Linking in Noisy Text Environments a production system for entity disambiguation on messy tex, based  on probabilistic tokenization and context-dependent document embeddings    Probabilistic tokenization: uses the method described [here](/doc/2019/07/mining_quality_phrases_from_mas) Entity linking is the task of mapping potentially ambiguous terms in text to their constituent entities in a knowledge base like Wikipedia. This is useful for organizing content, extracting structured data from textual documents, and in machine learning relevance applications like semantic search, knowledge graph construction, and question answering. Traditionally, this work has focused on text that has been well-formed, like news articles, but in common real world datasets such as messaging, resumes, or short-form social media, non-grammatical, loosely-structured text adds a new dimension to this problem. This paper presents Pangloss, a production system for entity disambiguation on noisy text. Pangloss combines a probabilistic linear-time key phrase identification algorithm with a semantic similarity engine based on context-dependent document embeddings to achieve better than state-of-the-art results (5% in F1) compared to other research or commercially available systems. In addition, Pangloss leverages a local embedded database with a tiered architecture to house its statistics and metadata, which allows rapid disambiguation in streaming contexts and on-device disambiguation in low-memory environments such as mobile phones.|sl:arxiv_author|Michael Conover
Négociations climat |skos:broader|Changement climatique
Semantic Vector Encoding and Similarity Search Using Fulltext Search Engines  The ubiquity of semantic vector space modeling raises the challenge of efficient searching in dense, high-dimensional vector spaces. We would naturally want to take advantage of the design and optimizations behind modern fulltext engines like Elasticsearch so as to meet the scalability and robustness demands of modern IR applications. This is the research challenge addressed in this paper.   The paper describes novel ways of encoding dense vectors into text documents, allowing the use of traditional inverted index engines.    [blog post](https://rare-technologies.com/semantic-search-fulltext-engine-acl-2017/)   Vector representations and vector space modeling (VSM) play a central role in modern machine learning. We propose a novel approach to `vector similarity searching' over dense semantic representations of words and documents that can be deployed on top of traditional inverted-index-based fulltext engines, taking advantage of their robustness, stability, scalability and ubiquity. We show that this approach allows the indexing and querying of dense vectors in text domains. This opens up exciting avenues for major efficiency gains, along with simpler deployment, scaling and monitoring. The end result is a fast and scalable vector database with a tunable trade-off between vector search performance and quality, backed by a standard fulltext engine such as Elasticsearch. We empirically demonstrate its querying performance and quality by applying this solution to the task of semantic searching over a dense vector representation of the entire English Wikipedia.|sl:arxiv_author|Radim Řehůřek
Airport|skos:broader|Apple
ONU|skos:broader|Etat du monde
Metric Learning|skos:broader|Similarity learning
GNN|skos:broader|ANN NN Artificial neural network
Parameter-free Sentence Embedding via Orthogonal Basis training-free approach for building sentence representations, Geometric Embedding (GEM), based on the geometric structure of word embedding space.     we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word’s novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace    [on www.groundai.com](https://www.groundai.com/project/zero-training-sentence-embedding-via-orthogonal-basis/)    [Open Revieww](/doc/?uri=https%3A%2F%2Fopenreview.net%2Fforum%3Fid%3DrJedbn0ctQ) ; [Related to this paper](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1704.05358)       We propose a simple and robust non-parameterized approach for building sentence representations. Inspired by the Gram-Schmidt Process in geometric theory, we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word's novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace. Following this motivation, we develop an innovative method based on orthogonal basis to combine pre-trained word embeddings into sentence representations. This approach requires zero parameters, along with efficient inference performance. We evaluate our approach on 11 downstream NLP tasks. Our model shows superior performance compared with non-parameterized alternatives and it is competitive to other approaches relying on either large amounts of labelled data or prolonged training time.|sl:arxiv_author|Chenguang Zhu
Phrases (NLP)|skos:broader|General NLP tasks
Bug Brother|skos:broader|Big Brother
Apache Shiro|skos:broader|Security
Allemagne|skos:broader|Pays d'Europe
iMac|skos:broader|Macintosh
Nginx|skos:broader|Web server
Named Entity Recognition|skos:broader|Sequence labeling
Sense2vec|skos:broader|Sense embeddings
Italie|skos:broader|Pays d'Europe
Lesk algorithm|skos:broader|Word-sense disambiguation
Judea Pearl|skos:broader|AI girls and guys
Reinhard Mey|skos:broader|Allemagne
Venus Express|skos:broader|Missions spatiales
Brésil|skos:broader|Amérique
Scalable Nearest Neighbor Search for Optimal Transport The Optimal Transport (a.k.a. Wasserstein) distance is an increasingly popular similarity measure for rich data domains, such as images or text documents. This raises the necessity for fast nearest neighbor search with respect to this distance, a problem that poses a substantial computational bottleneck for various tasks on massive datasets. In this work, we study fast tree-based approximation algorithms for searching nearest neighbors w.r.t. the Wasserstein-1 distance. A standard tree-based technique, known as Quadtree, has been previously shown to obtain good results. We introduce a variant of this algorithm, called Flowtree, and formally prove it achieves asymptotically better accuracy. Our extensive experiments, on real-world text and image datasets, show that Flowtree improves over various baselines and existing methods in either running time or accuracy. In particular, its quality of approximation is in line with previous high-accuracy methods, while its running time is much faster.|sl:arxiv_author|Tal Wagner
Cookies|skos:broader|Web dev
Encoding|skos:broader|Dev
aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (Most k-means-type algorithms require the number of clusters – k – to be specified in advance)|skos:broader|the task of grouping a set of objects in such a way that objects in the same group (cluster) are more similar (in some sense or another) to each other than to those in other groups.  
Encoding Categorical Variables with Conjugate Bayesian Models for WeWork Lead Scoring Engine  To encode high-cardinality categorical variables, we introduce a technique based on traditional Bayesian statistics. This technique is a paradigm for ensemble modeling, specifically stacking, where the base learner consists of a problem- specific conjugate Bayesian model (CBM)   Applied Data Scientists throughout various industries are commonly faced with the challenging task of encoding high-cardinality categorical features into digestible inputs for machine learning algorithms. This paper describes a Bayesian encoding technique developed for WeWork's lead scoring engine which outputs the probability of a person touring one of our office spaces based on interaction, enrichment, and geospatial data. We present a paradigm for ensemble modeling which mitigates the need to build complicated preprocessing and encoding schemes for categorical variables. In particular, domain-specific conjugate Bayesian models are employed as base learners for features in a stacked ensemble model. For each column of a categorical feature matrix we fit a problem-specific prior distribution, for example, the Beta distribution for a binary classification problem. In order to analytically derive the moments of the posterior distribution, we update the prior with the conjugate likelihood of the corresponding target variable for each unique value of the given categorical feature. This function of column and value encodes the categorical feature matrix so that the final learner in the ensemble model ingests low-dimensional numerical input. Experimental results on both curated and real world datasets demonstrate impressive accuracy and computational efficiency on a variety of problem archetypes. Particularly, for the lead scoring engine at WeWork -- where some categorical features have as many as 300,000 levels -- we have seen an AUC improvement from 0.87 to 0.97 through implementing conjugate Bayesian model encoding.|sl:arxiv_author|Daniel Salas
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:tag|tag:knowledge_resources
RotatE|skos:broader|Knowledge Graph Embeddings
Lauryn Hill|skos:broader|Musique
Imbalanced Data|skos:broader|Machine learning: problems
Origine de la vie|skos:broader|Histoire de la vie
Europe : aberrations|skos:broader|Construction européenne
Franco-Allemand|skos:broader|Allemagne
Synthetic life|skos:broader|Biology
Industrie de l'armement|skos:broader|Armement
Apple-Intel|skos:broader|Intel
Exploration marsienne|skos:broader|Exploration spatiale
Oregon|skos:broader|USA
Convolutional Knowledge Graph Embeddings|skos:broader|Knowledge Graph Embeddings
PocketSphinx|skos:broader|Speech-to-Text
Karen Blixen|skos:broader|Danemark
Cogema|skos:broader|Nucléaire
A Little Annotation does a Lot of Good: A Study in Bootstrapping Low-resource Named Entity Recognizers Most state-of-the-art models for named entity recognition (NER) rely on the availability of large amounts of labeled data, making them challenging to extend to new, lower-resourced languages. However, there are now several proposed approaches involving either cross-lingual transfer learning, which learns from other highly resourced languages, or active learning, which efficiently selects effective training data based on model predictions. This paper poses the question: given this recent progress, and limited human annotation, what is the most effective method for efficiently creating high-quality entity recognizers in under-resourced languages? Based on extensive experimentation using both simulated and real human annotation, we find a dual-strategy approach best, starting with a cross-lingual transferred model, then performing targeted annotation of only uncertain entity spans in the target language, minimizing annotator effort. Results demonstrate that cross-lingual transfer is a powerful tool when very little data can be annotated, but an entity-targeted annotation strategy can achieve competitive accuracy quickly, with just one-tenth of training data.|sl:arxiv_firstAuthor|Aditi Chaudhary
BERT + Sentence Embeddings|skos:broader|BERT
Span Selection Pre-training for Question Answering  a new pre-training task inspired by reading  comprehension and an effort to avoid encoding general knowledge in the transformer network itself    Current transformer architectures store general knowledge - large models, long pre-training time. Better to offload the requirement of general knowledge to a sparsely activated network.    Span selection as an additional auxiliary task: the query is a sentence drawn from a corpus  with a term replaced with a special token: [BLANK]. The term replaced by the blank is the answer term. The passage is  relevant as determined by a BM25 search, and answer-bearing (containing the answer  term). Unlike BERT’s cloze task, where the answer must be drawn from the model itself, the answer is found in a passage  using language understanding.     We hope to progress to a model of general purpose language modeling that uses an indexed long  term memory to retrieve world knowledge, rather than holding it in the densely activated transformer encoder layers. BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pre-trained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension and an effort to avoid encoding general knowledge in the transformer network itself. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple reading comprehension (MRC) and paraphrasing datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also establish a new SOTA in HotpotQA, improving answer prediction F1 by 4 F1 points and supporting fact prediction by 1 F1 point. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.|sl:arxiv_author|Avirup Sil
Jsonld/Jena|skos:broader|JSON-LD
MyCarEvent|skos:broader|OWL
Describing a Knowledge Base We aim to automatically generate natural language descriptions about an input structured knowledge base (KB). We build our generation framework based on a pointer network which can copy facts from the input KB, and add two attention mechanisms: (i) slot-aware attention to capture the association between a slot type and its corresponding slot value; and (ii) a new \\emph{table position self-attention} to capture the inter-dependencies among related slots. For evaluation, besides standard metrics including BLEU, METEOR, and ROUGE, we propose a KB reconstruction based metric by extracting a KB from the generation output and comparing it with the input KB. We also create a new data set which includes 106,216 pairs of structured KBs and their corresponding natural language descriptions for two distinct entity types. Experiments show that our approach significantly outperforms state-of-the-art methods. The reconstructed KB achieves 68.8% - 72.6% F-score.|sl:tag|tag:knowledge_base
No Fuss Distance Metric Learning using Proxies  We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity...   Traditionnaly, supervision is expressed in the form of sets of points that follow  an ordinal relationship – an anchor point x is similar to  a set of positive points Y , and dissimilar to a set of negative  points Z, and a loss defined over these distances is minimized.   Triplet-Based methods are challenging to optimize (a main issue is the need for finding informative triplets).     We propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss.    Mentioned in this [blog post](/doc/2020/01/training_a_speaker_embedding_fr):     Proxy based triplet learning: instead of generating triplets, we learn an embedding for each class and use the learnt embedding as a proxy for triplets as part of the training. In other words, we can train end to end without the computationally expensive step of resampling triplets after each network update.    Near the conclusion:     Our formulation of Proxy-NCA loss produces a loss very  similar to the standard cross-entropy loss used in classification.  However, we arrive at our formulation from a different  direction: we are not interested in the actual classifier and  indeed discard the proxies once the model has been trained.  Instead, the proxies are auxiliary variables, enabling more  effective optimization of the embedding model parameters.  As such, our formulation not only enables us to surpass the  state of the art in zero-shot learning, but also offers an explanation  to the effectiveness of the standard trick of training  a classifier, and using its penultimate layer’s output as the  embedding. We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity. Traditionally, for this problem supervision is expressed in the form of sets of points that follow an ordinal relationship -- an anchor point $x$ is similar to a set of positive points $Y$, and dissimilar to a set of negative points $Z$, and a loss defined over these distances is minimized. While the specifics of the optimization differ, in this work we collectively call this type of supervision Triplets and all methods that follow this pattern Triplet-Based methods. These methods are challenging to optimize. A main issue is the need for finding informative triplets, which is usually achieved by a variety of tricks such as increasing the batch size, hard or semi-hard triplet mining, etc. Even with these tricks, the convergence rate of such methods is slow. In this paper we propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss. This proxy-based loss is empirically better behaved. As a result, the proxy-loss improves on state-of-art results for three standard zero-shot learning datasets, by up to 15% points, while converging three times as fast as other triplet-based losses.|sl:arxiv_firstAuthor|Yair Movshovitz-Attias
Palmyra|skos:broader|Archéologie
Semantic tagging|skos:broader|Tagging
k-nearest neighbors algorithm|skos:broader|Nearest neighbor search
Liberté, liberté chérie|skos:broader|Liberté
Ian Davis|skos:broader|Technical girls and guys
Hierarchical Memory Networks|skos:broader|Memory in deep learning
Filme brasileiro@pt|skos:broader|Brésil
SWEO Interest Group|skos:broader|W3C
Extreme classification|skos:broader|Multi-label classification
KG Embeddings Library|skos:broader|Knowledge Graph Embeddings
The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives [blog post](http://www.semanlink.net/doc/2019/09/evolution_of_representations_in) We seek to understand how the representations of individual tokens and the structure of the learned feature space evolve between layers in deep neural networks under different learning objectives. We focus on the Transformers for our analysis as they have been shown effective on various tasks, including machine translation (MT), standard left-to-right language models (LM) and masked language modeling (MLM). Previous work used black-box probing tasks to show that the representations learned by the Transformer differ significantly depending on the objective. In this work, we use canonical correlation analysis and mutual information estimators to study how information flows across Transformer layers and how this process depends on the choice of learning objective. For example, as you go from bottom to top layers, information about the past in left-to-right language models gets vanished and predictions about the future get formed. In contrast, for MLM, representations initially acquire information about the context around the token, partially forgetting the token identity and producing a more generalized token representation. The token identity then gets recreated at the top MLM layers.|sl:arxiv_author|Rico Sennrich
VoIP|skos:broader|Internet
Film cubain|skos:broader|Film
Mozilla|skos:broader|Dev
Lobbies économiques|skos:broader|Lobby
Logistic regression|skos:broader|Regression analysis
TAP|skos:broader|Semantic Web : Application
Cambridge Analytica|skos:broader|Social manipulation
Learning to Remember Rare Events  a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training.    Our memory module can be easily added to any part of a supervised neural network Despite recent advances, memory-augmented deep neural networks are still limited when it comes to life-long and one-shot learning, especially in remembering rare events. We present a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training. Our memory module can be easily added to any part of a supervised neural network. To show its versatility we add it to a number of networks, from simple convolutional ones tested on image classification to deep sequence-to-sequence and recurrent-convolutional models. In all cases, the enhanced network gains the ability to remember and do life-long one-shot learning. Our module remembers training examples shown many thousands of steps in the past and it can successfully generalize from them. We set new state-of-the-art for one-shot learning on the Omniglot dataset and demonstrate, for the first time, life-long one-shot learning in recurrent neural networks on a large-scale machine translation task.|sl:arxiv_author|Ofir Nachum
Sem web: future|skos:broader|Semantic Web
Tensor|skos:broader|Machine learning: techniques
Beatles|skos:broader|Musique
Benjamin Heinzerling|skos:broader|NLP girls and guys
Markets are efficient if and only if P = NP Hmm wow I prove that if markets are weak-form efficient, meaning current prices fully reflect all information available in past prices, then P = NP, meaning every computational problem whose solution can be verified in polynomial time can also be solved in polynomial time. I also prove the converse by showing how we can program the market to solve NP-complete problems. Since P probably does not equal NP, markets are probably not efficient. Specifically, markets become increasingly inefficient as the time series lengthens or becomes more frequent. An illustration by way of partitioning the excess returns to momentum strategies based on data availability confirms this prediction.|sl:arxiv_author|Philip Maymin
A Comparative Study of Word Embeddings for Reading Comprehension abstract:   The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on    1.  the use of pre-trained word embeddings, and  2. the representation of out-of-vocabulary tokens at test time,     can turn out to have a larger impact than architectural choices on the final performance         The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on (1) the use of pre-trained word embeddings, and (2) the representation of out-of-vocabulary tokens at test time, can turn out to have a larger impact than architectural choices on the final performance. We systematically explore several options for these choices, and provide recommendations to researchers working in this area.|sl:tag|tag:ruslan_salakhutdinov
Shanghaï|skos:broader|Ville
Frog|skos:broader|Animal
Mac OS X 10.4|skos:broader|OSX OS X
Bitcoin|skos:broader|Money
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:arxiv_author|Peter Lu
Knowledge distillation|skos:broader|Machines teaching machines
MinHash|skos:broader|Algorithmes
OWL 2|skos:broader|OWL
Préhistoire|skos:broader|Histoire
Entity linking|skos:broader|Entity discovery and linking
Text Search|skos:broader|Information retrieval
Identity Crisis in Linked Data|skos:broader|URI
Clerezza|skos:broader|Restful semantic web services
Linux|skos:broader|Unix
Large scale distributed neural network training through online distillation   we use codistillation to refer to distillation performed:   1. using the same architecture for all the models;   2. using the same dataset to train all the models; and   3. using the distillation loss during training before any model has fully converged.     In general, we believe the quality gains of codistillation over well-tuned offline distillation will be  minor in practice and the more interesting research direction is exploring codistillation as a distributed  training algorithm     Codistillation with  the same data seems to be slightly better than the baseline, but codistillation using different data  gets much better results. These results show that the codistilling models are indeed successfully  transmitting useful information about different parts of the training data to each other.    Related to [Deep mutual learning](doc:2020/05/1706_00384_deep_mutual_learni) paper Techniques such as ensembling and distillation promise model quality improvements when paired with almost any base model. However, due to increased test-time cost (for ensembles) and increased complexity of the training pipeline (for distillation), these techniques are challenging to use in industrial settings. In this paper we explore a variant of distillation which is relatively straightforward to use as it does not require a complicated multi-stage setup or many new hyperparameters. Our first claim is that online distillation enables us to use extra parallelism to fit very large datasets about twice as fast. Crucially, we can still speed up training even after we have already reached the point at which additional parallelism provides no benefit for synchronous or asynchronous stochastic gradient descent. Two neural networks trained on disjoint subsets of the data can share knowledge by encouraging each model to agree with the predictions the other model would have made. These predictions can come from a stale version of the other model so they can be safely computed using weights that only rarely get transmitted. Our second claim is that online distillation is a cost-effective way to make the exact predictions of a model dramatically more reproducible. We support our claims using experiments on the Criteo Display Ad Challenge dataset, ImageNet, and the largest to-date dataset used for neural language modeling, containing $6\\times 10^{11}$ tokens and based on the Common Crawl repository of web data.|sl:arxiv_author|Alexandre Passos
On device NLP|skos:broader|NLP
Visualization Tools|skos:broader|Tools
Learning Confidence for Out-of-Distribution Detection in Neural Networks Modern neural networks are very powerful predictive models, but they are often incapable of recognizing when their predictions may be wrong. Closely related to this is the task of out-of-distribution detection, where a network must determine whether or not an input is outside of the set on which it is expected to safely perform. To jointly address these issues, we propose a method of learning confidence estimates for neural networks that is simple to implement and produces intuitively interpretable outputs. We demonstrate that on the task of out-of-distribution detection, our technique surpasses recently proposed techniques which construct confidence based on the network's output distribution, without requiring any additional labels or access to out-of-distribution examples. Additionally, we address the problem of calibrating out-of-distribution detectors, where we demonstrate that misclassified in-distribution examples can be used as a proxy for out-of-distribution examples.|sl:arxiv_author|Terrance DeVries
War|skos:broader|Conflits
Categorical Metadata Representation for Customized Text Classification  We observe that current representation methods for categorical metadata... are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category The performance of text classification has improved tremendously using intelligently engineered neural-based models, especially those injecting categorical metadata as additional information, e.g., using user/product information for sentiment classification. These information have been used to modify parts of the model (e.g., word embeddings, attention mechanisms) such that results can be customized according to the metadata. We observe that current representation methods for categorical metadata, which are devised for human consumption, are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category, and even such context is often scarce (for tail category). To this end, we propose to use basis vectors to effectively incorporate categorical metadata on various parts of a neural-based model. This additionally decreases the number of parameters dramatically, especially when the number of categorical features is large. Extensive experiments on various datasets with different properties are performed and show that through our method, we can represent categorical metadata more effectively to customize parts of the model, including unexplored ones, and increase the performance of the model greatly.|sl:arxiv_author|Seung-won Hwang
Natural Language Processing with Small Feed-Forward Networks google guys:      We show that small and shallow feed- forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.   We show that small and shallow feed-forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.|sl:arxiv_author|Ryan McDonald
Learning english|skos:broader|Anglais
A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efficient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximally preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We first introduce the formal definition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work address these challenges in their solutions. Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efficiency, problem settings, techniques and application scenarios.|sl:arxiv_author|Kevin Chen-Chuan Chang
Aïchi|skos:broader|Japon
Histoire coloniale|skos:broader|Colonisation
FaceNet: A Unified Embedding for Face Recognition and Clustering Learns a Euclidean embedding per image     Uses a deep CNN trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method.     state-of-the-art face recognition performance using only 128-bytes per face.      Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves 95.12%. Our system cuts the error rate in comparison to the best published result by 30% on both datasets. We also introduce the concept of harmonic embeddings, and a harmonic triplet loss, which describe different versions of face embeddings (produced by different networks) that are compatible to each other and allow for direct comparison between each other.|sl:tag|tag:arxiv_doc
A Comparative Study of Word Embeddings for Reading Comprehension abstract:   The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on    1.  the use of pre-trained word embeddings, and  2. the representation of out-of-vocabulary tokens at test time,     can turn out to have a larger impact than architectural choices on the final performance         The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on (1) the use of pre-trained word embeddings, and (2) the representation of out-of-vocabulary tokens at test time, can turn out to have a larger impact than architectural choices on the final performance. We systematically explore several options for these choices, and provide recommendations to researchers working in this area.|sl:tag|tag:oov
Manu Dibango|skos:broader|Music of Africa
Carbon sequestration|skos:broader|Climate crisis
hyperdoc2vec: Distributed Representations of Hypertext Documents Hypertext documents, such as web pages and academic papers, are of great importance in delivering information in our daily life. Although being effective on plain documents, conventional text embedding methods suffer from information loss if directly adapted to hyper-documents. In this paper, we propose a general embedding approach for hyper-documents, namely, hyperdoc2vec, along with four criteria characterizing necessary information that hyper-document embedding models should preserve. Systematic comparisons are conducted between hyperdoc2vec and several competitors on two tasks, i.e., paper classification and citation recommendation, in the academic paper domain. Analyses and experiments both validate the superiority of hyperdoc2vec to other models w.r.t. the four criteria.|sl:arxiv_firstAuthor|Jialong Han
Le gouvernement Chirac est trop con|skos:broader|Con de Chirac
RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space  We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.|sl:arxiv_author|Jian Tang
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).|sl:tag|tag:language_model
foaf+ssl|skos:broader|WebID
Phrase embeddings|skos:broader|Embeddings
English-grammar|skos:broader|Anglais
ESWC 2014|skos:broader|ESWC
Pierre Fresnay|skos:broader|Acteur
Bidirectional Encoder Representations from Transformers: pretraining technique for NLP.    [Google AI blog post](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)     BERT is designed to pre-train  deep bidirectional representations by jointly  conditioning on both left and right context in  all layers. As a result, the pre-trained BERT  representations can be fine-tuned with just one  additional output layer    BERT is pre-trained on two auxiliary tasks: Masked Language Model and  Next Sentence Prediction (but it has been shown in the RoBERTa paper that this  training objective doesn’t help that much).    The general BERT adaptation approach is to alter the model used for pre-training while retaining the transformer  encoder layers. The model discards the layers used for the final prediction in the pre-training tasks and adds layers to  predict the target task. All parameters are then fine tuned on the target task    Builds on [#The Transformer](/tag/attention_is_all_you_need)    Code and pre-trained models open-sourced on Nov 3rd, 2018.|skos:broader|replacement of the vectorial representation of words with a matrix representation where each word’s representation includes information about its context    Embedding words through a language model    Language-model-based encoders     The key idea underneath is to train a contextual encoder with a language model objective on a large unannotated text corpus. During the training, part of the text is masked and the goal is to encode the remaining context and predict the missing part. During the training, part of the text is masked and the goal is to encode the remaining  context and predict the missing part. ([source](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1902.11269))    
Dallol|skos:broader|Ethiopie
Musubi|skos:broader|Social Networks
Terre de Feu|skos:broader|Chili
fps ontologies|skos:broader|Ontologies
Semantic Web Services vs SOAP|skos:broader|Semantic Web Services
Paul Miller|skos:broader|Technical girls and guys
Span Selection Pre-training for Question Answering  a new pre-training task inspired by reading  comprehension and an effort to avoid encoding general knowledge in the transformer network itself    Current transformer architectures store general knowledge - large models, long pre-training time. Better to offload the requirement of general knowledge to a sparsely activated network.    Span selection as an additional auxiliary task: the query is a sentence drawn from a corpus  with a term replaced with a special token: [BLANK]. The term replaced by the blank is the answer term. The passage is  relevant as determined by a BM25 search, and answer-bearing (containing the answer  term). Unlike BERT’s cloze task, where the answer must be drawn from the model itself, the answer is found in a passage  using language understanding.     We hope to progress to a model of general purpose language modeling that uses an indexed long  term memory to retrieve world knowledge, rather than holding it in the densely activated transformer encoder layers. BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pre-trained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension and an effort to avoid encoding general knowledge in the transformer network itself. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple reading comprehension (MRC) and paraphrasing datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also establish a new SOTA in HotpotQA, improving answer prediction F1 by 4 F1 points and supporting fact prediction by 1 F1 point. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.|sl:arxiv_author|Rishav Chakravarti
Selective Question Answering under Domain Shift How you can get a QA model to abstain from answering when it doesn’t know the answer.     Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. To avoid giving wrong answers, question answering (QA) models need to know when to abstain from answering. Moreover, users often ask questions that diverge from the model's training data, making errors more likely and thus abstention more critical. In this work, we propose the setting of selective question answering under domain shift, in which a QA model is tested on a mixture of in-domain and out-of-domain data, and must answer (i.e., not abstain on) as many questions as possible while maintaining high accuracy. Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. Crucially, the calibrator benefits from observing the model's behavior on out-of-domain data, even if from a different domain than the test data. We combine this method with a SQuAD-trained QA model and evaluate on mixtures of SQuAD and five other QA datasets. Our method answers 56% of questions while maintaining 80% accuracy; in contrast, directly using the model's probabilities only answers 48% at 80% accuracy.|sl:tag|tag:uncertainty_in_deep_learning
RDF Validator|skos:broader|RDF Tools
Probing Neural Network Comprehension of Natural Language Arguments what has BERT learned about argument comprehension?    [Comments](/doc/2019/07/bert_s_success_in_some_benchmar) We are surprised to find that BERT's peak performance of 77% on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.|sl:arxiv_author|Hung-Yu Kao
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:tag|tag:nlp_microsoft
AdSense|skos:broader|Publicité Internet
Bernard Vatant|skos:broader|Technical girls and guys
Linked Data Platform|skos:broader|Linked Data
Denisovan|skos:broader|Origines de l'homme
Banque|skos:broader|Finance
A Review of Relational Machine Learning for Knowledge Graphs Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be trained on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive datasets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Google's Knowledge Vault project as an example of such combination.|sl:arxiv_author|Maximilian Nickel
An Introduction to Conditional Random Fields Often we wish to predict a large number of variables that depend on each other as well as on other observed variables. Structured prediction methods are essentially a combination of classification and graphical modeling, combining the ability of graphical models to compactly model multivariate data with the ability of classification methods to perform prediction using large sets of input features. This tutorial describes conditional random fields, a popular probabilistic method for structured prediction. CRFs have seen wide application in natural language processing, computer vision, and bioinformatics. We describe methods for inference and parameter estimation for CRFs, including practical issues for implementing large scale CRFs. We do not assume previous knowledge of graphical modeling, so this tutorial is intended to be useful to practitioners in a wide variety of fields.|sl:tag|tag:arxiv_doc
Einstein|skos:broader|Scientifique
Drupal/RDF|skos:broader|RDF
eRDF|skos:broader|RDF
Web tools|skos:broader|Tools
Medical Information Search|skos:broader|Medical Data
Microsoft|skos:broader|Software
Hayabusa|skos:broader|Japon
Knowledge Graph Completion|skos:broader|Knowledge Discovery
Knowledge Enhanced Contextual Word Representations General method to embed multiple knowledge bases into pre-trained language models (KB in the   sense as fixed collection of entity nodes)     The key idea is to explicitly model  entity spans in the input text and use an entity  linker to retrieve relevant entity embeddings from  a KB to form knowledge enhanced entity-span  representations.   Then,  update contextual word representations via a form of word-to-entity attention.    In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert's runtime is comparable to BERT's and it scales to large KBs.|sl:tag|tag:grounded_language_learning
Google Rich Snippets|skos:broader|Google: SEO
CEA, LIST|skos:broader|CEA
bengee|skos:broader|Technical guys
Learning to rank|skos:broader|Machine learning: problems
TopBraid/SPIN|skos:broader|Inference
Replace or Retrieve Keywords In Documents at Scale For a document of size N (characters) and a dictionary of M keywords, the time complexity is O(N) (compared to O(MxN) with regex). FlashText is designed to only match complete words (words with boundary characters on both sides). Different from Aho Corasick Algorithm, as it doesn't match substrings. This algorithm is also designed to go for the longest match first. For an input dictionary {Machine, Learning, Machine learning} on a string 'I like Machine learning', it will only consider the longest match, which is Machine Learning    [Github](https://github.com/vi3k6i5/flashtext) In this paper we introduce, the FlashText algorithm for replacing keywords or finding keywords in a given text. FlashText can search or replace keywords in one pass over a document. The time complexity of this algorithm is not dependent on the number of terms being searched or replaced. For a document of size N (characters) and a dictionary of M keywords, the time complexity will be O(N). This algorithm is much faster than Regex, because regex time complexity is O(MxN). It is also different from Aho Corasick Algorithm, as it doesn't match substrings. FlashText is designed to only match complete words (words with boundary characters on both sides). For an input dictionary of {Apple}, this algorithm won't match it to 'I like Pineapple'. This algorithm is also designed to go for the longest match first. For an input dictionary {Machine, Learning, Machine learning} on a string 'I like Machine learning', it will only consider the longest match, which is Machine Learning. We have made python implementation of this algorithm available as open-source on GitHub, released under the permissive MIT License.|sl:arxiv_author|Vikash Singh
eClassOWL|skos:broader|GoodRelations
University of Maryland|skos:broader|Universités américaines
SW demo|skos:broader|Demo
Concept Bottleneck Models  We seek to learn models that we can interact with using high-level concepts... We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these concept bottleneck models by editing their predicted concept values and propagating these changes to the final prediction... These models allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time. We seek to learn models that we can interact with using high-level concepts: if the model did not think there was a bone spur in the x-ray, would it still predict severe arthritis? State-of-the-art models today do not typically support the manipulation of concepts like the existence of bone spurs, as they are trained end-to-end to go directly from raw input (e.g., pixels) to output (e.g., arthritis severity). We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these \\emph{concept bottleneck models} by editing their predicted concept values and propagating these changes to the final prediction. On x-ray grading and bird identification, concept bottleneck models achieve competitive accuracy with standard end-to-end models, while enabling interpretation in terms of high-level clinical concepts (bone spurs) or bird attributes (wing color). These models also allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time.|sl:arxiv_author|Pang Wei Koh
Lobby agroalimentaire|skos:broader|Lobby
Méroé|skos:broader|Archéologie africaine
Amérindien|skos:broader|Amérique
GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden unit), or embedding-free units such as image pixels.|sl:tag|tag:yann_lecun
FaceNet: A Unified Embedding for Face Recognition and Clustering Learns a Euclidean embedding per image     Uses a deep CNN trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method.     state-of-the-art face recognition performance using only 128-bytes per face.      Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves 95.12%. Our system cuts the error rate in comparison to the best published result by 30% on both datasets. We also introduce the concept of harmonic embeddings, and a harmonic triplet loss, which describe different versions of face embeddings (produced by different networks) that are compatible to each other and allow for direct comparison between each other.|sl:tag|tag:face_recognition
Zotero|skos:broader|Open Source
Supervised machine learning|skos:broader|Machine learning
Text Embeddings|skos:broader|Embeddings in NLP
A mathematical theory of semantic development in deep neural networks  a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences?   An extensive body of empirical research has revealed remarkable regularities in the acquisition, organization, deployment, and neural representation of human semantic knowledge, thereby raising a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences? We address this question by mathematically analyzing the nonlinear dynamics of learning in deep linear networks. We find exact solutions to this learning dynamics that yield a conceptual explanation for the prevalence of many disparate phenomena in semantic cognition, including the hierarchical differentiation of concepts through rapid developmental transitions, the ubiquity of semantic illusions between such transitions, the emergence of item typicality and category coherence as factors controlling the speed of semantic processing, changing patterns of inductive projection over development, and the conservation of semantic similarity in neural representations across species. Thus, surprisingly, our simple neural model qualitatively recapitulates many diverse regularities underlying semantic development, while providing analytic insight into how the statistical structure of an environment can interact with nonlinear deep learning dynamics to give rise to these regularities.|sl:arxiv_author|Andrew M. Saxe
Semantic Web : Tools|skos:broader|Semantic Web
Semantic Statistics|skos:broader|Statistical data
Pêche|skos:broader|Océan
Enhancing the Power of Cardinal's Algorithm Cardinal's factorization algorithm of 1996 splits a univariate polynomial into two factors with root sets separated by the imaginary axis, which is an important goal itself and a basic step toward root-finding. The novelty of the algorithm and its potential power have been well recognized by experts immediately, but by 2016, that is, two decades later, its practical value still remains nil, particularly because of the high computational cost of performing its final stage by means of computing approximate greatest common divisor of two polynomials. We briefly recall Cardinal's algorithm and its difficulties, amend it based on some works performed since 1996, extend its power to splitting out factors of a more general class, and reduce the final stage of the algorithm to quite manageable computations with structured matrices. Some of our techniques can be of independent interest for matrix computations.|sl:tag|tag:algorithmes
Meetup Web Sémantique|skos:broader|Paris
Cinéma|skos:broader|Art
Probing Neural Network Comprehension of Natural Language Arguments what has BERT learned about argument comprehension?    [Comments](/doc/2019/07/bert_s_success_in_some_benchmar) We are surprised to find that BERT's peak performance of 77% on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.|sl:tag|tag:arxiv_doc
Patent Landscaping|skos:broader|AI 4 IP
Lisp|skos:broader|Programming language
Uber|skos:broader|Automobile
Ted Nelson|skos:broader|Technical girls and guys
Jeu d'échecs|skos:broader|Divers
Concept Extraction / Linking|skos:broader|Keyword/keyphrase extraction
Automotive and web technologies|skos:broader|Automobile 2.0
Nissan|skos:broader|Automobile
Python sample code|skos:broader|Sample code
Seyni Kountché|skos:broader|Niger
Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings (i.e. semantic representations) of word sequences as well. We present a simple but efficient unsupervised objective to train distributed representations of sentences. Our method outperforms the state-of-the-art unsupervised models on most benchmark tasks, highlighting the robustness of the produced general-purpose sentence embeddings.|sl:arxiv_firstAuthor|Matteo Pagliardini
Tabulator|skos:broader|Linking Open Data
RDF Parser|skos:broader|RDF
Facts as Experts: Adaptable and Interpretable Neural Memory over Symbolic Knowledge  a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge.... The model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones.     a  neural language model which learns to access information  in a symbolic knowledge graph.     This  model builds on the recently-proposed [Entities as  Experts](doc:2020/07/2004_07202_entities_as_expert) (EaE) language model (Févry et al., 2020),  which extends the same transformer (Vaswani  et al., 2017) architecture of BERT (Devlin et al., 2019) with an additional external memory for entities.     After training EaE, the embedding associated  with an entity will (ideally) capture information  about the textual context in which that  entity appears, and by inference, the entity’s semantic  properties     we include an additional  memory called a fact memory, which encodes  triples from a symbolic KB.     This combination results in a  neural language model which learns to access information  in a the symbolic knowledge graph.        TODO: read again IBM's [Span Selection Pre-training for Question Answering](doc:2019/09/_1909_04120_span_selection_pre) (an effort to avoid encoding general knowledge in the transformer network itself) Massive language models are the core of modern NLP modeling and have been shown to encode impressive amounts of commonsense and factual information. However, that knowledge exists only within the latent parameters of the model, inaccessible to inspection and interpretation, and even worse, factual information memorized from the training corpora is likely to become stale as the world changes. Knowledge stored as parameters will also inevitably exhibit all of the biases inherent in the source materials. To address these problems, we develop a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge. We show that this model dramatically improves performance on two knowledge-intensive question-answering tasks. More interestingly, the model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones in ways that are not possible for earlier models.|sl:arxiv_author|Haitian Sun
Detecting Potential Topics In News Using BERT, CRF and Wikipedia For a news content distribution platform like Dailyhunt, Named Entity Recognition is a pivotal task for building better user recommendation and notification algorithms. Apart from identifying names, locations, organisations from the news for 13+ Indian languages and use them in algorithms, we also need to identify n-grams which do not necessarily fit in the definition of Named-Entity, yet they are important. For example, me too movement, beef ban, alwar mob lynching. In this exercise, given an English language text, we are trying to detect case-less n-grams which convey important information and can be used as topics and/or hashtags for a news. Model is built using Wikipedia titles data, private English news corpus and BERT-Multilingual pre-trained model, Bi-GRU and CRF architecture. It shows promising results when compared with industry best Flair, Spacy and Stanford-caseless-NER in terms of F1 and especially Recall.|sl:tag|tag:arxiv_doc
fps dev|skos:broader|fps
Conversational AI|skos:broader|NLP tasks / problems
Treeview|skos:broader|Dev
Vidéo Ina.fr|skos:broader|Video
Al-Qaida|skos:broader|Terrorisme islamiste
An Introduction to Conditional Random Fields Often we wish to predict a large number of variables that depend on each other as well as on other observed variables. Structured prediction methods are essentially a combination of classification and graphical modeling, combining the ability of graphical models to compactly model multivariate data with the ability of classification methods to perform prediction using large sets of input features. This tutorial describes conditional random fields, a popular probabilistic method for structured prediction. CRFs have seen wide application in natural language processing, computer vision, and bioinformatics. We describe methods for inference and parameter estimation for CRFs, including practical issues for implementing large scale CRFs. We do not assume previous knowledge of graphical modeling, so this tutorial is intended to be useful to practitioners in a wide variety of fields.|sl:tag|tag:conditional_random_field
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Matt Botvinick
Improving Entity Linking by Modeling Latent Entity Type Information Existing state of the art neural entity linking models employ attention-based bag-of-words context model and pre-trained entity embeddings bootstrapped from word embeddings to assess topic level context compatibility. However, the latent entity type information in the immediate context of the mention is neglected, which causes the models often link mentions to incorrect entities with incorrect type. To tackle this problem, we propose to inject latent entity type information into the entity embeddings based on pre-trained BERT. In addition, we integrate a BERT-based entity similarity score into the local context model of a state-of-the-art model to better capture latent entity type information. Our model significantly outperforms the state-of-the-art entity linking models on standard benchmark (AIDA-CoNLL). Detailed experiment analysis demonstrates that our model corrects most of the type errors produced by the direct baseline.|sl:arxiv_author|Shuang Chen
Feature learning|skos:broader|Representation learning
Word2Bits - Quantized Word Vectors We show that high quality quantized word vectors using 1-2 bits per parameter can be learned by introducing a quantization function into Word2Vec. We furthermore show that training with the quantization function acts as a regularizer Word vectors require significant amounts of memory and storage, posing issues to resource limited devices like mobile phones and GPUs. We show that high quality quantized word vectors using 1-2 bits per parameter can be learned by introducing a quantization function into Word2Vec. We furthermore show that training with the quantization function acts as a regularizer. We train word vectors on English Wikipedia (2017) and evaluate them on standard word similarity and analogy tasks and on question answering (SQuAD). Our quantized word vectors not only take 8-16x less space than full precision (32 bit) word vectors but also outperform them on word similarity tasks and question answering.|sl:tag|tag:word_embedding
Lexicon Infused Phrase Embeddings for Named Entity Resolution Employs lexicons as part of the word embedding training:      The skip-gram model can be trained to  predict not only neighboring words but also lexicon  membership of the central word (or phrase).    Quickly demonstrates how we can plug phrase embeddings  into an existing log-linear CRF System.     Most state-of-the-art approaches for named-entity recognition (NER) use semi supervised information in the form of word clusters and lexicons. Recently neural network-based language models have been explored, as they as a byproduct generate highly informative vector representations for words, known as word embeddings. In this paper we present two contributions: a new form of learning word embeddings that can leverage information from relevant lexicons to improve the representations, and the first system to use neural word embeddings to achieve state-of-the-art results on named-entity recognition in both CoNLL and Ontonotes NER. Our system achieves an F1 score of 90.90 on the test set for CoNLL 2003---significantly better than any previous system trained on public data, and matching a system employing massive private industrial query-log data.|sl:tag|tag:phrase_embeddings
Arbres|skos:broader|Nature
Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective reviews the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. Neural-symbolic computing has now become the subject of interest of both academic and industry research laboratories. Graph Neural Networks (GNN) have been widely used in relational and symbolic domains, with widespread application of GNNs in combinatorial optimization, constraint satisfaction, relational reasoning and other scientific domains. The need for improved explainability, interpretability and trust of AI systems in general demands principled methodologies, as suggested by neural-symbolic computing. In this paper, we review the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. This includes the application of GNNs in several domains as well as its relationship to current developments in neural-symbolic computing.|sl:arxiv_author|Pedro Avelar
Revisiting Semi-Supervised Learning with Graph Embeddings We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.|sl:arxiv_author|Zhilin Yang
Missing Matter|skos:broader|Physics
Wolfram|skos:broader|Technical guys
Jeu d'échecs|skos:broader|Jeux
Fulani|skos:broader|Afrique de l'Ouest
Seevl|skos:broader|Alexandre Passant
Extinction d'espèces|skos:broader|Écologie
Variational autoencoder (VAE)|skos:broader|Autoencoder
FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence [github](https://github.com/google-research/fixmatch)     we demonstrate the power of a  simple combination of two common Semi-Supervised Learning methods: consistency  regularization and pseudo-labeling.    1. First generates pseudo-labels using the model’s  predictions on weakly-augmented unlabeled images. For a  given image, the pseudo-label is only retained if the model  produces a high-confidence prediction.   2. The model is then  trained to predict the pseudo-label when fed a strongly augmented  version of the same image. Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. In this paper, we demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling. Our algorithm, FixMatch, first generates pseudo-labels using the model's predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just 4 labels per class. Since FixMatch bears many similarities to existing SSL methods that achieve worse performance, we carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. We make our code available at https://github.com/google-research/fixmatch.|sl:arxiv_author|Zizhao Zhang
Building Machines That Learn and Think Like People  we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations   Recent progress in artificial intelligence (AI) has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn, and how they learn it. Specifically, we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models.|sl:arxiv_author|Brenden M. Lake
Gouvernement Sarkozy|skos:broader|Sarkozy
The Consciousness Prior consciousness seen as the formation of a low-dimensional combination of a few concepts constituting a conscious thought, i.e., consciousness as awareness at a particular time instant: the projection of a big vector (all the things conscious and unconscious in brain). Attention: additional mechanism describing what mind chooses to focus on.    [YouTube video](/doc/?uri=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYr1mOzC93xs) A new prior is proposed for learning representations of high-level concepts of the kind we manipulate with language. This prior can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by cognitive neuroscience theories of consciousness, seen as a bottleneck through which just a few elements, after having been selected by attention from a broader pool, are then broadcast and condition further processing, both in perception and decision-making. The set of recently selected elements one becomes aware of is seen as forming a low-dimensional conscious state. This conscious state is combining the few concepts constituting a conscious thought, i.e., what one is immediately conscious of at a particular moment. We claim that this architectural and information-processing constraint corresponds to assumptions about the joint distribution between high-level concepts. To the extent that these assumptions are generally true (and the form of natural language seems consistent with them), they can form a useful prior for representation learning. A low-dimensional thought or conscious state is analogous to a sentence: it involves only a few variables and yet can make a statement with very high probability of being true. This is consistent with a joint distribution (over high-level concepts) which has the form of a sparse factor graph, i.e., where the dependencies captured by each factor of the factor graph involve only very few variables while creating a strong dip in the overall energy function. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in a form similar to facts and rules, albeit capturing uncertainty as well as efficient search mechanisms implemented by attention mechanisms.|sl:tag|tag:representation_learning
Semantic Web|skos:broader|Web of data
Egit|skos:broader|Git
Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call fooling images (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.|sl:arxiv_author|Anh Nguyen
Cathares|skos:broader|Chrétienté
Unix|skos:broader|OS
Le Pen|skos:broader|Extrème droite
SPARQL|skos:broader|Semantic Web
Evaluation of sentence embeddings in downstream and linguistic probing tasks a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets     We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.           Despite the fast developmental pace of new sentence embedding methods, it is still challenging to find comprehensive evaluations of these different techniques. In the past years, we saw significant improvements in the field of sentence embeddings and especially towards the development of universal sentence encoders that could provide inductive transfer to a wide variety of downstream tasks. In this work, we perform a comprehensive evaluation of recent methods using a wide variety of downstream and linguistic feature probing tasks. We show that a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets. We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.|sl:tag|tag:embedding_evaluation
Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call fooling images (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.|sl:arxiv_firstAuthor|Anh Nguyen
Accident climatique|skos:broader|Catastrophe naturelle
Lyrics|skos:broader|Musique
OSEMA/DERI-Renault paper|skos:broader|fps: paper
What Does BERT Look At? An Analysis of BERT's Attention Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT's attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT's attention.|sl:tag|tag:arxiv_doc
Hydra/Templated Links|skos:broader|Hydra
each entity is defined by a short textual description, and the model must read these descriptions together with the mention context to make the linking decisions. |skos:broader|learn a classifier f : X → Y that must predict novel values of Y that were omitted from the training set (classification under the  restriction that the model cannot look  at any examples from the target classes) 
Boura|skos:broader|Terre cuite
Stacked Approximated Regression Machine: A Simple Deep Learning Approach This paper seems too good to be true! They can train a VGG-like net VERY quickly to good accuracy, without backprop. With the agreement of my coauthors, I Zhangyang Wang would like to withdraw the manuscript Stacked Approximated Regression Machine: A Simple Deep Learning Approach. Some experimental procedures were not included in the manuscript, which makes a part of important claims not meaningful. In the relevant research, I was solely responsible for carrying out the experiments; the other coauthors joined in the discussions leading to the main algorithm. Please see the updated text for more details.|sl:tag|tag:backpropagation
Linked Data publishing|skos:broader|RDF
Gorille|skos:broader|Grands Singes
Zinder : alimentation en eau|skos:broader|Chine / Afrique
Redis|skos:broader|NOSQL
Documentaire télé|skos:broader|TV
One-Shot Generalization in Deep Generative Models Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our models are able to generate compelling and diverse samples---having seen new examples just once---providing an important class of general-purpose models for one-shot machine learning.|sl:arxiv_author|Shakir Mohamed
Visualizing and Measuring the Geometry of BERT  At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.|sl:arxiv_firstAuthor|Andy Coenen
GNU|skos:broader|Open Source
Glaciologie|skos:broader|Glacier
Vie sur Mars|skos:broader|Vie extraterrestre
Rockart|skos:broader|Archéologie
Government data as Linked Data|skos:broader|Linked Data
Notes on Cardinal's Matrices These notes are motivated by the work of Jean-Paul Cardinal on symmetric matrices related to the Mertens function. He showed that certain norm bounds on his matrices implied the Riemann hypothesis. Using a different matrix norm we show an equivalence of the Riemann hypothesis to suitable norm bounds on his matrices in the new norm. Then we specify a deformed version of his Mertens function matrices that unconditionally satisfies a norm bound that is of the same strength as his Riemann hypothesis bound.|sl:tag|tag:arxiv_doc
Google Cloud|skos:broader|Cloud
Antibiotic resistance|skos:broader|Drug-resistant germs
Semantic markup in HTML|skos:broader|HTML
Blind relevance feedback|skos:broader|IR
Word Representations via Gaussian Embedding  Current work in lexical distributed representations maps each word to a point vector in low-dimensional space. Mapping instead to a density provides many interesting advantages     Novel word embedding algorithms that embed words directly as Gaussian distributional potential functions in an infinite dimensional function space. This allows us to map word types not only to vectors but to soft regions in space, modeling uncertainty, inclusion, and entailment, as well as providing a rich geometry of the latent space. Current work in lexical distributed representations maps each word to a point vector in low-dimensional space. Mapping instead to a density provides many interesting advantages, including better capturing uncertainty about a representation and its relationships, expressing asymmetries more naturally than dot product or cosine similarity, and enabling more expressive parameterization of decision boundaries. This paper advocates for density-based distributed embeddings and presents a method for learning representations in the space of Gaussian distributions. We compare performance on various word embedding benchmarks, investigate the ability of these embeddings to model entailment and other asymmetric relationships, and explore novel properties of the representation.|sl:tag|tag:word_embedding
From Word to Sense Embeddings: A Survey on Vector Representations of Meaning Survey focused on semantic representation of meaning (methods that try to directly model individual meanings of words).    Pb with word embeddings: the meaning conflation deficiency (representing a word with all its possible meanings as a single vector). Can be addressed by a method for modelling unambiguous lexical meaning.    two main branches of sense representation :    - unsupervised   - knowledge-based Over the past years, distributed semantic representations have proved to be effective and flexible keepers of prior knowledge to be integrated into downstream applications. This survey focuses on the representation of meaning. We start from the theoretical background behind word vector space models and highlight one of their major limitations: the meaning conflation deficiency, which arises from representing a word with all its possible meanings as a single vector. Then, we explain how this deficiency can be addressed through a transition from the word level to the more fine-grained level of word senses (in its broader acceptation) as a method for modelling unambiguous lexical meaning. We present a comprehensive overview of the wide range of techniques in the two main branches of sense representation, i.e., unsupervised and knowledge-based. Finally, this survey covers the main evaluation procedures and applications for this type of representation, and provides an analysis of four of its important aspects: interpretability, sense granularity, adaptability to different domains and compositionality.|sl:arxiv_author|Jose Camacho-Collados
Taxonomy expansion task|skos:broader|Knowledge Graph Completion
Winch 5|skos:broader|Francis Pisani
Visualizing and Measuring the Geometry of BERT  At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.|sl:arxiv_author|Fernanda Viégas
Boris Johnson|skos:broader|Homme politique
Tree of life|skos:broader|Evolution
Looks like everything (up to 2020-07-14) refers to this [github project](doc:2020/07/ukplab_sentence_transformers_s), [paper (Sentence-BERT)](doc:2019/08/_1908_10084_sentence_bert_sen)|skos:broader|Bidirectional Encoder Representations from Transformers: pretraining technique for NLP.    [Google AI blog post](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)     BERT is designed to pre-train  deep bidirectional representations by jointly  conditioning on both left and right context in  all layers. As a result, the pre-trained BERT  representations can be fine-tuned with just one  additional output layer    BERT is pre-trained on two auxiliary tasks: Masked Language Model and  Next Sentence Prediction (but it has been shown in the RoBERTa paper that this  training objective doesn’t help that much).    The general BERT adaptation approach is to alter the model used for pre-training while retaining the transformer  encoder layers. The model discards the layers used for the final prediction in the pre-training tasks and adds layers to  predict the target task. All parameters are then fine tuned on the target task    Builds on [#The Transformer](/tag/attention_is_all_you_need)    Code and pre-trained models open-sourced on Nov 3rd, 2018.
SemanticCampParis|skos:broader|Web sémantique sw
Wordnet|skos:broader|Text Corpora and Lexical Resources
Joint Embedding of Hierarchical Categories and Entities for Concept Categorization and Dataless Classification a framework that embeds entities and categories into a semantic space by integrating structured  knowledge and taxonomy hierarchy from large knowledge bases.    two methods:    1. Category Embedding model): it replaces the entities in the context with their directly  labeled categories to build categories’ context;   2. Hierarchical Category Embedding: it  further incorporates all ancestor categories of the context entities to utilize the hierarchical information. Due to the lack of structured knowledge applied in learning distributed representation of cate- gories, existing work cannot incorporate category hierarchies into entity information. We propose a framework that embeds entities and categories into a semantic space by integrating structured knowledge and taxonomy hierarchy from large knowledge bases. The framework allows to com- pute meaningful semantic relatedness between entities and categories. Our framework can han- dle both single-word concepts and multiple-word concepts with superior performance on concept categorization and yield state of the art results on dataless hierarchical classification.|sl:arxiv_firstAuthor|Yuezhang Li
Facts as Experts: Adaptable and Interpretable Neural Memory over Symbolic Knowledge  a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge.... The model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones.     a  neural language model which learns to access information  in a symbolic knowledge graph.     This  model builds on the recently-proposed [Entities as  Experts](doc:2020/07/2004_07202_entities_as_expert) (EaE) language model (Févry et al., 2020),  which extends the same transformer (Vaswani  et al., 2017) architecture of BERT (Devlin et al., 2019) with an additional external memory for entities.     After training EaE, the embedding associated  with an entity will (ideally) capture information  about the textual context in which that  entity appears, and by inference, the entity’s semantic  properties     we include an additional  memory called a fact memory, which encodes  triples from a symbolic KB.     This combination results in a  neural language model which learns to access information  in a the symbolic knowledge graph.        TODO: read again IBM's [Span Selection Pre-training for Question Answering](doc:2019/09/_1909_04120_span_selection_pre) (an effort to avoid encoding general knowledge in the transformer network itself) Massive language models are the core of modern NLP modeling and have been shown to encode impressive amounts of commonsense and factual information. However, that knowledge exists only within the latent parameters of the model, inaccessible to inspection and interpretation, and even worse, factual information memorized from the training corpora is likely to become stale as the world changes. Knowledge stored as parameters will also inevitably exhibit all of the biases inherent in the source materials. To address these problems, we develop a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge. We show that this model dramatically improves performance on two knowledge-intensive question-answering tasks. More interestingly, the model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones in ways that are not possible for earlier models.|sl:tag|tag:google_research
A Theoretical Analysis of Contrastive Unsupervised Representation Learning [blog post](/doc/?uri=http%3A%2F%2Fwww.offconvex.org%2F2019%2F03%2F19%2FCURL%2F) Recent empirical works have successfully used unlabeled data to learn feature representations that are broadly useful in downstream classification tasks. Several of these methods are reminiscent of the well-known word2vec embedding algorithm: leveraging availability of pairs of semantically similar data points and negative samples, the learner forces the inner product of representations of similar pairs with each other to be higher on average than with negative samples. The current paper uses the term contrastive learning for such algorithms and presents a theoretical framework for analyzing them by introducing latent classes and hypothesizing that semantically similar points are sampled from the same latent class. This framework allows us to show provable guarantees on the performance of the learned representations on the average classification task that is comprised of a subset of the same set of latent classes. Our generalization bound also shows that learned representations can reduce (labeled) sample complexity on downstream tasks. We conduct controlled experiments in both the text and image domains to support the theory.|sl:arxiv_firstAuthor|Sanjeev Arora
Covid19 : impréparation|skos:broader|Covid19
Robotique|skos:broader|Technologie
Loudness war|skos:broader|Musique
Maria-Fac|skos:broader|Maria
Commercialising the Semantic Web|skos:broader|Semantic Web
Coursera|skos:broader|Online Course Materials
ERNIE: Enhanced Language Representation with Informative Entities  We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.|sl:tag|tag:language_model
Semantic Web blog|skos:broader|Blog
Sylvain Gugger|skos:broader|AI girls and guys
Madame Bovary|skos:broader|Flaubert
Mami Wata|skos:broader|Afrique
Stacked Approximated Regression Machine: A Simple Deep Learning Approach This paper seems too good to be true! They can train a VGG-like net VERY quickly to good accuracy, without backprop. With the agreement of my coauthors, I Zhangyang Wang would like to withdraw the manuscript Stacked Approximated Regression Machine: A Simple Deep Learning Approach. Some experimental procedures were not included in the manuscript, which makes a part of important claims not meaningful. In the relevant research, I was solely responsible for carrying out the experiments; the other coauthors joined in the discussions leading to the main algorithm. Please see the updated text for more details.|sl:arxiv_author|Zhangyang Wang
Cheatsheet|skos:broader|Dev tip
Semantic Web propaganda|skos:broader|Semantic Web
Minoen|skos:broader|Crète antique
NLP: using Knowledge|skos:broader|NLP techniques
Internet Explorer|skos:broader|Brouteur
A mathematical theory of semantic development in deep neural networks  a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences?   An extensive body of empirical research has revealed remarkable regularities in the acquisition, organization, deployment, and neural representation of human semantic knowledge, thereby raising a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences? We address this question by mathematically analyzing the nonlinear dynamics of learning in deep linear networks. We find exact solutions to this learning dynamics that yield a conceptual explanation for the prevalence of many disparate phenomena in semantic cognition, including the hierarchical differentiation of concepts through rapid developmental transitions, the ubiquity of semantic illusions between such transitions, the emergence of item typicality and category coherence as factors controlling the speed of semantic processing, changing patterns of inductive projection over development, and the conservation of semantic similarity in neural representations across species. Thus, surprisingly, our simple neural model qualitatively recapitulates many diverse regularities underlying semantic development, while providing analytic insight into how the statistical structure of an environment can interact with nonlinear deep learning dynamics to give rise to these regularities.|sl:tag|tag:deep_learning
Jena User Conference|skos:broader|Jena
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Caglar Gulcehre
Java microframeworks|skos:broader|Java web dev
ranking function used by search engines to rank matching documents according to their relevance to a given search query. Bag-of-words based. Algorithm used by default in [Elasticsearch](elasticsearch) and [Lucene](lucene)  |skos:broader|formalism of information retrieval useful to derive  functions that rank matching documents according to their relevance to a given search query.
IRD|skos:broader|Recherche
Knowledge Compilation|skos:broader|Knowledge Representation
On Extractive and Abstractive Neural Document Summarization with Transformer Language Models  Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper. We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We show that this extractive step significantly improves summarization results. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher rouge scores. Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper.|sl:arxiv_author|Raymond Li
Uncertainty Reasoning|skos:broader|Artificial Intelligence
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Pushmeet Kohli
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:tag|tag:transfer_learning
GBIF|skos:broader|Biodiversité
Solr - autocomplete|skos:broader|Solr
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:tag|tag:arxiv_doc
SparqlPress is a project. Primary ingredients are WordPress and SPARQL The goal for SparqlPress is easy-to-use, low-barrier-of-entry, access to the linked data web. There are two, intimately-related sides to the idea: producing data, and consuming it. One goal is to make it easy for Wordpress to expose more data in SPARQL-friendly form. Another is to make it easier to use a Wordpress installation as a personal, perhaps even private, local aggregation of such data.|skos:broader|Backed by the flexibility of the RDF data model, and consisting of both a query language and data access protocol SPARQL has the potential to become a key component in Web 2.0 applications. SPARQL could provide a common query language for all Web 2.0 applications.
Learning Semantic Similarity for Very Short Texts In order to pair short text  fragments—as a concatenation of separate words—an adequate  distributed sentence representation is needed. Main contribution: a first step towards a hybrid method that  combines the strength of dense distributed representations—  as opposed to sparse term matching—with the strength of  tf-idf based methods. The combination of word embeddings and tf-idf  information might lead to a better model for semantic content  within very short text fragments. Levering data on social media, such as Twitter and Facebook, requires information retrieval algorithms to become able to relate very short text fragments to each other. Traditional text similarity methods such as tf-idf cosine-similarity, based on word overlap, mostly fail to produce good results in this case, since word overlap is little or non-existent. Recently, distributed word representations, or word embeddings, have been shown to successfully allow words to match on the semantic level. In order to pair short text fragments - as a concatenation of separate words - an adequate distributed sentence representation is needed, in existing literature often obtained by naively combining the individual word representations. We therefore investigated several text representations as a combination of word embeddings in the context of semantic pair matching. This paper investigates the effectiveness of several such naive techniques, as well as traditional tf-idf similarity, for fragments of different lengths. Our main contribution is a first step towards a hybrid method that combines the strength of dense distributed representations - as opposed to sparse term matching - with the strength of tf-idf based methods to automatically reduce the impact of less informative terms. Our new approach outperforms the existing techniques in a toy experimental set-up, leading to the conclusion that the combination of word embeddings and tf-idf information might lead to a better model for semantic content within very short text fragments.|sl:tag|tag:tf_idf
Classifier on top of a sentence2vec model.    Main idea: the morphological structure of a word carries important information about the meaning of the word, which is not taken into account by traditional [word embeddings](/tag/word_embedding). This is especially significant for morphologically rich languages (German, Turkish) in which a single word can have a large number of morphological forms, each of which might occur rarely, thus making it hard to train good word embeddings.    FastText attempts to solve this by treating each word as the aggregation of its subwords (uses character n-grams as features - avoids the OOV (out of vocabulary) problem)    (FastText represents words as the sum of their n-gram representations trained with a skip-gram model)    Embeddings learned using FastText (trained on wikipedia) are available in [many languages](https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md)            |skos:broader|[Best presentation](doc:2020/06/on_word_embeddings) about word embeddings, by [Sebastian Ruder](tag:sebastian_ruder)    Capture the idea that one can express “meaning” of words using a vector, so that the cosine of the angle between the vectors captures semantic similarity.    A set of language modeling and feature learning techniques where words from the vocabulary (and possibly phrases thereof) are mapped to vectors of real numbers in a low dimensional space, relative to the vocabulary size.     ~ Context-predicting models    ~ Latent feature representations of words    Paramaterized function mapping words in some language to vectors (perhaps 200 to 500 dimensions). Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with much lower dimension.    Plongement lexical in French    Word embedding of a word: a succinct representation of the distribution of other words around this word.    Methods to generate the mapping include neural networks, dimensionality reduction on the word co-occurrence matrix, probabilistic models, and explicit representation in terms of the context in which words appear.    In the new generation of models, the vector estimation problem is handled as a supervised task, where the weights in a word vector are set to maximize the probability of the contexts in which the word is observed in the corpus    The mapping may be generated training a neural network on a large corpus to predict a word given a context (Continuous Bag Of Words model) or to predict the context given a word (skip gram model). The context is a window of surrounding words.    The most known software to produce word embeddings is Tomas Mikolov's Word2vec. Pre-trained word embeddings are also available in the word2vec code.google page.    Applications:     - search document ranking  - boost the performance in NLP tasks such as syntactic parsing and sentiment analysis.          
Yahoo - My Web 2.0|skos:broader|Web 2.0
Haoussa|skos:broader|Peuples
Tribunal Pénal International|skos:broader|Justice internationale
OK, but where are the data about VW range? Partial stuff here: a href=http://www.volkswagen.co.uk/new/polo-v/which-model/compare/interiorhttp://www.volkswagen.co.uk/new/polo-v/which-model/compare/interior/a  |skos:broader|An ontology for linking product descriptions and business entities on the Web
Web 2.0 application|skos:broader|Web 2.0
Bas salaires|skos:broader|Economie
GooglePlus|skos:broader|Google
Mathématiques|skos:broader|Science
Beyond Vector Spaces: Compact Data Representation as Differentiable Weighted Graphs  In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE (Probabilistic Differentiable Graph Embeddings): a method that learns a weighted graph representation of data end-to-end by gradient descent.    [Github](https://github.com/stanis-morozov/prodige)     Learning useful representations is a key ingredient to the success of modern machine learning. Currently, representation learning mostly relies on embedding data into Euclidean space. However, recent work has shown that data in some domains is better modeled by non-euclidean metric spaces, and inappropriate geometry can result in inferior performance. In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE: a method that learns a weighted graph representation of data end-to-end by gradient descent. Greater generality and fewer model assumptions make PRODIGE more powerful than existing embedding-based approaches. We confirm the superiority of our method via extensive experiments on a wide range of tasks, including classification, compression, and collaborative filtering.|sl:arxiv_firstAuthor|Denis Mazur
Library of Alexandria|skos:broader|Alexandria
SPARQL Tutorial|skos:broader|SPARQL
JavaScript Promises|skos:broader|JavaScript
Terrorisme islamiste|skos:broader|Extrémisme islamique
Islam|skos:broader|Religion
Cassini-Huygens|skos:broader|Cassini
Linked Data Cache|skos:broader|Linked Data
answering arbitrary  context-independent questions (e.g. well-known  facts or historical details).Typically assumed  that the model can access an external collection  of knowledge (e.g. a  structured knowledge base or unstructured text  corpus) (~open-book exam)|skos:broader|For a description of the variants of this task, see this [paper](/doc/2020/02/how_much_knowledge_can_you_pack)    - reading comprehesion  - open-domain QA      - open-book exam      - open-book exam
Foxconn|skos:broader|Entreprise
Semantic Vector Encoding and Similarity Search Using Fulltext Search Engines  The ubiquity of semantic vector space modeling raises the challenge of efficient searching in dense, high-dimensional vector spaces. We would naturally want to take advantage of the design and optimizations behind modern fulltext engines like Elasticsearch so as to meet the scalability and robustness demands of modern IR applications. This is the research challenge addressed in this paper.   The paper describes novel ways of encoding dense vectors into text documents, allowing the use of traditional inverted index engines.    [blog post](https://rare-technologies.com/semantic-search-fulltext-engine-acl-2017/)   Vector representations and vector space modeling (VSM) play a central role in modern machine learning. We propose a novel approach to `vector similarity searching' over dense semantic representations of words and documents that can be deployed on top of traditional inverted-index-based fulltext engines, taking advantage of their robustness, stability, scalability and ubiquity. We show that this approach allows the indexing and querying of dense vectors in text domains. This opens up exciting avenues for major efficiency gains, along with simpler deployment, scaling and monitoring. The end result is a fast and scalable vector database with a tunable trade-off between vector search performance and quality, backed by a standard fulltext engine such as Elasticsearch. We empirically demonstrate its querying performance and quality by applying this solution to the task of semantic searching over a dense vector representation of the entire English Wikipedia.|sl:arxiv_author|Petr Sojka
regression model where the dependent variable is categorical.|skos:broader|a statistical process for estimating the relationships among variables.  
Ajax applications|skos:broader|Ajax
Representation Learning with Contrastive Predictive Coding  a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful [autoregressive models](/tag/autoregressive_model). We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using [negative sampling](/tag/negative_sampling).    a contrastive method that can be applied to any form of data that can be expressed in an ordered sequence: text, speech, video... While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.|sl:arxiv_firstAuthor|Aaron van den Oord
Jena|skos:broader|RDF
Thrace|skos:broader|Antiquité
Jure Leskovec|skos:broader|NLP girls and guys
OS X app|skos:broader|Mac OS X
Unsupervised machine translation|skos:broader|Machine translation
OPML|skos:broader|Dave Winer
Oiseau|skos:broader|Animal
TripleStore|skos:broader|RDF and database
Tim Berners-Lee|skos:broader|SW guys (and girls)
Dallol|skos:broader|Volcan
Stanford POS Tagger|skos:broader|NLP tools
Big Data Tools|skos:broader|Big Data
République Tchèque|skos:broader|Pays d'Europe
InceptionTime: Finding AlexNet for Time Series Classification Time series classification (TSC) is the area of machine learning interested in learning how to assign labels to time series. The last few decades of work in this area have led to significant progress in the accuracy of classifiers, with the state of the art now represented by the HIVE-COTE algorithm. While extremely accurate, HIVE-COTE is infeasible to use in many applications because of its very high training time complexity in O(N^2T^4) for a dataset with N time series of length T. For example, it takes HIVE-COTE more than 72,000s to learn from a small dataset with N=700 time series of short length T=46. Deep learning, on the other hand, has now received enormous attention because of its high scalability and state-of-the-art accuracy in computer vision and natural language processing tasks. Deep learning for TSC has only very recently started to be explored, with the first few architectures developed over the last 3 years only. The accuracy of deep learning for TSC has been raised to a competitive level, but has not quite reached the level of HIVE-COTE. This is what this paper achieves: outperforming HIVE-COTE's accuracy together with scalability. We take an important step towards finding the AlexNet network for TSC by presenting InceptionTime---an ensemble of deep Convolutional Neural Network (CNN) models, inspired by the Inception-v4 architecture. Our experiments show that InceptionTime slightly outperforms HIVE-COTE with a win/draw/loss on the UCR archive of 40/6/39. Not only is InceptionTime more accurate, but it is much faster: InceptionTime learns from that same dataset with 700 time series in 2,300s but can also learn from a dataset with 8M time series in 13 hours, a quantity of data that is fully out of reach of HIVE-COTE.|sl:arxiv_author|Benjamin Lucas
What Does BERT Look At? An Analysis of BERT's Attention Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT's attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT's attention.|sl:arxiv_author|Omer Levy
BBC - Programmes|skos:broader|BBC semantic publishing
Javadoc|skos:broader|Developer documentation
Word Translation Without Parallel Data  we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent studies showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally describe experiments on the English-Esperanto low-resource language pair, on which there only exists a limited amount of parallel data, to show the potential impact of our method in fully unsupervised machine translation. Our code, embeddings and dictionaries are publicly available.|sl:tag|tag:unsupervised_machine_translation
Semantic CMS|skos:broader|Semantic technology
Vary Header|skos:broader|HTTP Cache
Plastic waste trade|skos:broader|Plastic
CoKE: Contextualized Knowledge Graph Embedding A method to build contextualized entity and relation embeddings. Entities and relations may appear in different graph contexts. Edges and paths, both formulated as sequences of entities and relations, are passed as input to a Transformer encoder to learn the contextualized representations..    [Github](https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE) Knowledge graph embedding, which projects symbolic entities and relations into continuous vector spaces, is gaining increasing attention. Previous methods allow a single static embedding for each entity or relation, ignoring their intrinsic contextual nature, i.e., entities and relations may appear in different graph contexts, and accordingly, exhibit different properties. This work presents Contextualized Knowledge Graph Embedding (CoKE), a novel paradigm that takes into account such contextual nature, and learns dynamic, flexible, and fully contextualized entity and relation embeddings. Two types of graph contexts are studied: edges and paths, both formulated as sequences of entities and relations. CoKE takes a sequence as input and uses a Transformer encoder to obtain contextualized representations. These representations are hence naturally adaptive to the input, capturing contextual meanings of entities and relations therein. Evaluation on a wide variety of public benchmarks verifies the superiority of CoKE in link prediction and path query answering. It performs consistently better than, or at least equally well as current state-of-the-art in almost every case, in particular offering an absolute improvement of 21.0% in H@10 on path query answering. Our code is available at \\url{https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE}.|sl:arxiv_author|Quan Wang
KBPedia|skos:broader|Mike Bergman
Fourier|skos:broader|Mathématicien
PRISM|skos:broader|Big Brother
Visualizing and Measuring the Geometry of BERT  At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.|sl:arxiv_author|Andy Coenen
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:arxiv_author|Marcus Gomez
iphone|skos:broader|Apple
Generalization through Memorization: Nearest Neighbor Language Models extend LMs with nearest neighbor search in embedding space We introduce $k$NN-LMs, which extend a pre-trained neural language model (LM) by linearly interpolating it with a $k$-nearest neighbors ($k$NN) model. The nearest neighbors are computed according to distance in the pre-trained LM embedding space, and can be drawn from any text collection, including the original LM training data. Applying this augmentation to a strong Wikitext-103 LM, with neighbors drawn from the original training set, our $k$NN-LM achieves a new state-of-the-art perplexity of 15.79 - a 2.9 point improvement with no additional training. We also show that this approach has implications for efficiently scaling up to larger training sets and allows for effective domain adaptation, by simply varying the nearest neighbor datastore, again without further training. Qualitatively, the model is particularly helpful in predicting rare patterns, such as factual knowledge. Together, these results strongly suggest that learning similarity between sequences of text is easier than predicting the next word, and that nearest neighbor search is an effective approach for language modeling in the long tail.|sl:arxiv_author|Mike Lewis
Database to RDF mapping|skos:broader|RDF
FaceNet: A Unified Embedding for Face Recognition and Clustering Learns a Euclidean embedding per image     Uses a deep CNN trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method.     state-of-the-art face recognition performance using only 128-bytes per face.      Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves 95.12%. Our system cuts the error rate in comparison to the best published result by 30% on both datasets. We also introduce the concept of harmonic embeddings, and a harmonic triplet loss, which describe different versions of face embeddings (produced by different networks) that are compatible to each other and allow for direct comparison between each other.|sl:tag|tag:ml_google
Berlin|skos:broader|Allemagne
ML: evaluation|skos:broader|Machine learning: problems
Scandale des écoutes en Allemagne|skos:broader|Espionnage
fpservant@slideshare|skos:broader|fps
Twitter|skos:broader|Microblogs
AngularJS|skos:broader|Javascript framework
Bacteria|skos:broader|Biology
Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective reviews the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. Neural-symbolic computing has now become the subject of interest of both academic and industry research laboratories. Graph Neural Networks (GNN) have been widely used in relational and symbolic domains, with widespread application of GNNs in combinatorial optimization, constraint satisfaction, relational reasoning and other scientific domains. The need for improved explainability, interpretability and trust of AI systems in general demands principled methodologies, as suggested by neural-symbolic computing. In this paper, we review the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. This includes the application of GNNs in several domains as well as its relationship to current developments in neural-symbolic computing.|sl:tag|tag:arxiv_doc
National Taiwan University|skos:broader|Université
What's encoded by a NN|skos:broader|Neural networks
Poincaré Embeddings for Learning Hierarchical Representations  While complex symbolic datasets often exhibit a latent hierarchical structure, state-of-the-art methods typically learn embeddings in Euclidean vector spaces, which do not account for this property. For this purpose, we introduce a new approach for learning hierarchical representations of symbolic data by embedding them into hyperbolic space Representation learning has become an invaluable approach for learning from symbolic data such as text and graphs. However, while complex symbolic datasets often exhibit a latent hierarchical structure, state-of-the-art methods typically learn embeddings in Euclidean vector spaces, which do not account for this property. For this purpose, we introduce a new approach for learning hierarchical representations of symbolic data by embedding them into hyperbolic space -- or more precisely into an n-dimensional Poincar\\'e ball. Due to the underlying hyperbolic geometry, this allows us to learn parsimonious representations of symbolic data by simultaneously capturing hierarchy and similarity. We introduce an efficient algorithm to learn the embeddings based on Riemannian optimization and show experimentally that Poincar\\'e embeddings outperform Euclidean embeddings significantly on data with latent hierarchies, both in terms of representation capacity and in terms of generalization ability.|sl:arxiv_firstAuthor|Maximilian Nickel
Towards Understanding Linear Word Analogies A surprising property of word vectors is that word analogies can often be solved with vector arithmetic. However, it is unclear why arithmetic operators correspond to non-linear embedding models such as skip-gram with negative sampling (SGNS). We provide a formal explanation of this phenomenon without making the strong assumptions that past theories have made about the vector space and word distribution. Our theory has several implications. Past work has conjectured that linear substructures exist in vector spaces because relations can be represented as ratios; we prove that this holds for SGNS. We provide novel justification for the addition of SGNS word vectors by showing that it automatically down-weights the more frequent word, as weighting schemes do ad hoc. Lastly, we offer an information theoretic interpretation of Euclidean distance in vector spaces, justifying its use in capturing word dissimilarity.|sl:arxiv_author|Graeme Hirst
Livesearch|skos:broader|Ajax
nonlinear dimensionality reduction technique that is particularly well suited for embedding high-dimensional data into a space of two or three dimensions, which can then be visualized in a scatter plot. Specifically, it models each high-dimensional object by a two- or three-dimensional point in such a way that similar objects are modeled by nearby points and dissimilar objects are modeled by distant points.|skos:broader|process of reducing the number of random variables under consideration. Can be divided into feature selection and feature extraction.
Uncertainty Reasoning AND Semantic Web|skos:broader|Semantic Web
C2GWeb, Product description and Makolab|skos:broader|Mirek Sopek
NASA|skos:broader|Exploration spatiale
Programming language|skos:broader|Informatique
CoKE: Contextualized Knowledge Graph Embedding A method to build contextualized entity and relation embeddings. Entities and relations may appear in different graph contexts. Edges and paths, both formulated as sequences of entities and relations, are passed as input to a Transformer encoder to learn the contextualized representations..    [Github](https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE) Knowledge graph embedding, which projects symbolic entities and relations into continuous vector spaces, is gaining increasing attention. Previous methods allow a single static embedding for each entity or relation, ignoring their intrinsic contextual nature, i.e., entities and relations may appear in different graph contexts, and accordingly, exhibit different properties. This work presents Contextualized Knowledge Graph Embedding (CoKE), a novel paradigm that takes into account such contextual nature, and learns dynamic, flexible, and fully contextualized entity and relation embeddings. Two types of graph contexts are studied: edges and paths, both formulated as sequences of entities and relations. CoKE takes a sequence as input and uses a Transformer encoder to obtain contextualized representations. These representations are hence naturally adaptive to the input, capturing contextual meanings of entities and relations therein. Evaluation on a wide variety of public benchmarks verifies the superiority of CoKE in link prediction and path query answering. It performs consistently better than, or at least equally well as current state-of-the-art in almost every case, in particular offering an absolute improvement of 21.0% in H@10 on path query answering. Our code is available at \\url{https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE}.|sl:tag|tag:link_prediction
Erta Ale|skos:broader|Lac de lave
FIBO|skos:broader|Financial Data
Google car|skos:broader|Driverless car
Juliana Rotich|skos:broader|New Africa
Entities to topics|skos:broader|Entities
Universités françaises|skos:broader|Enseignement supérieur
Semi-supervised Clustering for Short Text via Deep Representation Learning semi-supervised method for short text clustering, where we represent texts as distributed vectors with neural networks, and use a small amount of labeled data to specify our intention for clustering. We design a novel objective to combine the representation learning process and the k-means clustering process together, and optimize the objective with both labeled data and unlabeled data iteratively until convergence through three steps:     1. assign each short text to its nearest centroid based on its representation from the current neural networks;  2. re-estimate the cluster centroids based on cluster assignments from step (1);  3. update neural networks according to the objective by keeping centroids and cluster assignments fixed.   In this work, we propose a semi-supervised method for short text clustering, where we represent texts as distributed vectors with neural networks, and use a small amount of labeled data to specify our intention for clustering. We design a novel objective to combine the representation learning process and the k-means clustering process together, and optimize the objective with both labeled data and unlabeled data iteratively until convergence through three steps: (1) assign each short text to its nearest centroid based on its representation from the current neural networks; (2) re-estimate the cluster centroids based on cluster assignments from step (1); (3) update neural networks according to the objective by keeping centroids and cluster assignments fixed. Experimental results on four datasets show that our method works significantly better than several other text clustering methods.|sl:tag|tag:arxiv_doc
Intel|skos:broader|Entreprise
De-extinction|skos:broader|Disparition d'espèces
AI: limits|skos:broader|Artificial Intelligence
Specializing Word Embeddings (for Parsing) by Information Bottleneck EMNLP best paper award. [Related blog post](doc:2020/06/information_bottleneck_for_nlp_) Pre-trained word embeddings like ELMo and BERT contain rich syntactic and semantic information, resulting in state-of-the-art performance on various tasks. We propose a very fast variational information bottleneck (VIB) method to nonlinearly compress these embeddings, keeping only the information that helps a discriminative parser. We compress each word embedding to either a discrete tag or a continuous vector. In the discrete version, our automatically compressed tags form an alternative tag set: we show experimentally that our tags capture most of the information in traditional POS tag annotations, but our tag sequences can be parsed more accurately at the same level of tag granularity. In the continuous version, we show experimentally that moderately compressing the word embeddings by our method yields a more accurate parser in 8 of 9 languages, unlike simple dimensionality reduction.|sl:arxiv_firstAuthor|Xiang Lisa Li
Sigma.js|skos:broader|JavaScript
French Semantic web company|skos:broader|Semantic web company
Notes d'install|skos:broader|fps notes
Still a Pain in the Neck: Evaluating Text Representations on Lexical Composition How well do contextualized word embeddings address lexical composition? They are good in recognizing meaning shift (\give in\ is different from \give\) but much worse with revealing implicit meaning (\hot tea\ is about temperature, \hot debate\ isn't). Building meaningful phrase representations is challenging because phrase meanings are not simply the sum of their constituent meanings. Lexical composition can shift the meanings of the constituent words and introduce implicit information. We tested a broad range of textual representations for their capacity to address these issues. We found that as expected, contextualized word representations perform better than static word embeddings, more so on detecting meaning shift than in recovering implicit information, in which their performance is still far from that of humans. Our evaluation suite, including 5 tasks related to lexical composition effects, can serve future research aiming to improve such representations.|sl:arxiv_author|Ido Dagan
Universités françaises|skos:broader|Université
Satori|skos:broader|Semantic Web
LinkTo Semanlink|skos:broader|About Semanlink
Building Machines That Learn and Think Like People  we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations   Recent progress in artificial intelligence (AI) has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn, and how they learn it. Specifically, we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models.|sl:tag|tag:human_like_ai
AI 4 IP|skos:broader|NLP + juridique
Natural Language Processing (almost) from Scratch seminal work    Abstract:     a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements   We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.|sl:tag|tag:ronan_collobert
Document Embedding with Paragraph Vectors Paragraph Vectors has been recently proposed as an unsupervised method for learning distributed representations for pieces of texts. In their work, the authors showed that the method can learn an embedding of movie review texts which can be leveraged for sentiment analysis. That proof of concept, while encouraging, was rather narrow. Here we consider tasks other than sentiment analysis, provide a more thorough comparison of Paragraph Vectors to other document modelling algorithms such as Latent Dirichlet Allocation, and evaluate performance of the method as we vary the dimensionality of the learned representation. We benchmarked the models on two document similarity data sets, one from Wikipedia, one from arXiv. We observe that the Paragraph Vector method performs significantly better than other methods, and propose a simple improvement to enhance embedding quality. Somewhat surprisingly, we also show that much like word embeddings, vector operations on Paragraph Vectors can perform useful semantic results.|sl:arxiv_author|Quoc V. Le
Trou noir|skos:broader|Gravitation
RSS Dev|skos:broader|Web dev
gensim|skos:broader|NLP tools
Retrofitting Word Vectors to Semantic Lexicons Method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed.     Graph-based learning technique for using lexical relational resources to obtain higher quality semantic vectors, which we call “retrofitting.” Retrofitting is applied as a post-processing step by running belief propagation on a graph constructed from lexicon-derived relational information to update word vectors. This allows retrofitting to be used on pre-trained word vectors obtained using any vector training model.    [github](https://github.com/mfaruqui/retrofitting)     Vector space word representations are learned from distributional information of words in large corpora. Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database. This paper proposes a method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed. Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, we obtain substantial improvements starting with a variety of word vector models. Our refinement method outperforms prior techniques for incorporating semantic lexicons into the word vector training algorithms.|sl:tag|tag:arxiv_doc
IPython notebook|skos:broader|IPython
Transformers as Soft Reasoners over Language  AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. We provide the first demonstration that this is possible, and characterize the extent of this capability. To do this, we use a collection of synthetic datasets that test increasing levels of reasoning complexity (number of rules, presence of negation, and depth of chaining). We find transformers appear to learn rule-based reasoning with high (99%) accuracy on these datasets, and in a way that generalizes to test data requiring substantially deeper chaining than in the training data (95%+ scores). We also demonstrate that the models transfer well to two hand-authored rulebases, and to rulebases paraphrased into more natural language. These findings are significant as it suggests a new role for transformers, namely as a limited soft theorem prover operating over explicit theories in language. This in turn suggests new possibilities for explainability, correctability, and counterfactual reasoning in question-answering. All datasets and a live demo are available at http://rule-reasoning.apps.allenai.org/|sl:arxiv_firstAuthor|Peter Clark
WSDL|skos:broader|Service description
Macaw: An Extensible Conversational Information Seeking Platform Conversational information seeking (CIS) has been recognized as a major emerging research area in information retrieval. Such research will require data and tools, to allow the implementation and study of conversational systems. This paper introduces Macaw, an open-source framework with a modular architecture for CIS research. Macaw supports multi-turn, multi-modal, and mixed-initiative interactions, and enables research for tasks such as document retrieval, question answering, recommendation, and structured data exploration. It has a modular design to encourage the study of new CIS algorithms, which can be evaluated in batch mode. It can also integrate with a user interface, which allows user studies and data collection in an interactive mode, where the back end can be fully algorithmic or a wizard of oz setup. Macaw is distributed under the MIT License.|sl:tag|tag:nlp_microsoft
Unsupervised Deep Embedding for Clustering Analysis Relatively little work has focused on learning representations for clustering. In this paper, we propose Deep Embedded Clustering (DEC), a method that simultaneously learns feature representations and cluster assignments using deep neural networks. DEC learns a mapping from the data space to a lower-dimensional feature space in which it iteratively optimizes a clustering objective Clustering is central to many data-driven application domains and has been studied extensively in terms of distance functions and grouping algorithms. Relatively little work has focused on learning representations for clustering. In this paper, we propose Deep Embedded Clustering (DEC), a method that simultaneously learns feature representations and cluster assignments using deep neural networks. DEC learns a mapping from the data space to a lower-dimensional feature space in which it iteratively optimizes a clustering objective. Our experimental evaluations on image and text corpora show significant improvement over state-of-the-art methods.|sl:arxiv_firstAuthor|Junyuan Xie
Reto Bachmann-Gmür|skos:broader|SW guys (and girls)
Amazon Mechanical Turk|skos:broader|Web marchand
Rijksmuseum|skos:broader|Musée
Enseignement français|skos:broader|Education
Word Translation Without Parallel Data  we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent studies showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally describe experiments on the English-Esperanto low-resource language pair, on which there only exists a limited amount of parallel data, to show the potential impact of our method in fully unsupervised machine translation. Our code, embeddings and dictionaries are publicly available.|sl:tag|tag:machine_translation
Histoire du monde|skos:broader|Histoire
Graph-based Semi-Supervised Learning|skos:broader|Semi-supervised learning
Héliosphère|skos:broader|Système solaire
Solid|skos:broader|Data ownership
SemWeb Pro 2011|skos:broader|SemWeb Pro
Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.|sl:arxiv_firstAuthor|Artur d'Avila Garcez
Semantic Web Outliner|skos:broader|Semantic Web : Tools
NLP conference|skos:broader|NLP event
XSPARQL|skos:broader|XQuery
ISP|skos:broader|Internet
Extinction de masse|skos:broader|Extinction d'espèces
Internet en Afrique|skos:broader|Afrique
Christine Golbreich|skos:broader|Technical girls and guys
Crustacé|skos:broader|Animal
Belgique|skos:broader|Europe
Carte d'identité|skos:broader|Divers
Hash-bang URIs|skos:broader|Hash URIs
Peter Patel-Schneider|skos:broader|Technical girls and guys
RDF and social networks|skos:broader|Social Networks
Concept Bottleneck Models  We seek to learn models that we can interact with using high-level concepts... We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these concept bottleneck models by editing their predicted concept values and propagating these changes to the final prediction... These models allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time. We seek to learn models that we can interact with using high-level concepts: if the model did not think there was a bone spur in the x-ray, would it still predict severe arthritis? State-of-the-art models today do not typically support the manipulation of concepts like the existence of bone spurs, as they are trained end-to-end to go directly from raw input (e.g., pixels) to output (e.g., arthritis severity). We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these \\emph{concept bottleneck models} by editing their predicted concept values and propagating these changes to the final prediction. On x-ray grading and bird identification, concept bottleneck models achieve competitive accuracy with standard end-to-end models, while enabling interpretation in terms of high-level clinical concepts (bone spurs) or bird attributes (wing color). These models also allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time.|sl:tag|tag:human_in_the_loop
Learning to rank|skos:broader|Ranking (information retrieval)
Recette de cuisine|skos:broader|Gastronomie
Poincaré Embeddings for Learning Hierarchical Representations  While complex symbolic datasets often exhibit a latent hierarchical structure, state-of-the-art methods typically learn embeddings in Euclidean vector spaces, which do not account for this property. For this purpose, we introduce a new approach for learning hierarchical representations of symbolic data by embedding them into hyperbolic space Representation learning has become an invaluable approach for learning from symbolic data such as text and graphs. However, while complex symbolic datasets often exhibit a latent hierarchical structure, state-of-the-art methods typically learn embeddings in Euclidean vector spaces, which do not account for this property. For this purpose, we introduce a new approach for learning hierarchical representations of symbolic data by embedding them into hyperbolic space -- or more precisely into an n-dimensional Poincar\\'e ball. Due to the underlying hyperbolic geometry, this allows us to learn parsimonious representations of symbolic data by simultaneously capturing hierarchy and similarity. We introduce an efficient algorithm to learn the embeddings based on Riemannian optimization and show experimentally that Poincar\\'e embeddings outperform Euclidean embeddings significantly on data with latent hierarchies, both in terms of representation capacity and in terms of generalization ability.|sl:tag|tag:arxiv_doc
Nebra Sky Disc|skos:broader|Archéologie européenne
Brouteur|skos:broader|Web
Bringing Light Into the Dark: A Large-scale Evaluation of Knowledge Graph Embedding Models Under a Unified Framework The heterogeneity in recently published knowledge graph embedding models' implementations, training, and evaluation has made fair and thorough comparisons difficult. In order to assess the reproducibility of previously published results, we re-implemented and evaluated 19 interaction models in the PyKEEN software package. Here, we outline which results could be reproduced with their reported hyper-parameters, which could only be reproduced with alternate hyper-parameters, and which could not be reproduced at all as well as provide insight as to why this might be the case. We then performed a large-scale benchmarking on four datasets with several thousands of experiments and 21,246 GPU hours of computation time. We present insights gained as to best practices, best configurations for each model, and where improvements could be made over previously published best configurations. Our results highlight that the combination of model architecture, training approach, loss function, and the explicit modeling of inverse relations is crucial for a model's performances, and not only determined by the model architecture. We provide evidence that several architectures can obtain results competitive to the state-of-the-art when configured carefully. We have made all code, experimental configurations, results, and analyses that lead to our interpretations available at https://github.com/pykeen/pykeen and https://github.com/pykeen/benchmarking|sl:arxiv_author|Jens Lehmann
Hindu/Muslim riots|skos:broader|Guerres de religion
Voûte nubienne|skos:broader|Architecture en terre
SKOS|skos:broader|RDF Vocabularies
Lune|skos:broader|Système solaire
Music source separation|skos:broader|Digital Audio
What Does BERT Look At? An Analysis of BERT's Attention Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT's attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT's attention.|sl:tag|tag:chris_manning
Technique de l'insecte stérile|skos:broader|Insecte
RDF browser|skos:broader|RDF
Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks Current machine learning systems operate, almost exclusively, in a statistical, or model-free mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks. To demonstrate the essential role of such models, I will present a summary of seven tasks which are beyond reach of current machine learning systems and which have been accomplished using the tools of causal modeling.|sl:tag|tag:machine_learning
John Sofakolle|skos:broader|Musique du Niger
inductive biases which impose constraints on relationships and interactions among entities in a learning process  |skos:broader|learning bias: the set of assumptions that a model makes in order to generalize to new inputs.    An inductive bias allows a learning algorithm to prioritize  one solution (or interpretation) over another, independent of the observed data (Mitchell,  1980). In a Bayesian model, inductive biases are typically expressed through the choice and  parameterization of the prior distribution [source](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1806.01261)
Compressive Transformers for Long-Range Sequence Modelling  the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning.    [Blog post](/doc/2020/02/a_new_model_and_dataset_for_lon) We present the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning. We find the Compressive Transformer obtains state-of-the-art language modelling results in the WikiText-103 and Enwik8 benchmarks, achieving 17.1 ppl and 0.97 bpc respectively. We also find it can model high-frequency speech effectively and can be used as a memory mechanism for RL, demonstrated on an object matching task. To promote the domain of long-range sequence learning, we propose a new open-vocabulary language modelling benchmark derived from books, PG-19.|sl:arxiv_author|Siddhant M. Jayakumar
StarSpace: Embed All The Things! We present StarSpace, a general-purpose neural embedding model that can solve a wide variety of problems: labeling tasks such as text classification, ranking tasks such as information retrieval/web search, collaborative filtering-based or content-based recommendation, embedding of multi-relational graphs, and learning word, sentence or document level embeddings. In each case the model works by embedding those entities comprised of discrete features and comparing them against each other -- learning similarities dependent on the task. Empirical results on a number of tasks show that StarSpace is highly competitive with existing methods, whilst also being generally applicable to new cases where those methods are not.|sl:arxiv_author|Keith Adams
Attention Models in Graphs: A Survey  An attention mechanism aids a model by  allowing it to focus on the most relevant parts of the input to make decisions   Graph-structured data arise naturally in many different application domains. By representing data as graphs, we can capture entities (i.e., nodes) as well as their relationships (i.e., edges) with each other. Many useful insights can be derived from graph-structured data as demonstrated by an ever-growing body of work focused on graph mining. However, in the real-world, graphs can be both large - with many complex patterns - and noisy which can pose a problem for effective graph mining. An effective way to deal with this issue is to incorporate attention into graph mining solutions. An attention mechanism allows a method to focus on task-relevant parts of the graph, helping it to make better decisions. In this work, we conduct a comprehensive and focused survey of the literature on the emerging field of graph attention models. We introduce three intuitive taxonomies to group existing work. These are based on problem setting (type of input and output), the type of attention mechanism used, and the task (e.g., graph classification, link prediction, etc.). We motivate our taxonomies through detailed examples and use each to survey competing approaches from a unique standpoint. Finally, we highlight several challenges in the area and discuss promising directions for future work.|sl:tag|tag:attention_in_graphs
Improving Entity Linking by Modeling Latent Entity Type Information Existing state of the art neural entity linking models employ attention-based bag-of-words context model and pre-trained entity embeddings bootstrapped from word embeddings to assess topic level context compatibility. However, the latent entity type information in the immediate context of the mention is neglected, which causes the models often link mentions to incorrect entities with incorrect type. To tackle this problem, we propose to inject latent entity type information into the entity embeddings based on pre-trained BERT. In addition, we integrate a BERT-based entity similarity score into the local context model of a state-of-the-art model to better capture latent entity type information. Our model significantly outperforms the state-of-the-art entity linking models on standard benchmark (AIDA-CoNLL). Detailed experiment analysis demonstrates that our model corrects most of the type errors produced by the direct baseline.|sl:arxiv_author|Feng Jiang
ATOM (Text editor)|skos:broader|Text Editor
TheWebConf 2018|skos:broader|TheWebConf
Minéralogie|skos:broader|Géologie
NN tips|skos:broader|Neural networks
Tsunami|skos:broader|Catastrophe naturelle
Neural Ranking Models with Weak Supervision Main Idea: To leverage large amounts of unsupervised data to infer “weak” labels and use that signal for learning supervised models as if we had the ground truth labels. See [blog post](/doc/?uri=http%3A%2F%2Fmostafadehghani.com%2F2017%2F04%2F23%2Fbeating-the-teacher-neural-ranking-models-with-weak-supervision%2F):     This is truly awesome since we have only used  BM25 as the supervisor to train a model which performs better than BM25 itself!   Despite the impressive improvements achieved by unsupervised deep neural networks in computer vision and NLP tasks, such improvements have not yet been observed in ranking for information retrieval. The reason may be the complexity of the ranking problem, as it is not obvious how to learn from queries and documents when no supervised signal is available. Hence, in this paper, we propose to train a neural ranking model using weak supervision, where labels are obtained automatically without human annotators or any external resources (e.g., click data). To this aim, we use the output of an unsupervised ranking model, such as BM25, as a weak supervision signal. We further train a set of simple yet effective ranking models based on feed-forward neural networks. We study their effectiveness under various learning scenarios (point-wise and pair-wise models) and using different input representations (i.e., from encoding query-document pairs into dense/sparse vectors to using word embedding representation). We train our networks using tens of millions of training instances and evaluate it on two standard collections: a homogeneous news collection(Robust) and a heterogeneous large-scale web collection (ClueWeb). Our experiments indicate that employing proper objective functions and letting the networks to learn the input representation based on weakly supervised data leads to impressive performance, with over 13% and 35% MAP improvements over the BM25 model on the Robust and the ClueWeb collections. Our findings also suggest that supervised neural ranking models can greatly benefit from pre-training on large amounts of weakly labeled data that can be easily obtained from unsupervised IR models.|sl:tag|tag:arxiv_doc
Document Embedding with Paragraph Vectors Paragraph Vectors has been recently proposed as an unsupervised method for learning distributed representations for pieces of texts. In their work, the authors showed that the method can learn an embedding of movie review texts which can be leveraged for sentiment analysis. That proof of concept, while encouraging, was rather narrow. Here we consider tasks other than sentiment analysis, provide a more thorough comparison of Paragraph Vectors to other document modelling algorithms such as Latent Dirichlet Allocation, and evaluate performance of the method as we vary the dimensionality of the learned representation. We benchmarked the models on two document similarity data sets, one from Wikipedia, one from arXiv. We observe that the Paragraph Vector method performs significantly better than other methods, and propose a simple improvement to enhance embedding quality. Somewhat surprisingly, we also show that much like word embeddings, vector operations on Paragraph Vectors can perform useful semantic results.|sl:arxiv_author|Christopher Olah
Maxent models|skos:broader|NLP techniques
Apache Spark|skos:broader|Machine Learning tool
css example|skos:broader|css
A practical tutorial on autoencoders for nonlinear feature fusion: Taxonomy, models, software and guidelines Many of the existing machine learning algorithms, both supervised and unsupervised, depend on the quality of the input characteristics to generate a good model. The amount of these variables is also important, since performance tends to decline as the input dimensionality increases, hence the interest in using feature fusion techniques, able to produce feature sets that are more compact and higher level. A plethora of procedures to fuse original variables for producing new ones has been developed in the past decades. The most basic ones use linear combinations of the original variables, such as PCA (Principal Component Analysis) and LDA (Linear Discriminant Analysis), while others find manifold embeddings of lower dimensionality based on non-linear combinations, such as Isomap or LLE (Linear Locally Embedding) techniques. More recently, autoencoders (AEs) have emerged as an alternative to manifold learning for conducting nonlinear feature fusion. Dozens of AE models have been proposed lately, each with its own specific traits. Although many of them can be used to generate reduced feature sets through the fusion of the original ones, there also AEs designed with other applications in mind. The goal of this paper is to provide the reader with a broad view of what an AE is, how they are used for feature fusion, a taxonomy gathering a broad range of models, and how they relate to other classical techniques. In addition, a set of didactic guidelines on how to choose the proper AE for a given task is supplied, together with a discussion of the software tools available. Finally, two case studies illustrate the usage of AEs with datasets of handwritten digits and breast cancer.|sl:arxiv_firstAuthor|David Charte
The Consciousness Prior consciousness seen as the formation of a low-dimensional combination of a few concepts constituting a conscious thought, i.e., consciousness as awareness at a particular time instant: the projection of a big vector (all the things conscious and unconscious in brain). Attention: additional mechanism describing what mind chooses to focus on.    [YouTube video](/doc/?uri=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYr1mOzC93xs) A new prior is proposed for learning representations of high-level concepts of the kind we manipulate with language. This prior can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by cognitive neuroscience theories of consciousness, seen as a bottleneck through which just a few elements, after having been selected by attention from a broader pool, are then broadcast and condition further processing, both in perception and decision-making. The set of recently selected elements one becomes aware of is seen as forming a low-dimensional conscious state. This conscious state is combining the few concepts constituting a conscious thought, i.e., what one is immediately conscious of at a particular moment. We claim that this architectural and information-processing constraint corresponds to assumptions about the joint distribution between high-level concepts. To the extent that these assumptions are generally true (and the form of natural language seems consistent with them), they can form a useful prior for representation learning. A low-dimensional thought or conscious state is analogous to a sentence: it involves only a few variables and yet can make a statement with very high probability of being true. This is consistent with a joint distribution (over high-level concepts) which has the form of a sparse factor graph, i.e., where the dependencies captured by each factor of the factor graph involve only very few variables while creating a strong dip in the overall energy function. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in a form similar to facts and rules, albeit capturing uncertainty as well as efficient search mechanisms implemented by attention mechanisms.|sl:tag|tag:thought_vector
Software|skos:broader|Technologie
Metropolitan Museum of Art|skos:broader|Musée
Désobéissance civile|skos:broader|Esprit de résistance
Part Of Speech Tagging|skos:broader|NLP tasks / problems
Championnat du monde|skos:broader|Sport
Jena TDB|skos:broader|TripleStore
Text to SQL|skos:broader|NLP tasks / problems
Edgar Morin|skos:broader|Intellectuel
EventKG: A Multilingual Event-Centric Temporal Knowledge Graph 690 thousand contemporary and historical events and over 2.3 million temporal relations One of the key requirements to facilitate semantic analytics of information regarding contemporary and historical events on the Web, in the news and in social media is the availability of reference knowledge repositories containing comprehensive representations of events and temporal relations. Existing knowledge graphs, with popular examples including DBpedia, YAGO and Wikidata, focus mostly on entity-centric information and are insufficient in terms of their coverage and completeness with respect to events and temporal relations. EventKG presented in this paper is a multilingual event-centric temporal knowledge graph that addresses this gap. EventKG incorporates over 690 thousand contemporary and historical events and over 2.3 million temporal relations extracted from several large-scale knowledge graphs and semi-structured sources and makes them available through a canonical representation.|sl:tag|tag:knowledge_graph
Knowledge Graphs|skos:broader|Knowledge Representation
Bush|skos:broader|Président des USA
Reformer: The Efficient Transformer Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O($L^2$) to O($L\\log L$), where $L$ is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of $N$ times, where $N$ is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.|sl:arxiv_author|Anselm Levskaya
CamemBERT|skos:broader|NLP: French
Kleenex|skos:broader|Société de consommation
hyperdoc2vec: Distributed Representations of Hypertext Documents Hypertext documents, such as web pages and academic papers, are of great importance in delivering information in our daily life. Although being effective on plain documents, conventional text embedding methods suffer from information loss if directly adapted to hyper-documents. In this paper, we propose a general embedding approach for hyper-documents, namely, hyperdoc2vec, along with four criteria characterizing necessary information that hyper-document embedding models should preserve. Systematic comparisons are conducted between hyperdoc2vec and several competitors on two tasks, i.e., paper classification and citation recommendation, in the academic paper domain. Analyses and experiments both validate the superiority of hyperdoc2vec to other models w.r.t. the four criteria.|sl:arxiv_author|Shuming Shi
Javadoc|skos:broader|Java
Design Challenges and Misconceptions in Neural Sequence Labeling design challenges of constructing effective and efficient neural sequence labeling systems We investigate the design challenges of constructing effective and efficient neural sequence labeling systems, by reproducing twelve neural sequence labeling models, which include most of the state-of-the-art structures, and conduct a systematic model comparison on three benchmarks (i.e. NER, Chunking, and POS tagging). Misconceptions and inconsistent conclusions in existing literature are examined and clarified under statistical experiments. In the comparison and analysis process, we reach several practical conclusions which can be useful to practitioners.|sl:tag|tag:named_entity_recognition
Gene editing|skos:broader|Manipulations génétiques
Pre-Trained Language Models|skos:broader|NLP: pretraining
XSL|skos:broader|XML
No Fuss Distance Metric Learning using Proxies  We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity...   Traditionnaly, supervision is expressed in the form of sets of points that follow  an ordinal relationship – an anchor point x is similar to  a set of positive points Y , and dissimilar to a set of negative  points Z, and a loss defined over these distances is minimized.   Triplet-Based methods are challenging to optimize (a main issue is the need for finding informative triplets).     We propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss.    Mentioned in this [blog post](/doc/2020/01/training_a_speaker_embedding_fr):     Proxy based triplet learning: instead of generating triplets, we learn an embedding for each class and use the learnt embedding as a proxy for triplets as part of the training. In other words, we can train end to end without the computationally expensive step of resampling triplets after each network update.    Near the conclusion:     Our formulation of Proxy-NCA loss produces a loss very  similar to the standard cross-entropy loss used in classification.  However, we arrive at our formulation from a different  direction: we are not interested in the actual classifier and  indeed discard the proxies once the model has been trained.  Instead, the proxies are auxiliary variables, enabling more  effective optimization of the embedding model parameters.  As such, our formulation not only enables us to surpass the  state of the art in zero-shot learning, but also offers an explanation  to the effectiveness of the standard trick of training  a classifier, and using its penultimate layer’s output as the  embedding. We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity. Traditionally, for this problem supervision is expressed in the form of sets of points that follow an ordinal relationship -- an anchor point $x$ is similar to a set of positive points $Y$, and dissimilar to a set of negative points $Z$, and a loss defined over these distances is minimized. While the specifics of the optimization differ, in this work we collectively call this type of supervision Triplets and all methods that follow this pattern Triplet-Based methods. These methods are challenging to optimize. A main issue is the need for finding informative triplets, which is usually achieved by a variety of tricks such as increasing the batch size, hard or semi-hard triplet mining, etc. Even with these tricks, the convergence rate of such methods is slow. In this paper we propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss. This proxy-based loss is empirically better behaved. As a result, the proxy-loss improves on state-of-art results for three standard zero-shot learning datasets, by up to 15% points, while converging three times as fast as other triplet-based losses.|sl:arxiv_author|Saurabh Singh
Hugo|skos:broader|Ecrivain
Indiens du Brésil|skos:broader|Brésil
Microdata|skos:broader|HTML Data
GINCO (Culture)|skos:broader|Semantic Web : Application
Mapping data from spreadsheets to RDF|skos:broader|Converting data into RDF
DeleteFB|skos:broader|Facebook
Thomas Piketty|skos:broader|Economiste
Jupiter|skos:broader|Système solaire
Topic Modeling over Short Texts by Incorporating Word Embeddings New method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo-texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic Inferring topics from the overwhelming amount of short texts becomes a critical but challenging task for many content analysis tasks, such as content charactering, user interest profiling, and emerging topic detecting. Existing methods such as probabilistic latent semantic analysis (PLSA) and latent Dirichlet allocation (LDA) cannot solve this prob- lem very well since only very limited word co-occurrence information is available in short texts. This paper studies how to incorporate the external word correlation knowledge into short texts to improve the coherence of topic modeling. Based on recent results in word embeddings that learn se- mantically representations for words from a large corpus, we introduce a novel method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo- texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic. The experiments on real-world datasets validate the effectiveness of our model comparing with the state-of-the-art models.|sl:arxiv_author|Tong Wang
Offshore leaks|skos:broader|Paradis fiscaux
Named Entity Recognition with Extremely Limited Data Named Entity Search (NES)     We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.     We do not propose this as a replacement  for NER, but as something to be used for an ephemeral or contextual  class of entity, when it does not make sense to label hundreds or  thousands of instances to learn a classifier Traditional information retrieval treats named entity recognition as a pre-indexing corpus annotation task, allowing entity tags to be indexed and used during search. Named entity taggers themselves are typically trained on thousands or tens of thousands of examples labeled by humans. However, there is a long tail of named entities classes, and for these cases, labeled data may be impossible to find or justify financially. We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.|sl:tag|tag:named_entity_recognition
Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks  Sentence-BERT  (SBERT), a modification of the pretrained  BERT network that use siamese and triplet network  structures to derive semantically meaningful  sentence embeddings that can be compared  using cosine-similarity.    Important because     - BERT ist unsuitable for semantic similarity  search as well as for unsupervised tasks  like clustering.  - simple methods such as using the CLS token give low quality sentence embeddings    However, the purpose of SBERT sentence embeddings  are not to be used for transfer learning for other  tasks.    [Related blog post](/doc/2020/01/richer_sentence_embeddings_usin); [Github](https://github.com/UKPLab/sentence-transformers) BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.|sl:tag|tag:bert_and_sentence_embeddings
Hindu/Muslim riots|skos:broader|Inde
Quantum computing|skos:broader|Mécanique quantique
Yahoo!|skos:broader|Internet
RDF in HTML|skos:broader|Web sémantique sw
XLNet: Generalized Autoregressive Pretraining for Language Understanding a new pretraining method for NLP that significantly improves upon BERT on 20 tasks (e.g., SQuAD, GLUE, RACE) With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.|sl:arxiv_author|Yiming Yang
Géométrie|skos:broader|Mathématiques
Genome editing|skos:broader|Manipulations génétiques
Coupe du monde 2018|skos:broader|Coupe du monde de football
Lucene|skos:broader|Text Search
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_firstAuthor|Aidan Hogan
Extrémisme islamique|skos:broader|Fondamentalisme islamique
RFID passports|skos:broader|RFID
Patricia Highsmith|skos:broader|Ecrivain
Baobab|skos:broader|Arbres
Semantic Overflow|skos:broader|Semantic Web
Feature hashing (\Hashing trick\)|skos:broader|Machine learning: techniques
Zero-shot Entity Linking with Dense Entity Retrieval We consider the zero-shot entity-linking challenge where each entity is defined by a short textual description, and the model must read these descriptions together with the mention context to make the final linking decisions. In this setting, retrieving entity candidates can be particularly challenging, since many of the common linking cues such as entity alias tables and link popularity are not available. In this paper, we introduce a simple and effective two stage approach for zero-shot linking, based on fine-tuned BERT architectures. In the first stage, we do retrieval in a dense space defined by a bi-encoder that independently embeds the mention context and the entity descriptions. Each candidate is then examined more carefully with a cross-encoder, that concatenates the mention and entity text. Our approach achieves a nearly 5 point absolute gain on a recently introduced zero-shot entity linking benchmark, driven largely by improvements over previous IR-based candidate retrieval. We also show that it performs well in the non-zero-shot setting, obtaining the state-of-the-art result on TACKBP-2010.|sl:arxiv_author|Luke Zettlemoyer
Vidéosurveillance|skos:broader|Etat policier
Gaël de Chalendar|skos:broader|NLP girls and guys
Semantic Web P2P|skos:broader|Semantic Web : Application
Embedding evaluation|skos:broader|Embeddings
Design Challenges and Misconceptions in Neural Sequence Labeling design challenges of constructing effective and efficient neural sequence labeling systems We investigate the design challenges of constructing effective and efficient neural sequence labeling systems, by reproducing twelve neural sequence labeling models, which include most of the state-of-the-art structures, and conduct a systematic model comparison on three benchmarks (i.e. NER, Chunking, and POS tagging). Misconceptions and inconsistent conclusions in existing literature are examined and clarified under statistical experiments. In the comparison and analysis process, we reach several practical conclusions which can be useful to practitioners.|sl:arxiv_author|Shuailong Liang
Quantum biology|skos:broader|Mécanique quantique
Feature extraction|skos:broader|Machine learning: techniques
ReactJS|skos:broader|JavaScript framework
Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective reviews the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. Neural-symbolic computing has now become the subject of interest of both academic and industry research laboratories. Graph Neural Networks (GNN) have been widely used in relational and symbolic domains, with widespread application of GNNs in combinatorial optimization, constraint satisfaction, relational reasoning and other scientific domains. The need for improved explainability, interpretability and trust of AI systems in general demands principled methodologies, as suggested by neural-symbolic computing. In this paper, we review the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. This includes the application of GNNs in several domains as well as its relationship to current developments in neural-symbolic computing.|sl:tag|tag:survey
SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver Integrating logical reasoning within deep learning architectures has been a major goal of modern AI systems. In this paper, we propose a new direction toward this goal by introducing a differentiable (smoothed) maximum satisfiability (MAXSAT) solver that can be integrated into the loop of larger deep learning systems. Our (approximate) solver is based upon a fast coordinate descent approach to solving the semidefinite program (SDP) associated with the MAXSAT problem. We show how to analytically differentiate through the solution to this SDP and efficiently solve the associated backward pass. We demonstrate that by integrating this solver into end-to-end learning systems, we can learn the logical structure of challenging problems in a minimally supervised fashion. In particular, we show that we can learn the parity function using single-bit supervision (a traditionally hard task for deep networks) and learn how to play 9x9 Sudoku solely from examples. We also solve a visual Sudok problem that maps images of Sudoku puzzles to their associated logical solutions by combining our MAXSAT solver with a traditional convolutional architecture. Our approach thus shows promise in integrating logical structures within deep learning.|sl:arxiv_author|Priya L. Donti
Representation learning for very short texts using weighted word embedding aggregation A method based on word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. a href=https://github.com/cedricdeboom/RepresentationLearningGithub/a (hmm...) (python code)     Short text messages such as tweets are very noisy and sparse in their use of vocabulary. Traditional textual representations, such as tf-idf, have difficulty grasping the semantic meaning of such texts, which is important in applications such as event detection, opinion mining, news recommendation, etc. We constructed a method based on semantic word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. For this purpose we designed a weight-based model and a learning procedure based on a novel median-based loss function. This paper discusses the details of our model and the optimization methods, together with the experimental results on both Wikipedia and Twitter data. We find that our method outperforms the baseline approaches in the experiments, and that it generalizes well on different word embeddings without retraining. Our method is therefore capable of retaining most of the semantic information in the text, and is applicable out-of-the-box.|sl:tag|tag:word_embedding
Unsupervised Deep Embedding for Clustering Analysis Relatively little work has focused on learning representations for clustering. In this paper, we propose Deep Embedded Clustering (DEC), a method that simultaneously learns feature representations and cluster assignments using deep neural networks. DEC learns a mapping from the data space to a lower-dimensional feature space in which it iteratively optimizes a clustering objective Clustering is central to many data-driven application domains and has been studied extensively in terms of distance functions and grouping algorithms. Relatively little work has focused on learning representations for clustering. In this paper, we propose Deep Embedded Clustering (DEC), a method that simultaneously learns feature representations and cluster assignments using deep neural networks. DEC learns a mapping from the data space to a lower-dimensional feature space in which it iteratively optimizes a clustering objective. Our experimental evaluations on image and text corpora show significant improvement over state-of-the-art methods.|sl:tag|tag:embeddings
Dan Connolly|skos:broader|SW guys (and girls)
RNN based Language Model|skos:broader|Recurrent neural network
Unifying distillation and privileged information A framework to learn from multiple machines and data representations, unifying two techniques that enable machines to learn from other machines: [distillation](tag:knowledge_distillation) ([Hinton et al., 2015](doc:2020/04/1503_02531_distilling_the_kno)) and privileged information (Vapnik & Izmailov, 2015)   Distillation (Hinton et al., 2015) and privileged information (Vapnik & Izmailov, 2015) are two techniques that enable machines to learn from other machines. This paper unifies these two techniques into generalized distillation, a framework to learn from multiple machines and data representations. We provide theoretical and causal insight about the inner workings of generalized distillation, extend it to unsupervised, semisupervised and multitask learning scenarios, and illustrate its efficacy on a variety of numerical simulations on both synthetic and real-world data.|sl:arxiv_firstAuthor|David Lopez-Paz
"Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One We propose to reinterpret a standard discriminative classifier of p(y|x) as an energy based model for the joint distribution p(x,y). In this setting, the standard class probabilities can be easily computed as well as unnormalized values of p(x) and p(x|y). Within this framework, standard discriminative architectures may beused and the model can also be trained on unlabeled data. We demonstrate that energy based training of the joint distribution improves calibration, robustness, andout-of-distribution detection while also enabling our models to generate samplesrivaling the quality of recent GAN approaches. We improve upon recently proposed techniques for scaling up the training of energy based models and presentan approach which adds little overhead compared to standard classification training. Our approach is the first to achieve performance rivaling the state-of-the-artin both generative and discriminative learning within one hybrid model."|sl:arxiv_author|Kuan-Chieh Wang
Energie du vide|skos:broader|Enigmes de la physique
Ajax|skos:broader|Web dev
Revisiting Semi-Supervised Learning with Graph Embeddings We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.|sl:arxiv_author|William W. Cohen
303-redirect|skos:broader|Concept's URI
Cédric Villani|skos:broader|Médaille Fields
Improving Entity Linking by Modeling Latent Entity Type Information Existing state of the art neural entity linking models employ attention-based bag-of-words context model and pre-trained entity embeddings bootstrapped from word embeddings to assess topic level context compatibility. However, the latent entity type information in the immediate context of the mention is neglected, which causes the models often link mentions to incorrect entities with incorrect type. To tackle this problem, we propose to inject latent entity type information into the entity embeddings based on pre-trained BERT. In addition, we integrate a BERT-based entity similarity score into the local context model of a state-of-the-art model to better capture latent entity type information. Our model significantly outperforms the state-of-the-art entity linking models on standard benchmark (AIDA-CoNLL). Detailed experiment analysis demonstrates that our model corrects most of the type errors produced by the direct baseline.|sl:tag|tag:nlp_microsoft
Maïs OGM|skos:broader|OGM
Visualizing and Measuring the Geometry of BERT  At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.|sl:arxiv_author|Ann Yuan
Natural Language Processing with Small Feed-Forward Networks google guys:      We show that small and shallow feed- forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.   We show that small and shallow feed-forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.|sl:arxiv_author|Ji Ma
Semantic Blog|skos:broader|Blog
Moteur de recherche|skos:broader|IR
Deep Mutual Learning  In this paper we explore a different but related idea to model distillation – that of mutual learning. Distillation starts with a powerful large and pre-trained teacher network and performs one-way knowledge transfer to a small untrained student. In contrast, in mutual learning we start with a pool of untrained students who learn simultaneously to solve the task together.    [critic here](doc:2020/06/1804_03235_large_scale_distri):     Zhang et al. (2017) reported a benefit in quality over  basic distillation, but they compare distilling model M1 into model M2 with training model M1  and model M2 using codistillation; they do not compare to distilling an ensemble of models M1  and M2 into model M3.     ...     we can achieve the 70.7% they report for online  distillation using traditional offline distillation. Model distillation is an effective and widely used technique to transfer knowledge from a teacher to a student network. The typical application is to transfer from a powerful large network or ensemble to a small network, that is better suited to low-memory or fast execution requirements. In this paper, we present a deep mutual learning (DML) strategy where, rather than one way transfer between a static pre-defined teacher and a student, an ensemble of students learn collaboratively and teach each other throughout the training process. Our experiments show that a variety of network architectures benefit from mutual learning and achieve compelling results on CIFAR-100 recognition and Market-1501 person re-identification benchmarks. Surprisingly, it is revealed that no prior powerful teacher network is necessary -- mutual learning of a collection of simple student networks works, and moreover outperforms distillation from a more powerful yet static teacher.|sl:arxiv_firstAuthor|Ying Zhang
Slot tagging|skos:broader|NLP tasks / problems
D3js|skos:broader|Data Visualization Tools
Google App Engine|skos:broader|Web dev
Le Pen|skos:broader|Homme politique
AI: business perspectives|skos:broader|Artificial Intelligence
Chirac ami des Africains|skos:broader|Chirac
Natural Language Processing (almost) from Scratch seminal work    Abstract:     a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements   We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.|sl:tag|tag:frequently_cited_paper
Théatre|skos:broader|Art
Paris NLP meetup|skos:broader|Paris
Variational Bayesian methods|skos:broader|Machine learning: techniques
Similarity Search for Efficient Active Learning and Search of Rare Concepts  Similarity search for Efficient Active Learning and Search (SEALS)    In [Active Learning](tag:active_learning): instead of searching globally for the optimal examples to label, leverage the fact that data is often heavily skewed and expand the candidate pool with the nearest neighbors of the labeled set.     Our work attacks both the labeling and computational costs of machine learning...SEALS dramatically reduces the barrier to machine learning, enabling small teams or individuals to  build accurate classifiers. SEALS does, however, introduce another system component, a similarity  search index, which adds some additional engineering complexity to build, tune, and maintain.  Fortunately, several highly optimized implementations like Annoy and [Faiss](doc:2020/06/facebookresearch_faiss_a_libra) work reasonably well  out of the box. Many active learning and search approaches are intractable for industrial settings with billions of unlabeled examples. Existing approaches, such as uncertainty sampling or information density, search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. However, in practice, data is often heavily skewed; only a small fraction of collected data will be relevant for a given learning task. For example, when identifying rare classes, detecting malicious content, or debugging model performance, the ratio of positive to negative examples can be 1 to 1,000 or more. In this work, we exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round by only looking at the nearest neighbors to the labeled examples. Empirically, we observe that learned representations effectively cluster unseen concepts, making active learning very effective and substantially reducing the number of viable unlabeled examples. We evaluate several active learning and search techniques in this setting on three large-scale datasets: ImageNet, Goodreads spoiler detection, and OpenImages. For rare classes, active learning methods need as little as 0.31% of the labeled data to match the average precision of full supervision. By limiting active learning methods to only consider the immediate neighbors of the labeled data as candidates for labeling, we need only process as little as 1% of the unlabeled data while achieving similar reductions in labeling costs as the traditional global approach. This process of expanding the candidate pool with the nearest neighbors of the labeled set can be done efficiently and reduces the computational complexity of selection by orders of magnitude.|sl:arxiv_author|Cody Coleman
Histropedia|skos:broader|Timeline
SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver Integrating logical reasoning within deep learning architectures has been a major goal of modern AI systems. In this paper, we propose a new direction toward this goal by introducing a differentiable (smoothed) maximum satisfiability (MAXSAT) solver that can be integrated into the loop of larger deep learning systems. Our (approximate) solver is based upon a fast coordinate descent approach to solving the semidefinite program (SDP) associated with the MAXSAT problem. We show how to analytically differentiate through the solution to this SDP and efficiently solve the associated backward pass. We demonstrate that by integrating this solver into end-to-end learning systems, we can learn the logical structure of challenging problems in a minimally supervised fashion. In particular, we show that we can learn the parity function using single-bit supervision (a traditionally hard task for deep networks) and learn how to play 9x9 Sudoku solely from examples. We also solve a visual Sudok problem that maps images of Sudoku puzzles to their associated logical solutions by combining our MAXSAT solver with a traditional convolutional architecture. Our approach thus shows promise in integrating logical structures within deep learning.|sl:arxiv_firstAuthor|Po-Wei Wang
Brexit|skos:broader|Europe and UK
KnowBert|skos:broader|Allen Institute for AI (A2I)
Cookie|skos:broader|Web app dev
Norilsk|skos:broader|Arctique
OGM|skos:broader|Manipulations génétiques
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Charles Nash
Photo|skos:broader|Divers
Java library|skos:broader|Java
Sportif|skos:broader|Sport
Moussa Poussi|skos:broader|Musique du Niger
Open Knowledge Network|skos:broader|Knowledge Graphs
Leonardo da Vinci|skos:broader|Peintre
Entity Linking often rely on rich structures and properties in the target knowledge base (KB). However, in many applications, the KB may be as simple and sparse as lists of names of the same type (e.g., lists of products) - the List-only entity linking problem  |skos:broader|= named entity disambiguation: the task of resolving multiple named entity mentions in a document to their correct references in a knowledge base.
fast.ai|skos:broader|Deep Learning
Yagán|skos:broader|Peuples
Bombe atomique|skos:broader|Armement
Large-scale Multi-label Learning with Missing Labels The multi-label classification problem has generated significant interest in recent years. However, existing approaches do not adequately address two key challenges: (a) the ability to tackle problems with a large number (say millions) of labels, and (b) the ability to handle data with missing labels. In this paper, we directly address both these problems by studying the multi-label problem in a generic empirical risk minimization (ERM) framework. Our framework, despite being simple, is surprisingly able to encompass several recent label-compression based methods which can be derived as special cases of our method. To optimize the ERM problem, we develop techniques that exploit the structure of specific loss functions - such as the squared loss function - to offer efficient algorithms. We further show that our learning framework admits formal excess risk bounds even in the presence of missing labels. Our risk bounds are tight and demonstrate better generalization performance for low-rank promoting trace-norm regularization when compared to (rank insensitive) Frobenius norm regularization. Finally, we present extensive empirical results on a variety of benchmark datasets and show that our methods perform significantly better than existing label compression based methods and can scale up to very large datasets such as the Wikipedia dataset.|sl:tag|tag:multi_label_classification
Faim|skos:broader|Grands problèmes
Semantic Hashing|skos:broader|NN 4 NLP
Logic|skos:broader|Mathématiques
Visualizing and Measuring the Geometry of BERT  At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.|sl:tag|tag:geometry_of_language_embeddings
BERT for Joint Intent Classification and Slot Filling  Experimental results show that our  proposed joint BERT model outperforms BERT  models modeling intent classification and slot filling  separately, demonstrating the efficacy of exploiting  the relationship between the two tasks.    Adding a CRF on top of the model doesn't improve the results. Intent classification and slot filling are two essential tasks for natural language understanding. They often suffer from small-scale human-labeled training data, resulting in poor generalization capability, especially for rare words. Recently a new language representation model, BERT (Bidirectional Encoder Representations from Transformers), facilitates pre-training deep bidirectional representations on large-scale unlabeled corpora, and has created state-of-the-art models for a wide variety of natural language processing tasks after simple fine-tuning. However, there has not been much effort on exploring BERT for natural language understanding. In this work, we propose a joint intent classification and slot filling model based on BERT. Experimental results demonstrate that our proposed model achieves significant improvement on intent classification accuracy, slot filling F1, and sentence-level semantic frame accuracy on several public benchmark datasets, compared to the attention-based recurrent neural network models and slot-gated models.|sl:arxiv_author|Qian Chen
A practical tutorial on autoencoders for nonlinear feature fusion: Taxonomy, models, software and guidelines Many of the existing machine learning algorithms, both supervised and unsupervised, depend on the quality of the input characteristics to generate a good model. The amount of these variables is also important, since performance tends to decline as the input dimensionality increases, hence the interest in using feature fusion techniques, able to produce feature sets that are more compact and higher level. A plethora of procedures to fuse original variables for producing new ones has been developed in the past decades. The most basic ones use linear combinations of the original variables, such as PCA (Principal Component Analysis) and LDA (Linear Discriminant Analysis), while others find manifold embeddings of lower dimensionality based on non-linear combinations, such as Isomap or LLE (Linear Locally Embedding) techniques. More recently, autoencoders (AEs) have emerged as an alternative to manifold learning for conducting nonlinear feature fusion. Dozens of AE models have been proposed lately, each with its own specific traits. Although many of them can be used to generate reduced feature sets through the fusion of the original ones, there also AEs designed with other applications in mind. The goal of this paper is to provide the reader with a broad view of what an AE is, how they are used for feature fusion, a taxonomy gathering a broad range of models, and how they relate to other classical techniques. In addition, a set of didactic guidelines on how to choose the proper AE for a given task is supplied, together with a discussion of the software tools available. Finally, two case studies illustrate the usage of AEs with datasets of handwritten digits and breast cancer.|sl:arxiv_author|María J. del Jesus
KBPedia|skos:broader|Knowledge Graphs
Linear Algebraic Structure of Word Senses, with Applications to Polysemy  Here it is shown that multiple word senses reside  in linear superposition within the word  embedding and simple sparse coding can recover  vectors that approximately capture the  senses     Each extracted word sense is accompanied by one of about  2000 “discourse atoms” that gives a succinct description of which other words co-occur with that word sense.     The success of the approach is mathematically explained using a variant of  the random walk on discourses model    (random walk: a generative model for language). Under the assumptions of this model,  there  exists a linear relationship between the vector of a  word w and the vectors of the words in its contexts (It is not the average of the words in w's context, but in a given corpus the matrix of the linear relationship does not depend on w. It can be estimated, and so we can compute the embedding of a word from the contexts it belongs to)    [Related blog post](/doc/?uri=https%3A%2F%2Fwww.offconvex.org%2F2016%2F07%2F10%2Fembeddingspolysemy%2F)   Word embeddings are ubiquitous in NLP and information retrieval, but it is unclear what they represent when the word is polysemous. Here it is shown that multiple word senses reside in linear superposition within the word embedding and simple sparse coding can recover vectors that approximately capture the senses. The success of our approach, which applies to several embedding methods, is mathematically explained using a variant of the random walk on discourses model (Arora et al., 2016). A novel aspect of our technique is that each extracted word sense is accompanied by one of about 2000 discourse atoms that gives a succinct description of which other words co-occur with that word sense. Discourse atoms can be of independent interest, and make the method potentially more useful. Empirical tests are used to verify and support the theory.|sl:tag|tag:sparse_dictionary_learning
Média conversationnel|skos:broader|Médias
Stefan Zweig|skos:broader|Intellectuel
Second Life|skos:broader|Massively multiplayer online games
Jena : Introduction|skos:broader|Jena
Le gouvernement Chirac est trop con|skos:broader|Gouvernement Chirac
Efficient Contextual Representation Learning Without Softmax Layer how to accelerate contextual representation learning.     Contextual representation models are difficult to train due to the large parameter sizes and high computational complexity     We find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size.  Therefore, we redesign the learning objectiv.   Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings.  Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary.  When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.    decouples learning contexts and words     Instead of using  a softmax layer to predict the distribution of the  missing word, we utilize and extend the SEMFIT  layer (Kumar and Tsvetkov, 2018) to predict the  embedding of the missing word. Contextual representation models have achieved great success in improving various downstream tasks. However, these language-model-based encoders are difficult to train due to the large parameter sizes and high computational complexity. By carefully examining the training procedure, we find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size. Therefore, we redesign the learning objective and propose an efficient framework for training contextual representation models. Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings. Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary. When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.|sl:arxiv_firstAuthor|Liunian Harold Li
Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks Current machine learning systems operate, almost exclusively, in a statistical, or model-free mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks. To demonstrate the essential role of such models, I will present a summary of seven tasks which are beyond reach of current machine learning systems and which have been accomplished using the tools of causal modeling.|sl:tag|tag:artificial_general_intelligence
AI black box|skos:broader|Explainable AI
Apache OpenNLP|skos:broader|NLP tools
Representation Learning for NLP|skos:broader|Representation learning
Maximum Entropy Classifier Softmax regression|skos:broader|Multiclass classification
GINCO (Culture)|skos:broader|Ministère de la culture
PlaNet - Photo Geolocation with Convolutional Neural Networks Is it possible to build a system to determine the location where a photo was taken using just its pixels? In general, the problem seems exceptionally difficult: it is trivial to construct situations where no location can be inferred. Yet images often contain informative cues such as landmarks, weather patterns, vegetation, road markings, and architectural details, which in combination may allow one to determine an approximate location and occasionally an exact location. Websites such as GeoGuessr and View from your Window suggest that humans are relatively good at integrating these cues to geolocate images, especially en-masse. In computer vision, the photo geolocation problem is usually approached using image retrieval methods. In contrast, we pose the problem as one of classification by subdividing the surface of the earth into thousands of multi-scale geographic cells, and train a deep network using millions of geotagged images. While previous approaches only recognize landmarks or perform approximate matching using global image descriptors, our model is able to use and integrate multiple visible cues. We show that the resulting model, called PlaNet, outperforms previous approaches and even attains superhuman levels of accuracy in some cases. Moreover, we extend our model to photo albums by combining it with a long short-term memory (LSTM) architecture. By learning to exploit temporal coherence to geolocate uncertain photos, we demonstrate that this model achieves a 50% performance improvement over the single-image model.|sl:arxiv_author|Tobias Weyand
Zitgist|skos:broader|Linked Data
Pont couvert|skos:broader|Pont
Pauvreté|skos:broader|Grands problèmes
fps@EC-Web'14|skos:broader|C2GWeb and Product description
Scalable Nearest Neighbor Search for Optimal Transport The Optimal Transport (a.k.a. Wasserstein) distance is an increasingly popular similarity measure for rich data domains, such as images or text documents. This raises the necessity for fast nearest neighbor search with respect to this distance, a problem that poses a substantial computational bottleneck for various tasks on massive datasets. In this work, we study fast tree-based approximation algorithms for searching nearest neighbors w.r.t. the Wasserstein-1 distance. A standard tree-based technique, known as Quadtree, has been previously shown to obtain good results. We introduce a variant of this algorithm, called Flowtree, and formally prove it achieves asymptotically better accuracy. Our extensive experiments, on real-world text and image datasets, show that Flowtree improves over various baselines and existing methods in either running time or accuracy. In particular, its quality of approximation is in line with previous high-accuracy methods, while its running time is much faster.|sl:arxiv_author|Ilya Razenshteyn
Language Models as Knowledge Bases? an analysis of the relational knowledge present in pretrained language models shows an ability of these models to recall factual knowledge  Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as fill-in-the-blank cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.|sl:arxiv_author|Anton Bakhtin
Resources-Oriented Web Services|skos:broader|Schema.org Actions
Similarity Search for Efficient Active Learning and Search of Rare Concepts  Similarity search for Efficient Active Learning and Search (SEALS)    In [Active Learning](tag:active_learning): instead of searching globally for the optimal examples to label, leverage the fact that data is often heavily skewed and expand the candidate pool with the nearest neighbors of the labeled set.     Our work attacks both the labeling and computational costs of machine learning...SEALS dramatically reduces the barrier to machine learning, enabling small teams or individuals to  build accurate classifiers. SEALS does, however, introduce another system component, a similarity  search index, which adds some additional engineering complexity to build, tune, and maintain.  Fortunately, several highly optimized implementations like Annoy and [Faiss](doc:2020/06/facebookresearch_faiss_a_libra) work reasonably well  out of the box. Many active learning and search approaches are intractable for industrial settings with billions of unlabeled examples. Existing approaches, such as uncertainty sampling or information density, search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. However, in practice, data is often heavily skewed; only a small fraction of collected data will be relevant for a given learning task. For example, when identifying rare classes, detecting malicious content, or debugging model performance, the ratio of positive to negative examples can be 1 to 1,000 or more. In this work, we exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round by only looking at the nearest neighbors to the labeled examples. Empirically, we observe that learned representations effectively cluster unseen concepts, making active learning very effective and substantially reducing the number of viable unlabeled examples. We evaluate several active learning and search techniques in this setting on three large-scale datasets: ImageNet, Goodreads spoiler detection, and OpenImages. For rare classes, active learning methods need as little as 0.31% of the labeled data to match the average precision of full supervision. By limiting active learning methods to only consider the immediate neighbors of the labeled data as candidates for labeling, we need only process as little as 1% of the unlabeled data while achieving similar reductions in labeling costs as the traditional global approach. This process of expanding the candidate pool with the nearest neighbors of the labeled set can be done efficiently and reduces the computational complexity of selection by orders of magnitude.|sl:arxiv_author|Roshan Sumbaly
NLTK|skos:broader|Python-NLP
Classification du vivant|skos:broader|Biologie
Mali|skos:broader|Sahel
BERT|skos:broader|Pre-Trained Language Models
Philosophe|skos:broader|Penseur
Film allemand|skos:broader|Film
Deep Mutual Learning  In this paper we explore a different but related idea to model distillation – that of mutual learning. Distillation starts with a powerful large and pre-trained teacher network and performs one-way knowledge transfer to a small untrained student. In contrast, in mutual learning we start with a pool of untrained students who learn simultaneously to solve the task together.    [critic here](doc:2020/06/1804_03235_large_scale_distri):     Zhang et al. (2017) reported a benefit in quality over  basic distillation, but they compare distilling model M1 into model M2 with training model M1  and model M2 using codistillation; they do not compare to distilling an ensemble of models M1  and M2 into model M3.     ...     we can achieve the 70.7% they report for online  distillation using traditional offline distillation. Model distillation is an effective and widely used technique to transfer knowledge from a teacher to a student network. The typical application is to transfer from a powerful large network or ensemble to a small network, that is better suited to low-memory or fast execution requirements. In this paper, we present a deep mutual learning (DML) strategy where, rather than one way transfer between a static pre-defined teacher and a student, an ensemble of students learn collaboratively and teach each other throughout the training process. Our experiments show that a variety of network architectures benefit from mutual learning and achieve compelling results on CIFAR-100 recognition and Market-1501 person re-identification benchmarks. Surprisingly, it is revealed that no prior powerful teacher network is necessary -- mutual learning of a collection of simple student networks works, and moreover outperforms distillation from a more powerful yet static teacher.|sl:tag|tag:knowledge_distillation
Semanlink: archives|skos:broader|Semanlink
FAQ|skos:broader|Q&A
Subword Semantic Hashing for Intent Classification on Small Datasets In this paper, we introduce the use of Semantic Hashing as embedding for the task of Intent Classification and achieve state-of-the-art performance on three frequently used benchmarks. Intent Classification on a small dataset is a challenging task for data-hungry state-of-the-art Deep Learning based systems. Semantic Hashing is an attempt to overcome such a challenge and learn robust text classification. Current word embedding based are dependent on vocabularies. One of the major drawbacks of such methods is out-of-vocabulary terms, especially when having small training datasets and using a wider vocabulary. This is the case in Intent Classification for chatbots, where typically small datasets are extracted from internet communication. Two problems arise by the use of internet communication. First, such datasets miss a lot of terms in the vocabulary to use word embeddings efficiently. Second, users frequently make spelling errors. Typically, the models for intent classification are not trained with spelling errors and it is difficult to think about ways in which users will make mistakes. Models depending on a word vocabulary will always face such issues. An ideal classifier should handle spelling errors inherently. With Semantic Hashing, we overcome these challenges and achieve state-of-the-art results on three datasets: AskUbuntu, Chatbot, and Web Application. Our benchmarks are available online: https://github.com/kumar-shridhar/Know-Your-Intent|sl:tag|tag:semantic_hashing
Categorical Metadata Representation for Customized Text Classification  We observe that current representation methods for categorical metadata... are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category The performance of text classification has improved tremendously using intelligently engineered neural-based models, especially those injecting categorical metadata as additional information, e.g., using user/product information for sentiment classification. These information have been used to modify parts of the model (e.g., word embeddings, attention mechanisms) such that results can be customized according to the metadata. We observe that current representation methods for categorical metadata, which are devised for human consumption, are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category, and even such context is often scarce (for tail category). To this end, we propose to use basis vectors to effectively incorporate categorical metadata on various parts of a neural-based model. This additionally decreases the number of parameters dramatically, especially when the number of categorical features is large. Extensive experiments on various datasets with different properties are performed and show that through our method, we can represent categorical metadata more effectively to customize parts of the model, including unexplored ones, and increase the performance of the model greatly.|sl:arxiv_author|Minji Seo
ATOM (Text editor)|skos:broader|GitHub
WWW 2013|skos:broader|Rio de Janeiro
MOOC|skos:broader|Online Learning
Mapping data from spreadsheets to RDF|skos:broader|Spreadsheets
xgboost|skos:broader|Gradient boosting
Épidémie|skos:broader|Maladie
Layered Graph Embedding for Entity Recommendation using Wikipedia in the Yahoo! Knowledge Graph an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia In this paper, we describe an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia. Through offline and online evaluations, we show that the resulting embeddings and recommendations perform well in terms of quality and user engagement. Balancing simplicity and quality, this framework provides default entity recommendations for English and other languages in the Yahoo! Knowledge Graph, which Wikipedia is a core subset of.|sl:arxiv_author|Chien-Chun Ni
CIA|skos:broader|Services secrets
Deep Learning frameworks|skos:broader|Deep Learning
Knowledge Enhanced Contextual Word Representations General method to embed multiple knowledge bases into pre-trained language models (KB in the   sense as fixed collection of entity nodes)     The key idea is to explicitly model  entity spans in the input text and use an entity  linker to retrieve relevant entity embeddings from  a KB to form knowledge enhanced entity-span  representations.   Then,  update contextual word representations via a form of word-to-entity attention.    In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert's runtime is comparable to BERT's and it scales to large KBs.|sl:arxiv_author|Sameer Singh
Graph Convolution for Multimodal Information Extraction from Visually Rich Documents Visually rich documents (VRDs) are ubiquitous in daily business and life. Examples are purchase receipts, insurance policy documents, custom declaration forms and so on. In VRDs, visual and layout information is critical for document understanding, and texts in such documents cannot be serialized into the one-dimensional sequence without losing information. Classic information extraction models such as BiLSTM-CRF typically operate on text sequences and do not incorporate visual features. In this paper, we introduce a graph convolution based model to combine textual and visual information presented in VRDs. Graph embeddings are trained to summarize the context of a text segment in the document, and further combined with text embeddings for entity extraction. Extensive experiments have been conducted to show that our method outperforms BiLSTM-CRF baselines by significant margins, on two real-world datasets. Additionally, ablation studies are also performed to evaluate the effectiveness of each component of our model.|sl:arxiv_author|Huasha Zhao
Perceptron|skos:broader|Linear classifier
Jeux Olympiques|skos:broader|Sport
Relativité générale|skos:broader|Relativité
Maven-Eclipse on My mac|skos:broader|Eclipse
Text Generation from Knowledge Graphs with Graph Transformers Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.|sl:arxiv_firstAuthor|Rik Koncel-Kedziorski
Deep Patent Landscaping Model Using Transformer and Graph Embedding a transformer encoder  for analyzing textual data present in patent documents  and a graph convolutional network for analyzing  patent metadata.    A benchmarking dataset for patent landscaping  based on patent trends reports published by the  Korean Patent Office. Data acquisition using Google's BigQuery public datasets.    10% improvement comparing to Google’s proposed Automated Patent Landscaping.    Empirical analysis of the importance of features (text vs metadata, citations vs classification)     Patent landscaping is a method used for searching related patents during a research and development (R&D) project. To avoid the risk of patent infringement and to follow current trends in technology, patent landscaping is a crucial task required during the early stages of an R&D project. As the process of patent landscaping requires advanced resources and can be tedious, the demand for automated patent landscaping has been gradually increasing. However, a shortage of well-defined benchmark datasets and comparable models makes it difficult to find related research studies. In this paper, we propose an automated patent landscaping model based on deep learning. To analyze the text of patents, the proposed model uses a modified transformer structure. To analyze the metadata of patents, we propose a graph embedding method that uses a diffusion graph called Diff2Vec. Furthermore, we introduce four benchmark datasets for comparing related research studies in patent landscaping. The datasets are produced by querying Google BigQuery, based on a search formula from a Korean patent attorney. The obtained results indicate that the proposed model and datasets can attain state-of-the-art performance, as compared with current patent landscaping models.|sl:tag|tag:patent_landscaping
RDF forms|skos:broader|Semantic Web Services
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:arxiv_author|Daniel Cer
Semantic Text Matching|skos:broader|Identification of similar documents
Object Oriented Programming|skos:broader|Programming
Automobile 2.0|skos:broader|Automobile
Semanlink2 related|skos:broader|Semanlink2
Big Brother|skos:broader|Etat policier
Google Groups|skos:broader|Google
Drupal/RDF|skos:broader|Linked Data
- [Home Page](https://www.fast.ai/)  - [MOOC](https://course.fast.ai/)  - [Github](https://github.com/fastai/fastai)  - [Forum](https://forums.fast.ai/)  - [docs.fast.ai](https://docs.fast.ai/)      |skos:broader|a set of algorithms in machine learning that attempt to model high-level abstractions in data by using architectures composed of multiple non-linear transformations. Deep learning is part of a broader family of machine learning methods based on learning representations of data.    One of the promises of deep learning is replacing handcrafted features with efficient algorithms for unsupervised or semi-supervised feature learning and hierarchical feature extraction    With Deep Learning, Ng says, you just give the system a lot of data so it can discover by itself what some of the concepts in the world are ([cf.](http://www.wired.com/2013/05/neuro-artificial-intelligence/all/))  
Crimes de l'église catholique|skos:broader|Horreur
Von Mises-Fisher Loss for Training Sequence to Sequence Models with Continuous Outputs predicting embeddings instead of word IDs (avoids a discrete softmax, using a new loss)    [@honnibal](https://twitter.com/honnibal/status/1073513114468081664)     The Softmax function is used in the final layer of nearly all existing sequence-to-sequence models for language generation. However, it is usually the slowest layer to compute which limits the vocabulary size to a subset of most frequent types; and it has a large memory footprint. We propose a general technique for replacing the softmax layer with a continuous embedding layer. Our primary innovations are a novel probabilistic loss, and a training and inference procedure in which we generate a probability distribution over pre-trained word embeddings, instead of a multinomial distribution over the vocabulary obtained via softmax. We evaluate this new class of sequence-to-sequence models with continuous outputs on the task of neural machine translation. We show that our models obtain upto 2.5x speed-up in training time while performing on par with the state-of-the-art models in terms of translation quality. These models are capable of handling very large vocabularies without compromising on translation quality. They also produce more meaningful errors than in the softmax-based models, as these errors typically lie in a subspace of the vector space of the reference translations.|sl:tag|tag:language_model
Coursera: Machine Learning|skos:broader|Coursera
 Deep contextualized word representations    each word is assigned a representation which is a function of the  entire corpus sentences to which they belong. The embeddings are  computed from the internal states of a two-layers bidirectional Language  Model, hence the name “ELMo”: Embeddings from Language  Models.    [Github](https://github.com/allenai/bilm-tf)    |skos:broader|[Best presentation](doc:2020/06/on_word_embeddings) about word embeddings, by [Sebastian Ruder](tag:sebastian_ruder)    Capture the idea that one can express “meaning” of words using a vector, so that the cosine of the angle between the vectors captures semantic similarity.    A set of language modeling and feature learning techniques where words from the vocabulary (and possibly phrases thereof) are mapped to vectors of real numbers in a low dimensional space, relative to the vocabulary size.     ~ Context-predicting models    ~ Latent feature representations of words    Paramaterized function mapping words in some language to vectors (perhaps 200 to 500 dimensions). Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with much lower dimension.    Plongement lexical in French    Word embedding of a word: a succinct representation of the distribution of other words around this word.    Methods to generate the mapping include neural networks, dimensionality reduction on the word co-occurrence matrix, probabilistic models, and explicit representation in terms of the context in which words appear.    In the new generation of models, the vector estimation problem is handled as a supervised task, where the weights in a word vector are set to maximize the probability of the contexts in which the word is observed in the corpus    The mapping may be generated training a neural network on a large corpus to predict a word given a context (Continuous Bag Of Words model) or to predict the context given a word (skip gram model). The context is a window of surrounding words.    The most known software to produce word embeddings is Tomas Mikolov's Word2vec. Pre-trained word embeddings are also available in the word2vec code.google page.    Applications:     - search document ranking  - boost the performance in NLP tasks such as syntactic parsing and sentiment analysis.          
AutoML-Zero: Evolving Machine Learning Algorithms From Scratch  Fun AutoML-Zero experiments: Evolutionary search discovers fundamental ML algorithms from scratch, e.g., small neural nets with backprop.   Can evolution be the “Master Algorithm”? ;) Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.|sl:arxiv_author|Quoc V. Le
Changement climatique|skos:broader|Climat
Beyond Vector Spaces: Compact Data Representation as Differentiable Weighted Graphs  In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE (Probabilistic Differentiable Graph Embeddings): a method that learns a weighted graph representation of data end-to-end by gradient descent.    [Github](https://github.com/stanis-morozov/prodige)     Learning useful representations is a key ingredient to the success of modern machine learning. Currently, representation learning mostly relies on embedding data into Euclidean space. However, recent work has shown that data in some domains is better modeled by non-euclidean metric spaces, and inappropriate geometry can result in inferior performance. In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE: a method that learns a weighted graph representation of data end-to-end by gradient descent. Greater generality and fewer model assumptions make PRODIGE more powerful than existing embedding-based approaches. We confirm the superiority of our method via extensive experiments on a wide range of tasks, including classification, compression, and collaborative filtering.|sl:tag|tag:vector_space_model
Guêpe|skos:broader|Insecte
jersey|skos:broader|RESTful Web Services
Macaw: An Extensible Conversational Information Seeking Platform Conversational information seeking (CIS) has been recognized as a major emerging research area in information retrieval. Such research will require data and tools, to allow the implementation and study of conversational systems. This paper introduces Macaw, an open-source framework with a modular architecture for CIS research. Macaw supports multi-turn, multi-modal, and mixed-initiative interactions, and enables research for tasks such as document retrieval, question answering, recommendation, and structured data exploration. It has a modular design to encourage the study of new CIS algorithms, which can be evaluated in batch mode. It can also integrate with a user interface, which allows user studies and data collection in an interactive mode, where the back end can be fully algorithmic or a wizard of oz setup. Macaw is distributed under the MIT License.|sl:tag|tag:information_retrieval
Servlet 3.0|skos:broader|Servlet
Entities as Experts: Sparse Memory Access with Entity Supervision   the problem of capturing declarative knowledge in the learned parameters of a language model...     Entities as Experts (EaE) can access distinct memories of the entities mentioned in a piece of text;     To understand the motivation for distinct and  independent entity representations: A traditional Transformer would need to build an internal representation  of Charles Darwin from the words “Charles”  and “Darwin”... Conversely, EAE can access  a dedicated representation of “Charles Darwin”,  which is a memory of all of the contexts in which  this entity has previously been mentioned.... Having retrieved  and re-integrated this memory it is much easier for  EAE to relate the question to the answer     EaE's entity representations are learned directly from text. Correct identification, and representation, of entities is essential to EaE's performance    Based on transformer architecture    Extension: [Facts as Experts](doc:2020/07/2007_00849_facts_as_experts_) We focus on the problem of capturing declarative knowledge in the learned parameters of a language model. We introduce a new model, Entities as Experts (EaE), that can access distinct memories of the entities mentioned in a piece of text. Unlike previous efforts to integrate entity knowledge into sequence models, EaE's entity representations are learned directly from text. These representations capture sufficient knowledge to answer TriviaQA questions such as Which Dr. Who villain has been played by Roger Delgado, Anthony Ainley, Eric Roberts?. EaE outperforms a Transformer model with $30\\times$ the parameters on this task. According to the Lama knowledge probes, EaE also contains more factual knowledge than a similar sized Bert. We show that associating parameters with specific entities means that EaE only needs to access a fraction of its parameters at inference time, and we show that the correct identification, and representation, of entities is essential to EaE's performance. We also argue that the discrete and independent entity representations in EaE make it more modular and interpretable than the Transformer architecture on which it is based.|sl:tag|tag:attention_is_all_you_need
Semi-supervised learning|skos:broader|Machine learning
Subword Semantic Hashing for Intent Classification on Small Datasets In this paper, we introduce the use of Semantic Hashing as embedding for the task of Intent Classification and achieve state-of-the-art performance on three frequently used benchmarks. Intent Classification on a small dataset is a challenging task for data-hungry state-of-the-art Deep Learning based systems. Semantic Hashing is an attempt to overcome such a challenge and learn robust text classification. Current word embedding based are dependent on vocabularies. One of the major drawbacks of such methods is out-of-vocabulary terms, especially when having small training datasets and using a wider vocabulary. This is the case in Intent Classification for chatbots, where typically small datasets are extracted from internet communication. Two problems arise by the use of internet communication. First, such datasets miss a lot of terms in the vocabulary to use word embeddings efficiently. Second, users frequently make spelling errors. Typically, the models for intent classification are not trained with spelling errors and it is difficult to think about ways in which users will make mistakes. Models depending on a word vocabulary will always face such issues. An ideal classifier should handle spelling errors inherently. With Semantic Hashing, we overcome these challenges and achieve state-of-the-art results on three datasets: AskUbuntu, Chatbot, and Web Application. Our benchmarks are available online: https://github.com/kumar-shridhar/Know-Your-Intent|sl:arxiv_author|Pedro Alonso
Metagenomics|skos:broader|Genetics Génétique
Administration française|skos:broader|France
Windows Media Player|skos:broader|Media Player
Vie extraterrestre|skos:broader|Biology
Perse|skos:broader|Antiquité iranienne
Google Brain|skos:broader|AI@Google
Hydra|skos:broader|Service description
FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence [github](https://github.com/google-research/fixmatch)     we demonstrate the power of a  simple combination of two common Semi-Supervised Learning methods: consistency  regularization and pseudo-labeling.    1. First generates pseudo-labels using the model’s  predictions on weakly-augmented unlabeled images. For a  given image, the pseudo-label is only retained if the model  produces a high-confidence prediction.   2. The model is then  trained to predict the pseudo-label when fed a strongly augmented  version of the same image. Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. In this paper, we demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling. Our algorithm, FixMatch, first generates pseudo-labels using the model's predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just 4 labels per class. Since FixMatch bears many similarities to existing SSL methods that achieve worse performance, we carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. We make our code available at https://github.com/google-research/fixmatch.|sl:arxiv_author|Colin Raffel
Croisades|skos:broader|Moyen-âge
KG-BERT: BERT for Knowledge Graph Completion Pre-trained language models for knowledge graph completion. Triples are treated as textual sequences. (Hum, j'ai déjà vu ça quelque part) Knowledge graphs are important resources for many artificial intelligence tasks but often suffer from incompleteness. In this work, we propose to use pre-trained language models for knowledge graph completion. We treat triples in knowledge graphs as textual sequences and propose a novel framework named Knowledge Graph Bidirectional Encoder Representations from Transformer (KG-BERT) to model these triples. Our method takes entity and relation descriptions of a triple as input and computes scoring function of the triple with the KG-BERT language model. Experimental results on multiple benchmark knowledge graphs show that our method can achieve state-of-the-art performance in triple classification, link prediction and relation prediction tasks.|sl:tag|tag:knowledge_graph_completion
Deep Patent Landscaping Model Using Transformer and Graph Embedding a transformer encoder  for analyzing textual data present in patent documents  and a graph convolutional network for analyzing  patent metadata.    A benchmarking dataset for patent landscaping  based on patent trends reports published by the  Korean Patent Office. Data acquisition using Google's BigQuery public datasets.    10% improvement comparing to Google’s proposed Automated Patent Landscaping.    Empirical analysis of the importance of features (text vs metadata, citations vs classification)     Patent landscaping is a method used for searching related patents during a research and development (R&D) project. To avoid the risk of patent infringement and to follow current trends in technology, patent landscaping is a crucial task required during the early stages of an R&D project. As the process of patent landscaping requires advanced resources and can be tedious, the demand for automated patent landscaping has been gradually increasing. However, a shortage of well-defined benchmark datasets and comparable models makes it difficult to find related research studies. In this paper, we propose an automated patent landscaping model based on deep learning. To analyze the text of patents, the proposed model uses a modified transformer structure. To analyze the metadata of patents, we propose a graph embedding method that uses a diffusion graph called Diff2Vec. Furthermore, we introduce four benchmark datasets for comparing related research studies in patent landscaping. The datasets are produced by querying Google BigQuery, based on a search formula from a Korean patent attorney. The obtained results indicate that the proposed model and datasets can attain state-of-the-art performance, as compared with current patent landscaping models.|sl:tag|tag:arxiv_doc
paggr|skos:broader|RDF Application
AI Conference|skos:broader|Artificial Intelligence
Deep Learning Book|skos:broader|Deep Learning
mSpace|skos:broader|Semantic Web : Application
Markets are efficient if and only if P = NP Hmm wow I prove that if markets are weak-form efficient, meaning current prices fully reflect all information available in past prices, then P = NP, meaning every computational problem whose solution can be verified in polynomial time can also be solved in polynomial time. I also prove the converse by showing how we can program the market to solve NP-complete problems. Since P probably does not equal NP, markets are probably not efficient. Specifically, markets become increasingly inefficient as the time series lengthens or becomes more frequent. An illustration by way of partitioning the excess returns to momentum strategies based on data availability confirms this prediction.|sl:tag|tag:markets
TabFact: A Large-scale Dataset for Table-based Fact Verification fact verification given semi-structured data as evidence The problem of verifying whether a textual hypothesis holds based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation. However, existing studies are mainly restricted to dealing with unstructured evidence (e.g., natural language sentences and documents, news, etc), while verification under structured evidence, such as tables, graphs, and databases, remains under-explored. This paper specifically aims to study the fact verification given semi-structured data as evidence. To this end, we construct a large-scale dataset called TabFact with 16k Wikipedia tables as the evidence for 118k human-annotated natural language statements, which are labeled as either ENTAILED or REFUTED. TabFact is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning. To address these reasoning challenges, we design two different models: Table-BERT and Latent Program Algorithm (LPA). Table-BERT leverages the state-of-the-art pre-trained language model to encode the linearized tables and statements into continuous vectors for verification. LPA parses statements into programs and executes them against the tables to obtain the returned binary value for verification. Both methods achieve similar accuracy but still lag far behind human performance. We also perform a comprehensive analysis to demonstrate great future opportunities. The data and code of the dataset are provided in \\url{https://github.com/wenhuchen/Table-Fact-Checking}.|sl:arxiv_author|Xiyou Zhou
Uriqr|skos:broader|Linked Data
Antiquité du Pakistan|skos:broader|Antiquité
Immune system Système immunitaire|skos:broader|Biology
Configuration as Linked Data|skos:broader|Linked Data: application
KG-BERT: BERT for Knowledge Graph Completion Pre-trained language models for knowledge graph completion. Triples are treated as textual sequences. (Hum, j'ai déjà vu ça quelque part) Knowledge graphs are important resources for many artificial intelligence tasks but often suffer from incompleteness. In this work, we propose to use pre-trained language models for knowledge graph completion. We treat triples in knowledge graphs as textual sequences and propose a novel framework named Knowledge Graph Bidirectional Encoder Representations from Transformer (KG-BERT) to model these triples. Our method takes entity and relation descriptions of a triple as input and computes scoring function of the triple with the KG-BERT language model. Experimental results on multiple benchmark knowledge graphs show that our method can achieve state-of-the-art performance in triple classification, link prediction and relation prediction tasks.|sl:tag|tag:pre_trained_language_models
Topic Modeling over Short Texts by Incorporating Word Embeddings New method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo-texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic Inferring topics from the overwhelming amount of short texts becomes a critical but challenging task for many content analysis tasks, such as content charactering, user interest profiling, and emerging topic detecting. Existing methods such as probabilistic latent semantic analysis (PLSA) and latent Dirichlet allocation (LDA) cannot solve this prob- lem very well since only very limited word co-occurrence information is available in short texts. This paper studies how to incorporate the external word correlation knowledge into short texts to improve the coherence of topic modeling. Based on recent results in word embeddings that learn se- mantically representations for words from a large corpus, we introduce a novel method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo- texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic. The experiments on real-world datasets validate the effectiveness of our model comparing with the state-of-the-art models.|sl:tag|tag:arxiv_doc
Label-aware Document Representation via Hybrid Attention for Extreme Multi-Label Text Classification  This paper is motivated to better explore the semantic relationship between each document and extreme labels by taking advantage of both document content and label correlation. Our objective is to establish an explicit label-aware representation for each document with a hybrid attention deep neural network model(LAHA) Extreme multi-label text classification (XMTC) aims at tagging a document with most relevant labels from an extremely large-scale label set. It is a challenging problem especially for the tail labels because there are only few training documents to build classifier. This paper is motivated to better explore the semantic relationship between each document and extreme labels by taking advantage of both document content and label correlation. Our objective is to establish an explicit label-aware representation for each document with a hybrid attention deep neural network model(LAHA). LAHA consists of three parts. The first part adopts a multi-label self-attention mechanism to detect the contribution of each word to labels. The second part exploits the label structure and document content to determine the semantic connection between words and labels in a same latent space. An adaptive fusion strategy is designed in the third part to obtain the final label-aware document representation so that the essence of previous two parts can be sufficiently integrated. Extensive experiments have been conducted on six benchmark datasets by comparing with the state-of-the-art methods. The results show the superiority of our proposed LAHA method, especially on the tail labels.|sl:tag|tag:arxiv_doc
Large Memory Layers with Product Keys  a structured memory which can be easily integrated into a neural network. The memory is very large by design and therefore significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time.     a key-value memory layer that can increase model capacity for a negligible computational cost. A 12-layer transformer with a memory outperforms a 24-layer transformer, and is 2x faster!     [Implementation](/doc/2019/08/product_key_memory_pkm_minima) This paper introduces a structured memory which can be easily integrated into a neural network. The memory is very large by design and significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time. This memory layer allows us to tackle very large scale language modeling tasks. In our experiments we consider a dataset with up to 30 billion words, and we plug our memory layer in a state-of-the-art transformer-based architecture. In particular, we found that a memory augmented model with only 12 layers outperforms a baseline transformer model with 24 layers, while being twice faster at inference time. We release our code for reproducibility purposes.|sl:arxiv_author|Hervé Jégou
C2GWeb-JS|skos:broader|C2GWeb
Semantic web and AI|skos:broader|Artificial Intelligence
HTML parsing|skos:broader|HTML Dev
Google Spreadsheets|skos:broader|Google
Capsule networks|skos:broader|Neural networks
Linked Data Service|skos:broader|Linked Data
FN|skos:broader|Politique française
JSON-LD frame|skos:broader|JSON-LD
Compressive Transformers for Long-Range Sequence Modelling  the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning.    [Blog post](/doc/2020/02/a_new_model_and_dataset_for_lon) We present the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning. We find the Compressive Transformer obtains state-of-the-art language modelling results in the WikiText-103 and Enwik8 benchmarks, achieving 17.1 ppl and 0.97 bpc respectively. We also find it can model high-frequency speech effectively and can be used as a memory mechanism for RL, demonstrated on an object matching task. To promote the domain of long-range sequence learning, we propose a new open-vocabulary language modelling benchmark derived from books, PG-19.|sl:tag|tag:attention_is_all_you_need
Continual Lifelong Learning with Neural Networks: A Review Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.|sl:arxiv_author|Ronald Kemker
Berlin|skos:broader|Ville
Social Networks|skos:broader|Internet
Download & Execute Javascript|skos:broader|JavaScript
Physique|skos:broader|Science
Pre-Trained Language Models|skos:broader|Transfer learning in NLP
Écologie|skos:broader|Environnement
Poincaré Embeddings|skos:broader|NLP@Facebook
A Theoretical Analysis of Contrastive Unsupervised Representation Learning [blog post](/doc/?uri=http%3A%2F%2Fwww.offconvex.org%2F2019%2F03%2F19%2FCURL%2F) Recent empirical works have successfully used unlabeled data to learn feature representations that are broadly useful in downstream classification tasks. Several of these methods are reminiscent of the well-known word2vec embedding algorithm: leveraging availability of pairs of semantically similar data points and negative samples, the learner forces the inner product of representations of similar pairs with each other to be higher on average than with negative samples. The current paper uses the term contrastive learning for such algorithms and presents a theoretical framework for analyzing them by introducing latent classes and hypothesizing that semantically similar points are sampled from the same latent class. This framework allows us to show provable guarantees on the performance of the learned representations on the average classification task that is comprised of a subset of the same set of latent classes. Our generalization bound also shows that learned representations can reduce (labeled) sample complexity on downstream tasks. We conduct controlled experiments in both the text and image domains to support the theory.|sl:arxiv_author|Sanjeev Arora
Steve Jobs|skos:broader|Apple
C2GWeb on the web|skos:broader|C2GWeb
1789|skos:broader|Révolution française
Facts as Experts: Adaptable and Interpretable Neural Memory over Symbolic Knowledge  a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge.... The model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones.     a  neural language model which learns to access information  in a symbolic knowledge graph.     This  model builds on the recently-proposed [Entities as  Experts](doc:2020/07/2004_07202_entities_as_expert) (EaE) language model (Févry et al., 2020),  which extends the same transformer (Vaswani  et al., 2017) architecture of BERT (Devlin et al., 2019) with an additional external memory for entities.     After training EaE, the embedding associated  with an entity will (ideally) capture information  about the textual context in which that  entity appears, and by inference, the entity’s semantic  properties     we include an additional  memory called a fact memory, which encodes  triples from a symbolic KB.     This combination results in a  neural language model which learns to access information  in a the symbolic knowledge graph.        TODO: read again IBM's [Span Selection Pre-training for Question Answering](doc:2019/09/_1909_04120_span_selection_pre) (an effort to avoid encoding general knowledge in the transformer network itself) Massive language models are the core of modern NLP modeling and have been shown to encode impressive amounts of commonsense and factual information. However, that knowledge exists only within the latent parameters of the model, inaccessible to inspection and interpretation, and even worse, factual information memorized from the training corpora is likely to become stale as the world changes. Knowledge stored as parameters will also inevitably exhibit all of the biases inherent in the source materials. To address these problems, we develop a neural language model that includes an explicit interface between symbolically interpretable factual information and subsymbolic neural knowledge. We show that this model dramatically improves performance on two knowledge-intensive question-answering tasks. More interestingly, the model can be updated without re-training by manipulating its symbolic representations. In particular this model allows us to add new facts and overwrite existing ones in ways that are not possible for earlier models.|sl:tag|tag:knowledge_graph_deep_learning
Photo journalisme|skos:broader|Photo
RDF Application|skos:broader|Semantic Web : Application
Traversing Knowledge Graphs in Vector Space Knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new \compositional\ training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. Path queries on a knowledge graph can be used to answer compositional questions such as What languages are spoken by people living in Lisbon?. However, knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new compositional training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. On a standard knowledge base completion task, we also demonstrate that compositional training acts as a novel form of structural regularization, reliably improving performance across all base models (reducing errors by up to 43%) and achieving new state-of-the-art results.|sl:tag|tag:arxiv_doc
HTML|skos:broader|Dev
Bringing Light Into the Dark: A Large-scale Evaluation of Knowledge Graph Embedding Models Under a Unified Framework The heterogeneity in recently published knowledge graph embedding models' implementations, training, and evaluation has made fair and thorough comparisons difficult. In order to assess the reproducibility of previously published results, we re-implemented and evaluated 19 interaction models in the PyKEEN software package. Here, we outline which results could be reproduced with their reported hyper-parameters, which could only be reproduced with alternate hyper-parameters, and which could not be reproduced at all as well as provide insight as to why this might be the case. We then performed a large-scale benchmarking on four datasets with several thousands of experiments and 21,246 GPU hours of computation time. We present insights gained as to best practices, best configurations for each model, and where improvements could be made over previously published best configurations. Our results highlight that the combination of model architecture, training approach, loss function, and the explicit modeling of inverse relations is crucial for a model's performances, and not only determined by the model architecture. We provide evidence that several architectures can obtain results competitive to the state-of-the-art when configured carefully. We have made all code, experimental configurations, results, and analyses that lead to our interpretations available at https://github.com/pykeen/pykeen and https://github.com/pykeen/benchmarking|sl:arxiv_author|Sahand Sharifzadeh
Calais|skos:broader|Semantic Web : Application
Advances in Pre-Training Distributed Word Representations  we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks Many Natural Language Processing applications nowadays rely on pre-trained word representations estimated from large text corpora such as news collections, Wikipedia and Web Crawl. In this paper, we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks.|sl:tag|tag:word_embedding
Transnets|skos:broader|Blog
Large-scale Multi-label Learning with Missing Labels The multi-label classification problem has generated significant interest in recent years. However, existing approaches do not adequately address two key challenges: (a) the ability to tackle problems with a large number (say millions) of labels, and (b) the ability to handle data with missing labels. In this paper, we directly address both these problems by studying the multi-label problem in a generic empirical risk minimization (ERM) framework. Our framework, despite being simple, is surprisingly able to encompass several recent label-compression based methods which can be derived as special cases of our method. To optimize the ERM problem, we develop techniques that exploit the structure of specific loss functions - such as the squared loss function - to offer efficient algorithms. We further show that our learning framework admits formal excess risk bounds even in the presence of missing labels. Our risk bounds are tight and demonstrate better generalization performance for low-rank promoting trace-norm regularization when compared to (rank insensitive) Frobenius norm regularization. Finally, we present extensive empirical results on a variety of benchmark datasets and show that our methods perform significantly better than existing label compression based methods and can scale up to very large datasets such as the Wikipedia dataset.|sl:tag|tag:arxiv_doc
Mallet|skos:broader|NLP tools
EDF|skos:broader|Entreprise
slides fps|skos:broader|Slides
Patel-Schneider|skos:broader|Technical guys
AI@Stanford|skos:broader|Stanford
Michael Rakowitz|skos:broader|Artiste
Knowledge Graphs + Text KG + NLP|skos:broader|Natural Language Processing
Exploring the Limits of Language Modeling recent advances in Recurrent Neural Networks for large scale Language Modeling In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon.|sl:arxiv_firstAuthor|Rafal Jozefowicz
Semantic Web blog|skos:broader|Semantic Web
Prix Nobel d'économie|skos:broader|Prix Nobel
Histoire anglaise|skos:broader|Histoire
Film espagnol|skos:broader|Espagne
snorql|skos:broader|dbpedia
A Primer in BERTology: What we know about how BERT works (article praised on [twitter](https://twitter.com/dennybritz/status/1233343170596917248?s=20) by D Britz and Y. Goldberg) Transformer-based models are now widely used in NLP, but we still do not understand a lot about their inner workings. This paper describes what is known to date about the famous BERT model (Devlin et al. 2019), synthesizing over 40 analysis studies. We also provide an overview of the proposed modifications to the model and its training regime. We then outline the directions for further research.|sl:tag|tag:survey
FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence [github](https://github.com/google-research/fixmatch)     we demonstrate the power of a  simple combination of two common Semi-Supervised Learning methods: consistency  regularization and pseudo-labeling.    1. First generates pseudo-labels using the model’s  predictions on weakly-augmented unlabeled images. For a  given image, the pseudo-label is only retained if the model  produces a high-confidence prediction.   2. The model is then  trained to predict the pseudo-label when fed a strongly augmented  version of the same image. Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. In this paper, we demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling. Our algorithm, FixMatch, first generates pseudo-labels using the model's predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just 4 labels per class. Since FixMatch bears many similarities to existing SSL methods that achieve worse performance, we carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. We make our code available at https://github.com/google-research/fixmatch.|sl:arxiv_author|Nicholas Carlini
Cocoon|skos:broader|Java
Kristallnacht|skos:broader|Nazisme
Voiture à hydrogène|skos:broader|Automotive
faiss|skos:broader|Library (code)
Natural Language Processing with Small Feed-Forward Networks google guys:      We show that small and shallow feed- forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.   We show that small and shallow feed-forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.|sl:tag|tag:arxiv_doc
Large-scale Multi-label Learning with Missing Labels The multi-label classification problem has generated significant interest in recent years. However, existing approaches do not adequately address two key challenges: (a) the ability to tackle problems with a large number (say millions) of labels, and (b) the ability to handle data with missing labels. In this paper, we directly address both these problems by studying the multi-label problem in a generic empirical risk minimization (ERM) framework. Our framework, despite being simple, is surprisingly able to encompass several recent label-compression based methods which can be derived as special cases of our method. To optimize the ERM problem, we develop techniques that exploit the structure of specific loss functions - such as the squared loss function - to offer efficient algorithms. We further show that our learning framework admits formal excess risk bounds even in the presence of missing labels. Our risk bounds are tight and demonstrate better generalization performance for low-rank promoting trace-norm regularization when compared to (rank insensitive) Frobenius norm regularization. Finally, we present extensive empirical results on a variety of benchmark datasets and show that our methods perform significantly better than existing label compression based methods and can scale up to very large datasets such as the Wikipedia dataset.|sl:arxiv_author|Purushottam Kar
Planet under pressure|skos:broader|Écologie
Car Options Ontology|skos:broader|GoodRelations
Java tip|skos:broader|Java
Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.|sl:arxiv_author|Michael Spranger
Afrique médiévale|skos:broader|Histoire de l'Afrique
Etudes scientifiques|skos:broader|sciences
INRIA|skos:broader|France
Jena rules|skos:broader|Jena
Génomique|skos:broader|Biotechnologies Biotechnologies
FaceNet: A Unified Embedding for Face Recognition and Clustering Learns a Euclidean embedding per image     Uses a deep CNN trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method.     state-of-the-art face recognition performance using only 128-bytes per face.      Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves 95.12%. Our system cuts the error rate in comparison to the best published result by 30% on both datasets. We also introduce the concept of harmonic embeddings, and a harmonic triplet loss, which describe different versions of face embeddings (produced by different networks) that are compatible to each other and allow for direct comparison between each other.|sl:tag|tag:siamese_network
What Does BERT Look At? An Analysis of BERT's Attention Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT's attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT's attention.|sl:tag|tag:what_s_encoded_by_a_nn
Snorkel|skos:broader|Training Data (NLP)
TripleStore|skos:broader|Semantic Web: databases
Compressive Transformers for Long-Range Sequence Modelling  the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning.    [Blog post](/doc/2020/02/a_new_model_and_dataset_for_lon) We present the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning. We find the Compressive Transformer obtains state-of-the-art language modelling results in the WikiText-103 and Enwik8 benchmarks, achieving 17.1 ppl and 0.97 bpc respectively. We also find it can model high-frequency speech effectively and can be used as a memory mechanism for RL, demonstrated on an object matching task. To promote the domain of long-range sequence learning, we propose a new open-vocabulary language modelling benchmark derived from books, PG-19.|sl:tag|tag:google_deepmind
Large scale distributed neural network training through online distillation   we use codistillation to refer to distillation performed:   1. using the same architecture for all the models;   2. using the same dataset to train all the models; and   3. using the distillation loss during training before any model has fully converged.     In general, we believe the quality gains of codistillation over well-tuned offline distillation will be  minor in practice and the more interesting research direction is exploring codistillation as a distributed  training algorithm     Codistillation with  the same data seems to be slightly better than the baseline, but codistillation using different data  gets much better results. These results show that the codistilling models are indeed successfully  transmitting useful information about different parts of the training data to each other.    Related to [Deep mutual learning](doc:2020/05/1706_00384_deep_mutual_learni) paper Techniques such as ensembling and distillation promise model quality improvements when paired with almost any base model. However, due to increased test-time cost (for ensembles) and increased complexity of the training pipeline (for distillation), these techniques are challenging to use in industrial settings. In this paper we explore a variant of distillation which is relatively straightforward to use as it does not require a complicated multi-stage setup or many new hyperparameters. Our first claim is that online distillation enables us to use extra parallelism to fit very large datasets about twice as fast. Crucially, we can still speed up training even after we have already reached the point at which additional parallelism provides no benefit for synchronous or asynchronous stochastic gradient descent. Two neural networks trained on disjoint subsets of the data can share knowledge by encouraging each model to agree with the predictions the other model would have made. These predictions can come from a stale version of the other model so they can be safely computed using weights that only rarely get transmitted. Our second claim is that online distillation is a cost-effective way to make the exact predictions of a model dramatically more reproducible. We support our claims using experiments on the Criteo Display Ad Challenge dataset, ImageNet, and the largest to-date dataset used for neural language modeling, containing $6\\times 10^{11}$ tokens and based on the Common Crawl repository of web data.|sl:arxiv_author|George E. Dahl
First Americans|skos:broader|Civilisations précolombiennes
OpenLink Ajax Toolkit (OAT)|skos:broader|Kingsley Idehen
A Tutorial on Network Embeddings Network embedding methods aim at learning low-dimensional latent representation of nodes in a network. These representations can be used as features for a wide range of tasks on graphs such as classification, clustering, link prediction, and visualization. In this survey, we give an overview of network embeddings by summarizing and categorizing recent advancements in this research field. We first discuss the desirable properties of network embeddings and briefly introduce the history of network embedding algorithms. Then, we discuss network embedding methods under different scenarios, such as supervised versus unsupervised learning, learning embeddings for homogeneous networks versus for heterogeneous networks, etc. We further demonstrate the applications of network embeddings, and conclude the survey with future work in this area.|sl:tag|tag:ml_google
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Victoria Langston
Drupal|skos:broader|Website: creation
General Motors|skos:broader|Entreprise
Grèce|skos:broader|Europe
Google Patents|skos:broader|Patent
FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence [github](https://github.com/google-research/fixmatch)     we demonstrate the power of a  simple combination of two common Semi-Supervised Learning methods: consistency  regularization and pseudo-labeling.    1. First generates pseudo-labels using the model’s  predictions on weakly-augmented unlabeled images. For a  given image, the pseudo-label is only retained if the model  produces a high-confidence prediction.   2. The model is then  trained to predict the pseudo-label when fed a strongly augmented  version of the same image. Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. In this paper, we demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling. Our algorithm, FixMatch, first generates pseudo-labels using the model's predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just 4 labels per class. Since FixMatch bears many similarities to existing SSL methods that achieve worse performance, we carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. We make our code available at https://github.com/google-research/fixmatch.|sl:arxiv_author|Han Zhang
Semantic Web : critique|skos:broader|Semantic Web
Supernova|skos:broader|Explosions cosmiques
Topic Modeling|skos:broader|NLP techniques
Uncertainty in Deep Learning|skos:broader|Uncertainty Reasoning
Macaw: An Extensible Conversational Information Seeking Platform Conversational information seeking (CIS) has been recognized as a major emerging research area in information retrieval. Such research will require data and tools, to allow the implementation and study of conversational systems. This paper introduces Macaw, an open-source framework with a modular architecture for CIS research. Macaw supports multi-turn, multi-modal, and mixed-initiative interactions, and enables research for tasks such as document retrieval, question answering, recommendation, and structured data exploration. It has a modular design to encourage the study of new CIS algorithms, which can be evaluated in batch mode. It can also integrate with a user interface, which allows user studies and data collection in an interactive mode, where the back end can be fully algorithmic or a wizard of oz setup. Macaw is distributed under the MIT License.|sl:tag|tag:chatbot
Samy Bengio|skos:broader|AI girls and guys
Word + Entity embeddings|skos:broader|Entity embeddings
A Little Annotation does a Lot of Good: A Study in Bootstrapping Low-resource Named Entity Recognizers Most state-of-the-art models for named entity recognition (NER) rely on the availability of large amounts of labeled data, making them challenging to extend to new, lower-resourced languages. However, there are now several proposed approaches involving either cross-lingual transfer learning, which learns from other highly resourced languages, or active learning, which efficiently selects effective training data based on model predictions. This paper poses the question: given this recent progress, and limited human annotation, what is the most effective method for efficiently creating high-quality entity recognizers in under-resourced languages? Based on extensive experimentation using both simulated and real human annotation, we find a dual-strategy approach best, starting with a cross-lingual transferred model, then performing targeted annotation of only uncertain entity spans in the target language, minimizing annotator effort. Results demonstrate that cross-lingual transfer is a powerful tool when very little data can be annotated, but an entity-targeted annotation strategy can achieve competitive accuracy quickly, with just one-tenth of training data.|sl:arxiv_author|Aditi Chaudhary
Barack's Wife Hillary: Using Knowledge-Graphs for Fact-Aware Language Modeling  a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset, a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark. In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language model's ability to complete sentences requiring factual knowledge, showing that the KGLM outperforms even very large language models in generating facts.|sl:arxiv_firstAuthor|Robert L. Logan IV
Dean Allemang|skos:broader|Technical girls and guys
Encoding Categorical Variables with Conjugate Bayesian Models for WeWork Lead Scoring Engine  To encode high-cardinality categorical variables, we introduce a technique based on traditional Bayesian statistics. This technique is a paradigm for ensemble modeling, specifically stacking, where the base learner consists of a problem- specific conjugate Bayesian model (CBM)   Applied Data Scientists throughout various industries are commonly faced with the challenging task of encoding high-cardinality categorical features into digestible inputs for machine learning algorithms. This paper describes a Bayesian encoding technique developed for WeWork's lead scoring engine which outputs the probability of a person touring one of our office spaces based on interaction, enrichment, and geospatial data. We present a paradigm for ensemble modeling which mitigates the need to build complicated preprocessing and encoding schemes for categorical variables. In particular, domain-specific conjugate Bayesian models are employed as base learners for features in a stacked ensemble model. For each column of a categorical feature matrix we fit a problem-specific prior distribution, for example, the Beta distribution for a binary classification problem. In order to analytically derive the moments of the posterior distribution, we update the prior with the conjugate likelihood of the corresponding target variable for each unique value of the given categorical feature. This function of column and value encodes the categorical feature matrix so that the final learner in the ensemble model ingests low-dimensional numerical input. Experimental results on both curated and real world datasets demonstrate impressive accuracy and computational efficiency on a variety of problem archetypes. Particularly, for the lead scoring engine at WeWork -- where some categorical features have as many as 300,000 levels -- we have seen an AUC improvement from 0.87 to 0.97 through implementing conjugate Bayesian model encoding.|sl:tag|tag:categorical_variables
Ian Horrocks|skos:broader|Technical girls and guys
URI Identity|skos:broader|URI
Similarity Search for Efficient Active Learning and Search of Rare Concepts  Similarity search for Efficient Active Learning and Search (SEALS)    In [Active Learning](tag:active_learning): instead of searching globally for the optimal examples to label, leverage the fact that data is often heavily skewed and expand the candidate pool with the nearest neighbors of the labeled set.     Our work attacks both the labeling and computational costs of machine learning...SEALS dramatically reduces the barrier to machine learning, enabling small teams or individuals to  build accurate classifiers. SEALS does, however, introduce another system component, a similarity  search index, which adds some additional engineering complexity to build, tune, and maintain.  Fortunately, several highly optimized implementations like Annoy and [Faiss](doc:2020/06/facebookresearch_faiss_a_libra) work reasonably well  out of the box. Many active learning and search approaches are intractable for industrial settings with billions of unlabeled examples. Existing approaches, such as uncertainty sampling or information density, search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. However, in practice, data is often heavily skewed; only a small fraction of collected data will be relevant for a given learning task. For example, when identifying rare classes, detecting malicious content, or debugging model performance, the ratio of positive to negative examples can be 1 to 1,000 or more. In this work, we exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round by only looking at the nearest neighbors to the labeled examples. Empirically, we observe that learned representations effectively cluster unseen concepts, making active learning very effective and substantially reducing the number of viable unlabeled examples. We evaluate several active learning and search techniques in this setting on three large-scale datasets: ImageNet, Goodreads spoiler detection, and OpenImages. For rare classes, active learning methods need as little as 0.31% of the labeled data to match the average precision of full supervision. By limiting active learning methods to only consider the immediate neighbors of the labeled data as candidates for labeling, we need only process as little as 1% of the unlabeled data while achieving similar reductions in labeling costs as the traditional global approach. This process of expanding the candidate pool with the nearest neighbors of the labeled set can be done efficiently and reduces the computational complexity of selection by orders of magnitude.|sl:arxiv_author|Matei Zaharia
[Vaswani, et al. 2017 paper](https://arxiv.org/abs/1706.03762): Attention is all you need.    [#seq2seq](/tag/sequence_to_sequence_learning) using only improved self-attention units (multi-head self-attention  mechanism), without any RNN.  |skos:broader|Training models to convert sequences from one domain (e.g. sentences in English) to sequences in another domain (e.g. the same sentences translated to French).    Example of transformation: translation from one language to another one (text or audio), QA answering, parsing sentences into grammar tree.    The seq2seq model generally uses an encoder-decoder architecture, where both encoder and decoder are RNN:    - the encoder encodes the input as a fixed length vector (the context vector)  - the decoder is initialized with the context vector to emit the output    Problems:    - fixed-length context vector is unable to remember long sentences. [#Attention mechanism](/tag/deep_learning_attention) allows to solve this problem  - since RNN-based seq2seq model are sequential models, they cannot be parallelized. [#The Transformer](/tag/attention_is_all_you_need) solves this      
Memory requirements in NN|skos:broader|Neural networks
fps and WWW 2008|skos:broader|fps
Learning Deep Latent Spaces for Multi-Label Classification Uses [Deep Canonical Correlation Analysis](/tag/deep_canonical_correlation_analysis) and autoencoder structures to learn a latent subspace from both feature and label domains for multi-label classification.    (several implementations on github)       Multi-label classification is a practical yet challenging task in machine learning related fields, since it requires the prediction of more than one label category for each input instance. We propose a novel deep neural networks (DNN) based model, Canonical Correlated AutoEncoder (C2AE), for solving this task. Aiming at better relating feature and label domain data for improved classification, we uniquely perform joint feature and label embedding by deriving a deep latent space, followed by the introduction of label-correlation sensitive loss function for recovering the predicted label outputs. Our C2AE is achieved by integrating the DNN architectures of canonical correlation analysis and autoencoder, which allows end-to-end learning and prediction with the ability to exploit label dependency. Moreover, our C2AE can be easily extended to address the learning problem with missing labels. Our experiments on multiple datasets with different scales confirm the effectiveness and robustness of our proposed method, which is shown to perform favorably against state-of-the-art methods for multi-label classification.|sl:arxiv_author|Chih-Kuan Yeh
Musique africaine African music|skos:broader|Africa
Foxconn|skos:broader|Chine : technologie
Entity Embeddings of Categorical Variables  We map categorical variables in a function approximation problem into Euclidean spaces, which are the entity embeddings of the categorical variables. The mapping is learned by a neural network during the standard supervised training process. Entity embedding not only reduces memory usage and speeds up neural networks compared with one-hot encoding, but more importantly by mapping similar values close to each other in the embedding space it reveals the intrinsic properties of the categorical variables We map categorical variables in a function approximation problem into Euclidean spaces, which are the entity embeddings of the categorical variables. The mapping is learned by a neural network during the standard supervised training process. Entity embedding not only reduces memory usage and speeds up neural networks compared with one-hot encoding, but more importantly by mapping similar values close to each other in the embedding space it reveals the intrinsic properties of the categorical variables. We applied it successfully in a recent Kaggle competition and were able to reach the third position with relative simple features. We further demonstrate in this paper that entity embedding helps the neural network to generalize better when the data is sparse and statistics is unknown. Thus it is especially useful for datasets with lots of high cardinality features, where other methods tend to overfit. We also demonstrate that the embeddings obtained from the trained neural network boost the performance of all tested machine learning methods considerably when used as the input features instead. As entity embedding defines a distance measure for categorical variables it can be used for visualizing categorical data and for data clustering.|sl:tag|tag:statistical_classification
Named Entity Recognition|skos:broader|Entity discovery and linking
Salzburg|skos:broader|Autriche
Impôt|skos:broader|Société
Representation Learning with Contrastive Predictive Coding  a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful [autoregressive models](/tag/autoregressive_model). We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using [negative sampling](/tag/negative_sampling).    a contrastive method that can be applied to any form of data that can be expressed in an ordered sequence: text, speech, video... While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.|sl:tag|tag:arxiv_doc
Towards a Seamless Integration of Word Senses into Downstream NLP Applications Lexical ambiguity can impede NLP systems from accurate understanding of semantics. Despite its potential benefits, the integration of sense-level information into NLP systems has remained understudied. By incorporating a novel disambiguation algorithm into a state-of-the-art classification model, we create a pipeline to integrate sense-level information into downstream NLP applications. We show that a simple disambiguation of the input text can lead to consistent performance improvement on multiple topic categorization and polarity detection datasets, particularly when the fine granularity of the underlying sense inventory is reduced and the document is sufficiently large. Our results also point to the need for sense representation research to focus more on in vivo evaluations which target the performance in downstream NLP applications rather than artificial benchmarks.|sl:tag|tag:using_word_embedding
AI 4 IP|skos:broader|Propriété intellectuelle
Amy Winehouse|skos:broader|Musicien
NEPOMUK|skos:broader|Semantic Web project
Antidot|skos:broader|French Semantic web company
Bhaskar Mitra|skos:broader|Microsoft Research
TheWebConf|skos:broader|Conférences
A Dual Embedding Space Model for Document Ranking Investigate neural word embeddings as a source of evidence in document ranking.    Presented in [this Stanford course on IR](/doc/?uri=https%3A%2F%2Fweb.stanford.edu%2Fclass%2Fcs276%2Fhandouts%2Flecture20-distributed-representations.pdf) by Chris Manning (starting slide 44)    They train a word2vec model, but retain both the input and the output projections.     During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs.      However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives A fundamental goal of search engines is to identify, given a query, documents that have relevant text. This is intrinsically difficult because the query and the document may use different vocabulary, or the document may contain query words without being relevant. We investigate neural word embeddings as a source of evidence in document ranking. We train a word2vec embedding model on a large unlabelled query corpus, but in contrast to how the model is commonly used, we retain both the input and the output projections, allowing us to leverage both the embedding spaces to derive richer distributional relationships. During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs. We postulate that the proposed Dual Embedding Space Model (DESM) captures evidence on whether a document is about a query term in addition to what is modelled by traditional term-frequency based approaches. Our experiments show that the DESM can re-rank top documents returned by a commercial Web search engine, like Bing, better than a term-matching based signal like TF-IDF. However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives, retrieving documents that are only loosely related to the query. We demonstrate that this problem can be solved effectively by ranking based on a linear mixture of the DESM and the word counting features.|sl:tag|tag:embeddings_in_ir
Catholicisme|skos:broader|Chrétienté
TV advertising|skos:broader|Télévision
Internet|skos:broader|NTIC
Ciao Vito|skos:broader|Vito
Moussa Kaka|skos:broader|Niger
CERN|skos:broader|Physique des particules
Riz|skos:broader|Agriculture
Vector space model|skos:broader|NLP techniques
Language Models as Knowledge Bases? an analysis of the relational knowledge present in pretrained language models shows an ability of these models to recall factual knowledge  Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as fill-in-the-blank cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.|sl:arxiv_author|Patrick Lewis
Personal Knowledge Graph|skos:broader|Knowledge Graphs
Reformer|skos:broader|Transformers
MaxEnt classifier (Multinomial logistic regression)|skos:broader|Multi-class classification
DocBERT: BERT for Document Classification We present, to our knowledge, the first application of BERT to document classification. A few characteristics of the task might lead one to think that BERT is not the most appropriate model: syntactic structures matter less for content categories, documents can often be longer than typical BERT input, and documents often have multiple labels. Nevertheless, we show that a straightforward classification model using BERT is able to achieve the state of the art across four popular datasets. To address the computational expense associated with BERT inference, we distill knowledge from BERT-large to small bidirectional LSTMs, reaching BERT-base parity on multiple datasets using 30x fewer parameters. The primary contribution of our paper is improved baselines that can provide the foundation for future work.|sl:arxiv_author|Jimmy Lin
HATEOAS|skos:broader|API
Maxent models|skos:broader|Maximum Entropy
NLP@Facebook|skos:broader|NLP Teams
Lost Boy|skos:broader|Technical guys
End-to-End Neural Entity Linking  We presented the first neural end-to-end entity linking  model and show the benefit of jointly optimizing  entity recognition and linking. Leveraging key  components, namely word, entity and mention embeddings,  we prove that engineered features can  be almost completely replaced by modern neural  networks. Entity Linking (EL) is an essential task for semantic text understanding and information extraction. Popular methods separately address the Mention Detection (MD) and Entity Disambiguation (ED) stages of EL, without leveraging their mutual dependency. We here propose the first neural end-to-end EL system that jointly discovers and links entities in a text document. The main idea is to consider all possible spans as potential mentions and learn contextual similarity scores over their entity candidates that are useful for both MD and ED decisions. Key components are context-aware mention embeddings, entity embeddings and a probabilistic mention - entity map, without demanding other engineered features. Empirically, we show that our end-to-end method significantly outperforms popular systems on the Gerbil platform when enough training data is available. Conversely, if testing datasets follow different annotation conventions compared to the training set (e.g. queries/ tweets vs news documents), our ED model coupled with a traditional NER system offers the best or second best EL accuracy.|sl:tag|tag:arxiv_doc
A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efficient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximally preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We first introduce the formal definition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work address these challenges in their solutions. Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efficiency, problem settings, techniques and application scenarios.|sl:tag|tag:survey
Representation learning for very short texts using weighted word embedding aggregation A method based on word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. a href=https://github.com/cedricdeboom/RepresentationLearningGithub/a (hmm...) (python code)     Short text messages such as tweets are very noisy and sparse in their use of vocabulary. Traditional textual representations, such as tf-idf, have difficulty grasping the semantic meaning of such texts, which is important in applications such as event detection, opinion mining, news recommendation, etc. We constructed a method based on semantic word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. For this purpose we designed a weight-based model and a learning procedure based on a novel median-based loss function. This paper discusses the details of our model and the optimization methods, together with the experimental results on both Wikipedia and Twitter data. We find that our method outperforms the baseline approaches in the experiments, and that it generalizes well on different word embeddings without retraining. Our method is therefore capable of retaining most of the semantic information in the text, and is applicable out-of-the-box.|sl:arxiv_author|Steven Van Canneyt
\Rapid Automatic Keyword Extraction\|skos:broader|“the automatic  selection of important and topical phrases  from the body of a document” (Turney, 2000)
Vie sur Mars|skos:broader|Mars
Sanjeev Arora|skos:broader|Technical girls and guys
Web 2.0|skos:broader|Internet
Pologne|skos:broader|Europe
Mac software|skos:broader|Macintosh
Towards Understanding Linear Word Analogies A surprising property of word vectors is that word analogies can often be solved with vector arithmetic. However, it is unclear why arithmetic operators correspond to non-linear embedding models such as skip-gram with negative sampling (SGNS). We provide a formal explanation of this phenomenon without making the strong assumptions that past theories have made about the vector space and word distribution. Our theory has several implications. Past work has conjectured that linear substructures exist in vector spaces because relations can be represented as ratios; we prove that this holds for SGNS. We provide novel justification for the addition of SGNS word vectors by showing that it automatically down-weights the more frequent word, as weighting schemes do ad hoc. Lastly, we offer an information theoretic interpretation of Euclidean distance in vector spaces, justifying its use in capturing word dissimilarity.|sl:tag|tag:arxiv_doc
Armée américaine|skos:broader|USA
Semantic Integration Hub|skos:broader|Semantic Web
GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden unit), or embedding-free units such as image pixels.|sl:arxiv_author|Yann LeCun
Çatalhöyük|skos:broader|Asie mineure
Audio classification|skos:broader|Statistical classification
Plantu|skos:broader|Journal Le Monde
Configuration ontology|skos:broader|Configuration as Linked Data
Deep Learning|skos:broader|Artificial Intelligence
Corent|skos:broader|Gaulois
Outsourcing|skos:broader|Délocalisations
Dynamic Object Model Pattern|skos:broader|Design pattern
Le Pen|skos:broader|Politique française
K-BERT: Enabling Language Representation with Knowledge Graph a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by equipped with a KG without pre-training by-self because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts.|sl:tag|tag:knowledge_graph_deep_learning
Good|skos:broader|I like I like
Differentiable Reasoning over a Virtual Knowledge Base  We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases.    [(Bhuwan Dhingra PhD Thesis)](doc:2020/07/end_to_end_learning_with_text_) We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. On HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking approach to retrieving the relevant passages required to answer a question. DrKIT is also very efficient, processing 10-100x more queries per second than existing multi-hop systems.|sl:tag|tag:knowledge_base
Acoustique|skos:broader|Physique
Google ranking|skos:broader|Ranking (information retrieval)
Hayabusa|skos:broader|Missions spatiales
A Tutorial on Network Embeddings Network embedding methods aim at learning low-dimensional latent representation of nodes in a network. These representations can be used as features for a wide range of tasks on graphs such as classification, clustering, link prediction, and visualization. In this survey, we give an overview of network embeddings by summarizing and categorizing recent advancements in this research field. We first discuss the desirable properties of network embeddings and briefly introduce the history of network embedding algorithms. Then, we discuss network embedding methods under different scenarios, such as supervised versus unsupervised learning, learning embeddings for homogeneous networks versus for heterogeneous networks, etc. We further demonstrate the applications of network embeddings, and conclude the survey with future work in this area.|sl:arxiv_author|Bryan Perozzi
Mallet|skos:broader|Machine Learning library
Filets à nuages|skos:broader|Eau
Using Information Content to Evaluate Semantic Similarity in a Taxonomy This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content. Experimental evaluation suggests that the measure performs encouragingly well (a correlation of r = 0.79 with a benchmark set of human similarity judgments, with an upper bound of r = 0.90 for human subjects performing the same task), and significantly better than the traditional edge counting approach (r = 0.66).|sl:tag|tag:arxiv_doc
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).|sl:tag|tag:bert
Apache Hive|skos:broader|apache.org
France is AI 2018|skos:broader|AI Conference
Mbilia Bel|skos:broader|Musicien
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:tag|tag:graph_neural_networks
slides fps|skos:broader|fps
Météorite|skos:broader|Astronomie
Film argentin|skos:broader|Film
W3C TAG|skos:broader|W3C
Hadoop|skos:broader|Distributed computing
Cheat sheet|skos:broader|Dev tips
Apache on my mac|skos:broader|Notes d'install
JSONP|skos:broader|Script tag hack
Semantic web and AI|skos:broader|Semantic Web
A Survey on Deep Learning for Named Entity Recognition mainly focus on generic NEs in English language Named entity recognition (NER) is the task to identify mentions of rigid designators from text belonging to predefined semantic types such as person, location, organization etc. NER always serves as the foundation for many natural language applications such as question answering, text summarization, and machine translation. Early NER systems got a huge success in achieving good performance with the cost of human engineering in designing domain-specific features and rules. In recent years, deep learning, empowered by continuous real-valued vector representations and semantic composition through nonlinear processing, has been employed in NER systems, yielding stat-of-the-art performance. In this paper, we provide a comprehensive review on existing deep learning techniques for NER. We first introduce NER resources, including tagged NER corpora and off-the-shelf NER tools. Then, we systematically categorize existing works based on a taxonomy along three axes: distributed representations for input, context encoder, and tag decoder. Next, we survey the most representative methods for recent applied techniques of deep learning in new NER problem settings and applications. Finally, we present readers with the challenges faced by NER systems and outline future directions in this area.|sl:arxiv_author|Chenliang Li
Multimedia + LD|skos:broader|Multimedia
ARQ|skos:broader|SPARQL AND Jena
LDOW2012|skos:broader|LDOW
Gaussian embedding|skos:broader|Embeddings
Une suite de matrices symétriques en rapport avec la fonction de Mertens  we explore a class of equivalence relations over N from which is constructed a sequence of symetric matrices related to the Mertens function. From numerical experimentations we suggest a conjecture, about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may play a more important part in this classical and difficult problem. In this paper we explore a class of equivalence relations over $\\N^\\ast$ from which is constructed a sequence of symetric matrices related to the Mertens function. From numerical experimentations we suggest a conjecture, about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may play a more important part in this classical and difficult problem.|sl:tag|tag:hypothese_de_riemann
Representation learning for very short texts using weighted word embedding aggregation A method based on word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. a href=https://github.com/cedricdeboom/RepresentationLearningGithub/a (hmm...) (python code)     Short text messages such as tweets are very noisy and sparse in their use of vocabulary. Traditional textual representations, such as tf-idf, have difficulty grasping the semantic meaning of such texts, which is important in applications such as event detection, opinion mining, news recommendation, etc. We constructed a method based on semantic word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. For this purpose we designed a weight-based model and a learning procedure based on a novel median-based loss function. This paper discusses the details of our model and the optimization methods, together with the experimental results on both Wikipedia and Twitter data. We find that our method outperforms the baseline approaches in the experiments, and that it generalizes well on different word embeddings without retraining. Our method is therefore capable of retaining most of the semantic information in the text, and is applicable out-of-the-box.|sl:arxiv_author|Thomas Demeester
Math|skos:broader|sciences
Vehicular communication systems|skos:broader|Automobile
KnowBert|skos:broader|BERT
Solid|skos:broader|Linked Data
Google Rich Snippets|skos:broader|Google
Bag of Tricks for Efficient Text Classification A simple and efficient baseline for text classification.     Our word features can  be averaged together to form good sentence representations.    Our experiments show that fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.   This paper explores a simple and efficient baseline for text classification. Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.|sl:arxiv_author|Tomas Mikolov
Archéologie africaine|skos:broader|Histoire de l'Afrique
Enhancing the Power of Cardinal's Algorithm Cardinal's factorization algorithm of 1996 splits a univariate polynomial into two factors with root sets separated by the imaginary axis, which is an important goal itself and a basic step toward root-finding. The novelty of the algorithm and its potential power have been well recognized by experts immediately, but by 2016, that is, two decades later, its practical value still remains nil, particularly because of the high computational cost of performing its final stage by means of computing approximate greatest common divisor of two polynomials. We briefly recall Cardinal's algorithm and its difficulties, amend it based on some works performed since 1996, extend its power to splitting out factors of a more general class, and reduce the final stage of the algorithm to quite manageable computations with structured matrices. Some of our techniques can be of independent interest for matrix computations.|sl:arxiv_author|Victor Y. Pan
Nikolai Vavilov|skos:broader|Botanique
K-BERT: Enabling Language Representation with Knowledge Graph a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by equipped with a KG without pre-training by-self because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts.|sl:tag|tag:language_model
NSA|skos:broader|USA
Oum Kalsoum|skos:broader|Egypte
Extractive Text Summarization|skos:broader|Text Summarization
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:tag|tag:ai_stanford
Mark Birbeck|skos:broader|SW guys (and girls)
sequence labelling tasks where the goal is to identify  the names of entities in a sentence. Named entities can  be proper nouns (locations, people, organizations...), or can be much more  domain-specific, such as diseases or genes in  biomedical NLP.|skos:broader|pattern recognition task that involves the assignment of a categorical label to each member of a sequence of observed values. Eg: POS tagging
Eminem|skos:broader|Rap
Binary classification models with \Uncertain\ predictions Binary classification models which can assign probabilities to categories such as the tissue is 75% likely to be tumorous or the chemical is 25% likely to be toxic are well understood statistically, but their utility as an input to decision making is less well explored. We argue that users need to know which is the most probable outcome, how likely that is to be true and, in addition, whether the model is capable enough to provide an answer. It is the last case, where the potential outcomes of the model explicitly include don't know that is addressed in this paper. Including this outcome would better separate those predictions that can lead directly to a decision from those where more data is needed. Where models produce an Uncertain answer similar to a human reply of don't know or 50:50 in the examples we refer to earlier, this would translate to actions such as operate on tumour or remove compound from use where the models give a more true than not answer. Where the models judge the result Uncertain the practical decision might be carry out more detailed laboratory testing of compound or commission new tissue analyses. The paper presents several examples where we first analyse the effect of its introduction, then present a methodology for separating Uncertain from binary predictions and finally, we provide arguments for its use in practice.|sl:arxiv_author|David E Leahy
Graph Convolutional Networks|skos:broader|Graph neural networks
Common Tag|skos:broader|Semantic tagging
PlaNet - Photo Geolocation with Convolutional Neural Networks Is it possible to build a system to determine the location where a photo was taken using just its pixels? In general, the problem seems exceptionally difficult: it is trivial to construct situations where no location can be inferred. Yet images often contain informative cues such as landmarks, weather patterns, vegetation, road markings, and architectural details, which in combination may allow one to determine an approximate location and occasionally an exact location. Websites such as GeoGuessr and View from your Window suggest that humans are relatively good at integrating these cues to geolocate images, especially en-masse. In computer vision, the photo geolocation problem is usually approached using image retrieval methods. In contrast, we pose the problem as one of classification by subdividing the surface of the earth into thousands of multi-scale geographic cells, and train a deep network using millions of geotagged images. While previous approaches only recognize landmarks or perform approximate matching using global image descriptors, our model is able to use and integrate multiple visible cues. We show that the resulting model, called PlaNet, outperforms previous approaches and even attains superhuman levels of accuracy in some cases. Moreover, we extend our model to photo albums by combining it with a long short-term memory (LSTM) architecture. By learning to exploit temporal coherence to geolocate uncertain photos, we demonstrate that this model achieves a 50% performance improvement over the single-image model.|sl:arxiv_firstAuthor|Tobias Weyand
Ciao Vito|skos:broader|Restaurant
Philosophe|skos:broader|Homme célèbre
Tulipe|skos:broader|Fleur
Manipulations génétiques|skos:broader|Genetics Génétique
Traversing Knowledge Graphs in Vector Space Knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new \compositional\ training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. Path queries on a knowledge graph can be used to answer compositional questions such as What languages are spoken by people living in Lisbon?. However, knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new compositional training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. On a standard knowledge base completion task, we also demonstrate that compositional training acts as a novel form of structural regularization, reliably improving performance across all base models (reducing errors by up to 43%) and achieving new state-of-the-art results.|sl:arxiv_author|Percy Liang
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:arxiv_author|Joseph Turian
Tomcat tips|skos:broader|Tips
Bactéries|skos:broader|Biologie
LibShortText|skos:broader|Python-NLP
Universal Language Model Fine-tuning for Text Classification code is available in the fastai lib    [blog post](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html)    [see also](/doc/?uri=https%3A%2F%2Fyashuseth.blog%2F2018%2F06%2F17%2Funderstanding-universal-language-model-fine-tuning-ulmfit%2F)             Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.|sl:arxiv_author|Jeremy Howard
Tim Berners-Lee|skos:broader|Grand Homme
Subtitles|skos:broader|Digital Video
BAM! Born-Again Multi-Task Networks for Natural Language Understanding  knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers It can be challenging to train multi-task neural networks that outperform or even match their single-task counterparts. To help address this, we propose using knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers. We evaluate our approach by multi-task fine-tuning BERT on the GLUE benchmark. Our method consistently improves over standard single-task and multi-task training.|sl:tag|tag:multitask_learning_in_nlp
Supervised learning techniques that also make use of unlabeled data for training – typically a small amount of labeled data with a large amount of unlabeled data.|skos:broader|the machine learning task of inferring a function from labeled training data.
Pangloss: Fast Entity Linking in Noisy Text Environments a production system for entity disambiguation on messy tex, based  on probabilistic tokenization and context-dependent document embeddings    Probabilistic tokenization: uses the method described [here](/doc/2019/07/mining_quality_phrases_from_mas) Entity linking is the task of mapping potentially ambiguous terms in text to their constituent entities in a knowledge base like Wikipedia. This is useful for organizing content, extracting structured data from textual documents, and in machine learning relevance applications like semantic search, knowledge graph construction, and question answering. Traditionally, this work has focused on text that has been well-formed, like news articles, but in common real world datasets such as messaging, resumes, or short-form social media, non-grammatical, loosely-structured text adds a new dimension to this problem. This paper presents Pangloss, a production system for entity disambiguation on noisy text. Pangloss combines a probabilistic linear-time key phrase identification algorithm with a semantic similarity engine based on context-dependent document embeddings to achieve better than state-of-the-art results (5% in F1) compared to other research or commercially available systems. In addition, Pangloss leverages a local embedded database with a tiered architecture to house its statistics and metadata, which allows rapid disambiguation in streaming contexts and on-device disambiguation in low-memory environments such as mobile phones.|sl:arxiv_firstAuthor|Michael Conover
Longformer: The Long-Document Transformer  Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Following prior work on long-sequence transformers, we evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8. In contrast to most prior work, we also pretrain Longformer and finetune it on a variety of downstream tasks. Our pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA.|sl:tag|tag:nlp_long_documents
Amazon Mechanical Turk|skos:broader|Délocalisation des services
Java library|skos:broader|Library (code)
LDOW2011|skos:broader|LDOW
Distributional semantics|skos:broader|NLP techniques
Cassini|skos:broader|Saturne
NLU is hard|skos:broader|NLU
Prohibition des narcotiques|skos:broader|Prohibition
fpservant@slideshare|skos:broader|SlideShare
Louvre|skos:broader|Paris
Differentiable Reasoning over a Virtual Knowledge Base  We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases.    [(Bhuwan Dhingra PhD Thesis)](doc:2020/07/end_to_end_learning_with_text_) We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. On HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking approach to retrieving the relevant passages required to answer a question. DrKIT is also very efficient, processing 10-100x more queries per second than existing multi-hop systems.|sl:tag|tag:ruslan_salakhutdinov
Go (Game)|skos:broader|Jeu
ERNIE: Enhanced Language Representation with Informative Entities  We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.|sl:arxiv_author|Maosong Sun
Âge du bronze|skos:broader|Préhistoire
Dengue|skos:broader|Maladie
Hierarchical clustering of text documents|skos:broader|Hierarchical clustering
Variational Inference: A Review for Statisticians One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.|sl:arxiv_author|Jon D. McAuliffe
Named Entity Disambiguation using Deep Learning on Graphs Evaluation of different deep learning techniques to create  a context vector from graphs, aimed at high-accuracy NED. (neural  approach for entity disambiguation using graphs as background  knowledge)     We tackle Named Entity Disambiguation (NED) by comparing entities  in short sentences with Wikidata graphs. Creating a context vector  from graphs through deep learning is a challenging problem that has  never been applied to NED. Our main contribution is to present an  experimental study of recent neural techniques, as well as a discussion  about which graph features are most important for the disambiguation  task...    [published paper](https://rd.springer.com/chapter/10.1007/978-3-030-15719-7_10)      In NED, the system  must be able to generate a context for an entity in a text and an entity  in a knowledge base, then correctly link the two.    Explore whether representing graphs  as triplets is more useful than using the full topological information of the graph    We tackle \\ac{NED} by comparing entities in short sentences with \\wikidata{} graphs. Creating a context vector from graphs through deep learning is a challenging problem that has never been applied to \\ac{NED}. Our main contribution is to present an experimental study of recent neural techniques, as well as a discussion about which graph features are most important for the disambiguation task. In addition, a new dataset (\\wikidatadisamb{}) is created to allow a clean and scalable evaluation of \\ac{NED} with \\wikidata{} entries, and to be used as a reference in future research. In the end our results show that a \\ac{Bi-LSTM} encoding of the graph triplets performs best, improving upon the baseline models and scoring an \ m{F1} value of $91.6\\%$ on the \\wikidatadisamb{} test set|sl:arxiv_author|Andrew D. O'Harney
XML|skos:broader|Data Interchange Format
Connectionist vs symbolic debate|skos:broader|Artificial Intelligence
Explorateur|skos:broader|Grand voyageur
Reformer: The Efficient Transformer Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O($L^2$) to O($L\\log L$), where $L$ is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of $N$ times, where $N$ is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.|sl:tag|tag:reformer
A method to map documents to a code (e.g., 32-bit memory address) so documents with semantically closed content are mapped to close addresses. Method introduced by  Ruslan Salakhutdinov and Geoffrey Hinton in this [paper](/doc/?uri=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2FS0888613X08001813)    |skos:broader|Finding items that are similar to a given query is the core  aspect of search and retrieval systems, as well as of  recommendation engines.
Henri Verdier|skos:broader|Technical girls and guys
Touareg|skos:broader|Sahara
Linux|skos:broader|Open Source
Xavier Bertrand|skos:broader|Gouvernement Sarkozy
Exploring the Limits of Language Modeling recent advances in Recurrent Neural Networks for large scale Language Modeling In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon.|sl:arxiv_author|Rafal Jozefowicz
Darwin|skos:broader|Grand Homme
Information visualization|skos:broader|Information
Film cubain|skos:broader|Cuba
Poincaré Embeddings for Learning Hierarchical Representations  While complex symbolic datasets often exhibit a latent hierarchical structure, state-of-the-art methods typically learn embeddings in Euclidean vector spaces, which do not account for this property. For this purpose, we introduce a new approach for learning hierarchical representations of symbolic data by embedding them into hyperbolic space Representation learning has become an invaluable approach for learning from symbolic data such as text and graphs. However, while complex symbolic datasets often exhibit a latent hierarchical structure, state-of-the-art methods typically learn embeddings in Euclidean vector spaces, which do not account for this property. For this purpose, we introduce a new approach for learning hierarchical representations of symbolic data by embedding them into hyperbolic space -- or more precisely into an n-dimensional Poincar\\'e ball. Due to the underlying hyperbolic geometry, this allows us to learn parsimonious representations of symbolic data by simultaneously capturing hierarchy and similarity. We introduce an efficient algorithm to learn the embeddings based on Riemannian optimization and show experimentally that Poincar\\'e embeddings outperform Euclidean embeddings significantly on data with latent hierarchies, both in terms of representation capacity and in terms of generalization ability.|sl:arxiv_author|Douwe Kiela
Targeted ads|skos:broader|Publicité
Exoplanètes|skos:broader|Astronomie
Neural Architectures for Named Entity Recognition Neural architectures for NER that use no language-specific resources or features beyond a small amount of supervised training data and unlabeled corpora.      Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.|sl:arxiv_firstAuthor|Guillaume Lample
Homme de Florès|skos:broader|Indonésie
Semantic framework|skos:broader|Frameworks
Extinction des dinosaures|skos:broader|Catastrophe naturelle
Voir com.hp.hpl.jena.sparql.engine.QueryExecutionBase|skos:broader|ARQ - A SPARQL Processor for Jena
Zitgist|skos:broader|Semantic Web : Application
StarSpace|skos:broader|Antoine Bordes
Deep Learning and the Information Bottleneck Principle  Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN.   Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.|sl:arxiv_firstAuthor|Naftali Tishby
Linear Algebraic Structure of Word Senses, with Applications to Polysemy  Here it is shown that multiple word senses reside  in linear superposition within the word  embedding and simple sparse coding can recover  vectors that approximately capture the  senses     Each extracted word sense is accompanied by one of about  2000 “discourse atoms” that gives a succinct description of which other words co-occur with that word sense.     The success of the approach is mathematically explained using a variant of  the random walk on discourses model    (random walk: a generative model for language). Under the assumptions of this model,  there  exists a linear relationship between the vector of a  word w and the vectors of the words in its contexts (It is not the average of the words in w's context, but in a given corpus the matrix of the linear relationship does not depend on w. It can be estimated, and so we can compute the embedding of a word from the contexts it belongs to)    [Related blog post](/doc/?uri=https%3A%2F%2Fwww.offconvex.org%2F2016%2F07%2F10%2Fembeddingspolysemy%2F)   Word embeddings are ubiquitous in NLP and information retrieval, but it is unclear what they represent when the word is polysemous. Here it is shown that multiple word senses reside in linear superposition within the word embedding and simple sparse coding can recover vectors that approximately capture the senses. The success of our approach, which applies to several embedding methods, is mathematically explained using a variant of the random walk on discourses model (Arora et al., 2016). A novel aspect of our technique is that each extracted word sense is accompanied by one of about 2000 discourse atoms that gives a succinct description of which other words co-occur with that word sense. Discourse atoms can be of independent interest, and make the method potentially more useful. Empirical tests are used to verify and support the theory.|sl:arxiv_author|Yingyu Liang
Deep Learning: A Critical Appraisal Although deep learning has historical roots going back decades, neither the term deep learning nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic (2012) deep network model of Imagenet. What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.|sl:tag|tag:deep_learning
Memory in deep learning|skos:broader|Deep Learning
Subword Semantic Hashing for Intent Classification on Small Datasets In this paper, we introduce the use of Semantic Hashing as embedding for the task of Intent Classification and achieve state-of-the-art performance on three frequently used benchmarks. Intent Classification on a small dataset is a challenging task for data-hungry state-of-the-art Deep Learning based systems. Semantic Hashing is an attempt to overcome such a challenge and learn robust text classification. Current word embedding based are dependent on vocabularies. One of the major drawbacks of such methods is out-of-vocabulary terms, especially when having small training datasets and using a wider vocabulary. This is the case in Intent Classification for chatbots, where typically small datasets are extracted from internet communication. Two problems arise by the use of internet communication. First, such datasets miss a lot of terms in the vocabulary to use word embeddings efficiently. Second, users frequently make spelling errors. Typically, the models for intent classification are not trained with spelling errors and it is difficult to think about ways in which users will make mistakes. Models depending on a word vocabulary will always face such issues. An ideal classifier should handle spelling errors inherently. With Semantic Hashing, we overcome these challenges and achieve state-of-the-art results on three datasets: AskUbuntu, Chatbot, and Web Application. Our benchmarks are available online: https://github.com/kumar-shridhar/Know-Your-Intent|sl:arxiv_author|Marcus Liwicki
Irak|skos:broader|Asie
Efficient Estimation of Word Representations in Vector Space We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.   We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.|sl:arxiv_author|Tomas Mikolov
NLP and Search|skos:broader|NLP: use cases
Apple Software|skos:broader|Apple
Displaying XML with css|skos:broader|css
Voûte nubienne|skos:broader|Sahel
Pérou|skos:broader|Amérique
SDB: A SPARQL Database for Jena|skos:broader|Jena and database
Affaires de Gado à Niamey|skos:broader|Gado
NLP girls and guys|skos:broader|AI girls and guys
VIE Vienna IKS Editables|skos:broader|Interactive Knowledge Stack
Semantic Web Platform|skos:broader|Semantic Web
Webmasters @ Google|skos:broader|Google
SPARQL en javascript|skos:broader|SPARQL
Bob Dylan|skos:broader|Musicien
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:tag|tag:human_ai_collaboration
Crise des migrants|skos:broader|Immigration
Google Fusion Tables|skos:broader|Google
Parthénogenèse|skos:broader|Sexe
Antonin Artaud|skos:broader|Folie
Advances in Pre-Training Distributed Word Representations  we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks Many Natural Language Processing applications nowadays rely on pre-trained word representations estimated from large text corpora such as news collections, Wikipedia and Web Crawl. In this paper, we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks.|sl:tag|tag:nlp_facebook
Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data Word embeddings are a popular approach to unsupervised learning of word relationships that are widely used in natural language processing. In this article, we present a new set of embeddings for medical concepts learned using an extremely large collection of multimodal medical data. Leaning on recent theoretical insights, we demonstrate how an insurance claims database of 60 million members, a collection of 20 million clinical notes, and 1.7 million full text biomedical journal articles can be combined to embed concepts into a common space, resulting in the largest ever set of embeddings for 108,477 medical concepts. To evaluate our approach, we present a new benchmark methodology based on statistical power specifically designed to test embeddings of medical concepts. Our approach, called cui2vec, attains state-of-the-art performance relative to previous methods in most instances. Finally, we provide a downloadable set of pre-trained embeddings for other researchers to use, as well as an online tool for interactive exploration of the cui2vec embeddings|sl:tag|tag:combining_word_and_entity_embeddings
ERNIE: Enhanced Language Representation with Informative Entities  We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.|sl:tag|tag:bert
RDF and Property Graphs|skos:broader|Property Graphs
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:arxiv_author|Jonathan May
Thermodynamique|skos:broader|Physique
URI encoding|skos:broader|Encoding
SQL to RDF mapping|skos:broader|Database to RDF mapping
AI@Facebook|skos:broader|AI teams
Self-Taught Convolutional Neural Networks for Short Text Clustering  We propose a flexible short text clustering framework which explores the feasibility and effectiveness of combining CNN and traditional unsupervised dimensionality reduction methods.     Non-biased deep feature representations can be learned through our self- taught CNN framework which does not use any external tags/labels or complicated NLP pre-processing.     The original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations.    [conf paper, same authors](http://www.aclweb.org/anthology/W15-1509) ; [gitgub repo (matlab)](https://github.com/jacoxu/STC2)   Short text clustering is a challenging problem due to its sparseness of text representation. Here we propose a flexible Self-Taught Convolutional neural network framework for Short Text Clustering (dubbed STC^2), which can flexibly and successfully incorporate more useful semantic features and learn non-biased deep text representation in an unsupervised manner. In our framework, the original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations. Extensive experimental results demonstrate that the proposed framework is effective, flexible and outperform several popular clustering methods when tested on three public short text datasets.|sl:arxiv_author|Suncong Zheng
Beijing Genomics Institute|skos:broader|Séquençage du génome
Israël|skos:broader|Juifs
Graph Convolutional Network GCN|skos:broader|GNN
Enfance|skos:broader|Jeunesse
Crise de la dette|skos:broader|Crise financière
Learning to Remember Rare Events  a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training.    Our memory module can be easily added to any part of a supervised neural network Despite recent advances, memory-augmented deep neural networks are still limited when it comes to life-long and one-shot learning, especially in remembering rare events. We present a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training. Our memory module can be easily added to any part of a supervised neural network. To show its versatility we add it to a number of networks, from simple convolutional ones tested on image classification to deep sequence-to-sequence and recurrent-convolutional models. In all cases, the enhanced network gains the ability to remember and do life-long one-shot learning. Our module remembers training examples shown many thousands of steps in the past and it can successfully generalize from them. We set new state-of-the-art for one-shot learning on the Omniglot dataset and demonstrate, for the first time, life-long one-shot learning in recurrent neural networks on a large-scale machine translation task.|sl:tag|tag:memory_in_deep_learning
Watson Speech-to-Text|skos:broader|IBM Watson
Medical IR, ML, IA|skos:broader|Santé
RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space  We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.|sl:arxiv_author|Jian-Yun Nie
Génome|skos:broader|Genetics Génétique
DRM in HTML 5|skos:broader|HTML5
Semantic Web search engine|skos:broader|Semantic Web : Tools
Développement durable|skos:broader|Écologie
Language Models as Knowledge Bases? an analysis of the relational knowledge present in pretrained language models shows an ability of these models to recall factual knowledge  Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as fill-in-the-blank cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.|sl:tag|tag:language_model
Automotive ontologies|skos:broader|Automotive and web technologies
A Dual Embedding Space Model for Document Ranking Investigate neural word embeddings as a source of evidence in document ranking.    Presented in [this Stanford course on IR](/doc/?uri=https%3A%2F%2Fweb.stanford.edu%2Fclass%2Fcs276%2Fhandouts%2Flecture20-distributed-representations.pdf) by Chris Manning (starting slide 44)    They train a word2vec model, but retain both the input and the output projections.     During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs.      However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives A fundamental goal of search engines is to identify, given a query, documents that have relevant text. This is intrinsically difficult because the query and the document may use different vocabulary, or the document may contain query words without being relevant. We investigate neural word embeddings as a source of evidence in document ranking. We train a word2vec embedding model on a large unlabelled query corpus, but in contrast to how the model is commonly used, we retain both the input and the output projections, allowing us to leverage both the embedding spaces to derive richer distributional relationships. During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs. We postulate that the proposed Dual Embedding Space Model (DESM) captures evidence on whether a document is about a query term in addition to what is modelled by traditional term-frequency based approaches. Our experiments show that the DESM can re-rank top documents returned by a commercial Web search engine, like Bing, better than a term-matching based signal like TF-IDF. However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives, retrieving documents that are only loosely related to the query. We demonstrate that this problem can be solved effectively by ranking based on a linear mixture of the DESM and the word counting features.|sl:tag|tag:ranking_information_retrieval
Film espagnol|skos:broader|Film
Automatic tagging|skos:broader|Tagging
Cohn-Bendit|skos:broader|I like I like
Sparse coding|skos:broader|Unsupervised machine learning
Spritz|skos:broader|Reading
dbpedia|skos:broader|Linked Data
Industrie pharmaceutique|skos:broader|Santé
Knowledge Graph Completion|skos:broader|Knowledge Graphs
Musée de Niamey|skos:broader|Musée
Encoding Categorical Variables with Conjugate Bayesian Models for WeWork Lead Scoring Engine  To encode high-cardinality categorical variables, we introduce a technique based on traditional Bayesian statistics. This technique is a paradigm for ensemble modeling, specifically stacking, where the base learner consists of a problem- specific conjugate Bayesian model (CBM)   Applied Data Scientists throughout various industries are commonly faced with the challenging task of encoding high-cardinality categorical features into digestible inputs for machine learning algorithms. This paper describes a Bayesian encoding technique developed for WeWork's lead scoring engine which outputs the probability of a person touring one of our office spaces based on interaction, enrichment, and geospatial data. We present a paradigm for ensemble modeling which mitigates the need to build complicated preprocessing and encoding schemes for categorical variables. In particular, domain-specific conjugate Bayesian models are employed as base learners for features in a stacked ensemble model. For each column of a categorical feature matrix we fit a problem-specific prior distribution, for example, the Beta distribution for a binary classification problem. In order to analytically derive the moments of the posterior distribution, we update the prior with the conjugate likelihood of the corresponding target variable for each unique value of the given categorical feature. This function of column and value encodes the categorical feature matrix so that the final learner in the ensemble model ingests low-dimensional numerical input. Experimental results on both curated and real world datasets demonstrate impressive accuracy and computational efficiency on a variety of problem archetypes. Particularly, for the lead scoring engine at WeWork -- where some categorical features have as many as 300,000 levels -- we have seen an AUC improvement from 0.87 to 0.97 through implementing conjugate Bayesian model encoding.|sl:arxiv_firstAuthor|Austin Slakey
salesforce|skos:broader|Entreprise
The Description Length of Deep Learning Models  Solomonoff’s general theory of inference (Solomonoff, 1964) and the [Minimum Description Length Principle](tag:minimum_description_length_principle) (Grünwald, 2007; Rissanen, 2007) formalize [Occam's razor](tag:occam_s_razor), and hold that a good model of data is a model that is good at losslessly  compressing the data, including the cost of describing the model itself. Deep neural  networks might seem to go against this principle given the large number of  parameters to be encoded.  We demonstrate experimentally the ability of deep neural networks to compress  the training data even when accounting for parameter encoding. Solomonoff's general theory of inference and the Minimum Description Length principle formalize Occam's razor, and hold that a good model of data is a model that is good at losslessly compressing the data, including the cost of describing the model itself. Deep neural networks might seem to go against this principle given the large number of parameters to be encoded. We demonstrate experimentally the ability of deep neural networks to compress the training data even when accounting for parameter encoding. The compression viewpoint originally motivated the use of variational methods in neural networks. Unexpectedly, we found that these variational methods provide surprisingly poor compression bounds, despite being explicitly built to minimize such bounds. This might explain the relatively poor practical performance of variational methods in deep learning. On the other hand, simple incremental encoding methods yield excellent compression values on deep networks, vindicating Solomonoff's approach.|sl:arxiv_author|Léonard Blier
Part Of Speech Tagging|skos:broader|General NLP tasks
Loi Renseignement|skos:broader|Big Brother
Unifying distillation and privileged information A framework to learn from multiple machines and data representations, unifying two techniques that enable machines to learn from other machines: [distillation](tag:knowledge_distillation) ([Hinton et al., 2015](doc:2020/04/1503_02531_distilling_the_kno)) and privileged information (Vapnik & Izmailov, 2015)   Distillation (Hinton et al., 2015) and privileged information (Vapnik & Izmailov, 2015) are two techniques that enable machines to learn from other machines. This paper unifies these two techniques into generalized distillation, a framework to learn from multiple machines and data representations. We provide theoretical and causal insight about the inner workings of generalized distillation, extend it to unsupervised, semisupervised and multitask learning scenarios, and illustrate its efficacy on a variety of numerical simulations on both synthetic and real-world data.|sl:arxiv_author|David Lopez-Paz
Representing Sentences as Low-Rank Subspaces  We observe a simple geometry of sentences -- the word representations of a given sentence roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors.    A sentence of N words is a matrix (300, N) (if 300 is the dim of the word embeddings space). We take the eg. 4 (hyperparam) heaviest singular values - a subspace with dim 4    Similarity between docs: principal angle between the subspaces (reminiscent of cosine similarity)     Sentences are important semantic units of natural language. A generic, distributional representation of sentences that can capture the latent semantics is beneficial to multiple downstream applications. We observe a simple geometry of sentences -- the word representations of a given sentence (on average 10.23 words in all SemEval datasets with a standard deviation 4.84) roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors. Such an unsupervised representation is empirically validated via semantic textual similarity tasks on 19 different datasets, where it outperforms the sophisticated neural network models, including skip-thought vectors, by 15% on average.|sl:tag|tag:arxiv_doc
BERT-of-Theseus: Compressing BERT by Progressive Module Replacing approach to compress BERT by progressive module replacing.     Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter    [Github](https://github.com/JetRunner/BERT-of-Theseus) In this paper, we propose a novel model compression approach to effectively compress BERT by progressive module replacing. Our approach first divides the original BERT into several modules and builds their compact substitutes. Then, we randomly replace the original modules with their substitutes to train the compact modules to mimic the behavior of the original modules. We progressively increase the probability of replacement through the training. In this way, our approach brings a deeper level of interaction between the original and compact models, and smooths the training process. Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter, liberating human effort from hyper-parameter tuning. Our approach outperforms existing knowledge distillation approaches on GLUE benchmark, showing a new perspective of model compression.|sl:tag|tag:knowledge_distillation
SWEO Interest Group|skos:broader|Semantic web: evangelization
Hippopotame|skos:broader|Animal
SL|skos:broader|PIM
Les 100 pièges de l'Anglais|skos:broader|Learning english
Neural Ranking Models with Weak Supervision Main Idea: To leverage large amounts of unsupervised data to infer “weak” labels and use that signal for learning supervised models as if we had the ground truth labels. See [blog post](/doc/?uri=http%3A%2F%2Fmostafadehghani.com%2F2017%2F04%2F23%2Fbeating-the-teacher-neural-ranking-models-with-weak-supervision%2F):     This is truly awesome since we have only used  BM25 as the supervisor to train a model which performs better than BM25 itself!   Despite the impressive improvements achieved by unsupervised deep neural networks in computer vision and NLP tasks, such improvements have not yet been observed in ranking for information retrieval. The reason may be the complexity of the ranking problem, as it is not obvious how to learn from queries and documents when no supervised signal is available. Hence, in this paper, we propose to train a neural ranking model using weak supervision, where labels are obtained automatically without human annotators or any external resources (e.g., click data). To this aim, we use the output of an unsupervised ranking model, such as BM25, as a weak supervision signal. We further train a set of simple yet effective ranking models based on feed-forward neural networks. We study their effectiveness under various learning scenarios (point-wise and pair-wise models) and using different input representations (i.e., from encoding query-document pairs into dense/sparse vectors to using word embedding representation). We train our networks using tens of millions of training instances and evaluate it on two standard collections: a homogeneous news collection(Robust) and a heterogeneous large-scale web collection (ClueWeb). Our experiments indicate that employing proper objective functions and letting the networks to learn the input representation based on weakly supervised data leads to impressive performance, with over 13% and 35% MAP improvements over the BM25 model on the Robust and the ClueWeb collections. Our findings also suggest that supervised neural ranking models can greatly benefit from pre-training on large amounts of weakly labeled data that can be easily obtained from unsupervised IR models.|sl:arxiv_author|Hamed Zamani
Civilisations précolombiennes|skos:broader|Amérique
SW: coreferences|skos:broader|Linked Data
NTIC et développement|skos:broader|Innovation
Revisiting Semi-Supervised Learning with Graph Embeddings We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.|sl:arxiv_firstAuthor|Zhilin Yang
OWL DL|skos:broader|OWL
Shanghaï|skos:broader|Chine
RDFa 1.1 Lite|skos:broader|RDFa Lite
Barack's Wife Hillary: Using Knowledge-Graphs for Fact-Aware Language Modeling  a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset, a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark. In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language model's ability to complete sentences requiring factual knowledge, showing that the KGLM outperforms even very large language models in generating facts.|sl:arxiv_author|Robert L. Logan IV
Microsoft Concept Graph|skos:broader|NLP@Microsoft
Baidu|skos:broader|Chine : technologie
NLP: using Knowledge|skos:broader|Knowledge
Hydra|skos:broader|APIs and Linked Data
Wiki|skos:broader|Internet
Natural Language Processing (almost) from Scratch seminal work    Abstract:     a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements   We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.|sl:arxiv_firstAuthor|Ronan Collobert
Mission \Voulet-Chanoine\|skos:broader|Tchad
Knowledge Graph Embeddings and Explainable AI survey of     - the state-of-the-art in the field of knowledge graph embeddings  - methods for explaining predictions obtained via knowledge graph embeddings. Knowledge graph embeddings are now a widely adopted approach to knowledge representation in which entities and relationships are embedded in vector spaces. In this chapter, we introduce the reader to the concept of knowledge graph embeddings by explaining what they are, how they can be generated and how they can be evaluated. We summarize the state-of-the-art in this field by describing the approaches that have been introduced to represent knowledge in the vector space. In relation to knowledge representation, we consider the problem of explainability, and discuss models and methods for explaining predictions obtained via knowledge graph embeddings.|sl:tag|tag:arxiv_doc
Von Mises-Fisher Loss for Training Sequence to Sequence Models with Continuous Outputs predicting embeddings instead of word IDs (avoids a discrete softmax, using a new loss)    [@honnibal](https://twitter.com/honnibal/status/1073513114468081664)     The Softmax function is used in the final layer of nearly all existing sequence-to-sequence models for language generation. However, it is usually the slowest layer to compute which limits the vocabulary size to a subset of most frequent types; and it has a large memory footprint. We propose a general technique for replacing the softmax layer with a continuous embedding layer. Our primary innovations are a novel probabilistic loss, and a training and inference procedure in which we generate a probability distribution over pre-trained word embeddings, instead of a multinomial distribution over the vocabulary obtained via softmax. We evaluate this new class of sequence-to-sequence models with continuous outputs on the task of neural machine translation. We show that our models obtain upto 2.5x speed-up in training time while performing on par with the state-of-the-art models in terms of translation quality. These models are capable of handling very large vocabularies without compromising on translation quality. They also produce more meaningful errors than in the softmax-based models, as these errors typically lie in a subspace of the vector space of the reference translations.|sl:tag|tag:sequence_to_sequence_learning
Flaubert|skos:broader|Ecrivain
Notes on Cardinal's Matrices These notes are motivated by the work of Jean-Paul Cardinal on symmetric matrices related to the Mertens function. He showed that certain norm bounds on his matrices implied the Riemann hypothesis. Using a different matrix norm we show an equivalence of the Riemann hypothesis to suitable norm bounds on his matrices in the new norm. Then we specify a deformed version of his Mertens function matrices that unconditionally satisfies a norm bound that is of the same strength as his Riemann hypothesis bound.|sl:tag|tag:hypothese_de_riemann
Stacked Approximated Regression Machine: A Simple Deep Learning Approach This paper seems too good to be true! They can train a VGG-like net VERY quickly to good accuracy, without backprop. With the agreement of my coauthors, I Zhangyang Wang would like to withdraw the manuscript Stacked Approximated Regression Machine: A Simple Deep Learning Approach. Some experimental procedures were not included in the manuscript, which makes a part of important claims not meaningful. In the relevant research, I was solely responsible for carrying out the experiments; the other coauthors joined in the discussions leading to the main algorithm. Please see the updated text for more details.|sl:arxiv_author|Shiyu Chang
Loi sur le voile|skos:broader|Islam
AI: startups|skos:broader|Artificial Intelligence
Tchernobyl|skos:broader|Industrie nucléaire
Empires d'Afrique de l'Ouest|skos:broader|Afrique de l'Ouest
OWL editor|skos:broader|OWL
DSSM (Deep Semantic Similarity Model)|skos:broader|Document embeddings
Hittite|skos:broader|Asie mineure
Barack's Wife Hillary: Using Knowledge-Graphs for Fact-Aware Language Modeling  a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset, a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark. In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language model's ability to complete sentences requiring factual knowledge, showing that the KGLM outperforms even very large language models in generating facts.|sl:arxiv_author|Matt Gardner
Fleur|skos:broader|Plante
Semantic Web Client Library|skos:broader|Linked Data
Good idea|skos:broader|Good
CCFD|skos:broader|Catholicisme
Natural Language Processing (almost) from Scratch seminal work    Abstract:     a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements   We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.|sl:arxiv_author|Leon Bottou
Computer vision|skos:broader|Artificial Intelligence
Burkina Faso|skos:broader|Sahel
Crise écologique|skos:broader|Écologie
Crime contre l'Humanité|skos:broader|Horreur
Ora Lassila|skos:broader|Nokia
Representation Learning with Contrastive Predictive Coding  a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful [autoregressive models](/tag/autoregressive_model). We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using [negative sampling](/tag/negative_sampling).    a contrastive method that can be applied to any form of data that can be expressed in an ordered sequence: text, speech, video... While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.|sl:tag|tag:contrastive_self_supervised_learning
Freedom Box|skos:broader|Internet
Multi-label Text classification|skos:broader|Text Classification
Graph Convolutional Networks (GCNs) strike a balance between modeling the full structure of the  graph dynamically, as the tensor model does, and modeling the local neighbourhood structure through  extracted features (as substructure counting methods and RDF2Vec do). ([source](/doc/2019/08/the_knowledge_graph_as_the_defa))  |skos:broader|Neural networks that operate on graphs
Ontology|skos:broader|KR
Unsupervised method to learn sentence representations.     Conceptually,  the model can be interpreted as a natural  extension of the word-contexts from C-BOW  to a larger sentence context,  with the sentence words being specifically  optimized towards additive combination over the  sentence, by means of the unsupervised objective  function  |skos:broader|In practice, many NLP applications rely on a simple sentence embedding: the average of the  embeddings of the words in it. We can do better.    Ex of use (besides trivial ones such as classification and similarity): use sentence embeddings to cluster  sentences in documents, which aids in the automatic extraction  of key information from large bodies of text.  
AI black box|skos:broader|Deep Learning
Entity discovery and linking|skos:broader|Entities
Lobby nucléaire|skos:broader|Lobby
Label-Embedding for Image Classification Attributes act as intermediate representations that enable parameter sharing between classes, a must when training data is scarce. We propose to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors. We introduce a function that measures the compatibility between an image and a label embedding. The parameters of this function are learned on a training set of labeled samples to ensure that, given an image, the correct classes rank higher than the incorrect ones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasets show that the proposed framework outperforms the standard Direct Attribute Prediction baseline in a zero-shot learning scenario. Label embedding enjoys a built-in ability to leverage alternative sources of information instead of or in addition to attributes, such as e.g. class hierarchies or textual descriptions. Moreover, label embedding encompasses the whole range of learning settings from zero-shot learning to regular learning with a large number of labeled examples.|sl:tag|tag:image_classification
Nemrud|skos:broader|Asie mineure
Semantic web company|skos:broader|Entreprise
Business case: semantic web|skos:broader|Business case
Knowledge Vault|skos:broader|Knowledge bases
France : bureaucratie|skos:broader|France
Con de Chirac|skos:broader|Chirac
SIOC|skos:broader|RDF and social networks
BERT-of-Theseus: Compressing BERT by Progressive Module Replacing approach to compress BERT by progressive module replacing.     Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter    [Github](https://github.com/JetRunner/BERT-of-Theseus) In this paper, we propose a novel model compression approach to effectively compress BERT by progressive module replacing. Our approach first divides the original BERT into several modules and builds their compact substitutes. Then, we randomly replace the original modules with their substitutes to train the compact modules to mimic the behavior of the original modules. We progressively increase the probability of replacement through the training. In this way, our approach brings a deeper level of interaction between the original and compact models, and smooths the training process. Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter, liberating human effort from hyper-parameter tuning. Our approach outperforms existing knowledge distillation approaches on GLUE benchmark, showing a new perspective of model compression.|sl:arxiv_firstAuthor|Canwen Xu
Economie allemande|skos:broader|Economie
Desktop search|skos:broader|Informatique
The Case for Learned Index Structures  we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs  Indexes are models: a B-Tree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term learned indexes. The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show, that by using neural nets we are able to outperform cache-optimized B-Trees by up to 70% in speed while saving an order-of-magnitude in memory over several real-world data sets. More importantly though, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work just provides a glimpse of what might be possible.|sl:tag|tag:semantic_hashing
Lobby agroalimentaire|skos:broader|Lobbies économiques
NSA|skos:broader|Services secrets
Haskell|skos:broader|Functional programming
Roam|skos:broader|Note taking app
Java: JNI|skos:broader|Java dev
Kassav'|skos:broader|Zouk
Text Summarization|skos:broader|Information extraction
A Hierarchical Multi-task Approach for Learning Embeddings from Semantic Tasks [Blog post](https://medium.com/dair-ai/hmtl-multi-task-learning-for-state-of-the-art-nlp-245572bbb601), [GitHub repo](https://github.com/huggingface/hmtl)   Much effort has been devoted to evaluate whether multi-task learning can be leveraged to learn rich representations that can be used in various Natural Language Processing (NLP) down-stream applications. However, there is still a lack of understanding of the settings in which multi-task learning has a significant effect. In this work, we introduce a hierarchical model trained in a multi-task learning setup on a set of carefully selected semantic tasks. The model is trained in a hierarchical fashion to introduce an inductive bias by supervising a set of low level tasks at the bottom layers of the model and more complex tasks at the top layers of the model. This model achieves state-of-the-art results on a number of tasks, namely Named Entity Recognition, Entity Mention Detection and Relation Extraction without hand-engineered features or external NLP tools like syntactic parsers. The hierarchical training supervision induces a set of shared semantic representations at lower layers of the model. We show that as we move from the bottom to the top layers of the model, the hidden states of the layers tend to represent more complex semantic information.|sl:tag|tag:arxiv_doc
Natural selection|skos:broader|Evolution
NLP@Microsoft|skos:broader|Microsoft
hyperdoc2vec: Distributed Representations of Hypertext Documents Hypertext documents, such as web pages and academic papers, are of great importance in delivering information in our daily life. Although being effective on plain documents, conventional text embedding methods suffer from information loss if directly adapted to hyper-documents. In this paper, we propose a general embedding approach for hyper-documents, namely, hyperdoc2vec, along with four criteria characterizing necessary information that hyper-document embedding models should preserve. Systematic comparisons are conducted between hyperdoc2vec and several competitors on two tasks, i.e., paper classification and citation recommendation, in the academic paper domain. Analyses and experiments both validate the superiority of hyperdoc2vec to other models w.r.t. the four criteria.|sl:arxiv_author|Yan Song
Advances in Pre-Training Distributed Word Representations  we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks Many Natural Language Processing applications nowadays rely on pre-trained word representations estimated from large text corpora such as news collections, Wikipedia and Web Crawl. In this paper, we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks.|sl:arxiv_firstAuthor|Tomas Mikolov
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|Michael Cochez
Web dev framework|skos:broader|Web dev
Quora Question Pairs|skos:broader|Kaggle
POWDER|skos:broader|W3C Working Draft
Digital Media|skos:broader|Technologie
Differentiable Reasoning over a Virtual Knowledge Base  We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases.    [(Bhuwan Dhingra PhD Thesis)](doc:2020/07/end_to_end_learning_with_text_) We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. On HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking approach to retrieving the relevant passages required to answer a question. DrKIT is also very efficient, processing 10-100x more queries per second than existing multi-hop systems.|sl:tag|tag:arxiv_doc
Learning Sparse, Distributed Representations using the Hebbian Principle The \fire together, wire together\ Hebbian model is a central principle for learning in neuroscience, but surprisingly, it has found limited applicability in modern machine learning. In this paper, we take a first step towards bridging this gap, by developing flavors of competitive Hebbian learning which produce sparse, distributed neural codes using online adaptation with minimal tuning The fire together, wire together Hebbian model is a central principle for learning in neuroscience, but surprisingly, it has found limited applicability in modern machine learning. In this paper, we take a first step towards bridging this gap, by developing flavors of competitive Hebbian learning which produce sparse, distributed neural codes using online adaptation with minimal tuning. We propose an unsupervised algorithm, termed Adaptive Hebbian Learning (AHL). We illustrate the distributed nature of the learned representations via output entropy computations for synthetic data, and demonstrate superior performance, compared to standard alternatives such as autoencoders, in training a deep convolutional net on standard image datasets.|sl:arxiv_author|Upamanyu Madhow
Belo Horizonte|skos:broader|Ville
Analyse sémantique|skos:broader|Semantic technology
Learning Confidence for Out-of-Distribution Detection in Neural Networks Modern neural networks are very powerful predictive models, but they are often incapable of recognizing when their predictions may be wrong. Closely related to this is the task of out-of-distribution detection, where a network must determine whether or not an input is outside of the set on which it is expected to safely perform. To jointly address these issues, we propose a method of learning confidence estimates for neural networks that is simple to implement and produces intuitively interpretable outputs. We demonstrate that on the task of out-of-distribution detection, our technique surpasses recently proposed techniques which construct confidence based on the network's output distribution, without requiring any additional labels or access to out-of-distribution examples. Additionally, we address the problem of calibrating out-of-distribution detectors, where we demonstrate that misclassified in-distribution examples can be used as a proxy for out-of-distribution examples.|sl:tag|tag:out_of_distribution_detection
Livre|skos:broader|Reading
Machine translation|skos:broader|NLP
Knowledge Enhanced Contextual Word Representations General method to embed multiple knowledge bases into pre-trained language models (KB in the   sense as fixed collection of entity nodes)     The key idea is to explicitly model  entity spans in the input text and use an entity  linker to retrieve relevant entity embeddings from  a KB to form knowledge enhanced entity-span  representations.   Then,  update contextual word representations via a form of word-to-entity attention.    In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert's runtime is comparable to BERT's and it scales to large KBs.|sl:tag|tag:multiple_knowledge_bases
A Tutorial on Network Embeddings Network embedding methods aim at learning low-dimensional latent representation of nodes in a network. These representations can be used as features for a wide range of tasks on graphs such as classification, clustering, link prediction, and visualization. In this survey, we give an overview of network embeddings by summarizing and categorizing recent advancements in this research field. We first discuss the desirable properties of network embeddings and briefly introduce the history of network embedding algorithms. Then, we discuss network embedding methods under different scenarios, such as supervised versus unsupervised learning, learning embeddings for homogeneous networks versus for heterogeneous networks, etc. We further demonstrate the applications of network embeddings, and conclude the survey with future work in this area.|sl:arxiv_firstAuthor|Haochen Chen
République Tchèque|skos:broader|Europe
 Create delightful python projects using Jupyter Notebooks|skos:broader|- [Home Page](https://www.fast.ai/)  - [MOOC](https://course.fast.ai/)  - [Github](https://github.com/fastai/fastai)  - [Forum](https://forums.fast.ai/)  - [docs.fast.ai](https://docs.fast.ai/)      
BAM! Born-Again Multi-Task Networks for Natural Language Understanding  knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers It can be challenging to train multi-task neural networks that outperform or even match their single-task counterparts. To help address this, we propose using knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers. We evaluate our approach by multi-task fine-tuning BERT on the GLUE benchmark. Our method consistently improves over standard single-task and multi-task training.|sl:arxiv_author|Kevin Clark
Publishing RDF Vocabularies|skos:broader|Semanlink related
Multimedia + LD|skos:broader|Linked Data
Chili|skos:broader|Amérique du sud
Loi sur le téléchargement|skos:broader|Industrie du disque
Azawad|skos:broader|Touareg
Delon|skos:broader|Acteur
IPv6|skos:broader|IP address
Parameter-free Sentence Embedding via Orthogonal Basis training-free approach for building sentence representations, Geometric Embedding (GEM), based on the geometric structure of word embedding space.     we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word’s novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace    [on www.groundai.com](https://www.groundai.com/project/zero-training-sentence-embedding-via-orthogonal-basis/)    [Open Revieww](/doc/?uri=https%3A%2F%2Fopenreview.net%2Fforum%3Fid%3DrJedbn0ctQ) ; [Related to this paper](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1704.05358)       We propose a simple and robust non-parameterized approach for building sentence representations. Inspired by the Gram-Schmidt Process in geometric theory, we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word's novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace. Following this motivation, we develop an innovative method based on orthogonal basis to combine pre-trained word embeddings into sentence representations. This approach requires zero parameters, along with efficient inference performance. We evaluate our approach on 11 downstream NLP tasks. Our model shows superior performance compared with non-parameterized alternatives and it is competitive to other approaches relying on either large amounts of labelled data or prolonged training time.|sl:tag|tag:nlp_microsoft
Truffe|skos:broader|Curiosité naturelle
The Consciousness Prior consciousness seen as the formation of a low-dimensional combination of a few concepts constituting a conscious thought, i.e., consciousness as awareness at a particular time instant: the projection of a big vector (all the things conscious and unconscious in brain). Attention: additional mechanism describing what mind chooses to focus on.    [YouTube video](/doc/?uri=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYr1mOzC93xs) A new prior is proposed for learning representations of high-level concepts of the kind we manipulate with language. This prior can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by cognitive neuroscience theories of consciousness, seen as a bottleneck through which just a few elements, after having been selected by attention from a broader pool, are then broadcast and condition further processing, both in perception and decision-making. The set of recently selected elements one becomes aware of is seen as forming a low-dimensional conscious state. This conscious state is combining the few concepts constituting a conscious thought, i.e., what one is immediately conscious of at a particular moment. We claim that this architectural and information-processing constraint corresponds to assumptions about the joint distribution between high-level concepts. To the extent that these assumptions are generally true (and the form of natural language seems consistent with them), they can form a useful prior for representation learning. A low-dimensional thought or conscious state is analogous to a sentence: it involves only a few variables and yet can make a statement with very high probability of being true. This is consistent with a joint distribution (over high-level concepts) which has the form of a sparse factor graph, i.e., where the dependencies captured by each factor of the factor graph involve only very few variables while creating a strong dip in the overall energy function. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in a form similar to facts and rules, albeit capturing uncertainty as well as efficient search mechanisms implemented by attention mechanisms.|sl:tag|tag:human_level_ai
Wembedder: Wikidata entity embedding web service web service for querying an embedding of entities in the Wikidata knowledge graph. The embedding is trained on the Wikidata dump using Gensim's Word2Vec implementation and a simple graph walk I present a web service for querying an embedding of entities in the Wikidata knowledge graph. The embedding is trained on the Wikidata dump using Gensim's Word2Vec implementation and a simple graph walk. A REST API is implemented. Together with the Wikidata API the web service exposes a multilingual resource for over 600'000 Wikidata items and properties.|sl:tag|tag:gensim
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).|sl:tag|tag:arxiv_doc
Finding items that are similar to a given query is the core  aspect of search and retrieval systems, as well as of  recommendation engines.|skos:broader|predict the  ating\ a user would give to an item
Cassini-Huygens|skos:broader|Titan
apache.org|skos:broader|Open Source
Evolution|skos:broader|Biology
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Victor Bapst
Knowledge Graph Embeddings|skos:broader|Knowledge Graphs
Tools|skos:broader|Dev
Doc2Vec|skos:broader|Sentence Embeddings
ARN|skos:broader|Genetics Génétique
RAKE|skos:broader|Keyword/keyphrase extraction
Entity linking|skos:broader|Entities
AllenNLP|skos:broader|Allen Institute for AI (A2I)
delicious api|skos:broader|Tagging
Knowledge-driven embeddings|skos:broader|Embeddings
Efficient Estimation of Word Representations in Vector Space We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.   We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.|sl:arxiv_firstAuthor|Tomas Mikolov
Jean-Claude Ameisen|skos:broader|Hérédité
Plastic print|skos:broader|Imprimantes
Towards a Seamless Integration of Word Senses into Downstream NLP Applications Lexical ambiguity can impede NLP systems from accurate understanding of semantics. Despite its potential benefits, the integration of sense-level information into NLP systems has remained understudied. By incorporating a novel disambiguation algorithm into a state-of-the-art classification model, we create a pipeline to integrate sense-level information into downstream NLP applications. We show that a simple disambiguation of the input text can lead to consistent performance improvement on multiple topic categorization and polarity detection datasets, particularly when the fine granularity of the underlying sense inventory is reduced and the document is sufficiently large. Our results also point to the need for sense representation research to focus more on in vivo evaluations which target the performance in downstream NLP applications rather than artificial benchmarks.|sl:tag|tag:arxiv_doc
Selective Question Answering under Domain Shift How you can get a QA model to abstain from answering when it doesn’t know the answer.     Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. To avoid giving wrong answers, question answering (QA) models need to know when to abstain from answering. Moreover, users often ask questions that diverge from the model's training data, making errors more likely and thus abstention more critical. In this work, we propose the setting of selective question answering under domain shift, in which a QA model is tested on a mixture of in-domain and out-of-domain data, and must answer (i.e., not abstain on) as many questions as possible while maintaining high accuracy. Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. Crucially, the calibrator benefits from observing the model's behavior on out-of-domain data, even if from a different domain than the test data. We combine this method with a SQuAD-trained QA model and evaluate on mixtures of SQuAD and five other QA datasets. Our method answers 56% of questions while maintaining 80% accuracy; in contrast, directly using the model's probabilities only answers 48% at 80% accuracy.|sl:tag|tag:nlp_stanford
Médecins sans frontières|skos:broader|Prix Nobel
Transformers as Soft Reasoners over Language  AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. We provide the first demonstration that this is possible, and characterize the extent of this capability. To do this, we use a collection of synthetic datasets that test increasing levels of reasoning complexity (number of rules, presence of negation, and depth of chaining). We find transformers appear to learn rule-based reasoning with high (99%) accuracy on these datasets, and in a way that generalizes to test data requiring substantially deeper chaining than in the training data (95%+ scores). We also demonstrate that the models transfer well to two hand-authored rulebases, and to rulebases paraphrased into more natural language. These findings are significant as it suggests a new role for transformers, namely as a limited soft theorem prover operating over explicit theories in language. This in turn suggests new possibilities for explainability, correctability, and counterfactual reasoning in question-answering. All datasets and a live demo are available at http://rule-reasoning.apps.allenai.org/|sl:tag|tag:rules
Biotechnologies Biotechnologies|skos:broader|Biology
A Little Annotation does a Lot of Good: A Study in Bootstrapping Low-resource Named Entity Recognizers Most state-of-the-art models for named entity recognition (NER) rely on the availability of large amounts of labeled data, making them challenging to extend to new, lower-resourced languages. However, there are now several proposed approaches involving either cross-lingual transfer learning, which learns from other highly resourced languages, or active learning, which efficiently selects effective training data based on model predictions. This paper poses the question: given this recent progress, and limited human annotation, what is the most effective method for efficiently creating high-quality entity recognizers in under-resourced languages? Based on extensive experimentation using both simulated and real human annotation, we find a dual-strategy approach best, starting with a cross-lingual transferred model, then performing targeted annotation of only uncertain entity spans in the target language, minimizing annotator effort. Results demonstrate that cross-lingual transfer is a powerful tool when very little data can be annotated, but an entity-targeted annotation strategy can achieve competitive accuracy quickly, with just one-tenth of training data.|sl:tag|tag:labeled_data
Afrique de l'Ouest|skos:broader|Afrique
Bayesian Deep Learning|skos:broader|Bayesian Reasoning
Musique brésilienne|skos:broader|Musique
ML ensemble meta-algorithm designed to improve the stability and accuracy of ML algorithms used in classification and regression (by combining classifications of randomly generated training sets)    Usually applied to decision tree methods, but can be used with any type of method. Special case of the model averaging approach.    Reduces variance, and hence the risk of overtting.    |skos:broader|Methods that use multiple learning algorithms to obtain better predictive performance
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:tag|tag:artificial_human_intelligence
LinkNBed: Multi-Graph Representation Learning with Entity Linkage   a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure     We posit that combining  graph alignment task with deep representation  learning across multi-relational graphs has potential  to induce a synergistic effect on both tasks Knowledge graphs have emerged as an important model for studying complex multi-relational data. This has given rise to the construction of numerous large scale but incomplete knowledge graphs encoding information extracted from various resources. An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledge-based inference for many downstream applications. To this end, we propose LinkNBed, a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure. Experiments on link prediction and entity linkage demonstrate substantial improvements over the state-of-the-art relational learning approaches.|sl:arxiv_author|Jun Ma
Présidentielles 2012|skos:broader|Politique française
Norilsk|skos:broader|Russie
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:arxiv_author|Mirella Lapata
Jiroft|skos:broader|Âge du bronze
Thérapie génique|skos:broader|Médecine
Knowledge Graph Embeddings and Explainable AI survey of     - the state-of-the-art in the field of knowledge graph embeddings  - methods for explaining predictions obtained via knowledge graph embeddings. Knowledge graph embeddings are now a widely adopted approach to knowledge representation in which entities and relationships are embedded in vector spaces. In this chapter, we introduce the reader to the concept of knowledge graph embeddings by explaining what they are, how they can be generated and how they can be evaluated. We summarize the state-of-the-art in this field by describing the approaches that have been introduced to represent knowledge in the vector space. In relation to knowledge representation, we consider the problem of explainability, and discuss models and methods for explaining predictions obtained via knowledge graph embeddings.|sl:tag|tag:good
Neural Ranking Models with Weak Supervision Main Idea: To leverage large amounts of unsupervised data to infer “weak” labels and use that signal for learning supervised models as if we had the ground truth labels. See [blog post](/doc/?uri=http%3A%2F%2Fmostafadehghani.com%2F2017%2F04%2F23%2Fbeating-the-teacher-neural-ranking-models-with-weak-supervision%2F):     This is truly awesome since we have only used  BM25 as the supervisor to train a model which performs better than BM25 itself!   Despite the impressive improvements achieved by unsupervised deep neural networks in computer vision and NLP tasks, such improvements have not yet been observed in ranking for information retrieval. The reason may be the complexity of the ranking problem, as it is not obvious how to learn from queries and documents when no supervised signal is available. Hence, in this paper, we propose to train a neural ranking model using weak supervision, where labels are obtained automatically without human annotators or any external resources (e.g., click data). To this aim, we use the output of an unsupervised ranking model, such as BM25, as a weak supervision signal. We further train a set of simple yet effective ranking models based on feed-forward neural networks. We study their effectiveness under various learning scenarios (point-wise and pair-wise models) and using different input representations (i.e., from encoding query-document pairs into dense/sparse vectors to using word embedding representation). We train our networks using tens of millions of training instances and evaluate it on two standard collections: a homogeneous news collection(Robust) and a heterogeneous large-scale web collection (ClueWeb). Our experiments indicate that employing proper objective functions and letting the networks to learn the input representation based on weakly supervised data leads to impressive performance, with over 13% and 35% MAP improvements over the BM25 model on the Robust and the ClueWeb collections. Our findings also suggest that supervised neural ranking models can greatly benefit from pre-training on large amounts of weakly labeled data that can be easily obtained from unsupervised IR models.|sl:tag|tag:weak_supervision
Retrofitting Word Vectors to Semantic Lexicons Method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed.     Graph-based learning technique for using lexical relational resources to obtain higher quality semantic vectors, which we call “retrofitting.” Retrofitting is applied as a post-processing step by running belief propagation on a graph constructed from lexicon-derived relational information to update word vectors. This allows retrofitting to be used on pre-trained word vectors obtained using any vector training model.    [github](https://github.com/mfaruqui/retrofitting)     Vector space word representations are learned from distributional information of words in large corpora. Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database. This paper proposes a method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed. Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, we obtain substantial improvements starting with a variety of word vector models. Our refinement method outperforms prior techniques for incorporating semantic lexicons into the word vector training algorithms.|sl:arxiv_author|Chris Dyer
Ian Goodfellow|skos:broader|AI girls and guys
Tiers-Monde|skos:broader|Grands problèmes
Retrofitting Word Vectors to Semantic Lexicons Method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed.     Graph-based learning technique for using lexical relational resources to obtain higher quality semantic vectors, which we call “retrofitting.” Retrofitting is applied as a post-processing step by running belief propagation on a graph constructed from lexicon-derived relational information to update word vectors. This allows retrofitting to be used on pre-trained word vectors obtained using any vector training model.    [github](https://github.com/mfaruqui/retrofitting)     Vector space word representations are learned from distributional information of words in large corpora. Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database. This paper proposes a method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed. Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, we obtain substantial improvements starting with a variety of word vector models. Our refinement method outperforms prior techniques for incorporating semantic lexicons into the word vector training algorithms.|sl:arxiv_firstAuthor|Manaal Faruqui
Yandex|skos:broader|Search Engines
Constraint Programming|skos:broader|Artificial Intelligence
Conquête spatiale|skos:broader|Espace
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:arxiv_author|Michael Smith
Sida|skos:broader|Maladie
Representation learning for very short texts using weighted word embedding aggregation A method based on word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. a href=https://github.com/cedricdeboom/RepresentationLearningGithub/a (hmm...) (python code)     Short text messages such as tweets are very noisy and sparse in their use of vocabulary. Traditional textual representations, such as tf-idf, have difficulty grasping the semantic meaning of such texts, which is important in applications such as event detection, opinion mining, news recommendation, etc. We constructed a method based on semantic word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. For this purpose we designed a weight-based model and a learning procedure based on a novel median-based loss function. This paper discusses the details of our model and the optimization methods, together with the experimental results on both Wikipedia and Twitter data. We find that our method outperforms the baseline approaches in the experiments, and that it generalizes well on different word embeddings without retraining. Our method is therefore capable of retaining most of the semantic information in the text, and is applicable out-of-the-box.|sl:tag|tag:nlp_short_texts
One-Shot Generalization|skos:broader|ML
Alexandria Ocasio-Cortez|skos:broader|Homme politique
Efficient Contextual Representation Learning Without Softmax Layer how to accelerate contextual representation learning.     Contextual representation models are difficult to train due to the large parameter sizes and high computational complexity     We find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size.  Therefore, we redesign the learning objectiv.   Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings.  Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary.  When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.    decouples learning contexts and words     Instead of using  a softmax layer to predict the distribution of the  missing word, we utilize and extend the SEMFIT  layer (Kumar and Tsvetkov, 2018) to predict the  embedding of the missing word. Contextual representation models have achieved great success in improving various downstream tasks. However, these language-model-based encoders are difficult to train due to the large parameter sizes and high computational complexity. By carefully examining the training procedure, we find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size. Therefore, we redesign the learning objective and propose an efficient framework for training contextual representation models. Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings. Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary. When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.|sl:tag|tag:contextualised_word_representations
for instance in image recognition using siamese networks, triplet loss function tries to maximize the distance between anchor image and negative image while minimizing the distance between anchor image and positive image, thereby learning to differentiate similar images to non similar ones|skos:broader|Introduced in the early 1990s by Bromley and LeCun to solve signature verification as an image matching problem
Jena User Conference|skos:broader|Semantic Web conferences
supervised learning models used for classification and regression analysis.    An SVM model is a representation of the training examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible.    Non-probabilistic binary linear classifier (some methods exist to use SVM in a probabilistic classification setting). Can be made non-linear with the kernel trick (implicitly mapping the inputs into high-dimensional feature spaces.)        |skos:broader|the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations whose category membership is known.
FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence [github](https://github.com/google-research/fixmatch)     we demonstrate the power of a  simple combination of two common Semi-Supervised Learning methods: consistency  regularization and pseudo-labeling.    1. First generates pseudo-labels using the model’s  predictions on weakly-augmented unlabeled images. For a  given image, the pseudo-label is only retained if the model  produces a high-confidence prediction.   2. The model is then  trained to predict the pseudo-label when fed a strongly augmented  version of the same image. Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. In this paper, we demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling. Our algorithm, FixMatch, first generates pseudo-labels using the model's predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just 4 labels per class. Since FixMatch bears many similarities to existing SSL methods that achieve worse performance, we carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. We make our code available at https://github.com/google-research/fixmatch.|sl:arxiv_author|Alex Kurakin
Traversing Knowledge Graphs in Vector Space Knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new \compositional\ training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. Path queries on a knowledge graph can be used to answer compositional questions such as What languages are spoken by people living in Lisbon?. However, knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new compositional training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. On a standard knowledge base completion task, we also demonstrate that compositional training acts as a novel form of structural regularization, reliably improving performance across all base models (reducing errors by up to 43%) and achieving new state-of-the-art results.|sl:tag|tag:knowledge_graph
Distilling Structured Knowledge into Embeddings for Explainable and Accurate Recommendation distilling structured knowledge from a differentiable path-based recommendation model.     proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons Recently, the embedding-based recommendation models (e.g., matrix factorization and deep models) have been prevalent in both academia and industry due to their effectiveness and flexibility. However, they also have such intrinsic limitations as lacking explainability and suffering from data sparsity. In this paper, we propose an end-to-end joint learning framework to get around these limitations without introducing any extra overhead by distilling structured knowledge from a differentiable path-based recommendation model. Through extensive experiments, we show that our proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons.|sl:arxiv_author|Yan Zhang
Wikilinks Corpus|skos:broader|Big Data
Personal assistant|skos:broader|Human-AI collaboration
Loi sur les oeuvres indisponibles|skos:broader|Propriété intellectuelle
Transfer Learning for Sequence Labeling Using Source Model and Target Data use-case ex: NER when the target data contains new categories In this paper, we propose an approach for transferring the knowledge of a neural model for sequence labeling, learned from the source domain, to a new model trained on a target domain, where new label categories appear. Our transfer learning (TL) techniques enable to adapt the source model using the target data and new categories, without accessing to the source data. Our solution consists in adding new neurons in the output layer of the target model and transferring parameters from the source model, which are then fine-tuned with the target data. Additionally, we propose a neural adapter to learn the difference between the source and the target label distribution, which provides additional important information to the target model. Our experiments on Named Entity Recognition show that (i) the learned knowledge in the source model can be effectively transferred when the target data contains new categories and (ii) our neural adapter further improves such transfer.|sl:arxiv_firstAuthor|Lingzhen Chen
Japon|skos:broader|Asie
Richesses sous-marines|skos:broader|Océan
URL|skos:broader|URI
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).|sl:arxiv_author|Kristina Toutanova
Pensée|skos:broader|Brain
Unsupervised Transfer Learning for Spoken Language Understanding in Intelligent Agents  We apply ELMo, ULMFiT (unsupervised transfer) with supervised transfer to reduce labeled data required for launching domains in Alexa by 10-15x User interaction with voice-powered agents generates large amounts of unlabeled utterances. In this paper, we explore techniques to efficiently transfer the knowledge from these unlabeled utterances to improve model performance on Spoken Language Understanding (SLU) tasks. We use Embeddings from Language Model (ELMo) to take advantage of unlabeled data by learning contextualized word representations. Additionally, we propose ELMo-Light (ELMoL), a faster and simpler unsupervised pre-training method for SLU. Our findings suggest unsupervised pre-training on a large corpora of unlabeled utterances leads to significantly better SLU performance compared to training from scratch and it can even outperform conventional supervised transfer. Additionally, we show that the gains from unsupervised transfer techniques can be further improved by supervised transfer. The improvements are more pronounced in low resource settings and when using only 1000 labeled in-domain samples, our techniques match the performance of training from scratch on 10-15x more labeled in-domain data.|sl:tag|tag:arxiv_doc
Enterprise System|skos:broader|Information System
Nietzsche|skos:broader|Philosophe
Pollution des océans|skos:broader|Pollution
Yagán|skos:broader|Terre de Feu
Biotech industry|skos:broader|Entreprise
httpRange-14|skos:broader|HTTP
Mai 68|skos:broader|France
Manu Dibango|skos:broader|I like I like
InceptionTime: Finding AlexNet for Time Series Classification Time series classification (TSC) is the area of machine learning interested in learning how to assign labels to time series. The last few decades of work in this area have led to significant progress in the accuracy of classifiers, with the state of the art now represented by the HIVE-COTE algorithm. While extremely accurate, HIVE-COTE is infeasible to use in many applications because of its very high training time complexity in O(N^2T^4) for a dataset with N time series of length T. For example, it takes HIVE-COTE more than 72,000s to learn from a small dataset with N=700 time series of short length T=46. Deep learning, on the other hand, has now received enormous attention because of its high scalability and state-of-the-art accuracy in computer vision and natural language processing tasks. Deep learning for TSC has only very recently started to be explored, with the first few architectures developed over the last 3 years only. The accuracy of deep learning for TSC has been raised to a competitive level, but has not quite reached the level of HIVE-COTE. This is what this paper achieves: outperforming HIVE-COTE's accuracy together with scalability. We take an important step towards finding the AlexNet network for TSC by presenting InceptionTime---an ensemble of deep Convolutional Neural Network (CNN) models, inspired by the Inception-v4 architecture. Our experiments show that InceptionTime slightly outperforms HIVE-COTE with a win/draw/loss on the UCR archive of 40/6/39. Not only is InceptionTime more accurate, but it is much faster: InceptionTime learns from that same dataset with 700 time series in 2,300s but can also learn from a dataset with 8M time series in 13 hours, a quantity of data that is fully out of reach of HIVE-COTE.|sl:arxiv_author|Germain Forestier
AutoML-Zero: Evolving Machine Learning Algorithms From Scratch  Fun AutoML-Zero experiments: Evolutionary search discovers fundamental ML algorithms from scratch, e.g., small neural nets with backprop.   Can evolution be the “Master Algorithm”? ;) Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.|sl:tag|tag:evolutionary_algorithm
Hongrie|skos:broader|Pays d'Europe
Knowledge Extraction|skos:broader|Artificial Intelligence
The Description Length of Deep Learning Models  Solomonoff’s general theory of inference (Solomonoff, 1964) and the [Minimum Description Length Principle](tag:minimum_description_length_principle) (Grünwald, 2007; Rissanen, 2007) formalize [Occam's razor](tag:occam_s_razor), and hold that a good model of data is a model that is good at losslessly  compressing the data, including the cost of describing the model itself. Deep neural  networks might seem to go against this principle given the large number of  parameters to be encoded.  We demonstrate experimentally the ability of deep neural networks to compress  the training data even when accounting for parameter encoding. Solomonoff's general theory of inference and the Minimum Description Length principle formalize Occam's razor, and hold that a good model of data is a model that is good at losslessly compressing the data, including the cost of describing the model itself. Deep neural networks might seem to go against this principle given the large number of parameters to be encoded. We demonstrate experimentally the ability of deep neural networks to compress the training data even when accounting for parameter encoding. The compression viewpoint originally motivated the use of variational methods in neural networks. Unexpectedly, we found that these variational methods provide surprisingly poor compression bounds, despite being explicitly built to minimize such bounds. This might explain the relatively poor practical performance of variational methods in deep learning. On the other hand, simple incremental encoding methods yield excellent compression values on deep networks, vindicating Solomonoff's approach.|sl:arxiv_firstAuthor|Léonard Blier
Knowledge Enhanced Contextual Word Representations General method to embed multiple knowledge bases into pre-trained language models (KB in the   sense as fixed collection of entity nodes)     The key idea is to explicitly model  entity spans in the input text and use an entity  linker to retrieve relevant entity embeddings from  a KB to form knowledge enhanced entity-span  representations.   Then,  update contextual word representations via a form of word-to-entity attention.    In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert's runtime is comparable to BERT's and it scales to large KBs.|sl:tag|tag:kd_mkb_biblio
General Motors|skos:broader|Automobile
Subword Semantic Hashing for Intent Classification on Small Datasets In this paper, we introduce the use of Semantic Hashing as embedding for the task of Intent Classification and achieve state-of-the-art performance on three frequently used benchmarks. Intent Classification on a small dataset is a challenging task for data-hungry state-of-the-art Deep Learning based systems. Semantic Hashing is an attempt to overcome such a challenge and learn robust text classification. Current word embedding based are dependent on vocabularies. One of the major drawbacks of such methods is out-of-vocabulary terms, especially when having small training datasets and using a wider vocabulary. This is the case in Intent Classification for chatbots, where typically small datasets are extracted from internet communication. Two problems arise by the use of internet communication. First, such datasets miss a lot of terms in the vocabulary to use word embeddings efficiently. Second, users frequently make spelling errors. Typically, the models for intent classification are not trained with spelling errors and it is difficult to think about ways in which users will make mistakes. Models depending on a word vocabulary will always face such issues. An ideal classifier should handle spelling errors inherently. With Semantic Hashing, we overcome these challenges and achieve state-of-the-art results on three datasets: AskUbuntu, Chatbot, and Web Application. Our benchmarks are available online: https://github.com/kumar-shridhar/Know-Your-Intent|sl:tag|tag:arxiv_doc
AQMI|skos:broader|Al-Qaida
Françafrique|skos:broader|Afrique
Semantic Web: CRM|skos:broader|CRM
Ouganda|skos:broader|Afrique
Natural Language Processing|skos:broader|IA AI
Automating the search for a patent's prior art with a full text similarity search [github](https://github.com/helmersl/patent_similarity_search)    mouais     More than ever, technical inventions are the symbol of our society's advance. Patents guarantee their creators protection against infringement. For an invention being patentable, its novelty and inventiveness have to be assessed. Therefore, a search for published work that describes similar inventions to a given patent application needs to be performed. Currently, this so-called search for prior art is executed with semi-automatically composed keyword queries, which is not only time consuming, but also prone to errors. In particular, errors may systematically arise by the fact that different keywords for the same technical concepts may exist across disciplines. In this paper, a novel approach is proposed, where the full text of a given patent application is compared to existing patents using machine learning and natural language processing techniques to automatically detect inventions that are similar to the one described in the submitted document. Various state-of-the-art approaches for feature extraction and document comparison are evaluated. In addition to that, the quality of the current search process is assessed based on ratings of a domain expert. The evaluation results show that our automated approach, besides accelerating the search process, also improves the search results for prior art with respect to their quality.|sl:tag|tag:arxiv_doc
MyFaces|skos:broader|Java Server Faces
Howto|skos:broader|Dev
Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs [GitHub](https://github.com/deepakn97/relationPrediction) [Blog post](/doc/2020/04/deepak_nathani_%7C_pay_attention_) The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention based feature embedding that captures both entity and relation features in any given entity's neighborhood. Additionally, we also encapsulate relation clusters and multihop relations in our model. Our empirical study offers insights into the efficacy of our attention based model and we show marked performance gains in comparison to state of the art methods on all datasets.|sl:arxiv_author|Deepak Nathani
Bigtable|skos:broader|Google
Knowledge Graph KG|skos:broader|Knowledge Base
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:tag|tag:microsoft_research
Singular value decomposition|skos:broader|Dimensionality reduction
HBase|skos:broader|NOSQL
booking.com|skos:broader|Hôtel
Technical girls and guys|skos:broader|Technologie
Belzoni|skos:broader|Archéologue
New York Times|skos:broader|Presse
Graph visualization|skos:broader|Visualization Tools
Document Embedding with Paragraph Vectors Paragraph Vectors has been recently proposed as an unsupervised method for learning distributed representations for pieces of texts. In their work, the authors showed that the method can learn an embedding of movie review texts which can be leveraged for sentiment analysis. That proof of concept, while encouraging, was rather narrow. Here we consider tasks other than sentiment analysis, provide a more thorough comparison of Paragraph Vectors to other document modelling algorithms such as Latent Dirichlet Allocation, and evaluate performance of the method as we vary the dimensionality of the learned representation. We benchmarked the models on two document similarity data sets, one from Wikipedia, one from arXiv. We observe that the Paragraph Vector method performs significantly better than other methods, and propose a simple improvement to enhance embedding quality. Somewhat surprisingly, we also show that much like word embeddings, vector operations on Paragraph Vectors can perform useful semantic results.|sl:arxiv_firstAuthor|Andrew M. Dai
HTML Editor|skos:broader|HTML
Internet en Afrique|skos:broader|NTIC et développement
Revisiting Semi-Supervised Learning with Graph Embeddings We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.|sl:tag|tag:semi_supervised_learning
Automating the search for a patent's prior art with a full text similarity search [github](https://github.com/helmersl/patent_similarity_search)    mouais     More than ever, technical inventions are the symbol of our society's advance. Patents guarantee their creators protection against infringement. For an invention being patentable, its novelty and inventiveness have to be assessed. Therefore, a search for published work that describes similar inventions to a given patent application needs to be performed. Currently, this so-called search for prior art is executed with semi-automatically composed keyword queries, which is not only time consuming, but also prone to errors. In particular, errors may systematically arise by the fact that different keywords for the same technical concepts may exist across disciplines. In this paper, a novel approach is proposed, where the full text of a given patent application is compared to existing patents using machine learning and natural language processing techniques to automatically detect inventions that are similar to the one described in the submitted document. Various state-of-the-art approaches for feature extraction and document comparison are evaluated. In addition to that, the quality of the current search process is assessed based on ratings of a domain expert. The evaluation results show that our automated approach, besides accelerating the search process, also improves the search results for prior art with respect to their quality.|sl:arxiv_author|Tim Oppermann
Topic Modeling|skos:broader|NLP tasks / problems
Elda|skos:broader|Linked Data API
NG4J|skos:broader|Jena
Concept linking Concept extraction|skos:broader|Topic extraction Keyword extraction Keyphrase extraction
AI, robots and jobs|skos:broader|Travail
An Introduction to Conditional Random Fields Often we wish to predict a large number of variables that depend on each other as well as on other observed variables. Structured prediction methods are essentially a combination of classification and graphical modeling, combining the ability of graphical models to compactly model multivariate data with the ability of classification methods to perform prediction using large sets of input features. This tutorial describes conditional random fields, a popular probabilistic method for structured prediction. CRFs have seen wide application in natural language processing, computer vision, and bioinformatics. We describe methods for inference and parameter estimation for CRFs, including practical issues for implementing large scale CRFs. We do not assume previous knowledge of graphical modeling, so this tutorial is intended to be useful to practitioners in a wide variety of fields.|sl:arxiv_author|Andrew McCallum
Lac de lave|skos:broader|Volcan
Portugal|skos:broader|Europe
End-To-End Memory Networks Neural network with a recurrent attention model over a possibly large external memory.    cité par [#A. Bordes](/tag/antoine_bordes) à [#ParisIsAI conf 2018](/tag/france_is_ai_2018.html) We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network (Weston et al., 2015) but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.|sl:tag|tag:nlp_facebook
ML as a service|skos:broader|Machine learning
Hannibal|skos:broader|Guerres puniques
Bhaskar Mitra|skos:broader|NLP girls and guys
Memory networks|skos:broader|Memory in deep learning
First introduced by vivisimo (bought by IBM in 2012 - \Now, Vivisimo Velocity Platform is IBM Watson Explorer\)|skos:broader|cluster analysis which seeks to build a hierarchy of clusters.    2 kinds:    - Agglomerative  - Divisive
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:tag|tag:ml_google
Désert|skos:broader|Géographie
KGAT: Knowledge Graph Attention Network for Recommendation To provide more accurate, diverse, and explainable recommendation, it is compulsory to go beyond modeling user-item interactions and take side information into account. Traditional methods like factorization machine (FM) cast it as a supervised learning problem, which assumes each interaction as an independent instance with side information encoded. Due to the overlook of the relations among instances or items (e.g., the director of a movie is also an actor of another movie), these methods are insufficient to distill the collaborative signal from the collective behaviors of users. In this work, we investigate the utility of knowledge graph (KG), which breaks down the independent interaction assumption by linking items with their attributes. We argue that in such a hybrid structure of KG and user-item graph, high-order relations --- which connect two items with one or multiple linked attributes --- are an essential factor for successful recommendation. We propose a new method named Knowledge Graph Attention Network (KGAT) which explicitly models the high-order connectivities in KG in an end-to-end fashion. It recursively propagates the embeddings from a node's neighbors (which can be users, items, or attributes) to refine the node's embedding, and employs an attention mechanism to discriminate the importance of the neighbors. Our KGAT is conceptually advantageous to existing KG-based recommendation methods, which either exploit high-order relations by extracting paths or implicitly modeling them with regularization. Empirical results on three public benchmarks show that KGAT significantly outperforms state-of-the-art methods like Neural FM and RippleNet. Further studies verify the efficacy of embedding propagation for high-order relation modeling and the interpretability benefits brought by the attention mechanism.|sl:arxiv_firstAuthor|Xiang Wang
foaf+ssl|skos:broader|SSL
Déclin de l'Europe|skos:broader|Europe
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:tag|tag:computational_neuroscience
Robots and society Jobbotization|skos:broader|IA AI
Cryptography|skos:broader|Cryptage
\Why Should I Trust You?\: Explaining the Predictions of Any Classifier technique that explains the predictions of any classifier by learning an interpretable model locally around the prediction Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.|sl:tag|tag:lime
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Adam Santoro
Text Similarity|skos:broader|NLP tasks / problems
Concept Extraction / Linking|skos:broader|NLP tasks / problems
Ruslan Salakhutdinov|skos:broader|AI girls and guys
Machine learning|skos:broader|Artificial Intelligence
A single decision tree is a highly non-linear classifier with typically low bias but high variance. Random forests address the problem of high variance by establishing a committee (i.e. average) of identically distributed single decision trees.|skos:broader|Methods that use multiple learning algorithms to obtain better predictive performance
Mur de Berlin|skos:broader|Allemagne
Validation: XML vs RDF|skos:broader|Validator
KG-BERT: BERT for Knowledge Graph Completion Pre-trained language models for knowledge graph completion. Triples are treated as textual sequences. (Hum, j'ai déjà vu ça quelque part) Knowledge graphs are important resources for many artificial intelligence tasks but often suffer from incompleteness. In this work, we propose to use pre-trained language models for knowledge graph completion. We treat triples in knowledge graphs as textual sequences and propose a novel framework named Knowledge Graph Bidirectional Encoder Representations from Transformer (KG-BERT) to model these triples. Our method takes entity and relation descriptions of a triple as input and computes scoring function of the triple with the KG-BERT language model. Experimental results on multiple benchmark knowledge graphs show that our method can achieve state-of-the-art performance in triple classification, link prediction and relation prediction tasks.|sl:tag|tag:attention_is_all_you_need
Natural Language Processing with Small Feed-Forward Networks google guys:      We show that small and shallow feed- forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.   We show that small and shallow feed-forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.|sl:arxiv_author|Jan A. Botha
Design Challenges and Misconceptions in Neural Sequence Labeling design challenges of constructing effective and efficient neural sequence labeling systems We investigate the design challenges of constructing effective and efficient neural sequence labeling systems, by reproducing twelve neural sequence labeling models, which include most of the state-of-the-art structures, and conduct a systematic model comparison on three benchmarks (i.e. NER, Chunking, and POS tagging). Misconceptions and inconsistent conclusions in existing literature are examined and clarified under statistical experiments. In the comparison and analysis process, we reach several practical conclusions which can be useful to practitioners.|sl:arxiv_firstAuthor|Jie Yang
Graph database and NLP|skos:broader|Knowledge Representation
Taxe carbone|skos:broader|Climate crisis
Peter Bloem|skos:broader|NLP girls and guys
Pre-Trained Language Models|skos:broader|Deep NLP
NLP datasets|skos:broader|NLP tools
Deep learning: implementing|skos:broader|Deep Learning
A practical tutorial on autoencoders for nonlinear feature fusion: Taxonomy, models, software and guidelines Many of the existing machine learning algorithms, both supervised and unsupervised, depend on the quality of the input characteristics to generate a good model. The amount of these variables is also important, since performance tends to decline as the input dimensionality increases, hence the interest in using feature fusion techniques, able to produce feature sets that are more compact and higher level. A plethora of procedures to fuse original variables for producing new ones has been developed in the past decades. The most basic ones use linear combinations of the original variables, such as PCA (Principal Component Analysis) and LDA (Linear Discriminant Analysis), while others find manifold embeddings of lower dimensionality based on non-linear combinations, such as Isomap or LLE (Linear Locally Embedding) techniques. More recently, autoencoders (AEs) have emerged as an alternative to manifold learning for conducting nonlinear feature fusion. Dozens of AE models have been proposed lately, each with its own specific traits. Although many of them can be used to generate reduced feature sets through the fusion of the original ones, there also AEs designed with other applications in mind. The goal of this paper is to provide the reader with a broad view of what an AE is, how they are used for feature fusion, a taxonomy gathering a broad range of models, and how they relate to other classical techniques. In addition, a set of didactic guidelines on how to choose the proper AE for a given task is supplied, together with a discussion of the software tools available. Finally, two case studies illustrate the usage of AEs with datasets of handwritten digits and breast cancer.|sl:tag|tag:autoencoder
Maladie|skos:broader|Santé
Personnage historique|skos:broader|Histoire
Distilling Structured Knowledge into Embeddings for Explainable and Accurate Recommendation distilling structured knowledge from a differentiable path-based recommendation model.     proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons Recently, the embedding-based recommendation models (e.g., matrix factorization and deep models) have been prevalent in both academia and industry due to their effectiveness and flexibility. However, they also have such intrinsic limitations as lacking explainability and suffering from data sparsity. In this paper, we propose an end-to-end joint learning framework to get around these limitations without introducing any extra overhead by distilling structured knowledge from a differentiable path-based recommendation model. Through extensive experiments, we show that our proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons.|sl:tag|tag:ai_facebook
Stanford NER|skos:broader|Named Entity Recognition
Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks Current machine learning systems operate, almost exclusively, in a statistical, or model-free mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks. To demonstrate the essential role of such models, I will present a summary of seven tasks which are beyond reach of current machine learning systems and which have been accomplished using the tools of causal modeling.|sl:arxiv_author|Judea Pearl
Musubi|skos:broader|Téléphone
Hugo|skos:broader|Grand Homme
RDF and SOA|skos:broader|SOA
Conquistadores|skos:broader|Histoire
RDFLib|skos:broader|Python
2D-NLP|skos:broader|Information extraction
React.js|skos:broader|JavaScript librairies
Jena|skos:broader|Semantic Web Dev
Orri Erling|skos:broader|SW guys (and girls)
Hervé Kempf|skos:broader|Journal Le Monde
Fake Blogs|skos:broader|Blog
SW guys (and girls)|skos:broader|Semantic Web
Cons de Français|skos:broader|France
A Primer in BERTology: What we know about how BERT works (article praised on [twitter](https://twitter.com/dennybritz/status/1233343170596917248?s=20) by D Britz and Y. Goldberg) Transformer-based models are now widely used in NLP, but we still do not understand a lot about their inner workings. This paper describes what is known to date about the famous BERT model (Devlin et al. 2019), synthesizing over 40 analysis studies. We also provide an overview of the proposed modifications to the model and its training regime. We then outline the directions for further research.|sl:arxiv_author|Anna Rogers
Ciao Vito|skos:broader|Portland (OR)
Henry Story|skos:broader|Technical girls and guys
Fact-checking|skos:broader|Vérité
Hierarchical Memory Networks  hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory Memory networks are neural networks with an explicit memory component that can be both read and written to by the network. The memory is often addressed in a soft way using a softmax function, making end-to-end training with backpropagation possible. However, this is not computationally scalable for applications which require the network to read from extremely large memories. On the other hand, it is well known that hard attention mechanisms based on reinforcement learning are challenging to train successfully. In this paper, we explore a form of hierarchical memory network, which can be considered as a hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory. Specifically, we propose to incorporate Maximum Inner Product Search (MIPS) in the training and inference procedures for our hierarchical memory network. We explore the use of various state-of-the art approximate MIPS techniques and report results on SimpleQuestions, a challenging large scale factoid question answering task.|sl:arxiv_author|Sarath Chandar
k-means clustering|skos:broader|Data mining
Coursera: The Data Scientist’s Toolbox|skos:broader|Coursera
Une suite de matrices symétriques en rapport avec la fonction de Mertens  we explore a class of equivalence relations over N from which is constructed a sequence of symetric matrices related to the Mertens function. From numerical experimentations we suggest a conjecture, about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may play a more important part in this classical and difficult problem. In this paper we explore a class of equivalence relations over $\\N^\\ast$ from which is constructed a sequence of symetric matrices related to the Mertens function. From numerical experimentations we suggest a conjecture, about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may play a more important part in this classical and difficult problem.|sl:tag|tag:arxiv_doc
Advances in Pre-Training Distributed Word Representations  we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks Many Natural Language Processing applications nowadays rely on pre-trained word representations estimated from large text corpora such as news collections, Wikipedia and Web Crawl. In this paper, we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks.|sl:tag|tag:tomas_mikolov
African art|skos:broader|Africa
Shoah|skos:broader|Nazisme
NIPS 2017|skos:broader|Deep Learning
Industrie du disque|skos:broader|Musique
Scalable Nearest Neighbor Search for Optimal Transport The Optimal Transport (a.k.a. Wasserstein) distance is an increasingly popular similarity measure for rich data domains, such as images or text documents. This raises the necessity for fast nearest neighbor search with respect to this distance, a problem that poses a substantial computational bottleneck for various tasks on massive datasets. In this work, we study fast tree-based approximation algorithms for searching nearest neighbors w.r.t. the Wasserstein-1 distance. A standard tree-based technique, known as Quadtree, has been previously shown to obtain good results. We introduce a variant of this algorithm, called Flowtree, and formally prove it achieves asymptotically better accuracy. Our extensive experiments, on real-world text and image datasets, show that Flowtree improves over various baselines and existing methods in either running time or accuracy. In particular, its quality of approximation is in line with previous high-accuracy methods, while its running time is much faster.|sl:tag|tag:word_mover_s_distance
SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver Integrating logical reasoning within deep learning architectures has been a major goal of modern AI systems. In this paper, we propose a new direction toward this goal by introducing a differentiable (smoothed) maximum satisfiability (MAXSAT) solver that can be integrated into the loop of larger deep learning systems. Our (approximate) solver is based upon a fast coordinate descent approach to solving the semidefinite program (SDP) associated with the MAXSAT problem. We show how to analytically differentiate through the solution to this SDP and efficiently solve the associated backward pass. We demonstrate that by integrating this solver into end-to-end learning systems, we can learn the logical structure of challenging problems in a minimally supervised fashion. In particular, we show that we can learn the parity function using single-bit supervision (a traditionally hard task for deep networks) and learn how to play 9x9 Sudoku solely from examples. We also solve a visual Sudok problem that maps images of Sudoku puzzles to their associated logical solutions by combining our MAXSAT solver with a traditional convolutional architecture. Our approach thus shows promise in integrating logical structures within deep learning.|sl:arxiv_author|Bryan Wilder
One-Shot Generalization in Deep Generative Models Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our models are able to generate compelling and diverse samples---having seen new examples just once---providing an important class of general-purpose models for one-shot machine learning.|sl:arxiv_author|Karol Gregor
Pharaon|skos:broader|Egypte antique
RDFLib|skos:broader|RDF Tools
Enseignement supérieur|skos:broader|Education
Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.|sl:arxiv_author|Quoc V. Le
Encoding Categorical Variables with Conjugate Bayesian Models for WeWork Lead Scoring Engine  To encode high-cardinality categorical variables, we introduce a technique based on traditional Bayesian statistics. This technique is a paradigm for ensemble modeling, specifically stacking, where the base learner consists of a problem- specific conjugate Bayesian model (CBM)   Applied Data Scientists throughout various industries are commonly faced with the challenging task of encoding high-cardinality categorical features into digestible inputs for machine learning algorithms. This paper describes a Bayesian encoding technique developed for WeWork's lead scoring engine which outputs the probability of a person touring one of our office spaces based on interaction, enrichment, and geospatial data. We present a paradigm for ensemble modeling which mitigates the need to build complicated preprocessing and encoding schemes for categorical variables. In particular, domain-specific conjugate Bayesian models are employed as base learners for features in a stacked ensemble model. For each column of a categorical feature matrix we fit a problem-specific prior distribution, for example, the Beta distribution for a binary classification problem. In order to analytically derive the moments of the posterior distribution, we update the prior with the conjugate likelihood of the corresponding target variable for each unique value of the given categorical feature. This function of column and value encodes the categorical feature matrix so that the final learner in the ensemble model ingests low-dimensional numerical input. Experimental results on both curated and real world datasets demonstrate impressive accuracy and computational efficiency on a variety of problem archetypes. Particularly, for the lead scoring engine at WeWork -- where some categorical features have as many as 300,000 levels -- we have seen an AUC improvement from 0.87 to 0.97 through implementing conjugate Bayesian model encoding.|sl:arxiv_author|Yoni Schamroth
RDFa|skos:broader|XHTML
Java|skos:broader|Dev
Information retrieval|skos:broader|Informatique
Ecole Montessori|skos:broader|Ecole
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Razvan Pascanu
Histoire de France|skos:broader|Histoire
A Primer on Neural Network Models for Natural Language Processing Over the past few years, neural networks have re-emerged as powerful machine-learning models, yielding state-of-the-art results in fields such as image recognition and speech processing. More recently, neural network models started to be applied also to textual natural language signals, again with very promising results. This tutorial surveys neural network models from the perspective of natural language processing research, in an attempt to bring natural-language researchers up to speed with the neural techniques. The tutorial covers input encoding for natural language tasks, feed-forward networks, convolutional networks, recurrent networks and recursive networks, as well as the computation graph abstraction for automatic gradient computation.|sl:tag|tag:nn_4_nlp
Modeling car diversity|skos:broader|Car diversity
Topic Modeling over Short Texts|skos:broader|NLP: short texts
Keras embedding layer|skos:broader|Keras
AutoML-Zero: Evolving Machine Learning Algorithms From Scratch  Fun AutoML-Zero experiments: Evolutionary search discovers fundamental ML algorithms from scratch, e.g., small neural nets with backprop.   Can evolution be the “Master Algorithm”? ;) Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.|sl:arxiv_firstAuthor|Esteban Real
Sequence-To-Sequence Encoder-Decoder Architecture|skos:broader|Sequence-to-sequence learning
A Survey Of Cross-lingual Word Embedding Models Cross-lingual representations of words enable us to reason about word meaning in multilingual contexts and are a key facilitator of cross-lingual transfer when developing natural language processing models for low-resource languages. In this survey, we provide a comprehensive typology of cross-lingual word embedding models. We compare their data requirements and objective functions. The recurring theme of the survey is that many of the models presented in the literature optimize for the same objectives, and that seemingly different models are often equivalent modulo optimization strategies, hyper-parameters, and such. We also discuss the different ways cross-lingual word embeddings are evaluated, as well as future challenges and research horizons.|sl:tag|tag:survey
Variable Selection Methods for Model-based Clustering Model-based clustering is a popular approach for clustering multivariate data which has seen applications in numerous fields. Nowadays, high-dimensional data are more and more common and the model-based clustering approach has adapted to deal with the increasing dimensionality. In particular, the development of variable selection techniques has received a lot of attention and research effort in recent years. Even for small size problems, variable selection has been advocated to facilitate the interpretation of the clustering results. This review provides a summary of the methods developed for variable selection in model-based clustering. Existing R packages implementing the different methods are indicated and illustrated in application to two data analysis examples.|sl:arxiv_author|Thomas Brendan Murphy
Natural Language Processing (almost) from Scratch seminal work    Abstract:     a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements   We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.|sl:tag|tag:arxiv_doc
Lingo|skos:broader|Clustering of text documents
Amazon Mechanical Turk|skos:broader|Artificial, Artificial Intelligence
Variational Inference: A Review for Statisticians One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.|sl:tag|tag:arxiv_doc
Innoraise|skos:broader|RDF and social networks
Pétrole et corruption|skos:broader|Corruption
Bitcoin|skos:broader|Virtual currency
Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.|sl:arxiv_firstAuthor|Zihang Dai
A Tutorial on Network Embeddings Network embedding methods aim at learning low-dimensional latent representation of nodes in a network. These representations can be used as features for a wide range of tasks on graphs such as classification, clustering, link prediction, and visualization. In this survey, we give an overview of network embeddings by summarizing and categorizing recent advancements in this research field. We first discuss the desirable properties of network embeddings and briefly introduce the history of network embedding algorithms. Then, we discuss network embedding methods under different scenarios, such as supervised versus unsupervised learning, learning embeddings for homogeneous networks versus for heterogeneous networks, etc. We further demonstrate the applications of network embeddings, and conclude the survey with future work in this area.|sl:tag|tag:survey
Fabien Gandon|skos:broader|SW guys (and girls)
OWLED 2007 AND fps|skos:broader|OWLED 2007
LOD use case|skos:broader|Linking Open Data
L'Afrique à la Bastille - 13 juillet 2007|skos:broader|Music of Africa
Hong Kong|skos:broader|Chine
Génomique|skos:broader|Genetics Génétique
Client side XSLT|skos:broader|XSLT
Martin Hepp|skos:broader|Technical girls and guys
Société de consommation|skos:broader|Capitalisme
Bag-of-words|skos:broader|NLP techniques
general implementation of (arbitrary order) linear chain Conditional Random Field (CRF) sequence models |skos:broader|sequence labelling tasks where the goal is to identify  the names of entities in a sentence. Named entities can  be proper nouns (locations, people, organizations...), or can be much more  domain-specific, such as diseases or genes in  biomedical NLP.
Transformers|skos:broader|NLP@Google
China's Social Credit System|skos:broader|Chine
A Tutorial on Distance Metric Learning: Mathematical Foundations, Algorithms and Experiments distance metric learning, a branch of machine learning that aims to learn distances from the data Distance metric learning is a branch of machine learning that aims to learn distances from the data. Distance metric learning can be useful to improve similarity learning algorithms, and also has applications in dimensionality reduction. This paper describes the distance metric learning problem and analyzes its main mathematical foundations. In addition, it also discusses some of the most popular distance metric learning techniques used in classification, showing their goals and the required information to understand and use them. Furthermore, some experiments to evaluate the performance of the different algorithms are also provided. Finally, this paper discusses several possibilities of future work in this topic.|sl:tag|tag:tutorial
NN 4 NLP|skos:broader|Neural networks
Efficient Contextual Representation Learning Without Softmax Layer how to accelerate contextual representation learning.     Contextual representation models are difficult to train due to the large parameter sizes and high computational complexity     We find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size.  Therefore, we redesign the learning objectiv.   Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings.  Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary.  When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.    decouples learning contexts and words     Instead of using  a softmax layer to predict the distribution of the  missing word, we utilize and extend the SEMFIT  layer (Kumar and Tsvetkov, 2018) to predict the  embedding of the missing word. Contextual representation models have achieved great success in improving various downstream tasks. However, these language-model-based encoders are difficult to train due to the large parameter sizes and high computational complexity. By carefully examining the training procedure, we find that the softmax layer (the output layer) causes significant inefficiency due to the large vocabulary size. Therefore, we redesign the learning objective and propose an efficient framework for training contextual representation models. Specifically, the proposed approach bypasses the softmax layer by performing language modeling with dimension reduction, and allows the models to leverage pre-trained word embeddings. Our framework reduces the time spent on the output layer to a negligible level, eliminates almost all the trainable parameters of the softmax layer and performs language modeling without truncating the vocabulary. When applied to ELMo, our method achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks.|sl:arxiv_author|Kai-Wei Chang
Hello Edge: Keyword Spotting on Microcontrollers Keyword spotting (KWS) is a critical component for enabling speech based user interactions on smart devices. It requires real-time response and high accuracy for good user experience. Recently, neural networks have become an attractive choice for KWS architecture because of their superior accuracy compared to traditional speech processing algorithms. Due to its always-on nature, KWS application has highly constrained power budget and typically runs on tiny microcontrollers with limited memory and compute capability. The design of neural network architecture for KWS must consider these constraints. In this work, we perform neural network architecture evaluation and exploration for running KWS on resource-constrained microcontrollers. We train various neural network architectures for keyword spotting published in literature to compare their accuracy and memory/compute requirements. We show that it is possible to optimize these neural network architectures to fit within the memory and compute constraints of microcontrollers without sacrificing accuracy. We further explore the depthwise separable convolutional neural network (DS-CNN) and compare it against other neural network architectures. DS-CNN achieves an accuracy of 95.4%, which is ~10% higher than the DNN model with similar number of parameters.|sl:tag|tag:arxiv_doc
Shenzhen|skos:broader|Chine
Wuhan|skos:broader|Chine
k-nearest neighbors algorithm|skos:broader|Machine learning: techniques
Delip Rao|skos:broader|AI girls and guys
Consciousness Prior|skos:broader|Yoshua Bengio
Espèces menacées|skos:broader|Écologie
REST|skos:broader|Informatique
Blog software|skos:broader|Blog
Longformer: The Long-Document Transformer  Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Following prior work on long-sequence transformers, we evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8. In contrast to most prior work, we also pretrain Longformer and finetune it on a variety of downstream tasks. Our pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA.|sl:arxiv_author|Matthew E. Peters
Neutrino|skos:broader|Physique des particules
XSS|skos:broader|Malicious code
TabFact: A Large-scale Dataset for Table-based Fact Verification fact verification given semi-structured data as evidence The problem of verifying whether a textual hypothesis holds based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation. However, existing studies are mainly restricted to dealing with unstructured evidence (e.g., natural language sentences and documents, news, etc), while verification under structured evidence, such as tables, graphs, and databases, remains under-explored. This paper specifically aims to study the fact verification given semi-structured data as evidence. To this end, we construct a large-scale dataset called TabFact with 16k Wikipedia tables as the evidence for 118k human-annotated natural language statements, which are labeled as either ENTAILED or REFUTED. TabFact is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning. To address these reasoning challenges, we design two different models: Table-BERT and Latent Program Algorithm (LPA). Table-BERT leverages the state-of-the-art pre-trained language model to encode the linearized tables and statements into continuous vectors for verification. LPA parses statements into programs and executes them against the tables to obtain the returned binary value for verification. Both methods achieve similar accuracy but still lag far behind human performance. We also perform a comprehensive analysis to demonstrate great future opportunities. The data and code of the dataset are provided in \\url{https://github.com/wenhuchen/Table-Fact-Checking}.|sl:arxiv_author|Wenhu Chen
Coding|skos:broader|Software
Agriculture française|skos:broader|Agriculture
Venus de Brassempouy|skos:broader|Paléolithique
Océanie|skos:broader|Géographie
Sentence Embeddings|skos:broader|Embeddings
Arts premiers|skos:broader|Art
K-BERT: Enabling Language Representation with Knowledge Graph a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by equipped with a KG without pre-training by-self because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts.|sl:arxiv_author|Weijie Liu
Lord of the Flies|skos:broader|L'humanité mérite de disparaître
String-searching algorithm|skos:broader|Algorithmes
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:tag|tag:taxonomy_expansion_task
Pulsar|skos:broader|Astrophysique
Concept Extraction / Linking|skos:broader|Automatic tagging
Grippe aviaire|skos:broader|Maladie
Zinder|skos:broader|Niger
Coursera: A History of the World since 1300|skos:broader|Coursera
End-To-End Memory Networks Neural network with a recurrent attention model over a possibly large external memory.    cité par [#A. Bordes](/tag/antoine_bordes) à [#ParisIsAI conf 2018](/tag/france_is_ai_2018.html) We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network (Weston et al., 2015) but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.|sl:tag|tag:arxiv_doc
ESWC 2008|skos:broader|ESWC
Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.|sl:arxiv_author|Ruslan Salakhutdinov
Montagne|skos:broader|Géographie
Graph-based Text Representations|skos:broader|NLP: Text Representation
Concept Bottleneck Models  We seek to learn models that we can interact with using high-level concepts... We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these concept bottleneck models by editing their predicted concept values and propagating these changes to the final prediction... These models allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time. We seek to learn models that we can interact with using high-level concepts: if the model did not think there was a bone spur in the x-ray, would it still predict severe arthritis? State-of-the-art models today do not typically support the manipulation of concepts like the existence of bone spurs, as they are trained end-to-end to go directly from raw input (e.g., pixels) to output (e.g., arthritis severity). We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these \\emph{concept bottleneck models} by editing their predicted concept values and propagating these changes to the final prediction. On x-ray grading and bird identification, concept bottleneck models achieve competitive accuracy with standard end-to-end models, while enabling interpretation in terms of high-level clinical concepts (bone spurs) or bird attributes (wing color). These models also allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time.|sl:tag|tag:concept_bottleneck_models
Cinéma français|skos:broader|France
End-To-End Memory Networks Neural network with a recurrent attention model over a possibly large external memory.    cité par [#A. Bordes](/tag/antoine_bordes) à [#ParisIsAI conf 2018](/tag/france_is_ai_2018.html) We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network (Weston et al., 2015) but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.|sl:arxiv_author|Rob Fergus
Word embedding: evaluation|skos:broader|Word embeddings
A Review of Relational Machine Learning for Knowledge Graphs Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be trained on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive datasets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Google's Knowledge Vault project as an example of such combination.|sl:tag|tag:arxiv_doc
Danemark|skos:broader|Pays d'Europe
Apple Java|skos:broader|Java
Parc du W|skos:broader|Niger
Mac OS X|skos:broader|Apple Software
FastText|skos:broader|NLP@Facebook
Detecting Potential Topics In News Using BERT, CRF and Wikipedia For a news content distribution platform like Dailyhunt, Named Entity Recognition is a pivotal task for building better user recommendation and notification algorithms. Apart from identifying names, locations, organisations from the news for 13+ Indian languages and use them in algorithms, we also need to identify n-grams which do not necessarily fit in the definition of Named-Entity, yet they are important. For example, me too movement, beef ban, alwar mob lynching. In this exercise, given an English language text, we are trying to detect case-less n-grams which convey important information and can be used as topics and/or hashtags for a news. Model is built using Wikipedia titles data, private English news corpus and BERT-Multilingual pre-trained model, Bi-GRU and CRF architecture. It shows promising results when compared with industry best Flair, Spacy and Stanford-caseless-NER in terms of F1 and especially Recall.|sl:tag|tag:wikipedia
URI Synonymity|skos:broader|Linked Data
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:arxiv_author|Sophia Sanchez
OWL RL|skos:broader|OWL
Semantic Interoperability|skos:broader|Semantic Web
Knowledge-based AI|skos:broader|Artificial Intelligence
Edvige|skos:broader|Sarkozy
CamemBERT|skos:broader|BERT
Voyage en Chine|skos:broader|Chine
Logiciel libre|skos:broader|Informatique
AI + Knowledge Bases|skos:broader|Artificial Intelligence
Espagne|skos:broader|Pays d'Europe
Google Patents|skos:broader|Google
Stanford|skos:broader|Universités américaines
DSSM (Deep Semantic Similarity Model)|skos:broader|Sentence Embeddings
Burningbird Mad Techie Woman|skos:broader|Technical guys
Cybersecurity Sécurité informatique|skos:broader|Sécurité
Lagos|skos:broader|Ville
LOD: Limitations on browseable data|skos:broader|Linked Data
Nick Clegg|skos:broader|Grande-Bretagne
Ecocide|skos:broader|Crime
Keras embedding layer|skos:broader|Embeddings
Mercure (Planète)|skos:broader|Système solaire
Bertrand Sajus|skos:broader|Ministère de la culture
Bernard Stiegler|skos:broader|Philosophe
Shoira Otabekova|skos:broader|Ouzbékistan
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:arxiv_author|Maurice Chiang
Improving Entity Linking by Modeling Latent Entity Type Information Existing state of the art neural entity linking models employ attention-based bag-of-words context model and pre-trained entity embeddings bootstrapped from word embeddings to assess topic level context compatibility. However, the latent entity type information in the immediate context of the mention is neglected, which causes the models often link mentions to incorrect entities with incorrect type. To tackle this problem, we propose to inject latent entity type information into the entity embeddings based on pre-trained BERT. In addition, we integrate a BERT-based entity similarity score into the local context model of a state-of-the-art model to better capture latent entity type information. Our model significantly outperforms the state-of-the-art entity linking models on standard benchmark (AIDA-CoNLL). Detailed experiment analysis demonstrates that our model corrects most of the type errors produced by the direct baseline.|sl:tag|tag:entity_linking
Vive le capitalisme !|skos:broader|Capitalisme
CKAN|skos:broader|Data portal
Drupal/RDF|skos:broader|Semantic CMS
NLP|skos:broader|Artificial Intelligence
Benjamin Nowack|skos:broader|Technical girls and guys
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|Eva Blomqvist
Révolution française|skos:broader|Histoire de France
Afrique francophone|skos:broader|Afrique
Missoula Floods|skos:broader|Catastrophe naturelle
Word embeddings with lexical resources|skos:broader|Sense embeddings
France|skos:broader|Pays d'Europe
Novartis|skos:broader|Industrie pharmaceutique
- Intent classification: predicting the intent of a query  - slot filling extracts semantic concepts in the query (a sequence labeling task that tags the input word sequence).    For example the user query could be “Find me an  action movie by Steven Spielberg”. The intent here is “find_movie” while  the slots are “genre” with value “action” and “directed_by” with value  “Steven Spielberg”.|skos:broader|extracting semantic concepts in a query (a sequence labeling task that tags the input word sequence).
HTML5|skos:broader|HTML
Pedro Almodóvar|skos:broader|Espagne
Metadata indexing|skos:broader|Semantic Web
Specializing Word Embeddings (for Parsing) by Information Bottleneck EMNLP best paper award. [Related blog post](doc:2020/06/information_bottleneck_for_nlp_) Pre-trained word embeddings like ELMo and BERT contain rich syntactic and semantic information, resulting in state-of-the-art performance on various tasks. We propose a very fast variational information bottleneck (VIB) method to nonlinearly compress these embeddings, keeping only the information that helps a discriminative parser. We compress each word embedding to either a discrete tag or a continuous vector. In the discrete version, our automatically compressed tags form an alternative tag set: we show experimentally that our tags capture most of the information in traditional POS tag annotations, but our tag sequences can be parsed more accurately at the same level of tag granularity. In the continuous version, we show experimentally that moderately compressing the word embeddings by our method yields a more accurate parser in 8 of 9 languages, unlike simple dimensionality reduction.|sl:tag|tag:word_embedding
Representing Sentences as Low-Rank Subspaces  We observe a simple geometry of sentences -- the word representations of a given sentence roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors.    A sentence of N words is a matrix (300, N) (if 300 is the dim of the word embeddings space). We take the eg. 4 (hyperparam) heaviest singular values - a subspace with dim 4    Similarity between docs: principal angle between the subspaces (reminiscent of cosine similarity)     Sentences are important semantic units of natural language. A generic, distributional representation of sentences that can capture the latent semantics is beneficial to multiple downstream applications. We observe a simple geometry of sentences -- the word representations of a given sentence (on average 10.23 words in all SemEval datasets with a standard deviation 4.84) roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors. Such an unsupervised representation is empirically validated via semantic textual similarity tasks on 19 different datasets, where it outperforms the sophisticated neural network models, including skip-thought vectors, by 15% on average.|sl:arxiv_author|Suma Bhat
Athènes|skos:broader|Grèce
Web Pollution|skos:broader|Grands problèmes
Acoustique musicale|skos:broader|Acoustique
Graph Convolution for Multimodal Information Extraction from Visually Rich Documents Visually rich documents (VRDs) are ubiquitous in daily business and life. Examples are purchase receipts, insurance policy documents, custom declaration forms and so on. In VRDs, visual and layout information is critical for document understanding, and texts in such documents cannot be serialized into the one-dimensional sequence without losing information. Classic information extraction models such as BiLSTM-CRF typically operate on text sequences and do not incorporate visual features. In this paper, we introduce a graph convolution based model to combine textual and visual information presented in VRDs. Graph embeddings are trained to summarize the context of a text segment in the document, and further combined with text embeddings for entity extraction. Extensive experiments have been conducted to show that our method outperforms BiLSTM-CRF baselines by significant margins, on two real-world datasets. Additionally, ablation studies are also performed to evaluate the effectiveness of each component of our model.|sl:tag|tag:2d_nlp
Pandémie|skos:broader|Maladie contagieuse
Enseignement scientifique|skos:broader|Science
Notes d'install|skos:broader|Installing apps
Ambiguity (NLP)|skos:broader|NLP tasks / problems
The Description Length of Deep Learning Models  Solomonoff’s general theory of inference (Solomonoff, 1964) and the [Minimum Description Length Principle](tag:minimum_description_length_principle) (Grünwald, 2007; Rissanen, 2007) formalize [Occam's razor](tag:occam_s_razor), and hold that a good model of data is a model that is good at losslessly  compressing the data, including the cost of describing the model itself. Deep neural  networks might seem to go against this principle given the large number of  parameters to be encoded.  We demonstrate experimentally the ability of deep neural networks to compress  the training data even when accounting for parameter encoding. Solomonoff's general theory of inference and the Minimum Description Length principle formalize Occam's razor, and hold that a good model of data is a model that is good at losslessly compressing the data, including the cost of describing the model itself. Deep neural networks might seem to go against this principle given the large number of parameters to be encoded. We demonstrate experimentally the ability of deep neural networks to compress the training data even when accounting for parameter encoding. The compression viewpoint originally motivated the use of variational methods in neural networks. Unexpectedly, we found that these variational methods provide surprisingly poor compression bounds, despite being explicitly built to minimize such bounds. This might explain the relatively poor practical performance of variational methods in deep learning. On the other hand, simple incremental encoding methods yield excellent compression values on deep networks, vindicating Solomonoff's approach.|sl:tag|tag:information_theory_and_deep_learning
FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence [github](https://github.com/google-research/fixmatch)     we demonstrate the power of a  simple combination of two common Semi-Supervised Learning methods: consistency  regularization and pseudo-labeling.    1. First generates pseudo-labels using the model’s  predictions on weakly-augmented unlabeled images. For a  given image, the pseudo-label is only retained if the model  produces a high-confidence prediction.   2. The model is then  trained to predict the pseudo-label when fed a strongly augmented  version of the same image. Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. In this paper, we demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling. Our algorithm, FixMatch, first generates pseudo-labels using the model's predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just 4 labels per class. Since FixMatch bears many similarities to existing SSL methods that achieve worse performance, we carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. We make our code available at https://github.com/google-research/fixmatch.|sl:tag|tag:arxiv_doc
Natural Language Processing with Small Feed-Forward Networks google guys:      We show that small and shallow feed- forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.   We show that small and shallow feed-forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.|sl:tag|tag:nn_4_nlp
DocBERT: BERT for Document Classification We present, to our knowledge, the first application of BERT to document classification. A few characteristics of the task might lead one to think that BERT is not the most appropriate model: syntactic structures matter less for content categories, documents can often be longer than typical BERT input, and documents often have multiple labels. Nevertheless, we show that a straightforward classification model using BERT is able to achieve the state of the art across four popular datasets. To address the computational expense associated with BERT inference, we distill knowledge from BERT-large to small bidirectional LSTMs, reaching BERT-base parity on multiple datasets using 30x fewer parameters. The primary contribution of our paper is improved baselines that can provide the foundation for future work.|sl:arxiv_author|Ashutosh Adhikari
Cocteau|skos:broader|Réalisateur
Forêt|skos:broader|Arbres
SonarQube|skos:broader|Dev tools
Distilling Structured Knowledge into Embeddings for Explainable and Accurate Recommendation distilling structured knowledge from a differentiable path-based recommendation model.     proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons Recently, the embedding-based recommendation models (e.g., matrix factorization and deep models) have been prevalent in both academia and industry due to their effectiveness and flexibility. However, they also have such intrinsic limitations as lacking explainability and suffering from data sparsity. In this paper, we propose an end-to-end joint learning framework to get around these limitations without introducing any extra overhead by distilling structured knowledge from a differentiable path-based recommendation model. Through extensive experiments, we show that our proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons.|sl:tag|tag:kd_mkb_related
Zaïre|skos:broader|RDC
Visualizing and Measuring the Geometry of BERT  At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.|sl:tag|tag:tree_embeddings
Grande-Bretagne|skos:broader|Royaume Uni
Attention Is All You Need  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.|sl:arxiv_firstAuthor|Ashish Vaswani
RDF Data source|skos:broader|RDF
Multnomah Falls|skos:broader|Oregon
Etat islamique|skos:broader|Terrorisme islamiste
Human-AI collaboration|skos:broader|Artificial Intelligence
Périclès|skos:broader|Personnage historique
JDBC|skos:broader|SQL
One-Shot Generalization in Deep Generative Models Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our models are able to generate compelling and diverse samples---having seen new examples just once---providing an important class of general-purpose models for one-shot machine learning.|sl:arxiv_author|Ivo Danihelka
Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data Word embeddings are a popular approach to unsupervised learning of word relationships that are widely used in natural language processing. In this article, we present a new set of embeddings for medical concepts learned using an extremely large collection of multimodal medical data. Leaning on recent theoretical insights, we demonstrate how an insurance claims database of 60 million members, a collection of 20 million clinical notes, and 1.7 million full text biomedical journal articles can be combined to embed concepts into a common space, resulting in the largest ever set of embeddings for 108,477 medical concepts. To evaluate our approach, we present a new benchmark methodology based on statistical power specifically designed to test embeddings of medical concepts. Our approach, called cui2vec, attains state-of-the-art performance relative to previous methods in most instances. Finally, we provide a downloadable set of pre-trained embeddings for other researchers to use, as well as an online tool for interactive exploration of the cui2vec embeddings|sl:tag|tag:arxiv_doc
Bio inspired computing devices|skos:broader|Brain
A Survey on Deep Learning for Named Entity Recognition mainly focus on generic NEs in English language Named entity recognition (NER) is the task to identify mentions of rigid designators from text belonging to predefined semantic types such as person, location, organization etc. NER always serves as the foundation for many natural language applications such as question answering, text summarization, and machine translation. Early NER systems got a huge success in achieving good performance with the cost of human engineering in designing domain-specific features and rules. In recent years, deep learning, empowered by continuous real-valued vector representations and semantic composition through nonlinear processing, has been employed in NER systems, yielding stat-of-the-art performance. In this paper, we provide a comprehensive review on existing deep learning techniques for NER. We first introduce NER resources, including tagged NER corpora and off-the-shelf NER tools. Then, we systematically categorize existing works based on a taxonomy along three axes: distributed representations for input, context encoder, and tag decoder. Next, we survey the most representative methods for recent applied techniques of deep learning in new NER problem settings and applications. Finally, we present readers with the challenges faced by NER systems and outline future directions in this area.|sl:arxiv_author|Jing Li
Gilles Lepin|skos:broader|Ami
Honda|skos:broader|Japon
Traversing Knowledge Graphs in Vector Space Knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new \compositional\ training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. Path queries on a knowledge graph can be used to answer compositional questions such as What languages are spoken by people living in Lisbon?. However, knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new compositional training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. On a standard knowledge base completion task, we also demonstrate that compositional training acts as a novel form of structural regularization, reliably improving performance across all base models (reducing errors by up to 43%) and achieving new state-of-the-art results.|sl:tag|tag:knowledge_graph_embeddings
Pétrole|skos:broader|Matières premières
Multilinguisme|skos:broader|Langues
C2GWeb: SEO|skos:broader|C2GWeb
RDF-driven web sites|skos:broader|RDF
Mbilia Bel|skos:broader|Zaïre
Label-Embedding for Image Classification Attributes act as intermediate representations that enable parameter sharing between classes, a must when training data is scarce. We propose to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors. We introduce a function that measures the compatibility between an image and a label embedding. The parameters of this function are learned on a training set of labeled samples to ensure that, given an image, the correct classes rank higher than the incorrect ones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasets show that the proposed framework outperforms the standard Direct Attribute Prediction baseline in a zero-shot learning scenario. Label embedding enjoys a built-in ability to leverage alternative sources of information instead of or in addition to attributes, such as e.g. class hierarchies or textual descriptions. Moreover, label embedding encompasses the whole range of learning settings from zero-shot learning to regular learning with a large number of labeled examples.|sl:arxiv_author|Cordelia Schmid
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:tag|tag:nn_symbolic_ai_hybridation
XLNet: Generalized Autoregressive Pretraining for Language Understanding a new pretraining method for NLP that significantly improves upon BERT on 20 tasks (e.g., SQuAD, GLUE, RACE) With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.|sl:arxiv_author|Jaime Carbonell
Winch 5|skos:broader|Livre
Naive Bayes classifier|skos:broader|Bayesian classification
Deep Learning Book|skos:broader|AI: books & journals
K-BERT: Enabling Language Representation with Knowledge Graph a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by equipped with a KG without pre-training by-self because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts.|sl:tag|tag:nlp_using_knowledge_graphs
Span Selection Pre-training for Question Answering  a new pre-training task inspired by reading  comprehension and an effort to avoid encoding general knowledge in the transformer network itself    Current transformer architectures store general knowledge - large models, long pre-training time. Better to offload the requirement of general knowledge to a sparsely activated network.    Span selection as an additional auxiliary task: the query is a sentence drawn from a corpus  with a term replaced with a special token: [BLANK]. The term replaced by the blank is the answer term. The passage is  relevant as determined by a BM25 search, and answer-bearing (containing the answer  term). Unlike BERT’s cloze task, where the answer must be drawn from the model itself, the answer is found in a passage  using language understanding.     We hope to progress to a model of general purpose language modeling that uses an indexed long  term memory to retrieve world knowledge, rather than holding it in the densely activated transformer encoder layers. BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pre-trained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension and an effort to avoid encoding general knowledge in the transformer network itself. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple reading comprehension (MRC) and paraphrasing datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also establish a new SOTA in HotpotQA, improving answer prediction F1 by 4 F1 points and supporting fact prediction by 1 F1 point. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.|sl:tag|tag:bert
Variable Selection Methods for Model-based Clustering Model-based clustering is a popular approach for clustering multivariate data which has seen applications in numerous fields. Nowadays, high-dimensional data are more and more common and the model-based clustering approach has adapted to deal with the increasing dimensionality. In particular, the development of variable selection techniques has received a lot of attention and research effort in recent years. Even for small size problems, variable selection has been advocated to facilitate the interpretation of the clustering results. This review provides a summary of the methods developed for variable selection in model-based clustering. Existing R packages implementing the different methods are indicated and illustrated in application to two data analysis examples.|sl:arxiv_author|Michael Fop
Paris NLP meetup|skos:broader|NLP event
Cryptage|skos:broader|Cybersecurity Sécurité informatique
Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks  Sentence-BERT  (SBERT), a modification of the pretrained  BERT network that use siamese and triplet network  structures to derive semantically meaningful  sentence embeddings that can be compared  using cosine-similarity.    Important because     - BERT ist unsuitable for semantic similarity  search as well as for unsupervised tasks  like clustering.  - simple methods such as using the CLS token give low quality sentence embeddings    However, the purpose of SBERT sentence embeddings  are not to be used for transfer learning for other  tasks.    [Related blog post](/doc/2020/01/richer_sentence_embeddings_usin); [Github](https://github.com/UKPLab/sentence-transformers) BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.|sl:arxiv_author|Nils Reimers
Keyword/keyphrase extraction|skos:broader|Keywords
Question Answering over Knowledge Graphs via Structural Query Patterns Natural language question answering over knowledge graphs is an important and interesting task as it enables common users to gain accurate answers in an easy and intuitive manner. However, it remains a challenge to bridge the gap between unstructured questions and structured knowledge graphs. To address the problem, a natural discipline is building a structured query to represent the input question. Searching the structured query over the knowledge graph can produce answers to the question. Distinct from the existing methods that are based on semantic parsing or templates, we propose an effective approach powered by a novel notion, structural query pattern, in this paper. Given an input question, we first generate its query sketch that is compatible with the underlying structure of the knowledge graph. Then, we complete the query graph by labeling the nodes and edges under the guidance of the structural query pattern. Finally, answers can be retrieved by executing the constructed query graph over the knowledge graph. Evaluations on three question answering benchmarks show that our proposed approach outperforms state-of-the-art methods significantly.|sl:arxiv_author|Weiguo Zheng
Brain implants|skos:broader|Brain
Variational Inference: A Review for Statisticians One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.|sl:tag|tag:variational_bayesian_methods
Programming language|skos:broader|Programming
Multi-label classification|skos:broader|Statistical classification
fps AND LDOW2008|skos:broader|LDOW2008
Google Fusion Tables|skos:broader|Tables
Semantic Wiki|skos:broader|Semantic Web : Application
Calvin|skos:broader|Religion
fps@EC-Web'14|skos:broader|fps: paper
ERNIE: Enhanced Language Representation with Informative Entities  We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.|sl:arxiv_author|Xu Han
No Fuss Distance Metric Learning using Proxies  We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity...   Traditionnaly, supervision is expressed in the form of sets of points that follow  an ordinal relationship – an anchor point x is similar to  a set of positive points Y , and dissimilar to a set of negative  points Z, and a loss defined over these distances is minimized.   Triplet-Based methods are challenging to optimize (a main issue is the need for finding informative triplets).     We propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss.    Mentioned in this [blog post](/doc/2020/01/training_a_speaker_embedding_fr):     Proxy based triplet learning: instead of generating triplets, we learn an embedding for each class and use the learnt embedding as a proxy for triplets as part of the training. In other words, we can train end to end without the computationally expensive step of resampling triplets after each network update.    Near the conclusion:     Our formulation of Proxy-NCA loss produces a loss very  similar to the standard cross-entropy loss used in classification.  However, we arrive at our formulation from a different  direction: we are not interested in the actual classifier and  indeed discard the proxies once the model has been trained.  Instead, the proxies are auxiliary variables, enabling more  effective optimization of the embedding model parameters.  As such, our formulation not only enables us to surpass the  state of the art in zero-shot learning, but also offers an explanation  to the effectiveness of the standard trick of training  a classifier, and using its penultimate layer’s output as the  embedding. We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity. Traditionally, for this problem supervision is expressed in the form of sets of points that follow an ordinal relationship -- an anchor point $x$ is similar to a set of positive points $Y$, and dissimilar to a set of negative points $Z$, and a loss defined over these distances is minimized. While the specifics of the optimization differ, in this work we collectively call this type of supervision Triplets and all methods that follow this pattern Triplet-Based methods. These methods are challenging to optimize. A main issue is the need for finding informative triplets, which is usually achieved by a variety of tricks such as increasing the batch size, hard or semi-hard triplet mining, etc. Even with these tricks, the convergence rate of such methods is slow. In this paper we propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss. This proxy-based loss is empirically better behaved. As a result, the proxy-loss improves on state-of-art results for three standard zero-shot learning datasets, by up to 15% points, while converging three times as fast as other triplet-based losses.|sl:tag|tag:arxiv_doc
Neural Ranking Models with Weak Supervision Main Idea: To leverage large amounts of unsupervised data to infer “weak” labels and use that signal for learning supervised models as if we had the ground truth labels. See [blog post](/doc/?uri=http%3A%2F%2Fmostafadehghani.com%2F2017%2F04%2F23%2Fbeating-the-teacher-neural-ranking-models-with-weak-supervision%2F):     This is truly awesome since we have only used  BM25 as the supervisor to train a model which performs better than BM25 itself!   Despite the impressive improvements achieved by unsupervised deep neural networks in computer vision and NLP tasks, such improvements have not yet been observed in ranking for information retrieval. The reason may be the complexity of the ranking problem, as it is not obvious how to learn from queries and documents when no supervised signal is available. Hence, in this paper, we propose to train a neural ranking model using weak supervision, where labels are obtained automatically without human annotators or any external resources (e.g., click data). To this aim, we use the output of an unsupervised ranking model, such as BM25, as a weak supervision signal. We further train a set of simple yet effective ranking models based on feed-forward neural networks. We study their effectiveness under various learning scenarios (point-wise and pair-wise models) and using different input representations (i.e., from encoding query-document pairs into dense/sparse vectors to using word embedding representation). We train our networks using tens of millions of training instances and evaluate it on two standard collections: a homogeneous news collection(Robust) and a heterogeneous large-scale web collection (ClueWeb). Our experiments indicate that employing proper objective functions and letting the networks to learn the input representation based on weakly supervised data leads to impressive performance, with over 13% and 35% MAP improvements over the BM25 model on the Robust and the ClueWeb collections. Our findings also suggest that supervised neural ranking models can greatly benefit from pre-training on large amounts of weakly labeled data that can be easily obtained from unsupervised IR models.|sl:arxiv_author|Mostafa Dehghani
Semanlink|skos:broader|Semantic tagging
Concept Bottleneck Models  We seek to learn models that we can interact with using high-level concepts... We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these concept bottleneck models by editing their predicted concept values and propagating these changes to the final prediction... These models allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time. We seek to learn models that we can interact with using high-level concepts: if the model did not think there was a bone spur in the x-ray, would it still predict severe arthritis? State-of-the-art models today do not typically support the manipulation of concepts like the existence of bone spurs, as they are trained end-to-end to go directly from raw input (e.g., pixels) to output (e.g., arthritis severity). We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these \\emph{concept bottleneck models} by editing their predicted concept values and propagating these changes to the final prediction. On x-ray grading and bird identification, concept bottleneck models achieve competitive accuracy with standard end-to-end models, while enabling interpretation in terms of high-level clinical concepts (bone spurs) or bird attributes (wing color). These models also allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time.|sl:arxiv_author|Emma Pierson
PCA is a statistical procedure that converts a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components.    - PCA is based on extracting the axes on which the data shows the highest variability.    PCA can be done by eigenvalue decomposition of a data covariance matrix or singular value decomposition of a data matrix, usually after mean centering and normalizing the data matrix for each attribute|skos:broader|process of reducing the number of random variables under consideration. Can be divided into feature selection and feature extraction.
Named Entity Disambiguation using Deep Learning on Graphs Evaluation of different deep learning techniques to create  a context vector from graphs, aimed at high-accuracy NED. (neural  approach for entity disambiguation using graphs as background  knowledge)     We tackle Named Entity Disambiguation (NED) by comparing entities  in short sentences with Wikidata graphs. Creating a context vector  from graphs through deep learning is a challenging problem that has  never been applied to NED. Our main contribution is to present an  experimental study of recent neural techniques, as well as a discussion  about which graph features are most important for the disambiguation  task...    [published paper](https://rd.springer.com/chapter/10.1007/978-3-030-15719-7_10)      In NED, the system  must be able to generate a context for an entity in a text and an entity  in a knowledge base, then correctly link the two.    Explore whether representing graphs  as triplets is more useful than using the full topological information of the graph    We tackle \\ac{NED} by comparing entities in short sentences with \\wikidata{} graphs. Creating a context vector from graphs through deep learning is a challenging problem that has never been applied to \\ac{NED}. Our main contribution is to present an experimental study of recent neural techniques, as well as a discussion about which graph features are most important for the disambiguation task. In addition, a new dataset (\\wikidatadisamb{}) is created to allow a clean and scalable evaluation of \\ac{NED} with \\wikidata{} entries, and to be used as a reference in future research. In the end our results show that a \\ac{Bi-LSTM} encoding of the graph triplets performs best, improving upon the baseline models and scoring an \ m{F1} value of $91.6\\%$ on the \\wikidatadisamb{} test set|sl:arxiv_author|Stefano Bragaglia
ML|skos:broader|IA AI
Hugo|skos:broader|Poète
Placentaires, marsupiaux et monotrèmes|skos:broader|Marsupiaux
Advances in Pre-Training Distributed Word Representations  we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks Many Natural Language Processing applications nowadays rely on pre-trained word representations estimated from large text corpora such as news collections, Wikipedia and Web Crawl. In this paper, we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks.|sl:arxiv_author|Piotr Bojanowski
Akhênaton|skos:broader|Egypte antique
Pillage de vestiges antiques|skos:broader|Archéologie
Hierarchical Memory Networks  hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory Memory networks are neural networks with an explicit memory component that can be both read and written to by the network. The memory is often addressed in a soft way using a softmax function, making end-to-end training with backpropagation possible. However, this is not computationally scalable for applications which require the network to read from extremely large memories. On the other hand, it is well known that hard attention mechanisms based on reinforcement learning are challenging to train successfully. In this paper, we explore a form of hierarchical memory network, which can be considered as a hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory. Specifically, we propose to incorporate Maximum Inner Product Search (MIPS) in the training and inference procedures for our hierarchical memory network. We explore the use of various state-of-the art approximate MIPS techniques and report results on SimpleQuestions, a challenging large scale factoid question answering task.|sl:tag|tag:arxiv_doc
Cerveau|skos:broader|Biologie
Entity Embeddings of Categorical Variables  We map categorical variables in a function approximation problem into Euclidean spaces, which are the entity embeddings of the categorical variables. The mapping is learned by a neural network during the standard supervised training process. Entity embedding not only reduces memory usage and speeds up neural networks compared with one-hot encoding, but more importantly by mapping similar values close to each other in the embedding space it reveals the intrinsic properties of the categorical variables We map categorical variables in a function approximation problem into Euclidean spaces, which are the entity embeddings of the categorical variables. The mapping is learned by a neural network during the standard supervised training process. Entity embedding not only reduces memory usage and speeds up neural networks compared with one-hot encoding, but more importantly by mapping similar values close to each other in the embedding space it reveals the intrinsic properties of the categorical variables. We applied it successfully in a recent Kaggle competition and were able to reach the third position with relative simple features. We further demonstrate in this paper that entity embedding helps the neural network to generalize better when the data is sparse and statistics is unknown. Thus it is especially useful for datasets with lots of high cardinality features, where other methods tend to overfit. We also demonstrate that the embeddings obtained from the trained neural network boost the performance of all tested machine learning methods considerably when used as the input features instead. As entity embedding defines a distance measure for categorical variables it can be used for visualizing categorical data and for data clustering.|sl:arxiv_author|Cheng Guo
Clustering of text documents|skos:broader|Clustering
Botanique|skos:broader|Biology
Fungal infections|skos:broader|Problèmes sanitaires
Feynman|skos:broader|Physique
Turtle|skos:broader|David Beckett
VW|skos:broader|Automotive
LOD cloud|skos:broader|Linking Open Data
RDF embeddings|skos:broader|Embeddings
Chinois|skos:broader|Chine
semblog|skos:broader|Blog software
JPA|skos:broader|Java
Question Answering|skos:broader|NLP tasks / problems
Jeux en ligne|skos:broader|Internet
SPARQL Clipboard|skos:broader|SPARQL
Quentin Tarantino|skos:broader|Réalisateur
C2GWeb-JS|skos:broader|Configuration ontology
Unsupervised Transfer Learning for Spoken Language Understanding in Intelligent Agents  We apply ELMo, ULMFiT (unsupervised transfer) with supervised transfer to reduce labeled data required for launching domains in Alexa by 10-15x User interaction with voice-powered agents generates large amounts of unlabeled utterances. In this paper, we explore techniques to efficiently transfer the knowledge from these unlabeled utterances to improve model performance on Spoken Language Understanding (SLU) tasks. We use Embeddings from Language Model (ELMo) to take advantage of unlabeled data by learning contextualized word representations. Additionally, we propose ELMo-Light (ELMoL), a faster and simpler unsupervised pre-training method for SLU. Our findings suggest unsupervised pre-training on a large corpora of unlabeled utterances leads to significantly better SLU performance compared to training from scratch and it can even outperform conventional supervised transfer. Additionally, we show that the gains from unsupervised transfer techniques can be further improved by supervised transfer. The improvements are more pronounced in low resource settings and when using only 1000 labeled in-domain samples, our techniques match the performance of training from scratch on 10-15x more labeled in-domain data.|sl:arxiv_firstAuthor|Aditya Siddhant
Grands problèmes|skos:broader|Etat du monde
Franco-Allemand|skos:broader|Europe
Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus.     In practice, some questions are best answered  using text, while others are best answered using  KBs. A natural question, then, is how to effectively  combine both types of information. Surprisingly  little prior work has looked at this problem. Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting. Source code is available at https://github.com/OceanskySun/GraftNet .|sl:tag|tag:kg_and_nlp
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).|sl:arxiv_firstAuthor|Jacob Devlin
Niklas Lindström|skos:broader|Technical girls and guys
Linking Open Data|skos:broader|Linked Data
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:tag|tag:text_in_kg_embeddings
OWL DL|skos:broader|Description Logic
Eclipse|skos:broader|Dev
Bernhard Haslhofer|skos:broader|SW guys (and girls)
Automatic tagging|skos:broader|NLP tasks / problems
Michel Serres|skos:broader|Intellectuel
Deep Learning for Symbolic Mathematics Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.|sl:tag|tag:deep_learning
Ian Davis|skos:broader|SW guys (and girls)
application of machine learning in the construction of ranking models. Training data consists of lists of items with some partial order specified between items in each list. |skos:broader|the machine learning task of inferring a function from labeled training data.
Longformer: The Long-Document Transformer  Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Following prior work on long-sequence transformers, we evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8. In contrast to most prior work, we also pretrain Longformer and finetune it on a variety of downstream tasks. Our pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA.|sl:arxiv_author|Arman Cohan
Bayesian classification|skos:broader|Statistical classification
Jean Rouch|skos:broader|Niger
The Consciousness Prior consciousness seen as the formation of a low-dimensional combination of a few concepts constituting a conscious thought, i.e., consciousness as awareness at a particular time instant: the projection of a big vector (all the things conscious and unconscious in brain). Attention: additional mechanism describing what mind chooses to focus on.    [YouTube video](/doc/?uri=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYr1mOzC93xs) A new prior is proposed for learning representations of high-level concepts of the kind we manipulate with language. This prior can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by cognitive neuroscience theories of consciousness, seen as a bottleneck through which just a few elements, after having been selected by attention from a broader pool, are then broadcast and condition further processing, both in perception and decision-making. The set of recently selected elements one becomes aware of is seen as forming a low-dimensional conscious state. This conscious state is combining the few concepts constituting a conscious thought, i.e., what one is immediately conscious of at a particular moment. We claim that this architectural and information-processing constraint corresponds to assumptions about the joint distribution between high-level concepts. To the extent that these assumptions are generally true (and the form of natural language seems consistent with them), they can form a useful prior for representation learning. A low-dimensional thought or conscious state is analogous to a sentence: it involves only a few variables and yet can make a statement with very high probability of being true. This is consistent with a joint distribution (over high-level concepts) which has the form of a sparse factor graph, i.e., where the dependencies captured by each factor of the factor graph involve only very few variables while creating a strong dip in the overall energy function. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in a form similar to facts and rules, albeit capturing uncertainty as well as efficient search mechanisms implemented by attention mechanisms.|sl:tag|tag:good
Genetics Génétique|skos:broader|Biology
Python 4 Data science|skos:broader|Data science
A practical tutorial on autoencoders for nonlinear feature fusion: Taxonomy, models, software and guidelines Many of the existing machine learning algorithms, both supervised and unsupervised, depend on the quality of the input characteristics to generate a good model. The amount of these variables is also important, since performance tends to decline as the input dimensionality increases, hence the interest in using feature fusion techniques, able to produce feature sets that are more compact and higher level. A plethora of procedures to fuse original variables for producing new ones has been developed in the past decades. The most basic ones use linear combinations of the original variables, such as PCA (Principal Component Analysis) and LDA (Linear Discriminant Analysis), while others find manifold embeddings of lower dimensionality based on non-linear combinations, such as Isomap or LLE (Linear Locally Embedding) techniques. More recently, autoencoders (AEs) have emerged as an alternative to manifold learning for conducting nonlinear feature fusion. Dozens of AE models have been proposed lately, each with its own specific traits. Although many of them can be used to generate reduced feature sets through the fusion of the original ones, there also AEs designed with other applications in mind. The goal of this paper is to provide the reader with a broad view of what an AE is, how they are used for feature fusion, a taxonomy gathering a broad range of models, and how they relate to other classical techniques. In addition, a set of didactic guidelines on how to choose the proper AE for a given task is supplied, together with a discussion of the software tools available. Finally, two case studies illustrate the usage of AEs with datasets of handwritten digits and breast cancer.|sl:tag|tag:arxiv_doc
Distance metric learning: the task of learning a distance function over objects consistent with a notion of similarity.     Suppose you want to implement a ML-based search engine that, given a query, ranks a variable number of documents by relevance. Metric learning is essentially learning a function that, given two inputs, tells you how relevant they are. [src](https://twitter.com/ericjang11/status/1259207970916667392?s=20)|skos:broader|The goal is to learn from examples a similarity function that measures how similar or related two objects are.    Distance metric learning: the task of learning a distance function over objects consistent with a notion of similarity.     Distance metric learning is a major tool for a variety  of problems in computer vision. It has successfully  been employed for image retrieval, near duplicate detection, clustering and zero-shot learning. ([src](doc/2020/02/_1703_07464_no_fuss_distance_m))
MaxEnt for NLP|skos:broader|Maxent models
Culture et sem web|skos:broader|Culture
Encoder-Decoder architecture|skos:broader|Machine learning: techniques
KGAT: Knowledge Graph Attention Network for Recommendation To provide more accurate, diverse, and explainable recommendation, it is compulsory to go beyond modeling user-item interactions and take side information into account. Traditional methods like factorization machine (FM) cast it as a supervised learning problem, which assumes each interaction as an independent instance with side information encoded. Due to the overlook of the relations among instances or items (e.g., the director of a movie is also an actor of another movie), these methods are insufficient to distill the collaborative signal from the collective behaviors of users. In this work, we investigate the utility of knowledge graph (KG), which breaks down the independent interaction assumption by linking items with their attributes. We argue that in such a hybrid structure of KG and user-item graph, high-order relations --- which connect two items with one or multiple linked attributes --- are an essential factor for successful recommendation. We propose a new method named Knowledge Graph Attention Network (KGAT) which explicitly models the high-order connectivities in KG in an end-to-end fashion. It recursively propagates the embeddings from a node's neighbors (which can be users, items, or attributes) to refine the node's embedding, and employs an attention mechanism to discriminate the importance of the neighbors. Our KGAT is conceptually advantageous to existing KG-based recommendation methods, which either exploit high-order relations by extracting paths or implicitly modeling them with regularization. Empirical results on three public benchmarks show that KGAT significantly outperforms state-of-the-art methods like Neural FM and RippleNet. Further studies verify the efficacy of embedding propagation for high-order relation modeling and the interpretability benefits brought by the attention mechanism.|sl:arxiv_author|Tat-Seng Chua
Deep Learning for Symbolic Mathematics Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.|sl:tag|tag:guillaume_lample
Documentaire TV|skos:broader|Télévision
Paléontologie humaine|skos:broader|Paléontologie
Specializing Word Embeddings (for Parsing) by Information Bottleneck EMNLP best paper award. [Related blog post](doc:2020/06/information_bottleneck_for_nlp_) Pre-trained word embeddings like ELMo and BERT contain rich syntactic and semantic information, resulting in state-of-the-art performance on various tasks. We propose a very fast variational information bottleneck (VIB) method to nonlinearly compress these embeddings, keeping only the information that helps a discriminative parser. We compress each word embedding to either a discrete tag or a continuous vector. In the discrete version, our automatically compressed tags form an alternative tag set: we show experimentally that our tags capture most of the information in traditional POS tag annotations, but our tag sequences can be parsed more accurately at the same level of tag granularity. In the continuous version, we show experimentally that moderately compressing the word embeddings by our method yields a more accurate parser in 8 of 9 languages, unlike simple dimensionality reduction.|sl:tag|tag:information_bottleneck_method
RDF Vocabularies|skos:broader|RDF
Mur de Berlin|skos:broader|RDA
Robotisation|skos:broader|Robotique
Barack's Wife Hillary: Using Knowledge-Graphs for Fact-Aware Language Modeling  a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset, a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark. In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language model's ability to complete sentences requiring factual knowledge, showing that the KGLM outperforms even very large language models in generating facts.|sl:tag|tag:allen_institute_for_ai_a2i
Biology|skos:broader|Science
Microsoft Media Center|skos:broader|Microsoft
Politique de l'enfant unique|skos:broader|Chine
Extrémophiles|skos:broader|Biology
Parameter-free Sentence Embedding via Orthogonal Basis training-free approach for building sentence representations, Geometric Embedding (GEM), based on the geometric structure of word embedding space.     we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word’s novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace    [on www.groundai.com](https://www.groundai.com/project/zero-training-sentence-embedding-via-orthogonal-basis/)    [Open Revieww](/doc/?uri=https%3A%2F%2Fopenreview.net%2Fforum%3Fid%3DrJedbn0ctQ) ; [Related to this paper](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1704.05358)       We propose a simple and robust non-parameterized approach for building sentence representations. Inspired by the Gram-Schmidt Process in geometric theory, we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word's novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace. Following this motivation, we develop an innovative method based on orthogonal basis to combine pre-trained word embeddings into sentence representations. This approach requires zero parameters, along with efficient inference performance. We evaluate our approach on 11 downstream NLP tasks. Our model shows superior performance compared with non-parameterized alternatives and it is competitive to other approaches relying on either large amounts of labelled data or prolonged training time.|sl:tag|tag:sentence_embeddings
Language Models as Knowledge Bases? an analysis of the relational knowledge present in pretrained language models shows an ability of these models to recall factual knowledge  Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as fill-in-the-blank cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.|sl:arxiv_author|Yuxiang Wu
Category Embedding|skos:broader|Embeddings
Tabulator|skos:broader|RDF browser
Knowledge Graph Conference 2019|skos:broader|Conférences
Deep Patent Landscaping Model Using Transformer and Graph Embedding a transformer encoder  for analyzing textual data present in patent documents  and a graph convolutional network for analyzing  patent metadata.    A benchmarking dataset for patent landscaping  based on patent trends reports published by the  Korean Patent Office. Data acquisition using Google's BigQuery public datasets.    10% improvement comparing to Google’s proposed Automated Patent Landscaping.    Empirical analysis of the importance of features (text vs metadata, citations vs classification)     Patent landscaping is a method used for searching related patents during a research and development (R&D) project. To avoid the risk of patent infringement and to follow current trends in technology, patent landscaping is a crucial task required during the early stages of an R&D project. As the process of patent landscaping requires advanced resources and can be tedious, the demand for automated patent landscaping has been gradually increasing. However, a shortage of well-defined benchmark datasets and comparable models makes it difficult to find related research studies. In this paper, we propose an automated patent landscaping model based on deep learning. To analyze the text of patents, the proposed model uses a modified transformer structure. To analyze the metadata of patents, we propose a graph embedding method that uses a diffusion graph called Diff2Vec. Furthermore, we introduce four benchmark datasets for comparing related research studies in patent landscaping. The datasets are produced by querying Google BigQuery, based on a search formula from a Korean patent attorney. The obtained results indicate that the proposed model and datasets can attain state-of-the-art performance, as compared with current patent landscaping models.|sl:arxiv_author|Sungchul Choi
Contestation|skos:broader|I like I like
Toumaï|skos:broader|Origines de l'homme
Makolab|skos:broader|Entreprise
V.S. Naipaul V. S. Naipaul|skos:broader|Ecrivain
Covid19|skos:broader|Pandémie
Yoav Goldberg|skos:broader|NLP girls and guys
Notes on Cardinal's Matrices These notes are motivated by the work of Jean-Paul Cardinal on symmetric matrices related to the Mertens function. He showed that certain norm bounds on his matrices implied the Riemann hypothesis. Using a different matrix norm we show an equivalence of the Riemann hypothesis to suitable norm bounds on his matrices in the new norm. Then we specify a deformed version of his Mertens function matrices that unconditionally satisfies a norm bound that is of the same strength as his Riemann hypothesis bound.|sl:arxiv_firstAuthor|Jeffrey C. Lagarias
Maven|skos:broader|Dev tools
Semanlink Feature Request|skos:broader|Semanlink todo
RSS Dev|skos:broader|RSS
Indonésie|skos:broader|Asie
Web architecture|skos:broader|Internet
Photo aérienne|skos:broader|Photo
Representation learning for very short texts using weighted word embedding aggregation A method based on word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. a href=https://github.com/cedricdeboom/RepresentationLearningGithub/a (hmm...) (python code)     Short text messages such as tweets are very noisy and sparse in their use of vocabulary. Traditional textual representations, such as tf-idf, have difficulty grasping the semantic meaning of such texts, which is important in applications such as event detection, opinion mining, news recommendation, etc. We constructed a method based on semantic word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. For this purpose we designed a weight-based model and a learning procedure based on a novel median-based loss function. This paper discusses the details of our model and the optimization methods, together with the experimental results on both Wikipedia and Twitter data. We find that our method outperforms the baseline approaches in the experiments, and that it generalizes well on different word embeddings without retraining. Our method is therefore capable of retaining most of the semantic information in the text, and is applicable out-of-the-box.|sl:tag|tag:arxiv_doc
Coursera: NLP class|skos:broader|NLP
Cross-validation|skos:broader|Machine learning: techniques
Entities as Experts: Sparse Memory Access with Entity Supervision   the problem of capturing declarative knowledge in the learned parameters of a language model...     Entities as Experts (EaE) can access distinct memories of the entities mentioned in a piece of text;     To understand the motivation for distinct and  independent entity representations: A traditional Transformer would need to build an internal representation  of Charles Darwin from the words “Charles”  and “Darwin”... Conversely, EAE can access  a dedicated representation of “Charles Darwin”,  which is a memory of all of the contexts in which  this entity has previously been mentioned.... Having retrieved  and re-integrated this memory it is much easier for  EAE to relate the question to the answer     EaE's entity representations are learned directly from text. Correct identification, and representation, of entities is essential to EaE's performance    Based on transformer architecture    Extension: [Facts as Experts](doc:2020/07/2007_00849_facts_as_experts_) We focus on the problem of capturing declarative knowledge in the learned parameters of a language model. We introduce a new model, Entities as Experts (EaE), that can access distinct memories of the entities mentioned in a piece of text. Unlike previous efforts to integrate entity knowledge into sequence models, EaE's entity representations are learned directly from text. These representations capture sufficient knowledge to answer TriviaQA questions such as Which Dr. Who villain has been played by Roger Delgado, Anthony Ainley, Eric Roberts?. EaE outperforms a Transformer model with $30\\times$ the parameters on this task. According to the Lama knowledge probes, EaE also contains more factual knowledge than a similar sized Bert. We show that associating parameters with specific entities means that EaE only needs to access a fraction of its parameters at inference time, and we show that the correct identification, and representation, of entities is essential to EaE's performance. We also argue that the discrete and independent entity representations in EaE make it more modular and interpretable than the Transformer architecture on which it is based.|sl:arxiv_author|Eunsol Choi
François Scharffe|skos:broader|SW guys (and girls)
John Steinbeck|skos:broader|Ecrivain
Implementing a Jena Graph|skos:broader|Jena dev
ML ensemble meta-algorithm for primarily reducing bias, and also variance in supervised learning, and a family of machine learning algorithms that convert weak learners to strong ones.    |skos:broader|Methods that use multiple learning algorithms to obtain better predictive performance
Falashas|skos:broader|Juifs
Knowledge Graph Construction|skos:broader|Knowledge Graphs
Visualizing and Measuring the Geometry of BERT  At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.|sl:arxiv_author|Been Kim
Neuroevolution|skos:broader|Neural networks
Jena|skos:broader|RDF Tools
Specializing Word Embeddings (for Parsing) by Information Bottleneck EMNLP best paper award. [Related blog post](doc:2020/06/information_bottleneck_for_nlp_) Pre-trained word embeddings like ELMo and BERT contain rich syntactic and semantic information, resulting in state-of-the-art performance on various tasks. We propose a very fast variational information bottleneck (VIB) method to nonlinearly compress these embeddings, keeping only the information that helps a discriminative parser. We compress each word embedding to either a discrete tag or a continuous vector. In the discrete version, our automatically compressed tags form an alternative tag set: we show experimentally that our tags capture most of the information in traditional POS tag annotations, but our tag sequences can be parsed more accurately at the same level of tag granularity. In the continuous version, we show experimentally that moderately compressing the word embeddings by our method yields a more accurate parser in 8 of 9 languages, unlike simple dimensionality reduction.|sl:tag|tag:arxiv_doc
InceptionTime: Finding AlexNet for Time Series Classification Time series classification (TSC) is the area of machine learning interested in learning how to assign labels to time series. The last few decades of work in this area have led to significant progress in the accuracy of classifiers, with the state of the art now represented by the HIVE-COTE algorithm. While extremely accurate, HIVE-COTE is infeasible to use in many applications because of its very high training time complexity in O(N^2T^4) for a dataset with N time series of length T. For example, it takes HIVE-COTE more than 72,000s to learn from a small dataset with N=700 time series of short length T=46. Deep learning, on the other hand, has now received enormous attention because of its high scalability and state-of-the-art accuracy in computer vision and natural language processing tasks. Deep learning for TSC has only very recently started to be explored, with the first few architectures developed over the last 3 years only. The accuracy of deep learning for TSC has been raised to a competitive level, but has not quite reached the level of HIVE-COTE. This is what this paper achieves: outperforming HIVE-COTE's accuracy together with scalability. We take an important step towards finding the AlexNet network for TSC by presenting InceptionTime---an ensemble of deep Convolutional Neural Network (CNN) models, inspired by the Inception-v4 architecture. Our experiments show that InceptionTime slightly outperforms HIVE-COTE with a win/draw/loss on the UCR archive of 40/6/39. Not only is InceptionTime more accurate, but it is much faster: InceptionTime learns from that same dataset with 700 time series in 2,300s but can also learn from a dataset with 8M time series in 13 hours, a quantity of data that is fully out of reach of HIVE-COTE.|sl:arxiv_author|Lhassane Idoumghar
A Primer in BERTology: What we know about how BERT works (article praised on [twitter](https://twitter.com/dennybritz/status/1233343170596917248?s=20) by D Britz and Y. Goldberg) Transformer-based models are now widely used in NLP, but we still do not understand a lot about their inner workings. This paper describes what is known to date about the famous BERT model (Devlin et al. 2019), synthesizing over 40 analysis studies. We also provide an overview of the proposed modifications to the model and its training regime. We then outline the directions for further research.|sl:arxiv_firstAuthor|Anna Rogers
TF-IDF|skos:broader|Information retrieval: techniques
MP3|skos:broader|Musique
535|skos:broader|Catastrophe naturelle
backplanejs|skos:broader|JavaScript librairies
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:arxiv_author|Houman Alborzi
Leigh Dodds|skos:broader|Technical girls and guys
List-only Entity Linking|skos:broader|Entity linking
Categorical Metadata Representation for Customized Text Classification  We observe that current representation methods for categorical metadata... are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category The performance of text classification has improved tremendously using intelligently engineered neural-based models, especially those injecting categorical metadata as additional information, e.g., using user/product information for sentiment classification. These information have been used to modify parts of the model (e.g., word embeddings, attention mechanisms) such that results can be customized according to the metadata. We observe that current representation methods for categorical metadata, which are devised for human consumption, are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category, and even such context is often scarce (for tail category). To this end, we propose to use basis vectors to effectively incorporate categorical metadata on various parts of a neural-based model. This additionally decreases the number of parameters dramatically, especially when the number of categorical features is large. Extensive experiments on various datasets with different properties are performed and show that through our method, we can represent categorical metadata more effectively to customize parts of the model, including unexplored ones, and increase the performance of the model greatly.|sl:arxiv_author|Kyungjae Lee
Hypercard|skos:broader|Apple
OpenStructs|skos:broader|Semantic framework
Hugh Glaser|skos:broader|Technical girls and guys
Sesame|skos:broader|RDF Framework
Arbres|skos:broader|Plante
JSON-LD APIs|skos:broader|JSON-LD
Unsupervised deep pre-training|skos:broader|Unsupervised machine learning
Text in KG embeddings|skos:broader|Knowledge Graphs and NLP
Language model|skos:broader|NLP techniques
Multi-Task Deep Neural Networks for Natural Language Understanding outperforms BERT in nine of eleven benchmark NLP tasks In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations in order to adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7% (2.2% absolute improvement). We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. The code and pre-trained models are publicly available at https://github.com/namisan/mt-dnn.|sl:tag|tag:nlp_microsoft
Falashas|skos:broader|Ethiopie
SWAD-E|skos:broader|Semantic Web
Bombay|skos:broader|Ville
Tomcat 7|skos:broader|Tomcat
An efficient framework for learning sentence representations Quick Thoughts. Framework for learning sentence representations from unlabelled data.     we reformulate the problem of predicting the context in which a sentence appears as a classification problem.   In this work we propose a simple and efficient framework for learning sentence representations from unlabelled data. Drawing inspiration from the distributional hypothesis and recent work on learning sentence representations, we reformulate the problem of predicting the context in which a sentence appears as a classification problem. Given a sentence and its context, a classifier distinguishes context sentences from other contrastive sentences based on their vector representations. This allows us to efficiently learn different types of encoding functions, and we show that the model learns high-quality sentence representations. We demonstrate that our sentence representations outperform state-of-the-art unsupervised and supervised representation learning methods on several downstream NLP tasks that involve understanding sentence semantics while achieving an order of magnitude speedup in training time.|sl:tag|tag:sentence_embeddings
Audi|skos:broader|Automobile
No Fuss Distance Metric Learning using Proxies  We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity...   Traditionnaly, supervision is expressed in the form of sets of points that follow  an ordinal relationship – an anchor point x is similar to  a set of positive points Y , and dissimilar to a set of negative  points Z, and a loss defined over these distances is minimized.   Triplet-Based methods are challenging to optimize (a main issue is the need for finding informative triplets).     We propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss.    Mentioned in this [blog post](/doc/2020/01/training_a_speaker_embedding_fr):     Proxy based triplet learning: instead of generating triplets, we learn an embedding for each class and use the learnt embedding as a proxy for triplets as part of the training. In other words, we can train end to end without the computationally expensive step of resampling triplets after each network update.    Near the conclusion:     Our formulation of Proxy-NCA loss produces a loss very  similar to the standard cross-entropy loss used in classification.  However, we arrive at our formulation from a different  direction: we are not interested in the actual classifier and  indeed discard the proxies once the model has been trained.  Instead, the proxies are auxiliary variables, enabling more  effective optimization of the embedding model parameters.  As such, our formulation not only enables us to surpass the  state of the art in zero-shot learning, but also offers an explanation  to the effectiveness of the standard trick of training  a classifier, and using its penultimate layer’s output as the  embedding. We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity. Traditionally, for this problem supervision is expressed in the form of sets of points that follow an ordinal relationship -- an anchor point $x$ is similar to a set of positive points $Y$, and dissimilar to a set of negative points $Z$, and a loss defined over these distances is minimized. While the specifics of the optimization differ, in this work we collectively call this type of supervision Triplets and all methods that follow this pattern Triplet-Based methods. These methods are challenging to optimize. A main issue is the need for finding informative triplets, which is usually achieved by a variety of tricks such as increasing the batch size, hard or semi-hard triplet mining, etc. Even with these tricks, the convergence rate of such methods is slow. In this paper we propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss. This proxy-based loss is empirically better behaved. As a result, the proxy-loss improves on state-of-art results for three standard zero-shot learning datasets, by up to 15% points, while converging three times as fast as other triplet-based losses.|sl:tag|tag:similarity_learning
Solid|skos:broader|Decentralized social network
Irlande|skos:broader|Europe
Learning with Memory Embeddings Embedding learning, a.k.a. representation learning, has been shown to be able to model large-scale semantic knowledge graphs. A key concept is a mapping of the knowledge graph to a tensor representation whose entries are predicted by models using latent representations of generalized entities. Latent variable models are well suited to deal with the high dimensionality and sparsity of typical knowledge graphs. In recent publications the embedding models were extended to also consider time evolutions, time patterns and subsymbolic representations. In this paper we map embedding models, which were developed purely as solutions to technical problems for modelling temporal knowledge graphs, to various cognitive memory functions, in particular to semantic and concept memory, episodic memory, sensory memory, short-term memory, and working memory. We discuss learning, query answering, the path from sensory input to semantic decoding, and the relationship between episodic memory and semantic memory. We introduce a number of hypotheses on human memory that can be derived from the developed mathematical models.|sl:arxiv_author|Stephan Baier
Dan Jurafsky|skos:broader|NLP girls and guys
Finding RDF documents|skos:broader|RDF
Alex Allauzen|skos:broader|NLP girls and guys
RDF and Property Graphs|skos:broader|RDF graphs
Blé|skos:broader|Agriculture
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:tag|tag:connectionist_vs_symbolic_debate
Time Series|skos:broader|Machine learning: problems
Diacritics in URI|skos:broader|Encoding
Cognition-as-a-Service|skos:broader|Cognitive computing
C2GWeb|skos:broader|C2G
RNN based Language Model|skos:broader|Language model
many early knowledge graph embeddings do not use literal attributes, only structure of the graph...    eg.: Description-Embodied Knowledge Representation Learning (DKRL) learns a structure-based representation (as TransE) and a description-based representation that can be used in an integrated scoring function, thus combining the relative  information coming from both text and facts.|skos:broader|How can we use knowledge graph in computing?    A knowledge graph is a symbolic and logical system but applications often involve numerical computing in continuous spaces.  Formal logic is neither tractable nor robust when dealing with knowledge graph. Hence the idea of Knowledge graph embeddings.    Generally, each entity is represented  as a point in that space while each relation is interpreted as an operation over entity embeddings (eg. in Bordes et al. transE, a translation). The embedding representations are usually learnt by minimizing a global loss function involving all entities and relations so that each entity  embedding encodes both local and global connectivity patterns of the original graph.  
Pretrained models|skos:broader|Machine learning: techniques
BERT for Joint Intent Classification and Slot Filling  Experimental results show that our  proposed joint BERT model outperforms BERT  models modeling intent classification and slot filling  separately, demonstrating the efficacy of exploiting  the relationship between the two tasks.    Adding a CRF on top of the model doesn't improve the results. Intent classification and slot filling are two essential tasks for natural language understanding. They often suffer from small-scale human-labeled training data, resulting in poor generalization capability, especially for rare words. Recently a new language representation model, BERT (Bidirectional Encoder Representations from Transformers), facilitates pre-training deep bidirectional representations on large-scale unlabeled corpora, and has created state-of-the-art models for a wide variety of natural language processing tasks after simple fine-tuning. However, there has not been much effort on exploring BERT for natural language understanding. In this work, we propose a joint intent classification and slot filling model based on BERT. Experimental results demonstrate that our proposed model achieves significant improvement on intent classification accuracy, slot filling F1, and sentence-level semantic frame accuracy on several public benchmark datasets, compared to the attention-based recurrent neural network models and slot-gated models.|sl:arxiv_firstAuthor|Qian Chen
Drug-resistant germs|skos:broader|Grands problèmes
Survey analysis|skos:broader|NLP: use cases
Bolsonaro|skos:broader|Neo-fascites
"Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One We propose to reinterpret a standard discriminative classifier of p(y|x) as an energy based model for the joint distribution p(x,y). In this setting, the standard class probabilities can be easily computed as well as unnormalized values of p(x) and p(x|y). Within this framework, standard discriminative architectures may beused and the model can also be trained on unlabeled data. We demonstrate that energy based training of the joint distribution improves calibration, robustness, andout-of-distribution detection while also enabling our models to generate samplesrivaling the quality of recent GAN approaches. We improve upon recently proposed techniques for scaling up the training of energy based models and presentan approach which adds little overhead compared to standard classification training. Our approach is the first to achieve performance rivaling the state-of-the-artin both generative and discriminative learning within one hybrid model."|sl:arxiv_firstAuthor|Will Grathwohl
Matthew Honnibal|skos:broader|NLP girls and guys
Micropayments on the web|skos:broader|Web
Google Play|skos:broader|Google
A Survey on Deep Learning for Named Entity Recognition mainly focus on generic NEs in English language Named entity recognition (NER) is the task to identify mentions of rigid designators from text belonging to predefined semantic types such as person, location, organization etc. NER always serves as the foundation for many natural language applications such as question answering, text summarization, and machine translation. Early NER systems got a huge success in achieving good performance with the cost of human engineering in designing domain-specific features and rules. In recent years, deep learning, empowered by continuous real-valued vector representations and semantic composition through nonlinear processing, has been employed in NER systems, yielding stat-of-the-art performance. In this paper, we provide a comprehensive review on existing deep learning techniques for NER. We first introduce NER resources, including tagged NER corpora and off-the-shelf NER tools. Then, we systematically categorize existing works based on a taxonomy along three axes: distributed representations for input, context encoder, and tag decoder. Next, we survey the most representative methods for recent applied techniques of deep learning in new NER problem settings and applications. Finally, we present readers with the challenges faced by NER systems and outline future directions in this area.|sl:arxiv_firstAuthor|Jing Li
Juliana Rotich|skos:broader|Technical girls and guys
Sahel|skos:broader|Afrique
TopBraid/SPIN|skos:broader|TopBraid
Génocide rwandais|skos:broader|Génocide
Laure Soulier|skos:broader|NLP girls and guys
Emerging Cross-lingual Structure in Pretrained Language Models We study the problem of multilingual masked language modeling, i.e. the training of a single model on concatenated text from multiple languages, and present a detailed study of several factors that influence why these models are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from independently trained models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these symmetries seem to be automatically discovered and aligned during the joint training process.|sl:tag|tag:pre_trained_language_models
Censure et maltraitance animale|skos:broader|Cruauté
Pic de Hubbert|skos:broader|Pétrole
StarSpace: Embed All The Things! We present StarSpace, a general-purpose neural embedding model that can solve a wide variety of problems: labeling tasks such as text classification, ranking tasks such as information retrieval/web search, collaborative filtering-based or content-based recommendation, embedding of multi-relational graphs, and learning word, sentence or document level embeddings. In each case the model works by embedding those entities comprised of discrete features and comparing them against each other -- learning similarities dependent on the task. Empirical results on a number of tasks show that StarSpace is highly competitive with existing methods, whilst also being generally applicable to new cases where those methods are not.|sl:arxiv_author|Ledell Wu
OWL|skos:broader|Ontologies
ensemble learning technique that combines multiple classification or regression models via a meta-classifier or a meta-regressor. The base level models are trained based on a complete training set, then the meta-model is trained on the outputs of the base level model as features. ([source](/doc/2019/07/ensemble_learning_to_improve_ma))  |skos:broader|Methods that use multiple learning algorithms to obtain better predictive performance
Tony Blair|skos:broader|Chef d'état
Explainable Deep Learning: A Field Guide for the Uninitiated Deep neural network (DNN) is an indispensable machine learning tool for achieving human-level performance on many learning tasks. Yet, due to its black-box nature, it is inherently difficult to understand which aspects of the input data drive the decisions of the network. There are various real-world scenarios in which humans need to make actionable decisions based on the output DNNs. Such decision support systems can be found in critical domains, such as legislation, law enforcement, etc. It is important that the humans making high-level decisions can be sure that the DNN decisions are driven by combinations of data features that are appropriate in the context of the deployment of the decision support system and that the decisions made are legally or ethically defensible. Due to the incredible pace at which DNN technology is being developed, the development of new methods and studies on explaining the decision-making process of DNNs has blossomed into an active research field. A practitioner beginning to study explainable deep learning may be intimidated by the plethora of orthogonal directions the field is taking. This complexity is further exacerbated by the general confusion that exists in defining what it means to be able to explain the actions of a deep learning system and to evaluate a system's ability to explain. To alleviate this problem, this article offers a field guide to deep learning explainability for those uninitiated in the field. The field guide: i) Discusses the traits of a deep learning system that researchers enhance in explainability research, ii) places explainability in the context of other related deep learning research areas, and iii) introduces three simple dimensions defining the space of foundational methods that contribute to explainable deep learning. The guide is designed as an easy-to-digest starting point for those just embarking in the field.|sl:arxiv_author|Marcel van Gerven
General Motors|skos:broader|USA
Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data Word embeddings are a popular approach to unsupervised learning of word relationships that are widely used in natural language processing. In this article, we present a new set of embeddings for medical concepts learned using an extremely large collection of multimodal medical data. Leaning on recent theoretical insights, we demonstrate how an insurance claims database of 60 million members, a collection of 20 million clinical notes, and 1.7 million full text biomedical journal articles can be combined to embed concepts into a common space, resulting in the largest ever set of embeddings for 108,477 medical concepts. To evaluate our approach, we present a new benchmark methodology based on statistical power specifically designed to test embeddings of medical concepts. Our approach, called cui2vec, attains state-of-the-art performance relative to previous methods in most instances. Finally, we provide a downloadable set of pre-trained embeddings for other researchers to use, as well as an online tool for interactive exploration of the cui2vec embeddings|sl:tag|tag:embeddings
NoSQL pour les nuls|skos:broader|Pour les nuls
fastai: A Layered API for Deep Learning Paper describing the fast.ai v2 API fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes: a new type dispatch system for Python along with a semantic type hierarchy for tensors; a GPU-optimized computer vision library which can be extended in pure Python; an optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 4-5 lines of code; a novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training; a new data block API; and much more. We have used this library to successfully create a complete deep learning course, which we were able to write more quickly than using previous approaches, and the code was more clear. The library is already in wide use in research, industry, and teaching. NB: This paper covers fastai v2, which is currently in pre-release at http://dev.fast.ai/|sl:tag|tag:api
 “a good cluster—or document grouping—is one, which possesses a good, readable description”.|skos:broader|Open Source Search Results Clustering Engine.     It can automatically organize small collections of documents into thematic categories.
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).|sl:arxiv_author|Jacob Devlin
Knowledge Enhanced Contextual Word Representations General method to embed multiple knowledge bases into pre-trained language models (KB in the   sense as fixed collection of entity nodes)     The key idea is to explicitly model  entity spans in the input text and use an entity  linker to retrieve relevant entity embeddings from  a KB to form knowledge enhanced entity-span  representations.   Then,  update contextual word representations via a form of word-to-entity attention.    In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert's runtime is comparable to BERT's and it scales to large KBs.|sl:arxiv_firstAuthor|Matthew E. Peters
BNF|skos:broader|France
Adaptative boosting    (Authors won Gödel Prize for their work)    output of the 'weak learners' is combined into a weighted sum that represents the final output of the boosted classifier. Sensitive to noisy data and outliers (says wikipedia)     AdaBoost (with decision trees as the weak learners) is often referred to as the best out-of-the-box classifier  |skos:broader|ML ensemble meta-algorithm for primarily reducing bias, and also variance in supervised learning, and a family of machine learning algorithms that convert weak learners to strong ones.    
Monsanto|skos:broader|Biotech industry
Médicaments génériques|skos:broader|Propriété intellectuelle
JSP|skos:broader|Internet Related Technologies
Semi-supervised learning|skos:broader|Machine learning: techniques
Towards a Seamless Integration of Word Senses into Downstream NLP Applications Lexical ambiguity can impede NLP systems from accurate understanding of semantics. Despite its potential benefits, the integration of sense-level information into NLP systems has remained understudied. By incorporating a novel disambiguation algorithm into a state-of-the-art classification model, we create a pipeline to integrate sense-level information into downstream NLP applications. We show that a simple disambiguation of the input text can lead to consistent performance improvement on multiple topic categorization and polarity detection datasets, particularly when the fine granularity of the underlying sense inventory is reduced and the document is sufficiently large. Our results also point to the need for sense representation research to focus more on in vivo evaluations which target the performance in downstream NLP applications rather than artificial benchmarks.|sl:tag|tag:lexical_ambiguity
Paul Krugman|skos:broader|Prix Nobel d'économie
Restful semantic web services|skos:broader|Semantic Web Services
httpRange-14 (solution)|skos:broader|httpRange-14
535|skos:broader|Histoire
CoKE: Contextualized Knowledge Graph Embedding A method to build contextualized entity and relation embeddings. Entities and relations may appear in different graph contexts. Edges and paths, both formulated as sequences of entities and relations, are passed as input to a Transformer encoder to learn the contextualized representations..    [Github](https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE) Knowledge graph embedding, which projects symbolic entities and relations into continuous vector spaces, is gaining increasing attention. Previous methods allow a single static embedding for each entity or relation, ignoring their intrinsic contextual nature, i.e., entities and relations may appear in different graph contexts, and accordingly, exhibit different properties. This work presents Contextualized Knowledge Graph Embedding (CoKE), a novel paradigm that takes into account such contextual nature, and learns dynamic, flexible, and fully contextualized entity and relation embeddings. Two types of graph contexts are studied: edges and paths, both formulated as sequences of entities and relations. CoKE takes a sequence as input and uses a Transformer encoder to obtain contextualized representations. These representations are hence naturally adaptive to the input, capturing contextual meanings of entities and relations therein. Evaluation on a wide variety of public benchmarks verifies the superiority of CoKE in link prediction and path query answering. It performs consistently better than, or at least equally well as current state-of-the-art in almost every case, in particular offering an absolute improvement of 21.0% in H@10 on path query answering. Our code is available at \\url{https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE}.|sl:tag|tag:knowledge_graph_embeddings
LHC|skos:broader|Expérience scientifique
ERNIE: Enhanced Language Representation with Informative Entities  We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.|sl:arxiv_firstAuthor|Zhengyan Zhang
Kadhafi|skos:broader|Lybie
LSTM|skos:broader|Recurrent neural network
Insecte|skos:broader|Arthropodes
HypiosVoCampParisMay2010|skos:broader|VoCamp
Ontologie visualization|skos:broader|Ontologies
Afripedia|skos:broader|Wikimedia
Naomi Klein|skos:broader|Critique du capitalisme
GRDDL|skos:broader|XHTML
A Primer in BERTology: What we know about how BERT works (article praised on [twitter](https://twitter.com/dennybritz/status/1233343170596917248?s=20) by D Britz and Y. Goldberg) Transformer-based models are now widely used in NLP, but we still do not understand a lot about their inner workings. This paper describes what is known to date about the famous BERT model (Devlin et al. 2019), synthesizing over 40 analysis studies. We also provide an overview of the proposed modifications to the model and its training regime. We then outline the directions for further research.|sl:tag|tag:bert
Longformer: The Long-Document Transformer  Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Following prior work on long-sequence transformers, we evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8. In contrast to most prior work, we also pretrain Longformer and finetune it on a variety of downstream tasks. Our pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA.|sl:tag|tag:arxiv_doc
Africa's Last Wild Places|skos:broader|Afrique
Civilisations précolombiennes|skos:broader|Archéologie
Semanlink|skos:broader|Personal Knowledge Graph
Steve Cayzer|skos:broader|SW guys (and girls)
construction of a decision tree from class-labeled training tuples    frequent problem: overfitting (=high variance)    |skos:broader|the machine learning task of inferring a function from labeled training data.
Learning to Remember Rare Events  a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training.    Our memory module can be easily added to any part of a supervised neural network Despite recent advances, memory-augmented deep neural networks are still limited when it comes to life-long and one-shot learning, especially in remembering rare events. We present a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training. Our memory module can be easily added to any part of a supervised neural network. To show its versatility we add it to a number of networks, from simple convolutional ones tested on image classification to deep sequence-to-sequence and recurrent-convolutional models. In all cases, the enhanced network gains the ability to remember and do life-long one-shot learning. Our module remembers training examples shown many thousands of steps in the past and it can successfully generalize from them. We set new state-of-the-art for one-shot learning on the Omniglot dataset and demonstrate, for the first time, life-long one-shot learning in recurrent neural networks on a large-scale machine translation task.|sl:arxiv_author|Samy Bengio
Spritz|skos:broader|GUI
Text Generation from Knowledge Graphs with Graph Transformers Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.|sl:arxiv_author|Mirella Lapata
Machine Learning Basics|skos:broader|Machine learning
Capitalism Surveillance|skos:broader|Big Brother
Tours|skos:broader|Ville
Homme politique|skos:broader|Politique
W3C Working Draft|skos:broader|W3C
Conscience artificielle|skos:broader|Anticipation
Mondeca|skos:broader|French Semantic web company
OWLED 2007|skos:broader|OWL
Medical Data|skos:broader|Santé
Negative Sampling|skos:broader|Machine learning: techniques
Simple idea|skos:broader|Good idea
Configuration ontology|skos:broader|C2GWeb
Retrofitting Word Vectors to Semantic Lexicons Method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed.     Graph-based learning technique for using lexical relational resources to obtain higher quality semantic vectors, which we call “retrofitting.” Retrofitting is applied as a post-processing step by running belief propagation on a graph constructed from lexicon-derived relational information to update word vectors. This allows retrofitting to be used on pre-trained word vectors obtained using any vector training model.    [github](https://github.com/mfaruqui/retrofitting)     Vector space word representations are learned from distributional information of words in large corpora. Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database. This paper proposes a method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed. Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, we obtain substantial improvements starting with a variety of word vector models. Our refinement method outperforms prior techniques for incorporating semantic lexicons into the word vector training algorithms.|sl:arxiv_author|Jesse Dodge
Autoencoder|skos:broader|Unsupervised machine learning
Olaf Hartig|skos:broader|SW guys (and girls)
Baïkal|skos:broader|Russie
Chris Bizer|skos:broader|Freie Universität Berlin
ElasticSearch: nearest neighbor(s)|skos:broader|ElasticSearch
Cinéma français|skos:broader|Cinéma
Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus.     In practice, some questions are best answered  using text, while others are best answered using  KBs. A natural question, then, is how to effectively  combine both types of information. Surprisingly  little prior work has looked at this problem. Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting. Source code is available at https://github.com/OceanskySun/GraftNet .|sl:arxiv_author|Manzil Zaheer
Apigee|skos:broader|API management
SOA|skos:broader|Web Services
Towards a Seamless Integration of Word Senses into Downstream NLP Applications Lexical ambiguity can impede NLP systems from accurate understanding of semantics. Despite its potential benefits, the integration of sense-level information into NLP systems has remained understudied. By incorporating a novel disambiguation algorithm into a state-of-the-art classification model, we create a pipeline to integrate sense-level information into downstream NLP applications. We show that a simple disambiguation of the input text can lead to consistent performance improvement on multiple topic categorization and polarity detection datasets, particularly when the fine granularity of the underlying sense inventory is reduced and the document is sufficiently large. Our results also point to the need for sense representation research to focus more on in vivo evaluations which target the performance in downstream NLP applications rather than artificial benchmarks.|sl:arxiv_author|Roberto Navigli
Learning Semantic Similarity for Very Short Texts In order to pair short text  fragments—as a concatenation of separate words—an adequate  distributed sentence representation is needed. Main contribution: a first step towards a hybrid method that  combines the strength of dense distributed representations—  as opposed to sparse term matching—with the strength of  tf-idf based methods. The combination of word embeddings and tf-idf  information might lead to a better model for semantic content  within very short text fragments. Levering data on social media, such as Twitter and Facebook, requires information retrieval algorithms to become able to relate very short text fragments to each other. Traditional text similarity methods such as tf-idf cosine-similarity, based on word overlap, mostly fail to produce good results in this case, since word overlap is little or non-existent. Recently, distributed word representations, or word embeddings, have been shown to successfully allow words to match on the semantic level. In order to pair short text fragments - as a concatenation of separate words - an adequate distributed sentence representation is needed, in existing literature often obtained by naively combining the individual word representations. We therefore investigated several text representations as a combination of word embeddings in the context of semantic pair matching. This paper investigates the effectiveness of several such naive techniques, as well as traditional tf-idf similarity, for fragments of different lengths. Our main contribution is a first step towards a hybrid method that combines the strength of dense distributed representations - as opposed to sparse term matching - with the strength of tf-idf based methods to automatically reduce the impact of less informative terms. Our new approach outperforms the existing techniques in a toy experimental set-up, leading to the conclusion that the combination of word embeddings and tf-idf information might lead to a better model for semantic content within very short text fragments.|sl:arxiv_author|Steven Van Canneyt
Pyramide|skos:broader|Architecture
Turtle in HTML|skos:broader|Turtle
Antibiotic resistance|skos:broader|Problèmes sanitaires
Bulgarie|skos:broader|Pays d'Europe
LDP: updates|skos:broader|Linked Data Platform
Information theory|skos:broader|Information
Alpinisme|skos:broader|Sport
Semantic Camp Paris|skos:broader|Paris
A generative model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar.    Models the intuition that the topic of a document will probabilistically influence the author’s choice of words when writing the document. Documents are interpreted as a mixture of topics (a probability distribution over topics), and topics as a probability distribution over words.    Encodes the intuition that documents cover a small number of topics and that topics often use a small number of words    LDA is an extension of [LSI/pLSI](latent_semantic_analysis)            |skos:broader|A statistical model for discovering the abstract topics that occur in a collection of documents.      
SemWeb China|skos:broader|Chine : technologie
A Primer on Neural Network Models for Natural Language Processing Over the past few years, neural networks have re-emerged as powerful machine-learning models, yielding state-of-the-art results in fields such as image recognition and speech processing. More recently, neural network models started to be applied also to textual natural language signals, again with very promising results. This tutorial surveys neural network models from the perspective of natural language processing research, in an attempt to bring natural-language researchers up to speed with the neural techniques. The tutorial covers input encoding for natural language tasks, feed-forward networks, convolutional networks, recurrent networks and recursive networks, as well as the computation graph abstraction for automatic gradient computation.|sl:arxiv_author|Yoav Goldberg
Reader mode (browsers)|skos:broader|Brouteur
Guha|skos:broader|SW guys (and girls)
BAM! Born-Again Multi-Task Networks for Natural Language Understanding  knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers It can be challenging to train multi-task neural networks that outperform or even match their single-task counterparts. To help address this, we propose using knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers. We evaluate our approach by multi-task fine-tuning BERT on the GLUE benchmark. Our method consistently improves over standard single-task and multi-task training.|sl:tag|tag:quoc_le
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:arxiv_author|Jiaming Shen
Cybersex|skos:broader|Internet
Entities as Experts: Sparse Memory Access with Entity Supervision   the problem of capturing declarative knowledge in the learned parameters of a language model...     Entities as Experts (EaE) can access distinct memories of the entities mentioned in a piece of text;     To understand the motivation for distinct and  independent entity representations: A traditional Transformer would need to build an internal representation  of Charles Darwin from the words “Charles”  and “Darwin”... Conversely, EAE can access  a dedicated representation of “Charles Darwin”,  which is a memory of all of the contexts in which  this entity has previously been mentioned.... Having retrieved  and re-integrated this memory it is much easier for  EAE to relate the question to the answer     EaE's entity representations are learned directly from text. Correct identification, and representation, of entities is essential to EaE's performance    Based on transformer architecture    Extension: [Facts as Experts](doc:2020/07/2007_00849_facts_as_experts_) We focus on the problem of capturing declarative knowledge in the learned parameters of a language model. We introduce a new model, Entities as Experts (EaE), that can access distinct memories of the entities mentioned in a piece of text. Unlike previous efforts to integrate entity knowledge into sequence models, EaE's entity representations are learned directly from text. These representations capture sufficient knowledge to answer TriviaQA questions such as Which Dr. Who villain has been played by Roger Delgado, Anthony Ainley, Eric Roberts?. EaE outperforms a Transformer model with $30\\times$ the parameters on this task. According to the Lama knowledge probes, EaE also contains more factual knowledge than a similar sized Bert. We show that associating parameters with specific entities means that EaE only needs to access a fraction of its parameters at inference time, and we show that the correct identification, and representation, of entities is essential to EaE's performance. We also argue that the discrete and independent entity representations in EaE make it more modular and interpretable than the Transformer architecture on which it is based.|sl:tag|tag:arxiv_doc
Toumaï|skos:broader|Separation of man and ape
NLP + Human Resources|skos:broader|NLP: use cases
Chirac|skos:broader|Chef d'état
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:arxiv_author|Souvik Sen
The information bottleneck method  We define the relevant information in a signal x ∈ X as being the information that this signal provides about another signal y ∈ Y. Examples include the information that face images provide about the names of the people portrayed, or the information that speech sounds provide about the words spoken. Understanding the signal x requires more than just predicting y, it also requires specifying which features of X play a role in the prediction. We formalize this problem as that of finding a short code for X that preserves the maximum information about Y. That is, we squeeze the information that X provides about Y through a ‘bottleneck’ formed by a limited set of codewords X ̃... This approach yields an exact set of self consistent equations for the coding rules X → X ̃ and X ̃ → Y .    (from the intro) : how to define meaningful / relevant information? An issue left out of information theory by Shannon (focus on the problem of transmitting information rather than judging its value to the recipient) -leads to  consider statistical and information theoretic principles as almost irrelevant  for the question of meaning.      In contrast, we argue here that information theory,  in particular lossy source compression, provides a natural quantitative  approach to the question of “relevant information.” Specifically, we formulate  a variational principle for the extraction or efficient representation of  relevant information.     We define the relevant information in a signal $x\\in X$ as being the information that this signal provides about another signal $y\\in \\Y$. Examples include the information that face images provide about the names of the people portrayed, or the information that speech sounds provide about the words spoken. Understanding the signal $x$ requires more than just predicting $y$, it also requires specifying which features of $\\X$ play a role in the prediction. We formalize this problem as that of finding a short code for $\\X$ that preserves the maximum information about $\\Y$. That is, we squeeze the information that $\\X$ provides about $\\Y$ through a `bottleneck' formed by a limited set of codewords $\\tX$. This constrained optimization problem can be seen as a generalization of rate distortion theory in which the distortion measure $d(x,\\x)$ emerges from the joint statistics of $\\X$ and $\\Y$. This approach yields an exact set of self consistent equations for the coding rules $X \\to \\tX$ and $\\tX \\to \\Y$. Solutions to these equations can be found by a convergent re-estimation method that generalizes the Blahut-Arimoto algorithm. Our variational principle provides a surprisingly rich framework for discussing a variety of problems in signal processing and learning, as will be described in detail elsewhere.|sl:tag|tag:arxiv_doc
sig.ma|skos:broader|Linked Data Browser
Visualizing and Measuring the Geometry of BERT  At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.|sl:tag|tag:nlp_google
Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus.     In practice, some questions are best answered  using text, while others are best answered using  KBs. A natural question, then, is how to effectively  combine both types of information. Surprisingly  little prior work has looked at this problem. Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting. Source code is available at https://github.com/OceanskySun/GraftNet .|sl:tag|tag:graph_embeddings
M3 Multi Media Museum|skos:broader|Digital Collections
Windows Vista|skos:broader|Windows
Barack's Wife Hillary: Using Knowledge-Graphs for Fact-Aware Language Modeling  a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset, a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark. In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language model's ability to complete sentences requiring factual knowledge, showing that the KGLM outperforms even very large language models in generating facts.|sl:arxiv_author|Matthew E. Peters
A Hierarchical Multi-task Approach for Learning Embeddings from Semantic Tasks [Blog post](https://medium.com/dair-ai/hmtl-multi-task-learning-for-state-of-the-art-nlp-245572bbb601), [GitHub repo](https://github.com/huggingface/hmtl)   Much effort has been devoted to evaluate whether multi-task learning can be leveraged to learn rich representations that can be used in various Natural Language Processing (NLP) down-stream applications. However, there is still a lack of understanding of the settings in which multi-task learning has a significant effect. In this work, we introduce a hierarchical model trained in a multi-task learning setup on a set of carefully selected semantic tasks. The model is trained in a hierarchical fashion to introduce an inductive bias by supervising a set of low level tasks at the bottom layers of the model and more complex tasks at the top layers of the model. This model achieves state-of-the-art results on a number of tasks, namely Named Entity Recognition, Entity Mention Detection and Relation Extraction without hand-engineered features or external NLP tools like syntactic parsers. The hierarchical training supervision induces a set of shared semantic representations at lower layers of the model. We show that as we move from the bottom to the top layers of the model, the hidden states of the layers tend to represent more complex semantic information.|sl:arxiv_author|Sebastian Ruder
NSA spying scandal|skos:broader|Big Brother
GPL|skos:broader|Open Source
Horizontal gene transfer|skos:broader|Genetics Génétique
The goal is to learn from examples a similarity function that measures how similar or related two objects are.    Distance metric learning: the task of learning a distance function over objects consistent with a notion of similarity.     Distance metric learning is a major tool for a variety  of problems in computer vision. It has successfully  been employed for image retrieval, near duplicate detection, clustering and zero-shot learning. ([src](doc/2020/02/_1703_07464_no_fuss_distance_m))|skos:broader|the machine learning task of inferring a function from labeled training data.
René Vautier|skos:broader|Anticolonialisme
Sibérie|skos:broader|Russie
Sahara|skos:broader|Désert
MusicBrainz|skos:broader|Musique
Wembedder: Wikidata entity embedding web service web service for querying an embedding of entities in the Wikidata knowledge graph. The embedding is trained on the Wikidata dump using Gensim's Word2Vec implementation and a simple graph walk I present a web service for querying an embedding of entities in the Wikidata knowledge graph. The embedding is trained on the Wikidata dump using Gensim's Word2Vec implementation and a simple graph walk. A REST API is implemented. Together with the Wikidata API the web service exposes a multilingual resource for over 600'000 Wikidata items and properties.|sl:tag|tag:word2vec
Multi-Document Summarization|skos:broader|Text Summarization
Conférences|skos:broader|Event
Python tips|skos:broader|Python
LDOW2013|skos:broader|LDOW
Large scale distributed neural network training through online distillation   we use codistillation to refer to distillation performed:   1. using the same architecture for all the models;   2. using the same dataset to train all the models; and   3. using the distillation loss during training before any model has fully converged.     In general, we believe the quality gains of codistillation over well-tuned offline distillation will be  minor in practice and the more interesting research direction is exploring codistillation as a distributed  training algorithm     Codistillation with  the same data seems to be slightly better than the baseline, but codistillation using different data  gets much better results. These results show that the codistilling models are indeed successfully  transmitting useful information about different parts of the training data to each other.    Related to [Deep mutual learning](doc:2020/05/1706_00384_deep_mutual_learni) paper Techniques such as ensembling and distillation promise model quality improvements when paired with almost any base model. However, due to increased test-time cost (for ensembles) and increased complexity of the training pipeline (for distillation), these techniques are challenging to use in industrial settings. In this paper we explore a variant of distillation which is relatively straightforward to use as it does not require a complicated multi-stage setup or many new hyperparameters. Our first claim is that online distillation enables us to use extra parallelism to fit very large datasets about twice as fast. Crucially, we can still speed up training even after we have already reached the point at which additional parallelism provides no benefit for synchronous or asynchronous stochastic gradient descent. Two neural networks trained on disjoint subsets of the data can share knowledge by encouraging each model to agree with the predictions the other model would have made. These predictions can come from a stale version of the other model so they can be safely computed using weights that only rarely get transmitted. Our second claim is that online distillation is a cost-effective way to make the exact predictions of a model dramatically more reproducible. We support our claims using experiments on the Criteo Display Ad Challenge dataset, ImageNet, and the largest to-date dataset used for neural language modeling, containing $6\\times 10^{11}$ tokens and based on the Common Crawl repository of web data.|sl:arxiv_author|Geoffrey E. Hinton
LinkNBed: Multi-Graph Representation Learning with Entity Linkage   a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure     We posit that combining  graph alignment task with deep representation  learning across multi-relational graphs has potential  to induce a synergistic effect on both tasks Knowledge graphs have emerged as an important model for studying complex multi-relational data. This has given rise to the construction of numerous large scale but incomplete knowledge graphs encoding information extracted from various resources. An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledge-based inference for many downstream applications. To this end, we propose LinkNBed, a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure. Experiments on link prediction and entity linkage demonstrate substantial improvements over the state-of-the-art relational learning approaches.|sl:arxiv_author|Xin Luna Dong
Marchés financiers|skos:broader|Economie
Knowledge Representation|skos:broader|Artificial Intelligence
Linked Data demo|skos:broader|SW demo
Lutte anti-terroriste|skos:broader|Terrorisme
MOAT|skos:broader|Tagging
Reasoning|skos:broader|Logic
Euro|skos:broader|Money
Unsupervised Deep Embedding for Clustering Analysis Relatively little work has focused on learning representations for clustering. In this paper, we propose Deep Embedded Clustering (DEC), a method that simultaneously learns feature representations and cluster assignments using deep neural networks. DEC learns a mapping from the data space to a lower-dimensional feature space in which it iteratively optimizes a clustering objective Clustering is central to many data-driven application domains and has been studied extensively in terms of distance functions and grouping algorithms. Relatively little work has focused on learning representations for clustering. In this paper, we propose Deep Embedded Clustering (DEC), a method that simultaneously learns feature representations and cluster assignments using deep neural networks. DEC learns a mapping from the data space to a lower-dimensional feature space in which it iteratively optimizes a clustering objective. Our experimental evaluations on image and text corpora show significant improvement over state-of-the-art methods.|sl:tag|tag:arxiv_doc
Linear Algebraic Structure of Word Senses, with Applications to Polysemy  Here it is shown that multiple word senses reside  in linear superposition within the word  embedding and simple sparse coding can recover  vectors that approximately capture the  senses     Each extracted word sense is accompanied by one of about  2000 “discourse atoms” that gives a succinct description of which other words co-occur with that word sense.     The success of the approach is mathematically explained using a variant of  the random walk on discourses model    (random walk: a generative model for language). Under the assumptions of this model,  there  exists a linear relationship between the vector of a  word w and the vectors of the words in its contexts (It is not the average of the words in w's context, but in a given corpus the matrix of the linear relationship does not depend on w. It can be estimated, and so we can compute the embedding of a word from the contexts it belongs to)    [Related blog post](/doc/?uri=https%3A%2F%2Fwww.offconvex.org%2F2016%2F07%2F10%2Fembeddingspolysemy%2F)   Word embeddings are ubiquitous in NLP and information retrieval, but it is unclear what they represent when the word is polysemous. Here it is shown that multiple word senses reside in linear superposition within the word embedding and simple sparse coding can recover vectors that approximately capture the senses. The success of our approach, which applies to several embedding methods, is mathematically explained using a variant of the random walk on discourses model (Arora et al., 2016). A novel aspect of our technique is that each extracted word sense is accompanied by one of about 2000 discourse atoms that gives a succinct description of which other words co-occur with that word sense. Discourse atoms can be of independent interest, and make the method potentially more useful. Empirical tests are used to verify and support the theory.|sl:tag|tag:word_embedding
Open University|skos:broader|Université
GraphDB|skos:broader|Graph database
Extinction de masse de la fin du permien|skos:broader|Extinction de masse
Mots/expressions remarquables|skos:broader|Langues
Enswers|skos:broader|Winch 5
NLP@Google|skos:broader|NLP Teams
AppleScript|skos:broader|Mac dev
Graph Attention Networks |skos:broader|Graph neural networks
Fukushima|skos:broader|Japon
Named Entity Recognition with Extremely Limited Data Named Entity Search (NES)     We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.     We do not propose this as a replacement  for NER, but as something to be used for an ephemeral or contextual  class of entity, when it does not make sense to label hundreds or  thousands of instances to learn a classifier Traditional information retrieval treats named entity recognition as a pre-indexing corpus annotation task, allowing entity tags to be indexed and used during search. Named entity taggers themselves are typically trained on thousands or tens of thousands of examples labeled by humans. However, there is a long tail of named entities classes, and for these cases, labeled data may be impossible to find or justify financially. We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.|sl:tag|tag:arxiv_doc
Sylvain|skos:broader|Ami
Boucle ferroviaire d’Afrique de l’Ouest|skos:broader|Afrique de l'Ouest
Jussieu|skos:broader|Sorbonne
Cascade|skos:broader|Eau
Similarity Search for Efficient Active Learning and Search of Rare Concepts  Similarity search for Efficient Active Learning and Search (SEALS)    In [Active Learning](tag:active_learning): instead of searching globally for the optimal examples to label, leverage the fact that data is often heavily skewed and expand the candidate pool with the nearest neighbors of the labeled set.     Our work attacks both the labeling and computational costs of machine learning...SEALS dramatically reduces the barrier to machine learning, enabling small teams or individuals to  build accurate classifiers. SEALS does, however, introduce another system component, a similarity  search index, which adds some additional engineering complexity to build, tune, and maintain.  Fortunately, several highly optimized implementations like Annoy and [Faiss](doc:2020/06/facebookresearch_faiss_a_libra) work reasonably well  out of the box. Many active learning and search approaches are intractable for industrial settings with billions of unlabeled examples. Existing approaches, such as uncertainty sampling or information density, search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. However, in practice, data is often heavily skewed; only a small fraction of collected data will be relevant for a given learning task. For example, when identifying rare classes, detecting malicious content, or debugging model performance, the ratio of positive to negative examples can be 1 to 1,000 or more. In this work, we exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round by only looking at the nearest neighbors to the labeled examples. Empirically, we observe that learned representations effectively cluster unseen concepts, making active learning very effective and substantially reducing the number of viable unlabeled examples. We evaluate several active learning and search techniques in this setting on three large-scale datasets: ImageNet, Goodreads spoiler detection, and OpenImages. For rare classes, active learning methods need as little as 0.31% of the labeled data to match the average precision of full supervision. By limiting active learning methods to only consider the immediate neighbors of the labeled data as candidates for labeling, we need only process as little as 1% of the unlabeled data while achieving similar reductions in labeling costs as the traditional global approach. This process of expanding the candidate pool with the nearest neighbors of the labeled set can be done efficiently and reduces the computational complexity of selection by orders of magnitude.|sl:arxiv_author|Alexander C. Berg
Squeak|skos:broader|Smalltalk
Championnat du monde d'athlétisme|skos:broader|Championnat du monde
Data Visualization Tools|skos:broader|Data visualisation
A Little Annotation does a Lot of Good: A Study in Bootstrapping Low-resource Named Entity Recognizers Most state-of-the-art models for named entity recognition (NER) rely on the availability of large amounts of labeled data, making them challenging to extend to new, lower-resourced languages. However, there are now several proposed approaches involving either cross-lingual transfer learning, which learns from other highly resourced languages, or active learning, which efficiently selects effective training data based on model predictions. This paper poses the question: given this recent progress, and limited human annotation, what is the most effective method for efficiently creating high-quality entity recognizers in under-resourced languages? Based on extensive experimentation using both simulated and real human annotation, we find a dual-strategy approach best, starting with a cross-lingual transferred model, then performing targeted annotation of only uncertain entity spans in the target language, minimizing annotator effort. Results demonstrate that cross-lingual transfer is a powerful tool when very little data can be annotated, but an entity-targeted annotation strategy can achieve competitive accuracy quickly, with just one-tenth of training data.|sl:arxiv_author|Zaid Sheikh
Biotechnologies Biotechnologies|skos:broader|Technologie
Linear algebra|skos:broader|Algèbre
Technique of analyzing relationships between a set of documents and the terms they contain, by producing a set of concepts related to the documents and terms. LSA assumes that words that are close in meaning will occur in similar pieces of text.    LSI transforms documents from either bag-of-words or (preferrably) TfIdf-weighted space into a latent space of a lower dimensionality.    A matrix containing word counts (in lines) per paragraph (column) is constructed from a large piece of text. [Singular value decomposition (SVD)](singular_value_decomposition) is used to reduce the number of rows while preserving the similarity structure among columns. Similarities between words and/or docs can then be evaluated using cosine-distance in the low-dimensional space    - pros:      - alleviate the problem of synonymy (note: wikipedia se contredit en ce qui concerne la polysémie. Je dirais que LSI ne peut pas régler ce pb)      - can output topics in a ranked order.   - cons:      - requires a num_topics parameter.      - dimensions have no easily interpretable meaning in natural language      - SVD is computation intensive (still a pb with improved algos?)      - wikipedia says that the probabilistic model of LSA does not match observed data: LSA assumes that words and documents form a joint Gaussian model (ergodic hypothesis), while a Poisson distribution has been observed. Thus, a newer alternative is probabilistic latent semantic analysis, based on a multinomial model, which is reported to give better results than standard LSA    [Gensim tuto about transformations](https://markroxor.github.io/gensim/static/notebooks/Topics_and_Transformations.html) says that LSI training is unique in that it can continue at any point, simply by providing more training documents.    (LSI or LSA ? Truncated SVD applied to document similarity is called Latent Semantic Indexing (LSI), but it is called Latent Semantic Analysis (LSA) when applied to word similarity.)      4 ways of looking at the Truncated SVD ([cf.](http://www.jair.org/media/2934/live-2934-4846-jair.pdf)) :    - Latent meaning: the truncated SVD creates a low-dimensional linear mapping between words in row space and context in columns which captures the hidden (latent) meaning in the words and contexts    - Noise reduction: the truncated SVD can be seen as a smoothed version of the original matrix ( which captures the signal and leaves out the noise)    - A way to discover high-order co-occurrence: when 2 words appear in similar context    - Sparsity reduction: the origin matrix is sparse, but the truncated SVD is dense. Sparsity may be viewed as a problem of insufficient data and truncated SVD as a way of simulating the missing text    [See also Introduction to Information Retrieval Manning 2008](https://nlp.stanford.edu/IR-book/html/htmledition/latent-semantic-indexing-1.html)                                      |skos:broader|Algebraic model for representing text documents as vectors of identifiers such as index terms.br/  Documents and queries are represented as vectors.  Each dimension corresponds to a separate term. If a term occurs in the document, its value in the vector is non-zero. One way of computing the value: TD-IDF          
Graph Convolution for Multimodal Information Extraction from Visually Rich Documents Visually rich documents (VRDs) are ubiquitous in daily business and life. Examples are purchase receipts, insurance policy documents, custom declaration forms and so on. In VRDs, visual and layout information is critical for document understanding, and texts in such documents cannot be serialized into the one-dimensional sequence without losing information. Classic information extraction models such as BiLSTM-CRF typically operate on text sequences and do not incorporate visual features. In this paper, we introduce a graph convolution based model to combine textual and visual information presented in VRDs. Graph embeddings are trained to summarize the context of a text segment in the document, and further combined with text embeddings for entity extraction. Extensive experiments have been conducted to show that our method outperforms BiLSTM-CRF baselines by significant margins, on two real-world datasets. Additionally, ablation studies are also performed to evaluate the effectiveness of each component of our model.|sl:tag|tag:arxiv_doc
Allen Institute for AI (A2I)|skos:broader|NLP Teams
Few-shot learning|skos:broader|Machine learning
Rayons cosmiques|skos:broader|Astronomie
Archéologie|skos:broader|Science
Impôt|skos:broader|Prélèvements obligatoires
Seq2Seq with Attention|skos:broader|Sequence-to-sequence learning
BAM! Born-Again Multi-Task Networks for Natural Language Understanding  knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers It can be challenging to train multi-task neural networks that outperform or even match their single-task counterparts. To help address this, we propose using knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers. We evaluate our approach by multi-task fine-tuning BERT on the GLUE benchmark. Our method consistently improves over standard single-task and multi-task training.|sl:arxiv_author|Urvashi Khandelwal
JavaScript framework|skos:broader|js
Romancier|skos:broader|Intellectuel
XMLHttpRequest|skos:broader|Web app dev
Entities as Experts: Sparse Memory Access with Entity Supervision   the problem of capturing declarative knowledge in the learned parameters of a language model...     Entities as Experts (EaE) can access distinct memories of the entities mentioned in a piece of text;     To understand the motivation for distinct and  independent entity representations: A traditional Transformer would need to build an internal representation  of Charles Darwin from the words “Charles”  and “Darwin”... Conversely, EAE can access  a dedicated representation of “Charles Darwin”,  which is a memory of all of the contexts in which  this entity has previously been mentioned.... Having retrieved  and re-integrated this memory it is much easier for  EAE to relate the question to the answer     EaE's entity representations are learned directly from text. Correct identification, and representation, of entities is essential to EaE's performance    Based on transformer architecture    Extension: [Facts as Experts](doc:2020/07/2007_00849_facts_as_experts_) We focus on the problem of capturing declarative knowledge in the learned parameters of a language model. We introduce a new model, Entities as Experts (EaE), that can access distinct memories of the entities mentioned in a piece of text. Unlike previous efforts to integrate entity knowledge into sequence models, EaE's entity representations are learned directly from text. These representations capture sufficient knowledge to answer TriviaQA questions such as Which Dr. Who villain has been played by Roger Delgado, Anthony Ainley, Eric Roberts?. EaE outperforms a Transformer model with $30\\times$ the parameters on this task. According to the Lama knowledge probes, EaE also contains more factual knowledge than a similar sized Bert. We show that associating parameters with specific entities means that EaE only needs to access a fraction of its parameters at inference time, and we show that the correct identification, and representation, of entities is essential to EaE's performance. We also argue that the discrete and independent entity representations in EaE make it more modular and interpretable than the Transformer architecture on which it is based.|sl:arxiv_firstAuthor|Thibault Févry
Benjamin Franklin|skos:broader|Grand Homme
Stanford POS Tagger|skos:broader|NLP@Stanford
Accelerated Mobile Pages (AMP)|skos:broader|Google
Antibiotic resistance|skos:broader|Grands problèmes
Archéologie amazonienne|skos:broader|Indiens du Brésil
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Daan Wierstra
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:arxiv_author|Daniel Rodriguez
Tim Bray|skos:broader|Technical girls and guys
Finlande|skos:broader|Pays d'Europe
Snorkel|skos:broader|Labeled Data
Thriller|skos:broader|Film
Sumer|skos:broader|Mésopotamie
NLP: book|skos:broader|AI: books & journals
CoKE: Contextualized Knowledge Graph Embedding A method to build contextualized entity and relation embeddings. Entities and relations may appear in different graph contexts. Edges and paths, both formulated as sequences of entities and relations, are passed as input to a Transformer encoder to learn the contextualized representations..    [Github](https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE) Knowledge graph embedding, which projects symbolic entities and relations into continuous vector spaces, is gaining increasing attention. Previous methods allow a single static embedding for each entity or relation, ignoring their intrinsic contextual nature, i.e., entities and relations may appear in different graph contexts, and accordingly, exhibit different properties. This work presents Contextualized Knowledge Graph Embedding (CoKE), a novel paradigm that takes into account such contextual nature, and learns dynamic, flexible, and fully contextualized entity and relation embeddings. Two types of graph contexts are studied: edges and paths, both formulated as sequences of entities and relations. CoKE takes a sequence as input and uses a Transformer encoder to obtain contextualized representations. These representations are hence naturally adaptive to the input, capturing contextual meanings of entities and relations therein. Evaluation on a wide variety of public benchmarks verifies the superiority of CoKE in link prediction and path query answering. It performs consistently better than, or at least equally well as current state-of-the-art in almost every case, in particular offering an absolute improvement of 21.0% in H@10 on path query answering. Our code is available at \\url{https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE}.|sl:arxiv_author|Pingping Huang
String-searching algorithm|skos:broader|Text processing
Programming|skos:broader|Dev
Realistic Re-evaluation of Knowledge Graph Completion Methods: An Experimental Study data redundancy (reverse relations), Cartesian product relations     A more fundamental defect  of these models is that the link prediction scenario, given  such data, is non-existent in the real-world In the active research area of employing embedding models for knowledge graph completion, particularly for the task of link prediction, most prior studies used two benchmark datasets FB15k and WN18 in evaluating such models. Most triples in these and other datasets in such studies belong to reverse and duplicate relations which exhibit high data redundancy due to semantic duplication, correlation or data incompleteness. This is a case of excessive data leakage---a model is trained using features that otherwise would not be available when the model needs to be applied for real prediction. There are also Cartesian product relations for which every triple formed by the Cartesian product of applicable subjects and objects is a true fact. Link prediction on the aforementioned relations is easy and can be achieved with even better accuracy using straightforward rules instead of sophisticated embedding models. A more fundamental defect of these models is that the link prediction scenario, given such data, is non-existent in the real-world. This paper is the first systematic study with the main objective of assessing the true effectiveness of embedding models when the unrealistic triples are removed. Our experiment results show these models are much less accurate than what we used to perceive. Their poor accuracy renders link prediction a task without truly effective automated solution. Hence, we call for re-investigation of possible effective approaches.|sl:arxiv_author|Mohammed Samiul Saeef Department of Computer Science and Engineering, University of Texas at Arlington
Scandale des écoutes en Allemagne|skos:broader|Angela Merkel
Semantic Web Services|skos:broader|Web Services
Pays-Bas|skos:broader|Europe
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:arxiv_firstAuthor|Yonatan Bisk
Cambridge Analytica|skos:broader|Facebook
No more DRM|skos:broader|DRM
Sahara|skos:broader|Afrique
Natural Language Processing with Small Feed-Forward Networks google guys:      We show that small and shallow feed- forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.   We show that small and shallow feed-forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.|sl:arxiv_author|Alex Salcianu
Semantic Vector Encoding and Similarity Search Using Fulltext Search Engines  The ubiquity of semantic vector space modeling raises the challenge of efficient searching in dense, high-dimensional vector spaces. We would naturally want to take advantage of the design and optimizations behind modern fulltext engines like Elasticsearch so as to meet the scalability and robustness demands of modern IR applications. This is the research challenge addressed in this paper.   The paper describes novel ways of encoding dense vectors into text documents, allowing the use of traditional inverted index engines.    [blog post](https://rare-technologies.com/semantic-search-fulltext-engine-acl-2017/)   Vector representations and vector space modeling (VSM) play a central role in modern machine learning. We propose a novel approach to `vector similarity searching' over dense semantic representations of words and documents that can be deployed on top of traditional inverted-index-based fulltext engines, taking advantage of their robustness, stability, scalability and ubiquity. We show that this approach allows the indexing and querying of dense vectors in text domains. This opens up exciting avenues for major efficiency gains, along with simpler deployment, scaling and monitoring. The end result is a fast and scalable vector database with a tunable trade-off between vector search performance and quality, backed by a standard fulltext engine such as Elasticsearch. We empirically demonstrate its querying performance and quality by applying this solution to the task of semantic searching over a dense vector representation of the entire English Wikipedia.|sl:arxiv_author|Jan Pomikálek
Logic and semantic web|skos:broader|Semantic Web
AutoML-Zero: Evolving Machine Learning Algorithms From Scratch  Fun AutoML-Zero experiments: Evolutionary search discovers fundamental ML algorithms from scratch, e.g., small neural nets with backprop.   Can evolution be the “Master Algorithm”? ;) Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.|sl:tag|tag:backpropagation_vs_biology
Banlieue|skos:broader|Société
public-lod@w3.org|skos:broader|Mailing list
Deep Learning for Symbolic Mathematics Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.|sl:arxiv_author|Guillaume Lample
Orson Welles|skos:broader|Réalisateur
Zero-shot Entity Linking|skos:broader|Entity linking
Orri Erling|skos:broader|Technical girls and guys
Virtuoso Open-Source Edition|skos:broader|Virtuoso
LOD & museum|skos:broader|Linking Open Data
Open University|skos:broader|Education
4store|skos:broader|TripleStore
Global brain|skos:broader|Anticipation
Gravity|skos:broader|Physics
Sarkozy et extrème droite|skos:broader|Sarkozyland
P=NP|skos:broader|Grands problèmes mathématiques
Automotive Ontology Working Group|skos:broader|Automobile
RDF embeddings|skos:broader|RDF
Synthetic life|skos:broader|Genetics Génétique
Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call fooling images (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.|sl:arxiv_author|Jeff Clune
Differentiable Top-k Operator with Optimal Transport  if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator   ...   We apply the proposed operator to the [k-nearest neighbors](tag:k_nearest_neighbors_algorithm) and [beam search](tag:beam_search) algorithms, and demonstrate improved performance The top-k operation, i.e., finding the k largest or smallest elements from a collection of scores, is an important model component, which is widely used in information retrieval, machine learning, and data mining. However, if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator. Specifically, our SOFT top-k operator approximates the output of the top-k operation as the solution of an Entropic Optimal Transport (EOT) problem. The gradient of the SOFT operator can then be efficiently approximated based on the optimality conditions of EOT problem. We apply the proposed operator to the k-nearest neighbors and beam search algorithms, and demonstrate improved performance.|sl:arxiv_author|Hanjun Dai
DBTune|skos:broader|Musique
Venus Express|skos:broader|Vénus
Identifying triples|skos:broader|RDF
Dereferencing HTTP URIs|skos:broader|URI dereferencing
Semantic Web : entreprise Semantic Web: enterprise|skos:broader|Web sémantique sw
Histoire des Jermas|skos:broader|Histoire de l'Afrique
Topic Modeling over Short Texts by Incorporating Word Embeddings New method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo-texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic Inferring topics from the overwhelming amount of short texts becomes a critical but challenging task for many content analysis tasks, such as content charactering, user interest profiling, and emerging topic detecting. Existing methods such as probabilistic latent semantic analysis (PLSA) and latent Dirichlet allocation (LDA) cannot solve this prob- lem very well since only very limited word co-occurrence information is available in short texts. This paper studies how to incorporate the external word correlation knowledge into short texts to improve the coherence of topic modeling. Based on recent results in word embeddings that learn se- mantically representations for words from a large corpus, we introduce a novel method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo- texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic. The experiments on real-world datasets validate the effectiveness of our model comparing with the state-of-the-art models.|sl:tag|tag:topic_models_word_embedding
Recurrent Memory Networks for Language Modeling  Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge.     In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data.     We demonstrate the power of RMN on language modeling and sentence completion tasks.     On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.   Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge. In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data. We demonstrate the power of RMN on language modeling and sentence completion tasks. On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.|sl:arxiv_author|Christof Monz
Marchés financiers|skos:broader|Finance
Graph Convolution for Multimodal Information Extraction from Visually Rich Documents Visually rich documents (VRDs) are ubiquitous in daily business and life. Examples are purchase receipts, insurance policy documents, custom declaration forms and so on. In VRDs, visual and layout information is critical for document understanding, and texts in such documents cannot be serialized into the one-dimensional sequence without losing information. Classic information extraction models such as BiLSTM-CRF typically operate on text sequences and do not incorporate visual features. In this paper, we introduce a graph convolution based model to combine textual and visual information presented in VRDs. Graph embeddings are trained to summarize the context of a text segment in the document, and further combined with text embeddings for entity extraction. Extensive experiments have been conducted to show that our method outperforms BiLSTM-CRF baselines by significant margins, on two real-world datasets. Additionally, ablation studies are also performed to evaluate the effectiveness of each component of our model.|sl:tag|tag:information_extraction
Deep Patent Landscaping Model Using Transformer and Graph Embedding a transformer encoder  for analyzing textual data present in patent documents  and a graph convolutional network for analyzing  patent metadata.    A benchmarking dataset for patent landscaping  based on patent trends reports published by the  Korean Patent Office. Data acquisition using Google's BigQuery public datasets.    10% improvement comparing to Google’s proposed Automated Patent Landscaping.    Empirical analysis of the importance of features (text vs metadata, citations vs classification)     Patent landscaping is a method used for searching related patents during a research and development (R&D) project. To avoid the risk of patent infringement and to follow current trends in technology, patent landscaping is a crucial task required during the early stages of an R&D project. As the process of patent landscaping requires advanced resources and can be tedious, the demand for automated patent landscaping has been gradually increasing. However, a shortage of well-defined benchmark datasets and comparable models makes it difficult to find related research studies. In this paper, we propose an automated patent landscaping model based on deep learning. To analyze the text of patents, the proposed model uses a modified transformer structure. To analyze the metadata of patents, we propose a graph embedding method that uses a diffusion graph called Diff2Vec. Furthermore, we introduce four benchmark datasets for comparing related research studies in patent landscaping. The datasets are produced by querying Google BigQuery, based on a search formula from a Korean patent attorney. The obtained results indicate that the proposed model and datasets can attain state-of-the-art performance, as compared with current patent landscaping models.|sl:tag|tag:attention_is_all_you_need
Word embeddings|skos:broader|Distributional semantics
Industrie de l'armement|skos:broader|industrie
Missing Labels (ML)|skos:broader|Machine learning: problems
Differentiable Reasoning over a Virtual Knowledge Base  We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases.    [(Bhuwan Dhingra PhD Thesis)](doc:2020/07/end_to_end_learning_with_text_) We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. On HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking approach to retrieving the relevant passages required to answer a question. DrKIT is also very efficient, processing 10-100x more queries per second than existing multi-hop systems.|sl:arxiv_firstAuthor|Bhuwan Dhingra
Concept Bottleneck Models  We seek to learn models that we can interact with using high-level concepts... We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these concept bottleneck models by editing their predicted concept values and propagating these changes to the final prediction... These models allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time. We seek to learn models that we can interact with using high-level concepts: if the model did not think there was a bone spur in the x-ray, would it still predict severe arthritis? State-of-the-art models today do not typically support the manipulation of concepts like the existence of bone spurs, as they are trained end-to-end to go directly from raw input (e.g., pixels) to output (e.g., arthritis severity). We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these \\emph{concept bottleneck models} by editing their predicted concept values and propagating these changes to the final prediction. On x-ray grading and bird identification, concept bottleneck models achieve competitive accuracy with standard end-to-end models, while enabling interpretation in terms of high-level clinical concepts (bone spurs) or bird attributes (wing color). These models also allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time.|sl:arxiv_author|Yew Siang Tang
Named Entity Recognition|skos:broader|NLP tasks / problems
The information bottleneck method  We define the relevant information in a signal x ∈ X as being the information that this signal provides about another signal y ∈ Y. Examples include the information that face images provide about the names of the people portrayed, or the information that speech sounds provide about the words spoken. Understanding the signal x requires more than just predicting y, it also requires specifying which features of X play a role in the prediction. We formalize this problem as that of finding a short code for X that preserves the maximum information about Y. That is, we squeeze the information that X provides about Y through a ‘bottleneck’ formed by a limited set of codewords X ̃... This approach yields an exact set of self consistent equations for the coding rules X → X ̃ and X ̃ → Y .    (from the intro) : how to define meaningful / relevant information? An issue left out of information theory by Shannon (focus on the problem of transmitting information rather than judging its value to the recipient) -leads to  consider statistical and information theoretic principles as almost irrelevant  for the question of meaning.      In contrast, we argue here that information theory,  in particular lossy source compression, provides a natural quantitative  approach to the question of “relevant information.” Specifically, we formulate  a variational principle for the extraction or efficient representation of  relevant information.     We define the relevant information in a signal $x\\in X$ as being the information that this signal provides about another signal $y\\in \\Y$. Examples include the information that face images provide about the names of the people portrayed, or the information that speech sounds provide about the words spoken. Understanding the signal $x$ requires more than just predicting $y$, it also requires specifying which features of $\\X$ play a role in the prediction. We formalize this problem as that of finding a short code for $\\X$ that preserves the maximum information about $\\Y$. That is, we squeeze the information that $\\X$ provides about $\\Y$ through a `bottleneck' formed by a limited set of codewords $\\tX$. This constrained optimization problem can be seen as a generalization of rate distortion theory in which the distortion measure $d(x,\\x)$ emerges from the joint statistics of $\\X$ and $\\Y$. This approach yields an exact set of self consistent equations for the coding rules $X \\to \\tX$ and $\\tX \\to \\Y$. Solutions to these equations can be found by a convergent re-estimation method that generalizes the Blahut-Arimoto algorithm. Our variational principle provides a surprisingly rich framework for discussing a variety of problems in signal processing and learning, as will be described in detail elsewhere.|sl:arxiv_author|Fernando C. Pereira ATT Shannon Laboratory
Spectral clustering|skos:broader|Clustering
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:tag|tag:google_research
Ethnologie|skos:broader|Géographie
Times|skos:broader|Presse
PCA is a statistical procedure that converts a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components.    - PCA is based on extracting the axes on which the data shows the highest variability.    PCA can be done by eigenvalue decomposition of a data covariance matrix or singular value decomposition of a data matrix, usually after mean centering and normalizing the data matrix for each attribute|skos:broader|In machine learning, unsupervised learning refers to the problem of trying to find hidden structure in unlabeled data
Orri Erling|skos:broader|OpenLink Software
Quora Question Pairs|skos:broader|Paraphrase identification
SWSE|skos:broader|Semantic Search
Mbilia Bel|skos:broader|Music of Africa
Learning Semantic Similarity for Very Short Texts In order to pair short text  fragments—as a concatenation of separate words—an adequate  distributed sentence representation is needed. Main contribution: a first step towards a hybrid method that  combines the strength of dense distributed representations—  as opposed to sparse term matching—with the strength of  tf-idf based methods. The combination of word embeddings and tf-idf  information might lead to a better model for semantic content  within very short text fragments. Levering data on social media, such as Twitter and Facebook, requires information retrieval algorithms to become able to relate very short text fragments to each other. Traditional text similarity methods such as tf-idf cosine-similarity, based on word overlap, mostly fail to produce good results in this case, since word overlap is little or non-existent. Recently, distributed word representations, or word embeddings, have been shown to successfully allow words to match on the semantic level. In order to pair short text fragments - as a concatenation of separate words - an adequate distributed sentence representation is needed, in existing literature often obtained by naively combining the individual word representations. We therefore investigated several text representations as a combination of word embeddings in the context of semantic pair matching. This paper investigates the effectiveness of several such naive techniques, as well as traditional tf-idf similarity, for fragments of different lengths. Our main contribution is a first step towards a hybrid method that combines the strength of dense distributed representations - as opposed to sparse term matching - with the strength of tf-idf based methods to automatically reduce the impact of less informative terms. Our new approach outperforms the existing techniques in a toy experimental set-up, leading to the conclusion that the combination of word embeddings and tf-idf information might lead to a better model for semantic content within very short text fragments.|sl:arxiv_author|Thomas Demeester
Charlie Hebdo|skos:broader|Rigolo
Apache Shiro|skos:broader|apache.org
Ammonite|skos:broader|Fossile
Tag Clusters|skos:broader|Semanlink related
BERT-of-Theseus: Compressing BERT by Progressive Module Replacing approach to compress BERT by progressive module replacing.     Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter    [Github](https://github.com/JetRunner/BERT-of-Theseus) In this paper, we propose a novel model compression approach to effectively compress BERT by progressive module replacing. Our approach first divides the original BERT into several modules and builds their compact substitutes. Then, we randomly replace the original modules with their substitutes to train the compact modules to mimic the behavior of the original modules. We progressively increase the probability of replacement through the training. In this way, our approach brings a deeper level of interaction between the original and compact models, and smooths the training process. Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter, liberating human effort from hyper-parameter tuning. Our approach outperforms existing knowledge distillation approaches on GLUE benchmark, showing a new perspective of model compression.|sl:tag|tag:arxiv_doc
NLP: Text Representation|skos:broader|NLP techniques
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:tag|tag:meaning_in_nlp
Graph Convolution for Multimodal Information Extraction from Visually Rich Documents Visually rich documents (VRDs) are ubiquitous in daily business and life. Examples are purchase receipts, insurance policy documents, custom declaration forms and so on. In VRDs, visual and layout information is critical for document understanding, and texts in such documents cannot be serialized into the one-dimensional sequence without losing information. Classic information extraction models such as BiLSTM-CRF typically operate on text sequences and do not incorporate visual features. In this paper, we introduce a graph convolution based model to combine textual and visual information presented in VRDs. Graph embeddings are trained to summarize the context of a text segment in the document, and further combined with text embeddings for entity extraction. Extensive experiments have been conducted to show that our method outperforms BiLSTM-CRF baselines by significant margins, on two real-world datasets. Additionally, ablation studies are also performed to evaluate the effectiveness of each component of our model.|sl:arxiv_firstAuthor|Xiaojing Liu
Crise financière|skos:broader|Marchés financiers
Glaciologie|skos:broader|Science
instead of just processing the words in a sentence from left to right, also go from right to left, allowing later words to help disambiguate the meaning of earlier words and phrases|skos:broader|Long short-term memory: recurrent neural network architecture well-suited for time series with long time lags between important events.  (cf the problem of long time dependencies, such as when you want to predict the next word in I grew up in France… I speak fluent [?]).    A solution to the vanishing gradient problem in RNNs          
Hello Edge: Keyword Spotting on Microcontrollers Keyword spotting (KWS) is a critical component for enabling speech based user interactions on smart devices. It requires real-time response and high accuracy for good user experience. Recently, neural networks have become an attractive choice for KWS architecture because of their superior accuracy compared to traditional speech processing algorithms. Due to its always-on nature, KWS application has highly constrained power budget and typically runs on tiny microcontrollers with limited memory and compute capability. The design of neural network architecture for KWS must consider these constraints. In this work, we perform neural network architecture evaluation and exploration for running KWS on resource-constrained microcontrollers. We train various neural network architectures for keyword spotting published in literature to compare their accuracy and memory/compute requirements. We show that it is possible to optimize these neural network architectures to fit within the memory and compute constraints of microcontrollers without sacrificing accuracy. We further explore the depthwise separable convolutional neural network (DS-CNN) and compare it against other neural network architectures. DS-CNN achieves an accuracy of 95.4%, which is ~10% higher than the DNN model with similar number of parameters.|sl:arxiv_author|Yundong Zhang
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:tag|tag:arxiv_doc
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:arxiv_author|Yintao Liu
fps@EC-Web'14|skos:broader|Semantic SEO
RDF|skos:broader|Semantic Web
Sparte|skos:broader|Grèce antique
Sarkozy et extrème droite|skos:broader|Sarkozy
Learning Confidence for Out-of-Distribution Detection in Neural Networks Modern neural networks are very powerful predictive models, but they are often incapable of recognizing when their predictions may be wrong. Closely related to this is the task of out-of-distribution detection, where a network must determine whether or not an input is outside of the set on which it is expected to safely perform. To jointly address these issues, we propose a method of learning confidence estimates for neural networks that is simple to implement and produces intuitively interpretable outputs. We demonstrate that on the task of out-of-distribution detection, our technique surpasses recently proposed techniques which construct confidence based on the network's output distribution, without requiring any additional labels or access to out-of-distribution examples. Additionally, we address the problem of calibrating out-of-distribution detectors, where we demonstrate that misclassified in-distribution examples can be used as a proxy for out-of-distribution examples.|sl:arxiv_firstAuthor|Terrance DeVries
Urbanisation|skos:broader|Monde moderne
SPARQL Construct|skos:broader|SPARQL
Apache Hive|skos:broader|Database
Patrick Gallinari|skos:broader|AI girls and guys
Telelamarna|skos:broader|Akhênaton
L'Afrique à la Bastille - 13 juillet 2007|skos:broader|Liberté, égalité, fraternité
Apache Hive|skos:broader|Data Warehouse
Belzoni|skos:broader|Egypte antique
A Survey on Knowledge Graph Embeddings with Literals: Which model links better Literal-ly? Knowledge Graphs (KGs) are composed of structured information about a particular domain in the form of entities and relations. In addition to the structured information KGs help in facilitating interconnectivity and interoperability between different resources represented in the Linked Data Cloud. KGs have been used in a variety of applications such as entity linking, question answering, recommender systems, etc. However, KG applications suffer from high computational and storage costs. Hence, there arises the necessity for a representation able to map the high dimensional KGs into low dimensional spaces, i.e., embedding space, preserving structural as well as relational information. This paper conducts a survey of KG embedding models which not only consider the structured information contained in the form of entities and relations in a KG but also the unstructured information represented as literals such as text, numerical values, images, etc. Along with a theoretical analysis and comparison of the methods proposed so far for generating KG embeddings with literals, an empirical evaluation of the different methods under identical settings has been performed for the general task of link prediction.|sl:tag|tag:knowledge_graph_embeddings
Smart energy grids|skos:broader|Energie
Machine Learning tool|skos:broader|Machine learning
Compressive Transformers for Long-Range Sequence Modelling  the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning.    [Blog post](/doc/2020/02/a_new_model_and_dataset_for_lon) We present the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning. We find the Compressive Transformer obtains state-of-the-art language modelling results in the WikiText-103 and Enwik8 benchmarks, achieving 17.1 ppl and 0.97 bpc respectively. We also find it can model high-frequency speech effectively and can be used as a memory mechanism for RL, demonstrated on an object matching task. To promote the domain of long-range sequence learning, we propose a new open-vocabulary language modelling benchmark derived from books, PG-19.|sl:tag|tag:arxiv_doc
Words|skos:broader|Langues
Predicting numeric values from text|skos:broader|NLP tasks / problems
SQL to RDF mapping|skos:broader|Relational Databases and the Semantic Web
Semantic Web and OOP|skos:broader|Semantic Web
POS POS Tagging|skos:broader|Sequence Tagging
Linked Data Platform|skos:broader|Read-Write Linked Data
Calais|skos:broader|Semantic Web : Tools
Semantically searchable distributed repository|skos:broader|Semantic Web : Application
Beyond Vector Spaces: Compact Data Representation as Differentiable Weighted Graphs  In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE (Probabilistic Differentiable Graph Embeddings): a method that learns a weighted graph representation of data end-to-end by gradient descent.    [Github](https://github.com/stanis-morozov/prodige)     Learning useful representations is a key ingredient to the success of modern machine learning. Currently, representation learning mostly relies on embedding data into Euclidean space. However, recent work has shown that data in some domains is better modeled by non-euclidean metric spaces, and inappropriate geometry can result in inferior performance. In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE: a method that learns a weighted graph representation of data end-to-end by gradient descent. Greater generality and fewer model assumptions make PRODIGE more powerful than existing embedding-based approaches. We confirm the superiority of our method via extensive experiments on a wide range of tasks, including classification, compression, and collaborative filtering.|sl:tag|tag:poincare_embeddings
Steve Cayzer|skos:broader|HP
OWL 1.1|skos:broader|OWL
Lalibela|skos:broader|Histoire de l'Afrique
Labeling data|skos:broader|Labeled Data
Mladic|skos:broader|Génocide
Continual Lifelong Learning with Neural Networks: A Review Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.|sl:arxiv_author|Stefan Wermter
Java 1.5 Mac OS X|skos:broader|Apple Java
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_firstAuthor|Peter W. Battaglia
AutoML-Zero: Evolving Machine Learning Algorithms From Scratch  Fun AutoML-Zero experiments: Evolutionary search discovers fundamental ML algorithms from scratch, e.g., small neural nets with backprop.   Can evolution be the “Master Algorithm”? ;) Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.|sl:tag|tag:quoc_le
Gilles Taddei|skos:broader|Ami
Beijing Genomics Institute|skos:broader|Génomique
Socrate|skos:broader|Philosophe
GWT|skos:broader|XMLHttpRequest
Mac dev|skos:broader|Macintosh
Self-Taught Convolutional Neural Networks for Short Text Clustering  We propose a flexible short text clustering framework which explores the feasibility and effectiveness of combining CNN and traditional unsupervised dimensionality reduction methods.     Non-biased deep feature representations can be learned through our self- taught CNN framework which does not use any external tags/labels or complicated NLP pre-processing.     The original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations.    [conf paper, same authors](http://www.aclweb.org/anthology/W15-1509) ; [gitgub repo (matlab)](https://github.com/jacoxu/STC2)   Short text clustering is a challenging problem due to its sparseness of text representation. Here we propose a flexible Self-Taught Convolutional neural network framework for Short Text Clustering (dubbed STC^2), which can flexibly and successfully incorporate more useful semantic features and learn non-biased deep text representation in an unsupervised manner. In our framework, the original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations. Extensive experimental results demonstrate that the proposed framework is effective, flexible and outperform several popular clustering methods when tested on three public short text datasets.|sl:tag|tag:surprises_me
Distributed Representations of Sentences and Documents Paragraph Vector: an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents.Represents each document by a dense vector which is trained to predict words in the document. Overcomes the weaknesses of the [Bag Of Words](/tag/bag_of_words) model (order of words, semantic of words)       Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, powerful, strong and Paris are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.|sl:tag|tag:arxiv_doc
Etat de la France|skos:broader|France
Selective Question Answering under Domain Shift How you can get a QA model to abstain from answering when it doesn’t know the answer.     Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. To avoid giving wrong answers, question answering (QA) models need to know when to abstain from answering. Moreover, users often ask questions that diverge from the model's training data, making errors more likely and thus abstention more critical. In this work, we propose the setting of selective question answering under domain shift, in which a QA model is tested on a mixture of in-domain and out-of-domain data, and must answer (i.e., not abstain on) as many questions as possible while maintaining high accuracy. Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. Crucially, the calibrator benefits from observing the model's behavior on out-of-domain data, even if from a different domain than the test data. We combine this method with a SQuAD-trained QA model and evaluate on mixtures of SQuAD and five other QA datasets. Our method answers 56% of questions while maintaining 80% accuracy; in contrast, directly using the model's probabilities only answers 48% at 80% accuracy.|sl:arxiv_author|Percy Liang
Catastrophe écologique|skos:broader|Catastrophe
create.js|skos:broader|JavaScript
Virtuoso Universal Server|skos:broader|Virtuoso
93|skos:broader|Banlieue
Good identifiers for product types based on Wikipediabr/  GoodRelations-compatible OWL DL class definitions for ca. 300,000 types of product or services that have an entry in the English Wikipedia  |skos:broader|An ontology for linking product descriptions and business entities on the Web
Python|skos:broader|Programming language
NLP|skos:broader|Favoris
End-To-End Entity Linking|skos:broader|Entity discovery and linking
Pubby|skos:broader|SPARQL endpoint
Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs [GitHub](https://github.com/deepakn97/relationPrediction) [Blog post](/doc/2020/04/deepak_nathani_%7C_pay_attention_) The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention based feature embedding that captures both entity and relation features in any given entity's neighborhood. Additionally, we also encapsulate relation clusters and multihop relations in our model. Our empirical study offers insights into the efficacy of our attention based model and we show marked performance gains in comparison to state of the art methods on all datasets.|sl:arxiv_author|Charu Sharma
Celera ou Craig Venter|skos:broader|Biotechnologies Biotechnologies
Keyword/keyphrase extraction|skos:broader|Automatic tagging
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:arxiv_author|Lucy Wang
RDF Schema|skos:broader|RDF Vocabularies
Transductive Learning|skos:broader|Machine learning: techniques
Common Web Language|skos:broader|Semantic Web
Rigolo|skos:broader|Fun
Ukraine|skos:broader|Ex URSS URSS
Representation Learning with Contrastive Predictive Coding  a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful [autoregressive models](/tag/autoregressive_model). We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using [negative sampling](/tag/negative_sampling).    a contrastive method that can be applied to any form of data that can be expressed in an ordered sequence: text, speech, video... While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.|sl:arxiv_author|Aaron van den Oord
David Cameron|skos:broader|Royaume Uni
Multiple Knowledge Bases|skos:broader|Knowledge bases
JavaScript DOM|skos:broader|JavaScript
A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efficient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximally preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We first introduce the formal definition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work address these challenges in their solutions. Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efficiency, problem settings, techniques and application scenarios.|sl:arxiv_firstAuthor|Hongyun Cai
huggingface/transformers|skos:broader|Hugging Face
TheWebConf 2018|skos:broader|J'y étais
Relational Databases and the Semantic Web|skos:broader|Database
Manipulations génétiques|skos:broader|Biotechnologies Biotechnologies
Tombouctou|skos:broader|Mali
Deep Learning: A Critical Appraisal Although deep learning has historical roots going back decades, neither the term deep learning nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic (2012) deep network model of Imagenet. What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.|sl:tag|tag:ia_limites
HBase|skos:broader|Big Data
Nasca|skos:broader|Pérou
Antifascisme|skos:broader|Fascisme
SOAP vs REST|skos:broader|Web services : critique
Embeddings|skos:broader|Machine learning: techniques
NoSQL and eventual consistency|skos:broader|NOSQL
Référentiel des opérations|skos:broader|SW in Technical Automotive Documentation
RDF forms|skos:broader|Forms
Tasmanian devil|skos:broader|Espèces menacées
Hierarchical temporal memory|skos:broader|Machine learning: techniques
Overfitting/Generalization|skos:broader|Machine learning: problems
Semantic Folding Theory And its Application in Semantic Fingerprinting Human language is recognized as a very complex domain since decades. No computer system has been able to reach human levels of performance so far. The only known computational system capable of proper language processing is the human brain. While we gather more and more data about the brain, its fundamental computational processes still remain obscure. The lack of a sound computational brain theory also prevents the fundamental understanding of Natural Language Processing. As always when science lacks a theoretical foundation, statistical modeling is applied to accommodate as many sampled real-world data as possible. An unsolved fundamental issue is the actual representation of language (data) within the brain, denoted as the Representational Problem. Starting with Jeff Hawkins' Hierarchical Temporal Memory (HTM) theory, a consistent computational theory of the human cortex, we have developed a corresponding theory of language data representation: The Semantic Folding Theory. The process of encoding words, by using a topographic semantic space as distributional reference frame into a sparse binary representational vector is called Semantic Folding and is the central topic of this document. Semantic Folding describes a method of converting language from its symbolic representation (text) into an explicit, semantically grounded representation that can be generically processed by Hawkins' HTM networks. As it turned out, this change in representation, by itself, can solve many complex NLP problems by applying Boolean operators and a generic similarity function like the Euclidian Distance. Many practical problems of statistical NLP systems, like the high cost of computation, the fundamental incongruity of precision and recall , the complex tuning procedures etc., can be elegantly overcome by applying Semantic Folding.|sl:tag|tag:semantic_folding
Extend SVMs with the aim of max-margin classification while ensuring that there are as few unlabelled observations near the margin as possible  |skos:broader|Reasoning from observed, specific (training) cases to specific (test) cases. In contrast, induction is reasoning from observed training cases to general rules, which are then applied to the test cases
DAO attack|skos:broader|Ethereum
This specification defines a merge of SPARQL and XQuery, and has the potential to bring XML and RDF closer together. XSPARQL provides concise and intuitive solutions for mapping between XML and RDF in either direction, addressing both the use cases of GRDDL and SAWSDL.  |skos:broader|Backed by the flexibility of the RDF data model, and consisting of both a query language and data access protocol SPARQL has the potential to become a key component in Web 2.0 applications. SPARQL could provide a common query language for all Web 2.0 applications.
Yamana|skos:broader|Native americans
Artificial Intelligence|skos:broader|Intelligence
Describing a Knowledge Base We aim to automatically generate natural language descriptions about an input structured knowledge base (KB). We build our generation framework based on a pointer network which can copy facts from the input KB, and add two attention mechanisms: (i) slot-aware attention to capture the association between a slot type and its corresponding slot value; and (ii) a new \\emph{table position self-attention} to capture the inter-dependencies among related slots. For evaluation, besides standard metrics including BLEU, METEOR, and ROUGE, we propose a KB reconstruction based metric by extracting a KB from the generation output and comparing it with the input KB. We also create a new data set which includes 106,216 pairs of structured KBs and their corresponding natural language descriptions for two distinct entity types. Experiments show that our approach significantly outperforms state-of-the-art methods. The reconstructed KB achieves 68.8% - 72.6% F-score.|sl:tag|tag:natural_language_generation
Archéologie africaine|skos:broader|Archéologie
Talis|skos:broader|Semantic web company
RESTful Web Services|skos:broader|Web Services
OKFN Datahub|skos:broader|Data management platform
Paul Miller|skos:broader|SW guys (and girls)
Paléontologie|skos:broader|Science
iphoto|skos:broader|OS X app
JSONP|skos:broader|JSON
J'ai un petit problème avec mon ordinateur|skos:broader|Computers
Universal Language Model Fine-tuning for Text Classification code is available in the fastai lib    [blog post](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html)    [see also](/doc/?uri=https%3A%2F%2Fyashuseth.blog%2F2018%2F06%2F17%2Funderstanding-universal-language-model-fine-tuning-ulmfit%2F)             Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.|sl:tag|tag:transfer_learning_in_nlp
GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden unit), or embedding-free units such as image pixels.|sl:tag|tag:embeddings
Models of consciousness|skos:broader|Conscience
Rio de Janeiro|skos:broader|Ville
Numérisation des œuvres indisponibles|skos:broader|Bibliothèque numérique
BERT-of-Theseus: Compressing BERT by Progressive Module Replacing approach to compress BERT by progressive module replacing.     Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter    [Github](https://github.com/JetRunner/BERT-of-Theseus) In this paper, we propose a novel model compression approach to effectively compress BERT by progressive module replacing. Our approach first divides the original BERT into several modules and builds their compact substitutes. Then, we randomly replace the original modules with their substitutes to train the compact modules to mimic the behavior of the original modules. We progressively increase the probability of replacement through the training. In this way, our approach brings a deeper level of interaction between the original and compact models, and smooths the training process. Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter, liberating human effort from hyper-parameter tuning. Our approach outperforms existing knowledge distillation approaches on GLUE benchmark, showing a new perspective of model compression.|sl:arxiv_author|Canwen Xu
Principal component analysis|skos:broader|Feature learning
Large Memory Layers with Product Keys  a structured memory which can be easily integrated into a neural network. The memory is very large by design and therefore significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time.     a key-value memory layer that can increase model capacity for a negligible computational cost. A 12-layer transformer with a memory outperforms a 24-layer transformer, and is 2x faster!     [Implementation](/doc/2019/08/product_key_memory_pkm_minima) This paper introduces a structured memory which can be easily integrated into a neural network. The memory is very large by design and significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time. This memory layer allows us to tackle very large scale language modeling tasks. In our experiments we consider a dataset with up to 30 billion words, and we plug our memory layer in a state-of-the-art transformer-based architecture. In particular, we found that a memory augmented model with only 12 layers outperforms a baseline transformer model with 24 layers, while being twice faster at inference time. We release our code for reproducibility purposes.|sl:arxiv_firstAuthor|Guillaume Lample
Continual Lifelong Learning with Neural Networks: A Review Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.|sl:tag|tag:arxiv_doc
Histoire du Niger|skos:broader|Niger
URI Synonymity|skos:broader|URI
Gautier Poupeau|skos:broader|SW guys (and girls)
Brinxmat|skos:broader|SW guys (and girls)
Mer|skos:broader|Géographie
Cost of Linked Data|skos:broader|Linked Data
Feature extraction|skos:broader|Features (Machine Learning)
Délocalisation des services|skos:broader|Délocalisations
Meetup Web Sémantique|skos:broader|Semantic Web
Commission européenne|skos:broader|Institutions européennes
Semantic data|skos:broader|Semantic Web
Swoogle|skos:broader|RDF Data source
USA|skos:broader|Amérique
KGE KG embedding Knowledge graph embedding|skos:broader|Knowledge Graph KG
AI girls and guys|skos:broader|Technical girls and guys
Microsoft|skos:broader|Entreprise
An efficient framework for learning sentence representations Quick Thoughts. Framework for learning sentence representations from unlabelled data.     we reformulate the problem of predicting the context in which a sentence appears as a classification problem.   In this work we propose a simple and efficient framework for learning sentence representations from unlabelled data. Drawing inspiration from the distributional hypothesis and recent work on learning sentence representations, we reformulate the problem of predicting the context in which a sentence appears as a classification problem. Given a sentence and its context, a classifier distinguishes context sentences from other contrastive sentences based on their vector representations. This allows us to efficiently learn different types of encoding functions, and we show that the model learns high-quality sentence representations. We demonstrate that our sentence representations outperform state-of-the-art unsupervised and supervised representation learning methods on several downstream NLP tasks that involve understanding sentence semantics while achieving an order of magnitude speedup in training time.|sl:tag|tag:nlp_google
A Tutorial on Distance Metric Learning: Mathematical Foundations, Algorithms and Experiments distance metric learning, a branch of machine learning that aims to learn distances from the data Distance metric learning is a branch of machine learning that aims to learn distances from the data. Distance metric learning can be useful to improve similarity learning algorithms, and also has applications in dimensionality reduction. This paper describes the distance metric learning problem and analyzes its main mathematical foundations. In addition, it also discusses some of the most popular distance metric learning techniques used in classification, showing their goals and the required information to understand and use them. Furthermore, some experiments to evaluate the performance of the different algorithms are also provided. Finally, this paper discusses several possibilities of future work in this topic.|sl:tag|tag:survey
Hérédité|skos:broader|Genetics Génétique
Chine-Europe|skos:broader|Europe
A Primer in BERTology: What we know about how BERT works (article praised on [twitter](https://twitter.com/dennybritz/status/1233343170596917248?s=20) by D Britz and Y. Goldberg) Transformer-based models are now widely used in NLP, but we still do not understand a lot about their inner workings. This paper describes what is known to date about the famous BERT model (Devlin et al. 2019), synthesizing over 40 analysis studies. We also provide an overview of the proposed modifications to the model and its training regime. We then outline the directions for further research.|sl:tag|tag:arxiv_doc
Zinder : alimentation en eau|skos:broader|Zinder
Knowledge Enhanced Contextual Word Representations General method to embed multiple knowledge bases into pre-trained language models (KB in the   sense as fixed collection of entity nodes)     The key idea is to explicitly model  entity spans in the input text and use an entity  linker to retrieve relevant entity embeddings from  a KB to form knowledge enhanced entity-span  representations.   Then,  update contextual word representations via a form of word-to-entity attention.    In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert's runtime is comparable to BERT's and it scales to large KBs.|sl:arxiv_author|Matthew E. Peters
SW Wiki|skos:broader|Wiki
css|skos:broader|Web dev
OWLED 2007 AND fps|skos:broader|SW in Technical Automotive Documentation
Rap|skos:broader|Musique
Niger|skos:broader|Afrique de l'Ouest
Vidéo Ina.fr|skos:broader|INA
Périodes glacières|skos:broader|Climat
African land grab|skos:broader|Terres agricoles
C2GWeb-JS|skos:broader|C2GWeb RDF
Differentiable Top-k Operator with Optimal Transport  if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator   ...   We apply the proposed operator to the [k-nearest neighbors](tag:k_nearest_neighbors_algorithm) and [beam search](tag:beam_search) algorithms, and demonstrate improved performance The top-k operation, i.e., finding the k largest or smallest elements from a collection of scores, is an important model component, which is widely used in information retrieval, machine learning, and data mining. However, if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator. Specifically, our SOFT top-k operator approximates the output of the top-k operation as the solution of an Entropic Optimal Transport (EOT) problem. The gradient of the SOFT operator can then be efficiently approximated based on the optimality conditions of EOT problem. We apply the proposed operator to the k-nearest neighbors and beam search algorithms, and demonstrate improved performance.|sl:tag|tag:arxiv_doc
Election|skos:broader|Démocratie
Zhang Qian|skos:broader|Histoire de la Chine
Word sense / Lexical ambiguity|skos:broader|NLP tasks / problems
Binary classification models with \Uncertain\ predictions Binary classification models which can assign probabilities to categories such as the tissue is 75% likely to be tumorous or the chemical is 25% likely to be toxic are well understood statistically, but their utility as an input to decision making is less well explored. We argue that users need to know which is the most probable outcome, how likely that is to be true and, in addition, whether the model is capable enough to provide an answer. It is the last case, where the potential outcomes of the model explicitly include don't know that is addressed in this paper. Including this outcome would better separate those predictions that can lead directly to a decision from those where more data is needed. Where models produce an Uncertain answer similar to a human reply of don't know or 50:50 in the examples we refer to earlier, this would translate to actions such as operate on tumour or remove compound from use where the models give a more true than not answer. Where the models judge the result Uncertain the practical decision might be carry out more detailed laboratory testing of compound or commission new tissue analyses. The paper presents several examples where we first analyse the effect of its introduction, then present a methodology for separating Uncertain from binary predictions and finally, we provide arguments for its use in practice.|sl:arxiv_firstAuthor|Damjan Krstajic
Deep Learning for Symbolic Mathematics Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.|sl:tag|tag:nlp_facebook
PhD Thesis|skos:broader|PhD
Chalutage en eaux profondes|skos:broader|Pêche
A Call for More Rigor in Unsupervised Cross-lingual Learning  a scenario without any parallel data and abundant monolingual data is unrealistic in practice We review motivations, definition, approaches, and methodology for unsupervised cross-lingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of the world's languages. However, we argue that a scenario without any parallel data and abundant monolingual data is unrealistic in practice. We also discuss different training signals that have been used in previous work, which depart from the pure unsupervised setting. We then describe common methodological issues in tuning and evaluation of unsupervised cross-lingual models and present best practices. Finally, we provide a unified outlook for different types of research in this area (i.e., cross-lingual word embeddings, deep multilingual pretraining, and unsupervised machine translation) and argue for comparable evaluation of these models.|sl:arxiv_firstAuthor|Mikel Artetxe
SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver Integrating logical reasoning within deep learning architectures has been a major goal of modern AI systems. In this paper, we propose a new direction toward this goal by introducing a differentiable (smoothed) maximum satisfiability (MAXSAT) solver that can be integrated into the loop of larger deep learning systems. Our (approximate) solver is based upon a fast coordinate descent approach to solving the semidefinite program (SDP) associated with the MAXSAT problem. We show how to analytically differentiate through the solution to this SDP and efficiently solve the associated backward pass. We demonstrate that by integrating this solver into end-to-end learning systems, we can learn the logical structure of challenging problems in a minimally supervised fashion. In particular, we show that we can learn the parity function using single-bit supervision (a traditionally hard task for deep networks) and learn how to play 9x9 Sudoku solely from examples. We also solve a visual Sudok problem that maps images of Sudoku puzzles to their associated logical solutions by combining our MAXSAT solver with a traditional convolutional architecture. Our approach thus shows promise in integrating logical structures within deep learning.|sl:arxiv_author|Po-Wei Wang
Pre-training via Paraphrasing We introduce MARGE, a pre-trained sequence-to-sequence model learned with an unsupervised multi-lingual multi-document paraphrasing objective. MARGE provides an alternative to the dominant masked language modeling paradigm, where we self-supervise the reconstruction of target text by retrieving a set of related texts (in many languages) and conditioning on them to maximize the likelihood of generating the original. We show it is possible to jointly learn to do retrieval and reconstruction, given only a random initialization. The objective noisily captures aspects of paraphrase, translation, multi-document summarization, and information retrieval, allowing for strong zero-shot performance on several tasks. For example, with no additional task-specific training we achieve BLEU scores of up to 35.8 for document translation. We further show that fine-tuning gives strong performance on a range of discriminative and generative tasks in many languages, making MARGE the most generally applicable pre-training method to date.|sl:arxiv_author|Armen Aghajanyan
Matière noire|skos:broader|Missing Matter
NLP tasks / problems|skos:broader|NLP
SW at Renault|skos:broader|Semantic Web
Parrot|skos:broader|RIF
ERNIE: Enhanced Language Representation with Informative Entities  We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.|sl:arxiv_author|Qun Liu
Pre-trained Models for Natural Language Processing: A Survey Recently, the emergence of pre-trained models (PTMs) has brought natural language processing (NLP) to a new era. In this survey, we provide a comprehensive review of PTMs for NLP. We first briefly introduce language representation learning and its research progress. Then we systematically categorize existing PTMs based on a taxonomy with four perspectives. Next, we describe how to adapt the knowledge of PTMs to the downstream tasks. Finally, we outline some potential directions of PTMs for future research. This survey is purposed to be a hands-on guide for understanding, using, and developing PTMs for various NLP tasks.|sl:arxiv_author|Xuanjing Huang
Docker-Tomcat|skos:broader|Tomcat
No Fuss Distance Metric Learning using Proxies  We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity...   Traditionnaly, supervision is expressed in the form of sets of points that follow  an ordinal relationship – an anchor point x is similar to  a set of positive points Y , and dissimilar to a set of negative  points Z, and a loss defined over these distances is minimized.   Triplet-Based methods are challenging to optimize (a main issue is the need for finding informative triplets).     We propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss.    Mentioned in this [blog post](/doc/2020/01/training_a_speaker_embedding_fr):     Proxy based triplet learning: instead of generating triplets, we learn an embedding for each class and use the learnt embedding as a proxy for triplets as part of the training. In other words, we can train end to end without the computationally expensive step of resampling triplets after each network update.    Near the conclusion:     Our formulation of Proxy-NCA loss produces a loss very  similar to the standard cross-entropy loss used in classification.  However, we arrive at our formulation from a different  direction: we are not interested in the actual classifier and  indeed discard the proxies once the model has been trained.  Instead, the proxies are auxiliary variables, enabling more  effective optimization of the embedding model parameters.  As such, our formulation not only enables us to surpass the  state of the art in zero-shot learning, but also offers an explanation  to the effectiveness of the standard trick of training  a classifier, and using its penultimate layer’s output as the  embedding. We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity. Traditionally, for this problem supervision is expressed in the form of sets of points that follow an ordinal relationship -- an anchor point $x$ is similar to a set of positive points $Y$, and dissimilar to a set of negative points $Z$, and a loss defined over these distances is minimized. While the specifics of the optimization differ, in this work we collectively call this type of supervision Triplets and all methods that follow this pattern Triplet-Based methods. These methods are challenging to optimize. A main issue is the need for finding informative triplets, which is usually achieved by a variety of tricks such as increasing the batch size, hard or semi-hard triplet mining, etc. Even with these tricks, the convergence rate of such methods is slow. In this paper we propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss. This proxy-based loss is empirically better behaved. As a result, the proxy-loss improves on state-of-art results for three standard zero-shot learning datasets, by up to 15% points, while converging three times as fast as other triplet-based losses.|sl:arxiv_author|Sergey Ioffe
Chrome|skos:broader|Brouteur
Attention Models in Graphs: A Survey  An attention mechanism aids a model by  allowing it to focus on the most relevant parts of the input to make decisions   Graph-structured data arise naturally in many different application domains. By representing data as graphs, we can capture entities (i.e., nodes) as well as their relationships (i.e., edges) with each other. Many useful insights can be derived from graph-structured data as demonstrated by an ever-growing body of work focused on graph mining. However, in the real-world, graphs can be both large - with many complex patterns - and noisy which can pose a problem for effective graph mining. An effective way to deal with this issue is to incorporate attention into graph mining solutions. An attention mechanism allows a method to focus on task-relevant parts of the graph, helping it to make better decisions. In this work, we conduct a comprehensive and focused survey of the literature on the emerging field of graph attention models. We introduce three intuitive taxonomies to group existing work. These are based on problem setting (type of input and output), the type of attention mechanism used, and the task (e.g., graph classification, link prediction, etc.). We motivate our taxonomies through detailed examples and use each to survey competing approaches from a unique standpoint. Finally, we highlight several challenges in the area and discuss promising directions for future work.|sl:arxiv_firstAuthor|John Boaz Lee
k-means clustering|skos:broader|Machine learning: techniques
Knowledge Enhanced Contextual Word Representations General method to embed multiple knowledge bases into pre-trained language models (KB in the   sense as fixed collection of entity nodes)     The key idea is to explicitly model  entity spans in the input text and use an entity  linker to retrieve relevant entity embeddings from  a KB to form knowledge enhanced entity-span  representations.   Then,  update contextual word representations via a form of word-to-entity attention.    In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert's runtime is comparable to BERT's and it scales to large KBs.|sl:tag|tag:good
No Fuss Distance Metric Learning using Proxies  We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity...   Traditionnaly, supervision is expressed in the form of sets of points that follow  an ordinal relationship – an anchor point x is similar to  a set of positive points Y , and dissimilar to a set of negative  points Z, and a loss defined over these distances is minimized.   Triplet-Based methods are challenging to optimize (a main issue is the need for finding informative triplets).     We propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss.    Mentioned in this [blog post](/doc/2020/01/training_a_speaker_embedding_fr):     Proxy based triplet learning: instead of generating triplets, we learn an embedding for each class and use the learnt embedding as a proxy for triplets as part of the training. In other words, we can train end to end without the computationally expensive step of resampling triplets after each network update.    Near the conclusion:     Our formulation of Proxy-NCA loss produces a loss very  similar to the standard cross-entropy loss used in classification.  However, we arrive at our formulation from a different  direction: we are not interested in the actual classifier and  indeed discard the proxies once the model has been trained.  Instead, the proxies are auxiliary variables, enabling more  effective optimization of the embedding model parameters.  As such, our formulation not only enables us to surpass the  state of the art in zero-shot learning, but also offers an explanation  to the effectiveness of the standard trick of training  a classifier, and using its penultimate layer’s output as the  embedding. We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity. Traditionally, for this problem supervision is expressed in the form of sets of points that follow an ordinal relationship -- an anchor point $x$ is similar to a set of positive points $Y$, and dissimilar to a set of negative points $Z$, and a loss defined over these distances is minimized. While the specifics of the optimization differ, in this work we collectively call this type of supervision Triplets and all methods that follow this pattern Triplet-Based methods. These methods are challenging to optimize. A main issue is the need for finding informative triplets, which is usually achieved by a variety of tricks such as increasing the batch size, hard or semi-hard triplet mining, etc. Even with these tricks, the convergence rate of such methods is slow. In this paper we propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss. This proxy-based loss is empirically better behaved. As a result, the proxy-loss improves on state-of-art results for three standard zero-shot learning datasets, by up to 15% points, while converging three times as fast as other triplet-based losses.|sl:tag|tag:google_research
Pre-trained Models for Natural Language Processing: A Survey Recently, the emergence of pre-trained models (PTMs) has brought natural language processing (NLP) to a new era. In this survey, we provide a comprehensive review of PTMs for NLP. We first briefly introduce language representation learning and its research progress. Then we systematically categorize existing PTMs based on a taxonomy with four perspectives. Next, we describe how to adapt the knowledge of PTMs to the downstream tasks. Finally, we outline some potential directions of PTMs for future research. This survey is purposed to be a hands-on guide for understanding, using, and developing PTMs for various NLP tasks.|sl:tag|tag:arxiv_doc
Regroupement familial et test ADN de filiation|skos:broader|Regroupement familial
Film turc|skos:broader|Film
Uranium|skos:broader|Energie
Learning Sparse, Distributed Representations using the Hebbian Principle The \fire together, wire together\ Hebbian model is a central principle for learning in neuroscience, but surprisingly, it has found limited applicability in modern machine learning. In this paper, we take a first step towards bridging this gap, by developing flavors of competitive Hebbian learning which produce sparse, distributed neural codes using online adaptation with minimal tuning The fire together, wire together Hebbian model is a central principle for learning in neuroscience, but surprisingly, it has found limited applicability in modern machine learning. In this paper, we take a first step towards bridging this gap, by developing flavors of competitive Hebbian learning which produce sparse, distributed neural codes using online adaptation with minimal tuning. We propose an unsupervised algorithm, termed Adaptive Hebbian Learning (AHL). We illustrate the distributed nature of the learned representations via output entropy computations for synthetic data, and demonstrate superior performance, compared to standard alternatives such as autoencoders, in training a deep convolutional net on standard image datasets.|sl:arxiv_author|Aseem Wadhwa
Pre-training via Paraphrasing We introduce MARGE, a pre-trained sequence-to-sequence model learned with an unsupervised multi-lingual multi-document paraphrasing objective. MARGE provides an alternative to the dominant masked language modeling paradigm, where we self-supervise the reconstruction of target text by retrieving a set of related texts (in many languages) and conditioning on them to maximize the likelihood of generating the original. We show it is possible to jointly learn to do retrieval and reconstruction, given only a random initialization. The objective noisily captures aspects of paraphrase, translation, multi-document summarization, and information retrieval, allowing for strong zero-shot performance on several tasks. For example, with no additional task-specific training we achieve BLEU scores of up to 35.8 for document translation. We further show that fine-tuning gives strong performance on a range of discriminative and generative tasks in many languages, making MARGE the most generally applicable pre-training method to date.|sl:arxiv_author|Mike Lewis
Semantic Web|skos:broader|Internet
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:arxiv_author|Christopher Ré
Labeled Data|skos:broader|Machine learning: problems
public-linked-json@w3.org|skos:broader|Mailing list
JVisualVM|skos:broader|Java dev
Marie-Jo Pérec|skos:broader|Sportif
Les petites cases|skos:broader|Semantic Web blog
France Inter|skos:broader|Radio
Disparition des abeilles|skos:broader|Insect collapse
Loi sur le voile|skos:broader|France
Solr + RDF|skos:broader|Solr
Differentiable Reasoning over a Virtual Knowledge Base  We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases.    [(Bhuwan Dhingra PhD Thesis)](doc:2020/07/end_to_end_learning_with_text_) We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. On HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking approach to retrieving the relevant passages required to answer a question. DrKIT is also very efficient, processing 10-100x more queries per second than existing multi-hop systems.|sl:arxiv_author|Vidhisha Balachandran
Sônia Braga|skos:broader|Brésil
Amazon Alexa|skos:broader|Amazon
Crimes de l'église catholique|skos:broader|Catholicisme
Java|skos:broader|Programming language
Sani Aboussa|skos:broader|Musique du Niger
Taxi|skos:broader|Automobile
Equitation|skos:broader|Sport
Youtube tutorial|skos:broader|Tutorial
Linear Algebraic Structure of Word Senses, with Applications to Polysemy  Here it is shown that multiple word senses reside  in linear superposition within the word  embedding and simple sparse coding can recover  vectors that approximately capture the  senses     Each extracted word sense is accompanied by one of about  2000 “discourse atoms” that gives a succinct description of which other words co-occur with that word sense.     The success of the approach is mathematically explained using a variant of  the random walk on discourses model    (random walk: a generative model for language). Under the assumptions of this model,  there  exists a linear relationship between the vector of a  word w and the vectors of the words in its contexts (It is not the average of the words in w's context, but in a given corpus the matrix of the linear relationship does not depend on w. It can be estimated, and so we can compute the embedding of a word from the contexts it belongs to)    [Related blog post](/doc/?uri=https%3A%2F%2Fwww.offconvex.org%2F2016%2F07%2F10%2Fembeddingspolysemy%2F)   Word embeddings are ubiquitous in NLP and information retrieval, but it is unclear what they represent when the word is polysemous. Here it is shown that multiple word senses reside in linear superposition within the word embedding and simple sparse coding can recover vectors that approximately capture the senses. The success of our approach, which applies to several embedding methods, is mathematically explained using a variant of the random walk on discourses model (Arora et al., 2016). A novel aspect of our technique is that each extracted word sense is accompanied by one of about 2000 discourse atoms that gives a succinct description of which other words co-occur with that word sense. Discourse atoms can be of independent interest, and make the method potentially more useful. Empirical tests are used to verify and support the theory.|sl:tag|tag:sanjeev_arora
Extracting Tables from Documents using Conditional Generative Adversarial Networks and Genetic Algorithms Extracting information from tables in documents presents a significant challenge in many industries and in academic research. Existing methods which take a bottom-up approach of integrating lines into cells and rows or columns neglect the available prior information relating to table structure. Our proposed method takes a top-down approach, first using a generative adversarial network to map a table image into a standardised `skeleton' table form denoting the approximate row and column borders without table content, then fitting renderings of candidate latent table structures to the skeleton structure using a distance measure optimised by a genetic algorithm.|sl:arxiv_author|Matthew Zeigenfuse
Span Selection Pre-training for Question Answering  a new pre-training task inspired by reading  comprehension and an effort to avoid encoding general knowledge in the transformer network itself    Current transformer architectures store general knowledge - large models, long pre-training time. Better to offload the requirement of general knowledge to a sparsely activated network.    Span selection as an additional auxiliary task: the query is a sentence drawn from a corpus  with a term replaced with a special token: [BLANK]. The term replaced by the blank is the answer term. The passage is  relevant as determined by a BM25 search, and answer-bearing (containing the answer  term). Unlike BERT’s cloze task, where the answer must be drawn from the model itself, the answer is found in a passage  using language understanding.     We hope to progress to a model of general purpose language modeling that uses an indexed long  term memory to retrieve world knowledge, rather than holding it in the densely activated transformer encoder layers. BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pre-trained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension and an effort to avoid encoding general knowledge in the transformer network itself. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple reading comprehension (MRC) and paraphrasing datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also establish a new SOTA in HotpotQA, improving answer prediction F1 by 4 F1 points and supporting fact prediction by 1 F1 point. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.|sl:arxiv_author|Anthony Ferritto
Distributed Representations of Sentences and Documents Paragraph Vector: an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents.Represents each document by a dense vector which is trained to predict words in the document. Overcomes the weaknesses of the [Bag Of Words](/tag/bag_of_words) model (order of words, semantic of words)       Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, powerful, strong and Paris are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.|sl:arxiv_firstAuthor|Quoc V. Le
Revisiting Semi-Supervised Learning with Graph Embeddings We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.|sl:tag|tag:graph_embeddings
An Introduction to Conditional Random Fields Often we wish to predict a large number of variables that depend on each other as well as on other observed variables. Structured prediction methods are essentially a combination of classification and graphical modeling, combining the ability of graphical models to compactly model multivariate data with the ability of classification methods to perform prediction using large sets of input features. This tutorial describes conditional random fields, a popular probabilistic method for structured prediction. CRFs have seen wide application in natural language processing, computer vision, and bioinformatics. We describe methods for inference and parameter estimation for CRFs, including practical issues for implementing large scale CRFs. We do not assume previous knowledge of graphical modeling, so this tutorial is intended to be useful to practitioners in a wide variety of fields.|sl:arxiv_firstAuthor|Charles Sutton
jsFiddle|skos:broader|Web tools
Social bookmarking|skos:broader|Social Content Services
Enigmes de la physique|skos:broader|Physique
Sites du Patrimoine mondial de l'Unesco|skos:broader|UNESCO
Information theory AND Deep Learning|skos:broader|Deep Learning
Shoah|skos:broader|Juifs
Bag of Tricks for Efficient Text Classification A simple and efficient baseline for text classification.     Our word features can  be averaged together to form good sentence representations.    Our experiments show that fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.   This paper explores a simple and efficient baseline for text classification. Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute.|sl:arxiv_author|Edouard Grave
Explainable Deep Learning: A Field Guide for the Uninitiated Deep neural network (DNN) is an indispensable machine learning tool for achieving human-level performance on many learning tasks. Yet, due to its black-box nature, it is inherently difficult to understand which aspects of the input data drive the decisions of the network. There are various real-world scenarios in which humans need to make actionable decisions based on the output DNNs. Such decision support systems can be found in critical domains, such as legislation, law enforcement, etc. It is important that the humans making high-level decisions can be sure that the DNN decisions are driven by combinations of data features that are appropriate in the context of the deployment of the decision support system and that the decisions made are legally or ethically defensible. Due to the incredible pace at which DNN technology is being developed, the development of new methods and studies on explaining the decision-making process of DNNs has blossomed into an active research field. A practitioner beginning to study explainable deep learning may be intimidated by the plethora of orthogonal directions the field is taking. This complexity is further exacerbated by the general confusion that exists in defining what it means to be able to explain the actions of a deep learning system and to evaluate a system's ability to explain. To alleviate this problem, this article offers a field guide to deep learning explainability for those uninitiated in the field. The field guide: i) Discusses the traits of a deep learning system that researchers enhance in explainability research, ii) places explainability in the context of other related deep learning research areas, and iii) introduces three simple dimensions defining the space of foundational methods that contribute to explainable deep learning. The guide is designed as an easy-to-digest starting point for those just embarking in the field.|sl:tag|tag:explainable_ai
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:arxiv_author|Yoshua Bengio
Tom Heath|skos:broader|SW guys (and girls)
La communauté internationale est une garce|skos:broader|Garce
Newton|skos:broader|Grand Homme
Encrypted Media Extensions|skos:broader|DRM in HTML 5
Portugal|skos:broader|Pays d'Europe
New Africa|skos:broader|Afrique
Wikipedia|skos:broader|Wiki
Caetano Veloso|skos:broader|Musicien
Physique des particules : modèle standard|skos:broader|Physique des particules
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:arxiv_author|Haidong Shao
Andrew McCallum|skos:broader|NLP girls and guys
Sarraounia Mangou|skos:broader|Histoire du Niger
Online Learning|skos:broader|NTIC
Word-sense disambiguation|skos:broader|Word sense / Lexical ambiguity
Triplet Loss|skos:broader|Siamese networks
RDF Template|skos:broader|RDF
Sentence Similarity|skos:broader|Text Similarity
Fact-checking|skos:broader|Médias
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:arxiv_author|Yinfei Yang
ELMo|skos:broader|Contextualized word representations
Dev tips|skos:broader|Dev
Sem web demo|skos:broader|Semantic Web
Graphs+Machine Learning|skos:broader|Graph
CRISPR|skos:broader|Gene editing
A Call for More Rigor in Unsupervised Cross-lingual Learning  a scenario without any parallel data and abundant monolingual data is unrealistic in practice We review motivations, definition, approaches, and methodology for unsupervised cross-lingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of the world's languages. However, we argue that a scenario without any parallel data and abundant monolingual data is unrealistic in practice. We also discuss different training signals that have been used in previous work, which depart from the pure unsupervised setting. We then describe common methodological issues in tuning and evaluation of unsupervised cross-lingual models and present best practices. Finally, we provide a unified outlook for different types of research in this area (i.e., cross-lingual word embeddings, deep multilingual pretraining, and unsupervised machine translation) and argue for comparable evaluation of these models.|sl:arxiv_author|Eneko Agirre
techniques that make use of the spectrum (eigenvalues) of the similarity matrix of the data to perform dimensionality reduction before clustering in fewer dimensions.|skos:broader|the task of grouping a set of objects in such a way that objects in the same group (cluster) are more similar (in some sense or another) to each other than to those in other groups.  
Jerma|skos:broader|Niger
Antiwork|skos:broader|Travailler moins
Hierarchical Memory Networks  hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory Memory networks are neural networks with an explicit memory component that can be both read and written to by the network. The memory is often addressed in a soft way using a softmax function, making end-to-end training with backpropagation possible. However, this is not computationally scalable for applications which require the network to read from extremely large memories. On the other hand, it is well known that hard attention mechanisms based on reinforcement learning are challenging to train successfully. In this paper, we explore a form of hierarchical memory network, which can be considered as a hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory. Specifically, we propose to incorporate Maximum Inner Product Search (MIPS) in the training and inference procedures for our hierarchical memory network. We explore the use of various state-of-the art approximate MIPS techniques and report results on SimpleQuestions, a challenging large scale factoid question answering task.|sl:tag|tag:hierarchical_memory_networks
Ofir|skos:broader|Ami
Colza transgénique|skos:broader|OGM
Filme brasileiro@pt|skos:broader|Cinéma brésilien
Musée archéologique de Bagdad|skos:broader|Musée
Linear Algebraic Structure of Word Senses, with Applications to Polysemy  Here it is shown that multiple word senses reside  in linear superposition within the word  embedding and simple sparse coding can recover  vectors that approximately capture the  senses     Each extracted word sense is accompanied by one of about  2000 “discourse atoms” that gives a succinct description of which other words co-occur with that word sense.     The success of the approach is mathematically explained using a variant of  the random walk on discourses model    (random walk: a generative model for language). Under the assumptions of this model,  there  exists a linear relationship between the vector of a  word w and the vectors of the words in its contexts (It is not the average of the words in w's context, but in a given corpus the matrix of the linear relationship does not depend on w. It can be estimated, and so we can compute the embedding of a word from the contexts it belongs to)    [Related blog post](/doc/?uri=https%3A%2F%2Fwww.offconvex.org%2F2016%2F07%2F10%2Fembeddingspolysemy%2F)   Word embeddings are ubiquitous in NLP and information retrieval, but it is unclear what they represent when the word is polysemous. Here it is shown that multiple word senses reside in linear superposition within the word embedding and simple sparse coding can recover vectors that approximately capture the senses. The success of our approach, which applies to several embedding methods, is mathematically explained using a variant of the random walk on discourses model (Arora et al., 2016). A novel aspect of our technique is that each extracted word sense is accompanied by one of about 2000 discourse atoms that gives a succinct description of which other words co-occur with that word sense. Discourse atoms can be of independent interest, and make the method potentially more useful. Empirical tests are used to verify and support the theory.|sl:arxiv_firstAuthor|Sanjeev Arora
SIOC|skos:broader|RDF Vocabularies
email classification|skos:broader|Text Classification
Jupyter|skos:broader|Python tools
IBM developerWorks|skos:broader|Dev
Text Generation from Knowledge Graphs with Graph Transformers Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.|sl:tag|tag:natural_language_generation
Semantic Web / Web 2.0|skos:broader|Semantic Web
Enceladus|skos:broader|Saturn
XLNet: Generalized Autoregressive Pretraining for Language Understanding a new pretraining method for NLP that significantly improves upon BERT on 20 tasks (e.g., SQuAD, GLUE, RACE) With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.|sl:arxiv_author|Ruslan Salakhutdinov
Research papers|skos:broader|Recherche
Collaborative ontologie creation|skos:broader|Ontologies
Chatbots|skos:broader|Conversational AI
Antiquité iranienne|skos:broader|Iran
Biodiversité : effondrement|skos:broader|Biodiversité
K-BERT: Enabling Language Representation with Knowledge Graph a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by equipped with a KG without pre-training by-self because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts.|sl:arxiv_firstAuthor|Weijie Liu
Self-Taught Convolutional Neural Networks for Short Text Clustering  We propose a flexible short text clustering framework which explores the feasibility and effectiveness of combining CNN and traditional unsupervised dimensionality reduction methods.     Non-biased deep feature representations can be learned through our self- taught CNN framework which does not use any external tags/labels or complicated NLP pre-processing.     The original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations.    [conf paper, same authors](http://www.aclweb.org/anthology/W15-1509) ; [gitgub repo (matlab)](https://github.com/jacoxu/STC2)   Short text clustering is a challenging problem due to its sparseness of text representation. Here we propose a flexible Self-Taught Convolutional neural network framework for Short Text Clustering (dubbed STC^2), which can flexibly and successfully incorporate more useful semantic features and learn non-biased deep text representation in an unsupervised manner. In our framework, the original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations. Extensive experimental results demonstrate that the proposed framework is effective, flexible and outperform several popular clustering methods when tested on three public short text datasets.|sl:arxiv_author|Guanhua Tian
The Matrix Calculus You Need For Deep Learning Related blog post [The Math Behind Neural Networks](https://towardsdatascience.com/step-by-step-the-math-behind-neural-networks-490dc1f3cfd9) This paper is an attempt to explain all the matrix calculus you need in order to understand the training of deep neural networks. We assume no math knowledge beyond what you learned in calculus 1, and provide links to help you refresh the necessary math where needed. Note that you do not need to understand this material before you start learning to train and use deep learning in practice; rather, this material is for those who are already familiar with the basics of neural networks, and wish to deepen their understanding of the underlying math. Don't worry if you get stuck at some point along the way---just go back and reread the previous section, and try writing down and working through some examples. And if you're still stuck, we're happy to answer your questions in the Theory category at forums.fast.ai. Note: There is a reference section at the end of the paper summarizing all the key matrix calculus rules and terminology discussed here. See related articles at http://explained.ai|sl:arxiv_author|Terence Parr
Blob|skos:broader|Biologie
Deep Mutual Learning  In this paper we explore a different but related idea to model distillation – that of mutual learning. Distillation starts with a powerful large and pre-trained teacher network and performs one-way knowledge transfer to a small untrained student. In contrast, in mutual learning we start with a pool of untrained students who learn simultaneously to solve the task together.    [critic here](doc:2020/06/1804_03235_large_scale_distri):     Zhang et al. (2017) reported a benefit in quality over  basic distillation, but they compare distilling model M1 into model M2 with training model M1  and model M2 using codistillation; they do not compare to distilling an ensemble of models M1  and M2 into model M3.     ...     we can achieve the 70.7% they report for online  distillation using traditional offline distillation. Model distillation is an effective and widely used technique to transfer knowledge from a teacher to a student network. The typical application is to transfer from a powerful large network or ensemble to a small network, that is better suited to low-memory or fast execution requirements. In this paper, we present a deep mutual learning (DML) strategy where, rather than one way transfer between a static pre-defined teacher and a student, an ensemble of students learn collaboratively and teach each other throughout the training process. Our experiments show that a variety of network architectures benefit from mutual learning and achieve compelling results on CIFAR-100 recognition and Market-1501 person re-identification benchmarks. Surprisingly, it is revealed that no prior powerful teacher network is necessary -- mutual learning of a collection of simple student networks works, and moreover outperforms distillation from a more powerful yet static teacher.|sl:arxiv_author|Ying Zhang
W3C Working group|skos:broader|W3C
Latent Semantic Analysis|skos:broader|Vector space model
Agriculture africaine|skos:broader|Afrique
C2GWeb|skos:broader|Configuration as Linked Data
RFID|skos:broader|NTIC
RDF data visualization|skos:broader|RDF Tools
Cosmic microwave background|skos:broader|Big bang
Universal Language Model Fine-tuning for Text Classification code is available in the fastai lib    [blog post](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html)    [see also](/doc/?uri=https%3A%2F%2Fyashuseth.blog%2F2018%2F06%2F17%2Funderstanding-universal-language-model-fine-tuning-ulmfit%2F)             Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.|sl:tag|tag:sebastian_ruder
NSA|skos:broader|Cybersurveillance
Pétrole|skos:broader|Energie
EMNLP 2018|skos:broader|Bruxelles
Musicien|skos:broader|Artiste
Film français|skos:broader|France
Bringing Light Into the Dark: A Large-scale Evaluation of Knowledge Graph Embedding Models Under a Unified Framework The heterogeneity in recently published knowledge graph embedding models' implementations, training, and evaluation has made fair and thorough comparisons difficult. In order to assess the reproducibility of previously published results, we re-implemented and evaluated 19 interaction models in the PyKEEN software package. Here, we outline which results could be reproduced with their reported hyper-parameters, which could only be reproduced with alternate hyper-parameters, and which could not be reproduced at all as well as provide insight as to why this might be the case. We then performed a large-scale benchmarking on four datasets with several thousands of experiments and 21,246 GPU hours of computation time. We present insights gained as to best practices, best configurations for each model, and where improvements could be made over previously published best configurations. Our results highlight that the combination of model architecture, training approach, loss function, and the explicit modeling of inverse relations is crucial for a model's performances, and not only determined by the model architecture. We provide evidence that several architectures can obtain results competitive to the state-of-the-art when configured carefully. We have made all code, experimental configurations, results, and analyses that lead to our interpretations available at https://github.com/pykeen/pykeen and https://github.com/pykeen/benchmarking|sl:tag|tag:knowledge_graph_embeddings
Exalead|skos:broader|Search Engines
Patent finding|skos:broader|Patent
End-To-End Memory Networks Neural network with a recurrent attention model over a possibly large external memory.    cité par [#A. Bordes](/tag/antoine_bordes) à [#ParisIsAI conf 2018](/tag/france_is_ai_2018.html) We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network (Weston et al., 2015) but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.|sl:tag|tag:memory_networks
Culture et sem web|skos:broader|Semantic Web
Ópera do Malandro|skos:broader|Filme brasileiro@pt
Google Research|skos:broader|Google
Joint Embedding of Hierarchical Categories and Entities for Concept Categorization and Dataless Classification a framework that embeds entities and categories into a semantic space by integrating structured  knowledge and taxonomy hierarchy from large knowledge bases.    two methods:    1. Category Embedding model): it replaces the entities in the context with their directly  labeled categories to build categories’ context;   2. Hierarchical Category Embedding: it  further incorporates all ancestor categories of the context entities to utilize the hierarchical information. Due to the lack of structured knowledge applied in learning distributed representation of cate- gories, existing work cannot incorporate category hierarchies into entity information. We propose a framework that embeds entities and categories into a semantic space by integrating structured knowledge and taxonomy hierarchy from large knowledge bases. The framework allows to com- pute meaningful semantic relatedness between entities and categories. Our framework can han- dle both single-word concepts and multiple-word concepts with superior performance on concept categorization and yield state of the art results on dataless hierarchical classification.|sl:arxiv_author|Ronghuo Zheng
Text Clustering|skos:broader|Data clustering Cluster analysis
Big data & semantic web|skos:broader|Big Data
Lenka Zdeborová|skos:broader|AI girls and guys
Selective Question Answering under Domain Shift How you can get a QA model to abstain from answering when it doesn’t know the answer.     Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. To avoid giving wrong answers, question answering (QA) models need to know when to abstain from answering. Moreover, users often ask questions that diverge from the model's training data, making errors more likely and thus abstention more critical. In this work, we propose the setting of selective question answering under domain shift, in which a QA model is tested on a mixture of in-domain and out-of-domain data, and must answer (i.e., not abstain on) as many questions as possible while maintaining high accuracy. Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. Crucially, the calibrator benefits from observing the model's behavior on out-of-domain data, even if from a different domain than the test data. We combine this method with a SQuAD-trained QA model and evaluate on mixtures of SQuAD and five other QA datasets. Our method answers 56% of questions while maintaining 80% accuracy; in contrast, directly using the model's probabilities only answers 48% at 80% accuracy.|sl:arxiv_author|Robin Jia
Rome|skos:broader|Italie
Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data Word embeddings are a popular approach to unsupervised learning of word relationships that are widely used in natural language processing. In this article, we present a new set of embeddings for medical concepts learned using an extremely large collection of multimodal medical data. Leaning on recent theoretical insights, we demonstrate how an insurance claims database of 60 million members, a collection of 20 million clinical notes, and 1.7 million full text biomedical journal articles can be combined to embed concepts into a common space, resulting in the largest ever set of embeddings for 108,477 medical concepts. To evaluate our approach, we present a new benchmark methodology based on statistical power specifically designed to test embeddings of medical concepts. Our approach, called cui2vec, attains state-of-the-art performance relative to previous methods in most instances. Finally, we provide a downloadable set of pre-trained embeddings for other researchers to use, as well as an online tool for interactive exploration of the cui2vec embeddings|sl:arxiv_author|Inbar Fried
Gouvernement Chirac|skos:broader|Chirac
SQL to RDF mapping|skos:broader|RDF and database
New Horizons|skos:broader|NASA
Cazuza|skos:broader|Brésil
Jean Dujardin|skos:broader|Acteur
sindice|skos:broader|Semantic Web search engine
Film italien|skos:broader|Italie
Pellet|skos:broader|Clark and Parsia
Training Data (NLP)|skos:broader|Training data
BERT|skos:broader|Contextualized word representations
Bringing Light Into the Dark: A Large-scale Evaluation of Knowledge Graph Embedding Models Under a Unified Framework The heterogeneity in recently published knowledge graph embedding models' implementations, training, and evaluation has made fair and thorough comparisons difficult. In order to assess the reproducibility of previously published results, we re-implemented and evaluated 19 interaction models in the PyKEEN software package. Here, we outline which results could be reproduced with their reported hyper-parameters, which could only be reproduced with alternate hyper-parameters, and which could not be reproduced at all as well as provide insight as to why this might be the case. We then performed a large-scale benchmarking on four datasets with several thousands of experiments and 21,246 GPU hours of computation time. We present insights gained as to best practices, best configurations for each model, and where improvements could be made over previously published best configurations. Our results highlight that the combination of model architecture, training approach, loss function, and the explicit modeling of inverse relations is crucial for a model's performances, and not only determined by the model architecture. We provide evidence that several architectures can obtain results competitive to the state-of-the-art when configured carefully. We have made all code, experimental configurations, results, and analyses that lead to our interpretations available at https://github.com/pykeen/pykeen and https://github.com/pykeen/benchmarking|sl:arxiv_author|Laurent Vermue
Online Course Materials|skos:broader|Education
Semantic mashups|skos:broader|Mashups
Jena GRDDL Reader|skos:broader|GRDDL
The HSIC Bottleneck: Deep Learning without Back-Propagation  we show that it is possible to learn classification tasks at near competitive accuracy without  backpropagation, by maximizing a surrogate of the mutual information between hidden representations and labels and  simultaneously minimizing the mutual dependency between hidden representations and the inputs...  the hidden units of a network trained in this way form useful representations. Specifically, fully competitive accuracy  can be obtained by freezing the network trained without backpropagation and appending and training a one-layer  network using conventional SGD to convert convert the representation to the desired format.    The training method uses an approximation of the [#information bottleneck](/tag/information_bottleneck_method).    Advantages:     - The method facilitates parallel processing and requires significantly less operations.    - It does not suffer from exploding or vanishing gradients.   - It is biologically more plausible than Backpropagation     We introduce the HSIC (Hilbert-Schmidt independence criterion) bottleneck for training deep neural networks. The HSIC bottleneck is an alternative to the conventional cross-entropy loss and backpropagation that has a number of distinct advantages. It mitigates exploding and vanishing gradients, resulting in the ability to learn very deep networks without skip connections. There is no requirement for symmetric feedback or update locking. We find that the HSIC bottleneck provides performance on MNIST/FashionMNIST/CIFAR10 classification comparable to backpropagation with a cross-entropy target, even when the system is not encouraged to make the output resemble the classification labels. Appending a single layer trained with SGD (without backpropagation) to reformat the information further improves performance.|sl:tag|tag:backpropagation
Hierarchical Memory Networks  hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory Memory networks are neural networks with an explicit memory component that can be both read and written to by the network. The memory is often addressed in a soft way using a softmax function, making end-to-end training with backpropagation possible. However, this is not computationally scalable for applications which require the network to read from extremely large memories. On the other hand, it is well known that hard attention mechanisms based on reinforcement learning are challenging to train successfully. In this paper, we explore a form of hierarchical memory network, which can be considered as a hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory. Specifically, we propose to incorporate Maximum Inner Product Search (MIPS) in the training and inference procedures for our hierarchical memory network. We explore the use of various state-of-the art approximate MIPS techniques and report results on SimpleQuestions, a challenging large scale factoid question answering task.|sl:arxiv_author|Yoshua Bengio
Uruguay|skos:broader|Amérique du sud
Text Generation from Knowledge Graphs with Graph Transformers Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.|sl:tag|tag:kg_and_nlp
Unifying distillation and privileged information A framework to learn from multiple machines and data representations, unifying two techniques that enable machines to learn from other machines: [distillation](tag:knowledge_distillation) ([Hinton et al., 2015](doc:2020/04/1503_02531_distilling_the_kno)) and privileged information (Vapnik & Izmailov, 2015)   Distillation (Hinton et al., 2015) and privileged information (Vapnik & Izmailov, 2015) are two techniques that enable machines to learn from other machines. This paper unifies these two techniques into generalized distillation, a framework to learn from multiple machines and data representations. We provide theoretical and causal insight about the inner workings of generalized distillation, extend it to unsupervised, semisupervised and multitask learning scenarios, and illustrate its efficacy on a variety of numerical simulations on both synthetic and real-world data.|sl:tag|tag:ai_facebook
A voir|skos:broader|Todo list
Label-aware Document Representation via Hybrid Attention for Extreme Multi-Label Text Classification  This paper is motivated to better explore the semantic relationship between each document and extreme labels by taking advantage of both document content and label correlation. Our objective is to establish an explicit label-aware representation for each document with a hybrid attention deep neural network model(LAHA) Extreme multi-label text classification (XMTC) aims at tagging a document with most relevant labels from an extremely large-scale label set. It is a challenging problem especially for the tail labels because there are only few training documents to build classifier. This paper is motivated to better explore the semantic relationship between each document and extreme labels by taking advantage of both document content and label correlation. Our objective is to establish an explicit label-aware representation for each document with a hybrid attention deep neural network model(LAHA). LAHA consists of three parts. The first part adopts a multi-label self-attention mechanism to detect the contribution of each word to labels. The second part exploits the label structure and document content to determine the semantic connection between words and labels in a same latent space. An adaptive fusion strategy is designed in the third part to obtain the final label-aware document representation so that the essence of previous two parts can be sufficiently integrated. Extensive experiments have been conducted on six benchmark datasets by comparing with the state-of-the-art methods. The results show the superiority of our proposed LAHA method, especially on the tail labels.|sl:arxiv_author|Boli Chen
Siamese network|skos:broader|ANN NN Artificial neural network
Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.|sl:arxiv_author|Marco Gori
GitHub Pages|skos:broader|GitHub
RDFa|skos:broader|HTML Data
Language modeling: task of predicting the next word in a text given the previous words. Example of concrete practical applications: intelligent keyboards     Language model: probability distribution over sequences of words. Statistical language models try to learn the probability of the next word given its previous words.     Models rely on an auto-regressive factorization of the joint probability of a corpus using different approaches, from n-gram models to RNNs (SOTA as of 2018-01) ([source](https://arxiv.org/abs/1801.06146))|skos:broader|In machine learning, unsupervised learning refers to the problem of trying to find hidden structure in unlabeled data
Emerging Cross-lingual Structure in Pretrained Language Models We study the problem of multilingual masked language modeling, i.e. the training of a single model on concatenated text from multiple languages, and present a detailed study of several factors that influence why these models are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from independently trained models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these symmetries seem to be automatically discovered and aligned during the joint training process.|sl:arxiv_author|Alexis Conneau
Sigma.js|skos:broader|Graph visualization
Géologie|skos:broader|Science
Episodic Memory|skos:broader|Mémoire humaine
SKOS editor|skos:broader|SKOS
Poincaré Embeddings|skos:broader|Entity embeddings
Ora Lassila|skos:broader|SW guys (and girls)
Leningrad|skos:broader|Ex URSS URSS
TransE|skos:broader|Knowledge Graph Embeddings
OWLlink Protocol|skos:broader|OWL
Natural Language Processing (almost) from Scratch seminal work    Abstract:     a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements   We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.|sl:arxiv_author|Koray Kavukcuoglu
African languages|skos:broader|Afrique
Newton|skos:broader|Scientifique
N-grams|skos:broader|Language model
Technorati|skos:broader|Tagging
Tony Blair|skos:broader|Homme politique
"Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One We propose to reinterpret a standard discriminative classifier of p(y|x) as an energy based model for the joint distribution p(x,y). In this setting, the standard class probabilities can be easily computed as well as unnormalized values of p(x) and p(x|y). Within this framework, standard discriminative architectures may beused and the model can also be trained on unlabeled data. We demonstrate that energy based training of the joint distribution improves calibration, robustness, andout-of-distribution detection while also enabling our models to generate samplesrivaling the quality of recent GAN approaches. We improve upon recently proposed techniques for scaling up the training of energy based models and presentan approach which adds little overhead compared to standard classification training. Our approach is the first to achieve performance rivaling the state-of-the-artin both generative and discriminative learning within one hybrid model."|sl:tag|tag:arxiv_doc
Semantic Web: databases|skos:broader|Semantic Web
Structured Knowledge Distillation for Dense Prediction In this paper, we consider transferring the structure information from large networks to small ones for dense prediction tasks. Previous knowledge distillation strategies used for dense prediction tasks often directly borrow the distillation scheme for image classification and perform knowledge distillation for each pixel separately, leading to sub-optimal performance. Here we propose to distill structured knowledge from large networks to small networks, taking into account the fact that dense prediction is a structured prediction problem. Specifically, we study two structured distillation schemes: i)pair-wise distillation that distills the pairwise similarities by building a static graph, and ii)holistic distillation that uses adversarial training to distill holistic knowledge. The effectiveness of our knowledge distillation approaches is demonstrated by extensive experiments on three dense prediction tasks: semantic segmentation, depth estimation, and object detection.|sl:tag|tag:arxiv_doc
Zero-shot Entity Linking with Dense Entity Retrieval We consider the zero-shot entity-linking challenge where each entity is defined by a short textual description, and the model must read these descriptions together with the mention context to make the final linking decisions. In this setting, retrieving entity candidates can be particularly challenging, since many of the common linking cues such as entity alias tables and link popularity are not available. In this paper, we introduce a simple and effective two stage approach for zero-shot linking, based on fine-tuned BERT architectures. In the first stage, we do retrieval in a dense space defined by a bi-encoder that independently embeds the mention context and the entity descriptions. Each candidate is then examined more carefully with a cross-encoder, that concatenates the mention and entity text. Our approach achieves a nearly 5 point absolute gain on a recently introduced zero-shot entity linking benchmark, driven largely by improvements over previous IR-based candidate retrieval. We also show that it performs well in the non-zero-shot setting, obtaining the state-of-the-art result on TACKBP-2010.|sl:tag|tag:zero_shot_entity_linking
Modèles économiques|skos:broader|Economie
ExxonMobil|skos:broader|Compagnies pétrolières
Topic embeddings|skos:broader|Embeddings in NLP
Semantic feature extraction|skos:broader|Semantic technology
Leo Sauermann|skos:broader|Semantic Desktop
To see|skos:broader|Todo list
David Cameron|skos:broader|Homme politique
Differentiable Top-k Operator with Optimal Transport  if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator   ...   We apply the proposed operator to the [k-nearest neighbors](tag:k_nearest_neighbors_algorithm) and [beam search](tag:beam_search) algorithms, and demonstrate improved performance The top-k operation, i.e., finding the k largest or smallest elements from a collection of scores, is an important model component, which is widely used in information retrieval, machine learning, and data mining. However, if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator. Specifically, our SOFT top-k operator approximates the output of the top-k operation as the solution of an Entropic Optimal Transport (EOT) problem. The gradient of the SOFT operator can then be efficiently approximated based on the optimality conditions of EOT problem. We apply the proposed operator to the k-nearest neighbors and beam search algorithms, and demonstrate improved performance.|sl:arxiv_author|Minshuo Chen
Sarkozyland|skos:broader|Sarkozy
Apache web server|skos:broader|Web server
Semantic feature extraction|skos:broader|Feature extraction
Clint Eastwood|skos:broader|Réalisateur
Datao|skos:broader|Olivier Rossel
Pape|skos:broader|Eglise catholique
Restful semantic web services|skos:broader|RESTful Web Services
Firefighter|skos:broader|Fire
Voyager|skos:broader|NASA
Grands Singes|skos:broader|Espèces menacées
Craig Venter Institute|skos:broader|Celera ou Craig Venter
Turing|skos:broader|Scientifique
Tahar Ben Jelloun|skos:broader|Maroc
Loi sur le téléchargement|skos:broader|Piratage des œuvres
TopBraid|skos:broader|TopQuadrant
DeepType: Multilingual Entity Linking by Neural Type System Evolution The wealth of structured (e.g. Wikidata) and unstructured data about the world available today presents an incredible opportunity for tomorrow's Artificial Intelligence. So far, integration of these two different modalities is a difficult process, involving many decisions concerning how best to represent the information so that it will be captured or useful, and hand-labeling large amounts of data. DeepType overcomes this challenge by explicitly integrating symbolic information into the reasoning process of a neural network with a type system. First we construct a type system, and second, we use it to constrain the outputs of a neural network to respect the symbolic structure. We achieve this by reformulating the design problem into a mixed integer problem: create a type system and subsequently train a neural network with it. In this reformulation discrete variables select which parent-child relations from an ontology are types within the type system, while continuous variables control a classifier fit to the type system. The original problem cannot be solved exactly, so we propose a 2-step algorithm: 1) heuristic search or stochastic optimization over discrete variables that define a type system informed by an Oracle and a Learnability heuristic, 2) gradient descent to fit classifier parameters. We apply DeepType to the problem of Entity Linking on three standard datasets (i.e. WikiDisamb30, CoNLL (YAGO), TAC KBP 2010) and find that it outperforms all existing solutions by a wide margin, including approaches that rely on a human-designed type system or recent deep learning-based entity embeddings, while explicitly using symbolic information lets it integrate new entities without retraining.|sl:arxiv_firstAuthor|Jonathan Raiman
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:tag|tag:consciousness_prior
Mac OS X Tip|skos:broader|Tips
Distributed Representations of Sentences and Documents Paragraph Vector: an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents.Represents each document by a dense vector which is trained to predict words in the document. Overcomes the weaknesses of the [Bag Of Words](/tag/bag_of_words) model (order of words, semantic of words)       Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, powerful, strong and Paris are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.|sl:arxiv_author|Quoc V. Le
RDF Service|skos:broader|RDF
Enswers|skos:broader|Corée du Sud
Hierarchical Memory Networks  hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory Memory networks are neural networks with an explicit memory component that can be both read and written to by the network. The memory is often addressed in a soft way using a softmax function, making end-to-end training with backpropagation possible. However, this is not computationally scalable for applications which require the network to read from extremely large memories. On the other hand, it is well known that hard attention mechanisms based on reinforcement learning are challenging to train successfully. In this paper, we explore a form of hierarchical memory network, which can be considered as a hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory. Specifically, we propose to incorporate Maximum Inner Product Search (MIPS) in the training and inference procedures for our hierarchical memory network. We explore the use of various state-of-the art approximate MIPS techniques and report results on SimpleQuestions, a challenging large scale factoid question answering task.|sl:tag|tag:yoshua_bengio
Using Information Content to Evaluate Semantic Similarity in a Taxonomy This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content. Experimental evaluation suggests that the measure performs encouragingly well (a correlation of r = 0.79 with a benchmark set of human similarity judgments, with an upper bound of r = 0.90 for human subjects performing the same task), and significantly better than the traditional edge counting approach (r = 0.66).|sl:tag|tag:taxonomies
OGM|skos:broader|Genetics Génétique
Alexandre Monnin|skos:broader|SW guys (and girls)
Polluted places|skos:broader|Pollution
XSPARQL|skos:broader|SPARQL
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).|sl:arxiv_author|Kenton Lee
Topic modelling for humans ; Python framework for fast Vector Space Modelling    |skos:broader|A statistical model for discovering the abstract topics that occur in a collection of documents.      
Topic Modeling over Short Texts by Incorporating Word Embeddings New method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo-texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic Inferring topics from the overwhelming amount of short texts becomes a critical but challenging task for many content analysis tasks, such as content charactering, user interest profiling, and emerging topic detecting. Existing methods such as probabilistic latent semantic analysis (PLSA) and latent Dirichlet allocation (LDA) cannot solve this prob- lem very well since only very limited word co-occurrence information is available in short texts. This paper studies how to incorporate the external word correlation knowledge into short texts to improve the coherence of topic modeling. Based on recent results in word embeddings that learn se- mantically representations for words from a large corpus, we introduce a novel method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo- texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic. The experiments on real-world datasets validate the effectiveness of our model comparing with the state-of-the-art models.|sl:arxiv_author|Jipeng Qiang
Erich Maria Remarque|skos:broader|Ecrivain
Natural Language Processing with Small Feed-Forward Networks google guys:      We show that small and shallow feed- forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.   We show that small and shallow feed-forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.|sl:arxiv_author|Slav Petrov
Clustering|skos:broader|Unsupervised machine learning
Representation learning for very short texts using weighted word embedding aggregation A method based on word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. a href=https://github.com/cedricdeboom/RepresentationLearningGithub/a (hmm...) (python code)     Short text messages such as tweets are very noisy and sparse in their use of vocabulary. Traditional textual representations, such as tf-idf, have difficulty grasping the semantic meaning of such texts, which is important in applications such as event detection, opinion mining, news recommendation, etc. We constructed a method based on semantic word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. For this purpose we designed a weight-based model and a learning procedure based on a novel median-based loss function. This paper discusses the details of our model and the optimization methods, together with the experimental results on both Wikipedia and Twitter data. We find that our method outperforms the baseline approaches in the experiments, and that it generalizes well on different word embeddings without retraining. Our method is therefore capable of retaining most of the semantic information in the text, and is applicable out-of-the-box.|sl:arxiv_author|Bart Dhoedt
Chrétienté|skos:broader|Religion
PAC|skos:broader|Subventions agricoles
Ajax|skos:broader|JavaScript
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:tag|tag:arxiv_doc
Apache on my mac|skos:broader|Apache web server
Verger de Gado à Niamey|skos:broader|Jardin
Bootstrap aggregating (Bagging)|skos:broader|Ensemble learning
Hubble|skos:broader|Exploration spatiale
Ville|skos:broader|Géographie
Coursera: Deep Learning|skos:broader|Deep Learning
Bourbaki|skos:broader|Mathématiques
TabFact: A Large-scale Dataset for Table-based Fact Verification fact verification given semi-structured data as evidence The problem of verifying whether a textual hypothesis holds based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation. However, existing studies are mainly restricted to dealing with unstructured evidence (e.g., natural language sentences and documents, news, etc), while verification under structured evidence, such as tables, graphs, and databases, remains under-explored. This paper specifically aims to study the fact verification given semi-structured data as evidence. To this end, we construct a large-scale dataset called TabFact with 16k Wikipedia tables as the evidence for 118k human-annotated natural language statements, which are labeled as either ENTAILED or REFUTED. TabFact is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning. To address these reasoning challenges, we design two different models: Table-BERT and Latent Program Algorithm (LPA). Table-BERT leverages the state-of-the-art pre-trained language model to encode the linearized tables and statements into continuous vectors for verification. LPA parses statements into programs and executes them against the tables to obtain the returned binary value for verification. Both methods achieve similar accuracy but still lag far behind human performance. We also perform a comprehensive analysis to demonstrate great future opportunities. The data and code of the dataset are provided in \\url{https://github.com/wenhuchen/Table-Fact-Checking}.|sl:tag|tag:arxiv_doc
Origine de la vie|skos:broader|Science
Hello Edge: Keyword Spotting on Microcontrollers Keyword spotting (KWS) is a critical component for enabling speech based user interactions on smart devices. It requires real-time response and high accuracy for good user experience. Recently, neural networks have become an attractive choice for KWS architecture because of their superior accuracy compared to traditional speech processing algorithms. Due to its always-on nature, KWS application has highly constrained power budget and typically runs on tiny microcontrollers with limited memory and compute capability. The design of neural network architecture for KWS must consider these constraints. In this work, we perform neural network architecture evaluation and exploration for running KWS on resource-constrained microcontrollers. We train various neural network architectures for keyword spotting published in literature to compare their accuracy and memory/compute requirements. We show that it is possible to optimize these neural network architectures to fit within the memory and compute constraints of microcontrollers without sacrificing accuracy. We further explore the depthwise separable convolutional neural network (DS-CNN) and compare it against other neural network architectures. DS-CNN achieves an accuracy of 95.4%, which is ~10% higher than the DNN model with similar number of parameters.|sl:arxiv_author|Vikas Chandra
KG-BERT: BERT for Knowledge Graph Completion Pre-trained language models for knowledge graph completion. Triples are treated as textual sequences. (Hum, j'ai déjà vu ça quelque part) Knowledge graphs are important resources for many artificial intelligence tasks but often suffer from incompleteness. In this work, we propose to use pre-trained language models for knowledge graph completion. We treat triples in knowledge graphs as textual sequences and propose a novel framework named Knowledge Graph Bidirectional Encoder Representations from Transformer (KG-BERT) to model these triples. Our method takes entity and relation descriptions of a triple as input and computes scoring function of the triple with the KG-BERT language model. Experimental results on multiple benchmark knowledge graphs show that our method can achieve state-of-the-art performance in triple classification, link prediction and relation prediction tasks.|sl:arxiv_author|Liang Yao
ATOM (Text editor)|skos:broader|GitHub project
Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective reviews the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. Neural-symbolic computing has now become the subject of interest of both academic and industry research laboratories. Graph Neural Networks (GNN) have been widely used in relational and symbolic domains, with widespread application of GNNs in combinatorial optimization, constraint satisfaction, relational reasoning and other scientific domains. The need for improved explainability, interpretability and trust of AI systems in general demands principled methodologies, as suggested by neural-symbolic computing. In this paper, we review the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. This includes the application of GNNs in several domains as well as its relationship to current developments in neural-symbolic computing.|sl:arxiv_firstAuthor|Luis Lamb
GWT|skos:broader|JavaScript framework
Transition énergétique|skos:broader|Energie
Semanlink dev|skos:broader|Dev
Art d'Afrique|skos:broader|Afrique
Singe|skos:broader|Animal
Von Mises-Fisher Loss for Training Sequence to Sequence Models with Continuous Outputs predicting embeddings instead of word IDs (avoids a discrete softmax, using a new loss)    [@honnibal](https://twitter.com/honnibal/status/1073513114468081664)     The Softmax function is used in the final layer of nearly all existing sequence-to-sequence models for language generation. However, it is usually the slowest layer to compute which limits the vocabulary size to a subset of most frequent types; and it has a large memory footprint. We propose a general technique for replacing the softmax layer with a continuous embedding layer. Our primary innovations are a novel probabilistic loss, and a training and inference procedure in which we generate a probability distribution over pre-trained word embeddings, instead of a multinomial distribution over the vocabulary obtained via softmax. We evaluate this new class of sequence-to-sequence models with continuous outputs on the task of neural machine translation. We show that our models obtain upto 2.5x speed-up in training time while performing on par with the state-of-the-art models in terms of translation quality. These models are capable of handling very large vocabularies without compromising on translation quality. They also produce more meaningful errors than in the softmax-based models, as these errors typically lie in a subspace of the vector space of the reference translations.|sl:arxiv_firstAuthor|Sachin Kumar
Jeu|skos:broader|Jeux
Nelson Mandela|skos:broader|Grand Homme
KGAT: Knowledge Graph Attention Network for Recommendation To provide more accurate, diverse, and explainable recommendation, it is compulsory to go beyond modeling user-item interactions and take side information into account. Traditional methods like factorization machine (FM) cast it as a supervised learning problem, which assumes each interaction as an independent instance with side information encoded. Due to the overlook of the relations among instances or items (e.g., the director of a movie is also an actor of another movie), these methods are insufficient to distill the collaborative signal from the collective behaviors of users. In this work, we investigate the utility of knowledge graph (KG), which breaks down the independent interaction assumption by linking items with their attributes. We argue that in such a hybrid structure of KG and user-item graph, high-order relations --- which connect two items with one or multiple linked attributes --- are an essential factor for successful recommendation. We propose a new method named Knowledge Graph Attention Network (KGAT) which explicitly models the high-order connectivities in KG in an end-to-end fashion. It recursively propagates the embeddings from a node's neighbors (which can be users, items, or attributes) to refine the node's embedding, and employs an attention mechanism to discriminate the importance of the neighbors. Our KGAT is conceptually advantageous to existing KG-based recommendation methods, which either exploit high-order relations by extracting paths or implicitly modeling them with regularization. Empirical results on three public benchmarks show that KGAT significantly outperforms state-of-the-art methods like Neural FM and RippleNet. Further studies verify the efficacy of embedding propagation for high-order relation modeling and the interpretability benefits brought by the attention mechanism.|sl:tag|tag:arxiv_doc
Advances in Pre-Training Distributed Word Representations  we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks Many Natural Language Processing applications nowadays rely on pre-trained word representations estimated from large text corpora such as news collections, Wikipedia and Web Crawl. In this paper, we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks.|sl:arxiv_author|Tomas Mikolov
Word Translation Without Parallel Data  we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent studies showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally describe experiments on the English-Esperanto low-resource language pair, on which there only exists a limited amount of parallel data, to show the potential impact of our method in fully unsupervised machine translation. Our code, embeddings and dictionaries are publicly available.|sl:arxiv_author|Alexis Conneau
Tombe d'amphipolis|skos:broader|Alexandre le Grand
Piggy Bank|skos:broader|SIMILE
Towards a Seamless Integration of Word Senses into Downstream NLP Applications Lexical ambiguity can impede NLP systems from accurate understanding of semantics. Despite its potential benefits, the integration of sense-level information into NLP systems has remained understudied. By incorporating a novel disambiguation algorithm into a state-of-the-art classification model, we create a pipeline to integrate sense-level information into downstream NLP applications. We show that a simple disambiguation of the input text can lead to consistent performance improvement on multiple topic categorization and polarity detection datasets, particularly when the fine granularity of the underlying sense inventory is reduced and the document is sufficiently large. Our results also point to the need for sense representation research to focus more on in vivo evaluations which target the performance in downstream NLP applications rather than artificial benchmarks.|sl:arxiv_author|Nigel Collier
Industrie pharmaceutique|skos:broader|industrie
Antoine Bordes|skos:broader|NLP girls and guys
Homme de Florès|skos:broader|Paléontologie humaine
Woody Allen|skos:broader|Cinéma américain
Amazon Mechanical Turk|skos:broader|Amazon
Freie Universität Berlin|skos:broader|Université
Tasmanian devil|skos:broader|Tasmanie
NMT|skos:broader|ANN NN Artificial neural network
Semantic Vector Encoding and Similarity Search Using Fulltext Search Engines  The ubiquity of semantic vector space modeling raises the challenge of efficient searching in dense, high-dimensional vector spaces. We would naturally want to take advantage of the design and optimizations behind modern fulltext engines like Elasticsearch so as to meet the scalability and robustness demands of modern IR applications. This is the research challenge addressed in this paper.   The paper describes novel ways of encoding dense vectors into text documents, allowing the use of traditional inverted index engines.    [blog post](https://rare-technologies.com/semantic-search-fulltext-engine-acl-2017/)   Vector representations and vector space modeling (VSM) play a central role in modern machine learning. We propose a novel approach to `vector similarity searching' over dense semantic representations of words and documents that can be deployed on top of traditional inverted-index-based fulltext engines, taking advantage of their robustness, stability, scalability and ubiquity. We show that this approach allows the indexing and querying of dense vectors in text domains. This opens up exciting avenues for major efficiency gains, along with simpler deployment, scaling and monitoring. The end result is a fast and scalable vector database with a tunable trade-off between vector search performance and quality, backed by a standard fulltext engine such as Elasticsearch. We empirically demonstrate its querying performance and quality by applying this solution to the task of semantic searching over a dense vector representation of the entire English Wikipedia.|sl:arxiv_author|Vít Novotný
Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks  Sentence-BERT  (SBERT), a modification of the pretrained  BERT network that use siamese and triplet network  structures to derive semantically meaningful  sentence embeddings that can be compared  using cosine-similarity.    Important because     - BERT ist unsuitable for semantic similarity  search as well as for unsupervised tasks  like clustering.  - simple methods such as using the CLS token give low quality sentence embeddings    However, the purpose of SBERT sentence embeddings  are not to be used for transfer learning for other  tasks.    [Related blog post](/doc/2020/01/richer_sentence_embeddings_usin); [Github](https://github.com/UKPLab/sentence-transformers) BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.|sl:tag|tag:emnlp_2019
Solar storm|skos:broader|Soleil
Knowledge Graph Embedding by Relational Rotation in Complex Space|skos:broader|How can we use knowledge graph in computing?    A knowledge graph is a symbolic and logical system but applications often involve numerical computing in continuous spaces.  Formal logic is neither tractable nor robust when dealing with knowledge graph. Hence the idea of Knowledge graph embeddings.    Generally, each entity is represented  as a point in that space while each relation is interpreted as an operation over entity embeddings (eg. in Bordes et al. transE, a translation). The embedding representations are usually learnt by minimizing a global loss function involving all entities and relations so that each entity  embedding encodes both local and global connectivity patterns of the original graph.  
Deep Learning and the Information Bottleneck Principle  Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN.   Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.|sl:arxiv_author|Noga Zaslavsky
blogmarks|skos:broader|Tagging
Le Pen|skos:broader|Méchant
Paradis fiscaux|skos:broader|Finance
FBI v. Apple|skos:broader|Apple
Histoire des sciences|skos:broader|Science
KG-BERT: BERT for Knowledge Graph Completion Pre-trained language models for knowledge graph completion. Triples are treated as textual sequences. (Hum, j'ai déjà vu ça quelque part) Knowledge graphs are important resources for many artificial intelligence tasks but often suffer from incompleteness. In this work, we propose to use pre-trained language models for knowledge graph completion. We treat triples in knowledge graphs as textual sequences and propose a novel framework named Knowledge Graph Bidirectional Encoder Representations from Transformer (KG-BERT) to model these triples. Our method takes entity and relation descriptions of a triple as input and computes scoring function of the triple with the KG-BERT language model. Experimental results on multiple benchmark knowledge graphs show that our method can achieve state-of-the-art performance in triple classification, link prediction and relation prediction tasks.|sl:arxiv_author|Chengsheng Mao
Google Knowledge Graph|skos:broader|Google
Product Knowledge Graph|skos:broader|Product description
Sentiment analysis|skos:broader|Data mining
Manaal Faruqui|skos:broader|NLP girls and guys
Grillon|skos:broader|Insecte
Linear Algebraic Structure of Word Senses, with Applications to Polysemy  Here it is shown that multiple word senses reside  in linear superposition within the word  embedding and simple sparse coding can recover  vectors that approximately capture the  senses     Each extracted word sense is accompanied by one of about  2000 “discourse atoms” that gives a succinct description of which other words co-occur with that word sense.     The success of the approach is mathematically explained using a variant of  the random walk on discourses model    (random walk: a generative model for language). Under the assumptions of this model,  there  exists a linear relationship between the vector of a  word w and the vectors of the words in its contexts (It is not the average of the words in w's context, but in a given corpus the matrix of the linear relationship does not depend on w. It can be estimated, and so we can compute the embedding of a word from the contexts it belongs to)    [Related blog post](/doc/?uri=https%3A%2F%2Fwww.offconvex.org%2F2016%2F07%2F10%2Fembeddingspolysemy%2F)   Word embeddings are ubiquitous in NLP and information retrieval, but it is unclear what they represent when the word is polysemous. Here it is shown that multiple word senses reside in linear superposition within the word embedding and simple sparse coding can recover vectors that approximately capture the senses. The success of our approach, which applies to several embedding methods, is mathematically explained using a variant of the random walk on discourses model (Arora et al., 2016). A novel aspect of our technique is that each extracted word sense is accompanied by one of about 2000 discourse atoms that gives a succinct description of which other words co-occur with that word sense. Discourse atoms can be of independent interest, and make the method potentially more useful. Empirical tests are used to verify and support the theory.|sl:tag|tag:arxiv_doc
Théorie des cordes|skos:broader|Physique
A Survey Of Cross-lingual Word Embedding Models Cross-lingual representations of words enable us to reason about word meaning in multilingual contexts and are a key facilitator of cross-lingual transfer when developing natural language processing models for low-resource languages. In this survey, we provide a comprehensive typology of cross-lingual word embedding models. We compare their data requirements and objective functions. The recurring theme of the survey is that many of the models presented in the literature optimize for the same objectives, and that seemingly different models are often equivalent modulo optimization strategies, hyper-parameters, and such. We also discuss the different ways cross-lingual word embeddings are evaluated, as well as future challenges and research horizons.|sl:tag|tag:cross_lingual_word_embeddings
Search Engines|skos:broader|Information retrieval
API management|skos:broader|API
Robotic imitation|skos:broader|Robotique
Categorical Metadata Representation for Customized Text Classification  We observe that current representation methods for categorical metadata... are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category The performance of text classification has improved tremendously using intelligently engineered neural-based models, especially those injecting categorical metadata as additional information, e.g., using user/product information for sentiment classification. These information have been used to modify parts of the model (e.g., word embeddings, attention mechanisms) such that results can be customized according to the metadata. We observe that current representation methods for categorical metadata, which are devised for human consumption, are not as effective as claimed in popular classification methods, outperformed even by simple concatenation of categorical features in the final layer of the sentence encoder. We conjecture that categorical features are harder to represent for machine use, as available context only indirectly describes the category, and even such context is often scarce (for tail category). To this end, we propose to use basis vectors to effectively incorporate categorical metadata on various parts of a neural-based model. This additionally decreases the number of parameters dramatically, especially when the number of categorical features is large. Extensive experiments on various datasets with different properties are performed and show that through our method, we can represent categorical metadata more effectively to customize parts of the model, including unexplored ones, and increase the performance of the model greatly.|sl:arxiv_author|Sua Sung
sig.ma|skos:broader|Richard Cyganiak
Nature (journal)|skos:broader|Publication scientifique
Alphago|skos:broader|Go (Game)
Eau de Mars|skos:broader|Mars
Technological singularity|skos:broader|Technologie
Human-like AI|skos:broader|Artificial Intelligence
Apple sucks|skos:broader|Apple
Representation learning|skos:broader|Machine learning: problems
Thomas Wolf|skos:broader|NLP girls and guys
Realistic Re-evaluation of Knowledge Graph Completion Methods: An Experimental Study data redundancy (reverse relations), Cartesian product relations     A more fundamental defect  of these models is that the link prediction scenario, given  such data, is non-existent in the real-world In the active research area of employing embedding models for knowledge graph completion, particularly for the task of link prediction, most prior studies used two benchmark datasets FB15k and WN18 in evaluating such models. Most triples in these and other datasets in such studies belong to reverse and duplicate relations which exhibit high data redundancy due to semantic duplication, correlation or data incompleteness. This is a case of excessive data leakage---a model is trained using features that otherwise would not be available when the model needs to be applied for real prediction. There are also Cartesian product relations for which every triple formed by the Cartesian product of applicable subjects and objects is a true fact. Link prediction on the aforementioned relations is easy and can be achieved with even better accuracy using straightforward rules instead of sophisticated embedding models. A more fundamental defect of these models is that the link prediction scenario, given such data, is non-existent in the real-world. This paper is the first systematic study with the main objective of assessing the true effectiveness of embedding models when the unrealistic triples are removed. Our experiment results show these models are much less accurate than what we used to perceive. Their poor accuracy renders link prediction a task without truly effective automated solution. Hence, we call for re-investigation of possible effective approaches.|sl:tag|tag:knowledge_graph_completion
Semantic Text Matching|skos:broader|Text Similarity
limule|skos:broader|Espèces menacées
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|José Emilio Labra Gayo
GNU Octave|skos:broader|Mathématiques
Variational autoencoder (VAE)|skos:broader|Deep latent variable models
Solr|skos:broader|apache.org
Privacy and internet|skos:broader|Internet
Junk DNA|skos:broader|ADN
A Call for More Rigor in Unsupervised Cross-lingual Learning  a scenario without any parallel data and abundant monolingual data is unrealistic in practice We review motivations, definition, approaches, and methodology for unsupervised cross-lingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of the world's languages. However, we argue that a scenario without any parallel data and abundant monolingual data is unrealistic in practice. We also discuss different training signals that have been used in previous work, which depart from the pure unsupervised setting. We then describe common methodological issues in tuning and evaluation of unsupervised cross-lingual models and present best practices. Finally, we provide a unified outlook for different types of research in this area (i.e., cross-lingual word embeddings, deep multilingual pretraining, and unsupervised machine translation) and argue for comparable evaluation of these models.|sl:arxiv_author|Dani Yogatama
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:arxiv_author|Nicole Limtiaco
EDF|skos:broader|Energie
Coursera: R Programming|skos:broader|R
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:arxiv_author|Nicolas Pinto
SDMX-RDF|skos:broader|Semantic Statistics
Barack's Wife Hillary: Using Knowledge-Graphs for Fact-Aware Language Modeling  a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset, a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark. In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language model's ability to complete sentences requiring factual knowledge, showing that the KGLM outperforms even very large language models in generating facts.|sl:arxiv_author|Nelson F. Liu
Graph Embeddings|skos:broader|Embeddings
Koskas|skos:broader|KODE
Reboisement|skos:broader|Plantation d'arbres
Afrique francophone|skos:broader|Francophonie
JDBC|skos:broader|Java dev
Microsoft Research|skos:broader|Microsoft
Publicité Internet|skos:broader|Internet
markdown-it|skos:broader|Markown / Javascript
David Beckett|skos:broader|Technical girls and guys
Learning Semantic Similarity for Very Short Texts In order to pair short text  fragments—as a concatenation of separate words—an adequate  distributed sentence representation is needed. Main contribution: a first step towards a hybrid method that  combines the strength of dense distributed representations—  as opposed to sparse term matching—with the strength of  tf-idf based methods. The combination of word embeddings and tf-idf  information might lead to a better model for semantic content  within very short text fragments. Levering data on social media, such as Twitter and Facebook, requires information retrieval algorithms to become able to relate very short text fragments to each other. Traditional text similarity methods such as tf-idf cosine-similarity, based on word overlap, mostly fail to produce good results in this case, since word overlap is little or non-existent. Recently, distributed word representations, or word embeddings, have been shown to successfully allow words to match on the semantic level. In order to pair short text fragments - as a concatenation of separate words - an adequate distributed sentence representation is needed, in existing literature often obtained by naively combining the individual word representations. We therefore investigated several text representations as a combination of word embeddings in the context of semantic pair matching. This paper investigates the effectiveness of several such naive techniques, as well as traditional tf-idf similarity, for fragments of different lengths. Our main contribution is a first step towards a hybrid method that combines the strength of dense distributed representations - as opposed to sparse term matching - with the strength of tf-idf based methods to automatically reduce the impact of less informative terms. Our new approach outperforms the existing techniques in a toy experimental set-up, leading to the conclusion that the combination of word embeddings and tf-idf information might lead to a better model for semantic content within very short text fragments.|sl:tag|tag:word_embedding
Ours polaire|skos:broader|Ours
A Review of Relational Machine Learning for Knowledge Graphs Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be trained on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive datasets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Google's Knowledge Vault project as an example of such combination.|sl:arxiv_author|Kevin Murphy
Moussa Kaka|skos:broader|Journaliste
Musée archéologique de Bagdad|skos:broader|Irak
TouchGraph|skos:broader|Graph visualization
FBI v. Apple|skos:broader|Vie privée
TripleStore|skos:broader|Relational Databases and the Semantic Web
backplanejs|skos:broader|Unobtrusive JavaScript
Java in python|skos:broader|Java
spaCy|skos:broader|NLP tools
Pedro Almodóvar|skos:broader|Réalisateur
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Ashish Vaswani
photos online|skos:broader|Photo
Graph Editor|skos:broader|Graph
Python 4 Data science|skos:broader|Python
huggingface/transformers|skos:broader|Transformers
Embeddings|skos:broader|Representation learning
spurl|skos:broader|Social bookmarking
Maxent models|skos:broader|Machine learning: techniques
Elda|skos:broader|Epimorphics
Tchernobyl|skos:broader|Ex URSS URSS
Lycée|skos:broader|Education
Film indien|skos:broader|Film
Deep Mutual Learning  In this paper we explore a different but related idea to model distillation – that of mutual learning. Distillation starts with a powerful large and pre-trained teacher network and performs one-way knowledge transfer to a small untrained student. In contrast, in mutual learning we start with a pool of untrained students who learn simultaneously to solve the task together.    [critic here](doc:2020/06/1804_03235_large_scale_distri):     Zhang et al. (2017) reported a benefit in quality over  basic distillation, but they compare distilling model M1 into model M2 with training model M1  and model M2 using codistillation; they do not compare to distilling an ensemble of models M1  and M2 into model M3.     ...     we can achieve the 70.7% they report for online  distillation using traditional offline distillation. Model distillation is an effective and widely used technique to transfer knowledge from a teacher to a student network. The typical application is to transfer from a powerful large network or ensemble to a small network, that is better suited to low-memory or fast execution requirements. In this paper, we present a deep mutual learning (DML) strategy where, rather than one way transfer between a static pre-defined teacher and a student, an ensemble of students learn collaboratively and teach each other throughout the training process. Our experiments show that a variety of network architectures benefit from mutual learning and achieve compelling results on CIFAR-100 recognition and Market-1501 person re-identification benchmarks. Surprisingly, it is revealed that no prior powerful teacher network is necessary -- mutual learning of a collection of simple student networks works, and moreover outperforms distillation from a more powerful yet static teacher.|sl:arxiv_author|Tao Xiang
Hérodote|skos:broader|Grèce antique
Automotive AND W3C|skos:broader|Automotive and web technologies
Neural Architectures for Named Entity Recognition Neural architectures for NER that use no language-specific resources or features beyond a small amount of supervised training data and unlabeled corpora.      Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.|sl:arxiv_author|Guillaume Lample
Concept's URI|skos:broader|LD
BLINK|skos:broader|Wikification
Archéologie chinoise|skos:broader|Archéologie
Sani Aboussa|skos:broader|Musicien
Mines d'or|skos:broader|Industrie minière
SVD factorizes the word-context co-occurrence matrix into the product of three matrices UΣV where U and V are orthonormal matrices (i.e. square matrices whose rows and columns are orthogonal unit vectors) and Σ is a diagonal matrix of eigenvalues in decreasing order.    |skos:broader|process of reducing the number of random variables under consideration. Can be divided into feature selection and feature extraction.
Stemming|skos:broader|NLP tasks / problems
XLNet: Generalized Autoregressive Pretraining for Language Understanding a new pretraining method for NLP that significantly improves upon BERT on 20 tasks (e.g., SQuAD, GLUE, RACE) With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.|sl:arxiv_firstAuthor|Zhilin Yang
several representations are proposed to extend word representation for phrases ([Yin and Schütze, 2014](/doc/?uri=http%3A%2F%2Faclweb.org%2Fanthology%2FP14-3006); Yu and Dredze, 2015; Passos et al., 2014). However, they don’t use structured knowledge to derive phrase representations (as said [here](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1607.07956))    [Sabastian Ruder](/tag/sebastian_ruder) in 2017 says the [following](http://ruder.io/word-embeddings-2017/index.html#phrasesandmultiwordexpressions):     explicitly modelling phrases has so far not shown significant improvements on downstream tasks that would justify the additional complexity    (but hum: what's about NER - in particular if using external knowledge such as lexicons?)        |skos:broader|The objective of embedding methods is to organize symbolic objects (e.g., words, entities, concepts) in a way such that their similarity in the embedding space reflects their semantic or functional similarity  
RDF-OWL documentation tool|skos:broader|Documentation tool
A Survey on Deep Learning for Named Entity Recognition mainly focus on generic NEs in English language Named entity recognition (NER) is the task to identify mentions of rigid designators from text belonging to predefined semantic types such as person, location, organization etc. NER always serves as the foundation for many natural language applications such as question answering, text summarization, and machine translation. Early NER systems got a huge success in achieving good performance with the cost of human engineering in designing domain-specific features and rules. In recent years, deep learning, empowered by continuous real-valued vector representations and semantic composition through nonlinear processing, has been employed in NER systems, yielding stat-of-the-art performance. In this paper, we provide a comprehensive review on existing deep learning techniques for NER. We first introduce NER resources, including tagged NER corpora and off-the-shelf NER tools. Then, we systematically categorize existing works based on a taxonomy along three axes: distributed representations for input, context encoder, and tag decoder. Next, we survey the most representative methods for recent applied techniques of deep learning in new NER problem settings and applications. Finally, we present readers with the challenges faced by NER systems and outline future directions in this area.|sl:tag|tag:arxiv_doc
Kapuscinski|skos:broader|Littérature
GAO|skos:broader|fps ontologies
SHACL|skos:broader|Semantic Web
No Fuss Distance Metric Learning using Proxies  We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity...   Traditionnaly, supervision is expressed in the form of sets of points that follow  an ordinal relationship – an anchor point x is similar to  a set of positive points Y , and dissimilar to a set of negative  points Z, and a loss defined over these distances is minimized.   Triplet-Based methods are challenging to optimize (a main issue is the need for finding informative triplets).     We propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss.    Mentioned in this [blog post](/doc/2020/01/training_a_speaker_embedding_fr):     Proxy based triplet learning: instead of generating triplets, we learn an embedding for each class and use the learnt embedding as a proxy for triplets as part of the training. In other words, we can train end to end without the computationally expensive step of resampling triplets after each network update.    Near the conclusion:     Our formulation of Proxy-NCA loss produces a loss very  similar to the standard cross-entropy loss used in classification.  However, we arrive at our formulation from a different  direction: we are not interested in the actual classifier and  indeed discard the proxies once the model has been trained.  Instead, the proxies are auxiliary variables, enabling more  effective optimization of the embedding model parameters.  As such, our formulation not only enables us to surpass the  state of the art in zero-shot learning, but also offers an explanation  to the effectiveness of the standard trick of training  a classifier, and using its penultimate layer’s output as the  embedding. We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity. Traditionally, for this problem supervision is expressed in the form of sets of points that follow an ordinal relationship -- an anchor point $x$ is similar to a set of positive points $Y$, and dissimilar to a set of negative points $Z$, and a loss defined over these distances is minimized. While the specifics of the optimization differ, in this work we collectively call this type of supervision Triplets and all methods that follow this pattern Triplet-Based methods. These methods are challenging to optimize. A main issue is the need for finding informative triplets, which is usually achieved by a variety of tricks such as increasing the batch size, hard or semi-hard triplet mining, etc. Even with these tricks, the convergence rate of such methods is slow. In this paper we propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss. This proxy-based loss is empirically better behaved. As a result, the proxy-loss improves on state-of-art results for three standard zero-shot learning datasets, by up to 15% points, while converging three times as fast as other triplet-based losses.|sl:tag|tag:zero_shot_learning
Deep NLP|skos:broader|NLP
Afripedia|skos:broader|Francophonie
Songhaï|skos:broader|Peuples
Reptile|skos:broader|Animal
Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.|sl:tag|tag:attention_is_all_you_need
PIMO|skos:broader|Personal ontology
Backbone.js|skos:broader|JavaScript librairies
Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks  Sentence-BERT  (SBERT), a modification of the pretrained  BERT network that use siamese and triplet network  structures to derive semantically meaningful  sentence embeddings that can be compared  using cosine-similarity.    Important because     - BERT ist unsuitable for semantic similarity  search as well as for unsupervised tasks  like clustering.  - simple methods such as using the CLS token give low quality sentence embeddings    However, the purpose of SBERT sentence embeddings  are not to be used for transfer learning for other  tasks.    [Related blog post](/doc/2020/01/richer_sentence_embeddings_usin); [Github](https://github.com/UKPLab/sentence-transformers) BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.|sl:tag|tag:siamese_network
Yves Roth|skos:broader|Souvenirs
Celte|skos:broader|Archéologie européenne
Mars Express|skos:broader|esa
SolrCloud|skos:broader|Solr
Peter Patel-Schneider|skos:broader|SW guys (and girls)
Self-Supervised Learning|skos:broader|Machine learning
URI opacity|skos:broader|URI
Representation Learning with Contrastive Predictive Coding  a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful [autoregressive models](/tag/autoregressive_model). We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using [negative sampling](/tag/negative_sampling).    a contrastive method that can be applied to any form of data that can be expressed in an ordered sequence: text, speech, video... While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.|sl:tag|tag:unsupervised_machine_learning
NLP: applications|skos:broader|Natural Language Processing
On Extractive and Abstractive Neural Document Summarization with Transformer Language Models  Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper. We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We show that this extractive step significantly improves summarization results. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher rouge scores. Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper.|sl:arxiv_author|Jonathan Pilault
Evolution|skos:broader|Histoire de la vie
InceptionTime: Finding AlexNet for Time Series Classification Time series classification (TSC) is the area of machine learning interested in learning how to assign labels to time series. The last few decades of work in this area have led to significant progress in the accuracy of classifiers, with the state of the art now represented by the HIVE-COTE algorithm. While extremely accurate, HIVE-COTE is infeasible to use in many applications because of its very high training time complexity in O(N^2T^4) for a dataset with N time series of length T. For example, it takes HIVE-COTE more than 72,000s to learn from a small dataset with N=700 time series of short length T=46. Deep learning, on the other hand, has now received enormous attention because of its high scalability and state-of-the-art accuracy in computer vision and natural language processing tasks. Deep learning for TSC has only very recently started to be explored, with the first few architectures developed over the last 3 years only. The accuracy of deep learning for TSC has been raised to a competitive level, but has not quite reached the level of HIVE-COTE. This is what this paper achieves: outperforming HIVE-COTE's accuracy together with scalability. We take an important step towards finding the AlexNet network for TSC by presenting InceptionTime---an ensemble of deep Convolutional Neural Network (CNN) models, inspired by the Inception-v4 architecture. Our experiments show that InceptionTime slightly outperforms HIVE-COTE with a win/draw/loss on the UCR archive of 40/6/39. Not only is InceptionTime more accurate, but it is much faster: InceptionTime learns from that same dataset with 700 time series in 2,300s but can also learn from a dataset with 8M time series in 13 hours, a quantity of data that is fully out of reach of HIVE-COTE.|sl:arxiv_author|Pierre-Alain Muller
The HSIC Bottleneck: Deep Learning without Back-Propagation  we show that it is possible to learn classification tasks at near competitive accuracy without  backpropagation, by maximizing a surrogate of the mutual information between hidden representations and labels and  simultaneously minimizing the mutual dependency between hidden representations and the inputs...  the hidden units of a network trained in this way form useful representations. Specifically, fully competitive accuracy  can be obtained by freezing the network trained without backpropagation and appending and training a one-layer  network using conventional SGD to convert convert the representation to the desired format.    The training method uses an approximation of the [#information bottleneck](/tag/information_bottleneck_method).    Advantages:     - The method facilitates parallel processing and requires significantly less operations.    - It does not suffer from exploding or vanishing gradients.   - It is biologically more plausible than Backpropagation     We introduce the HSIC (Hilbert-Schmidt independence criterion) bottleneck for training deep neural networks. The HSIC bottleneck is an alternative to the conventional cross-entropy loss and backpropagation that has a number of distinct advantages. It mitigates exploding and vanishing gradients, resulting in the ability to learn very deep networks without skip connections. There is no requirement for symmetric feedback or update locking. We find that the HSIC bottleneck provides performance on MNIST/FashionMNIST/CIFAR10 classification comparable to backpropagation with a cross-entropy target, even when the system is not encouraged to make the output resemble the classification labels. Appending a single layer trained with SGD (without backpropagation) to reformat the information further improves performance.|sl:arxiv_author|W. Bastiaan Kleijn
Natural Language Processing with Small Feed-Forward Networks google guys:      We show that small and shallow feed- forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.   We show that small and shallow feed-forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.|sl:arxiv_author|Anton Bakalov
ESWC 2011|skos:broader|ESWC
Semantic browsing|skos:broader|Semanlink related
Self-Taught Convolutional Neural Networks for Short Text Clustering  We propose a flexible short text clustering framework which explores the feasibility and effectiveness of combining CNN and traditional unsupervised dimensionality reduction methods.     Non-biased deep feature representations can be learned through our self- taught CNN framework which does not use any external tags/labels or complicated NLP pre-processing.     The original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations.    [conf paper, same authors](http://www.aclweb.org/anthology/W15-1509) ; [gitgub repo (matlab)](https://github.com/jacoxu/STC2)   Short text clustering is a challenging problem due to its sparseness of text representation. Here we propose a flexible Self-Taught Convolutional neural network framework for Short Text Clustering (dubbed STC^2), which can flexibly and successfully incorporate more useful semantic features and learn non-biased deep text representation in an unsupervised manner. In our framework, the original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations. Extensive experimental results demonstrate that the proposed framework is effective, flexible and outperform several popular clustering methods when tested on three public short text datasets.|sl:arxiv_author|Jun Zhao
Catastrophic forgetting|skos:broader|Deep Learning
Relations franco-américaines|skos:broader|Relations Europe-USA
Parasitisme|skos:broader|Biology
Named Entity Recognition with Extremely Limited Data Named Entity Search (NES)     We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.     We do not propose this as a replacement  for NER, but as something to be used for an ephemeral or contextual  class of entity, when it does not make sense to label hundreds or  thousands of instances to learn a classifier Traditional information retrieval treats named entity recognition as a pre-indexing corpus annotation task, allowing entity tags to be indexed and used during search. Named entity taggers themselves are typically trained on thousands or tens of thousands of examples labeled by humans. However, there is a long tail of named entities classes, and for these cases, labeled data may be impossible to find or justify financially. We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.|sl:arxiv_author|Sheikh Muhammad Sarwar
FastText|skos:broader|Word embeddings
Jupiter/Europe|skos:broader|Jupiter
NLP: French|skos:broader|NLP
FBI v. Apple|skos:broader|Backdoor
Nokia|skos:broader|Téléphone
Entity Embeddings of Categorical Variables  We map categorical variables in a function approximation problem into Euclidean spaces, which are the entity embeddings of the categorical variables. The mapping is learned by a neural network during the standard supervised training process. Entity embedding not only reduces memory usage and speeds up neural networks compared with one-hot encoding, but more importantly by mapping similar values close to each other in the embedding space it reveals the intrinsic properties of the categorical variables We map categorical variables in a function approximation problem into Euclidean spaces, which are the entity embeddings of the categorical variables. The mapping is learned by a neural network during the standard supervised training process. Entity embedding not only reduces memory usage and speeds up neural networks compared with one-hot encoding, but more importantly by mapping similar values close to each other in the embedding space it reveals the intrinsic properties of the categorical variables. We applied it successfully in a recent Kaggle competition and were able to reach the third position with relative simple features. We further demonstrate in this paper that entity embedding helps the neural network to generalize better when the data is sparse and statistics is unknown. Thus it is especially useful for datasets with lots of high cardinality features, where other methods tend to overfit. We also demonstrate that the embeddings obtained from the trained neural network boost the performance of all tested machine learning methods considerably when used as the input features instead. As entity embedding defines a distance measure for categorical variables it can be used for visualizing categorical data and for data clustering.|sl:tag|tag:entity_embeddings
MPAA|skos:broader|Propriété intellectuelle
A Tutorial on Network Embeddings Network embedding methods aim at learning low-dimensional latent representation of nodes in a network. These representations can be used as features for a wide range of tasks on graphs such as classification, clustering, link prediction, and visualization. In this survey, we give an overview of network embeddings by summarizing and categorizing recent advancements in this research field. We first discuss the desirable properties of network embeddings and briefly introduce the history of network embedding algorithms. Then, we discuss network embedding methods under different scenarios, such as supervised versus unsupervised learning, learning embeddings for homogeneous networks versus for heterogeneous networks, etc. We further demonstrate the applications of network embeddings, and conclude the survey with future work in this area.|sl:tag|tag:arxiv_doc
Dave Reynolds|skos:broader|SW guys (and girls)
Selective Question Answering under Domain Shift How you can get a QA model to abstain from answering when it doesn’t know the answer.     Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. To avoid giving wrong answers, question answering (QA) models need to know when to abstain from answering. Moreover, users often ask questions that diverge from the model's training data, making errors more likely and thus abstention more critical. In this work, we propose the setting of selective question answering under domain shift, in which a QA model is tested on a mixture of in-domain and out-of-domain data, and must answer (i.e., not abstain on) as many questions as possible while maintaining high accuracy. Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. Crucially, the calibrator benefits from observing the model's behavior on out-of-domain data, even if from a different domain than the test data. We combine this method with a SQuAD-trained QA model and evaluate on mixtures of SQuAD and five other QA datasets. Our method answers 56% of questions while maintaining 80% accuracy; in contrast, directly using the model's probabilities only answers 48% at 80% accuracy.|sl:arxiv_author|Amita Kamath
Crimes de l'église catholique|skos:broader|Crime
Topic Modeling over Short Texts|skos:broader|Topic Modeling
A system for rapidly creating training sets with weak supervision     The System for Programmatically Building and Managing Training Data|skos:broader|data labeling is usually the bottleneck in developing NLP applications. Pbs of shifting contexts on social networks
[Doc](https://huggingface.co/transformers/)|skos:broader|[Vaswani, et al. 2017 paper](https://arxiv.org/abs/1706.03762): Attention is all you need.    [#seq2seq](/tag/sequence_to_sequence_learning) using only improved self-attention units (multi-head self-attention  mechanism), without any RNN.  
XSL|skos:broader|Dev
Tomcat|skos:broader|Servlet
A Survey Of Cross-lingual Word Embedding Models Cross-lingual representations of words enable us to reason about word meaning in multilingual contexts and are a key facilitator of cross-lingual transfer when developing natural language processing models for low-resource languages. In this survey, we provide a comprehensive typology of cross-lingual word embedding models. We compare their data requirements and objective functions. The recurring theme of the survey is that many of the models presented in the literature optimize for the same objectives, and that seemingly different models are often equivalent modulo optimization strategies, hyper-parameters, and such. We also discuss the different ways cross-lingual word embeddings are evaluated, as well as future challenges and research horizons.|sl:tag|tag:arxiv_doc
An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks For most deep learning practitioners, sequence modeling is synonymous with recurrent networks. Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation. Given a new sequence modeling task or dataset, which architecture should one use? We conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling. The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks. Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as LSTMs across a diverse range of tasks and datasets, while demonstrating longer effective memory. We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks. To assist related work, we have made code available at http://github.com/locuslab/TCN .|sl:tag|tag:sequence_modeling_cnn_vs_rnn
jersey/RDF|skos:broader|Semantic Web Services
Memory leak|skos:broader|Dev
Scala|skos:broader|Programming language
Apple CarPlay|skos:broader|Automobile
Generalization through Memorization: Nearest Neighbor Language Models extend LMs with nearest neighbor search in embedding space We introduce $k$NN-LMs, which extend a pre-trained neural language model (LM) by linearly interpolating it with a $k$-nearest neighbors ($k$NN) model. The nearest neighbors are computed according to distance in the pre-trained LM embedding space, and can be drawn from any text collection, including the original LM training data. Applying this augmentation to a strong Wikitext-103 LM, with neighbors drawn from the original training set, our $k$NN-LM achieves a new state-of-the-art perplexity of 15.79 - a 2.9 point improvement with no additional training. We also show that this approach has implications for efficiently scaling up to larger training sets and allows for effective domain adaptation, by simply varying the nearest neighbor datastore, again without further training. Qualitatively, the model is particularly helpful in predicting rare patterns, such as factual knowledge. Together, these results strongly suggest that learning similarity between sequences of text is easier than predicting the next word, and that nearest neighbor search is an effective approach for language modeling in the long tail.|sl:tag|tag:dan_jurafsky
Google ranking|skos:broader|Search Engines
RSS Dev|skos:broader|Dev
Topic Modeling over Short Texts by Incorporating Word Embeddings New method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo-texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic Inferring topics from the overwhelming amount of short texts becomes a critical but challenging task for many content analysis tasks, such as content charactering, user interest profiling, and emerging topic detecting. Existing methods such as probabilistic latent semantic analysis (PLSA) and latent Dirichlet allocation (LDA) cannot solve this prob- lem very well since only very limited word co-occurrence information is available in short texts. This paper studies how to incorporate the external word correlation knowledge into short texts to improve the coherence of topic modeling. Based on recent results in word embeddings that learn se- mantically representations for words from a large corpus, we introduce a novel method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo- texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic. The experiments on real-world datasets validate the effectiveness of our model comparing with the state-of-the-art models.|sl:arxiv_author|Xindong Wu
Langues anciennes|skos:broader|Langues
Liberté, égalité, fraternité|skos:broader|Liberté
DocBERT: BERT for Document Classification We present, to our knowledge, the first application of BERT to document classification. A few characteristics of the task might lead one to think that BERT is not the most appropriate model: syntactic structures matter less for content categories, documents can often be longer than typical BERT input, and documents often have multiple labels. Nevertheless, we show that a straightforward classification model using BERT is able to achieve the state of the art across four popular datasets. To address the computational expense associated with BERT inference, we distill knowledge from BERT-large to small bidirectional LSTMs, reaching BERT-base parity on multiple datasets using 30x fewer parameters. The primary contribution of our paper is improved baselines that can provide the foundation for future work.|sl:tag|tag:nlp_text_classification
Transfer learning in NLP|skos:broader|Transfer learning
Knowledge Enhanced Contextual Word Representations General method to embed multiple knowledge bases into pre-trained language models (KB in the   sense as fixed collection of entity nodes)     The key idea is to explicitly model  entity spans in the input text and use an entity  linker to retrieve relevant entity embeddings from  a KB to form knowledge enhanced entity-span  representations.   Then,  update contextual word representations via a form of word-to-entity attention.    In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert's runtime is comparable to BERT's and it scales to large KBs.|sl:arxiv_author|Vidur Joshi
Blog|skos:broader|Internet
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.|sl:arxiv_author|Yarin Gal
Une suite de matrices symétriques en rapport avec la fonction de Mertens  we explore a class of equivalence relations over N from which is constructed a sequence of symetric matrices related to the Mertens function. From numerical experimentations we suggest a conjecture, about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may play a more important part in this classical and difficult problem. In this paper we explore a class of equivalence relations over $\\N^\\ast$ from which is constructed a sequence of symetric matrices related to the Mertens function. From numerical experimentations we suggest a conjecture, about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may play a more important part in this classical and difficult problem.|sl:tag|tag:jean_paul
Sense2vec|skos:broader|Word sense / Lexical ambiguity
Disco Hyperdata Browser|skos:broader|Chris Bizer
Transfer learning in NLP|skos:broader|NLP tasks / problems
OpenLink Ajax Toolkit (OAT)|skos:broader|OpenLink Software
FranceConnect|skos:broader|France
Bringing Light Into the Dark: A Large-scale Evaluation of Knowledge Graph Embedding Models Under a Unified Framework The heterogeneity in recently published knowledge graph embedding models' implementations, training, and evaluation has made fair and thorough comparisons difficult. In order to assess the reproducibility of previously published results, we re-implemented and evaluated 19 interaction models in the PyKEEN software package. Here, we outline which results could be reproduced with their reported hyper-parameters, which could only be reproduced with alternate hyper-parameters, and which could not be reproduced at all as well as provide insight as to why this might be the case. We then performed a large-scale benchmarking on four datasets with several thousands of experiments and 21,246 GPU hours of computation time. We present insights gained as to best practices, best configurations for each model, and where improvements could be made over previously published best configurations. Our results highlight that the combination of model architecture, training approach, loss function, and the explicit modeling of inverse relations is crucial for a model's performances, and not only determined by the model architecture. We provide evidence that several architectures can obtain results competitive to the state-of-the-art when configured carefully. We have made all code, experimental configurations, results, and analyses that lead to our interpretations available at https://github.com/pykeen/pykeen and https://github.com/pykeen/benchmarking|sl:tag|tag:survey
fps @ LDOW 2013|skos:broader|C2GWeb
Crète|skos:broader|Grèce
NLP: introduction|skos:broader|NLP
The Web Ontology for Products and Servicesbr/  OWL Representation of the eCl@ss Classification Standard|skos:broader|An ontology for linking product descriptions and business entities on the Web
What Does BERT Look At? An Analysis of BERT's Attention Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT's attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT's attention.|sl:tag|tag:bertology
Entities as Experts: Sparse Memory Access with Entity Supervision   the problem of capturing declarative knowledge in the learned parameters of a language model...     Entities as Experts (EaE) can access distinct memories of the entities mentioned in a piece of text;     To understand the motivation for distinct and  independent entity representations: A traditional Transformer would need to build an internal representation  of Charles Darwin from the words “Charles”  and “Darwin”... Conversely, EAE can access  a dedicated representation of “Charles Darwin”,  which is a memory of all of the contexts in which  this entity has previously been mentioned.... Having retrieved  and re-integrated this memory it is much easier for  EAE to relate the question to the answer     EaE's entity representations are learned directly from text. Correct identification, and representation, of entities is essential to EaE's performance    Based on transformer architecture    Extension: [Facts as Experts](doc:2020/07/2007_00849_facts_as_experts_) We focus on the problem of capturing declarative knowledge in the learned parameters of a language model. We introduce a new model, Entities as Experts (EaE), that can access distinct memories of the entities mentioned in a piece of text. Unlike previous efforts to integrate entity knowledge into sequence models, EaE's entity representations are learned directly from text. These representations capture sufficient knowledge to answer TriviaQA questions such as Which Dr. Who villain has been played by Roger Delgado, Anthony Ainley, Eric Roberts?. EaE outperforms a Transformer model with $30\\times$ the parameters on this task. According to the Lama knowledge probes, EaE also contains more factual knowledge than a similar sized Bert. We show that associating parameters with specific entities means that EaE only needs to access a fraction of its parameters at inference time, and we show that the correct identification, and representation, of entities is essential to EaE's performance. We also argue that the discrete and independent entity representations in EaE make it more modular and interpretable than the Transformer architecture on which it is based.|sl:arxiv_author|Nicholas FitzGerald
Text Corpora and Lexical Resources|skos:broader|NLP
NLP+Automotive|skos:broader|NLP: use cases
DARPA Grand Challenge|skos:broader|DARPA
LDOW2013|skos:broader|WWW 2013
Memory Embeddings|skos:broader|Embeddings
Argentine|skos:broader|Amérique latine
The Consciousness Prior consciousness seen as the formation of a low-dimensional combination of a few concepts constituting a conscious thought, i.e., consciousness as awareness at a particular time instant: the projection of a big vector (all the things conscious and unconscious in brain). Attention: additional mechanism describing what mind chooses to focus on.    [YouTube video](/doc/?uri=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYr1mOzC93xs) A new prior is proposed for learning representations of high-level concepts of the kind we manipulate with language. This prior can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by cognitive neuroscience theories of consciousness, seen as a bottleneck through which just a few elements, after having been selected by attention from a broader pool, are then broadcast and condition further processing, both in perception and decision-making. The set of recently selected elements one becomes aware of is seen as forming a low-dimensional conscious state. This conscious state is combining the few concepts constituting a conscious thought, i.e., what one is immediately conscious of at a particular moment. We claim that this architectural and information-processing constraint corresponds to assumptions about the joint distribution between high-level concepts. To the extent that these assumptions are generally true (and the form of natural language seems consistent with them), they can form a useful prior for representation learning. A low-dimensional thought or conscious state is analogous to a sentence: it involves only a few variables and yet can make a statement with very high probability of being true. This is consistent with a joint distribution (over high-level concepts) which has the form of a sparse factor graph, i.e., where the dependencies captured by each factor of the factor graph involve only very few variables while creating a strong dip in the overall energy function. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in a form similar to facts and rules, albeit capturing uncertainty as well as efficient search mechanisms implemented by attention mechanisms.|sl:tag|tag:conscience_artificielle
SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver Integrating logical reasoning within deep learning architectures has been a major goal of modern AI systems. In this paper, we propose a new direction toward this goal by introducing a differentiable (smoothed) maximum satisfiability (MAXSAT) solver that can be integrated into the loop of larger deep learning systems. Our (approximate) solver is based upon a fast coordinate descent approach to solving the semidefinite program (SDP) associated with the MAXSAT problem. We show how to analytically differentiate through the solution to this SDP and efficiently solve the associated backward pass. We demonstrate that by integrating this solver into end-to-end learning systems, we can learn the logical structure of challenging problems in a minimally supervised fashion. In particular, we show that we can learn the parity function using single-bit supervision (a traditionally hard task for deep networks) and learn how to play 9x9 Sudoku solely from examples. We also solve a visual Sudok problem that maps images of Sudoku puzzles to their associated logical solutions by combining our MAXSAT solver with a traditional convolutional architecture. Our approach thus shows promise in integrating logical structures within deep learning.|sl:tag|tag:nn_symbolic_ai_hybridation
Panthéon (Paris)|skos:broader|Monuments historiques
TheWebConf 2020|skos:broader|TheWebConf
Film policier|skos:broader|Film
Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation   An embedding method specifically designed for NED that jointly maps words and entities into the same continuous vector space.    We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words Named Entity Disambiguation (NED) refers to the task of resolving multiple named entity mentions in a document to their correct references in a knowledge base (KB) (e.g., Wikipedia). In this paper, we propose a novel embedding method specifically designed for NED. The proposed method jointly maps words and entities into the same continuous vector space. We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words. By combining contexts based on the proposed embedding with standard NED features, we achieved state-of-the-art accuracy of 93.1% on the standard CoNLL dataset and 85.2% on the TAC 2010 dataset.|sl:arxiv_firstAuthor|Ikuya Yamada
Span Selection Pre-training for Question Answering  a new pre-training task inspired by reading  comprehension and an effort to avoid encoding general knowledge in the transformer network itself    Current transformer architectures store general knowledge - large models, long pre-training time. Better to offload the requirement of general knowledge to a sparsely activated network.    Span selection as an additional auxiliary task: the query is a sentence drawn from a corpus  with a term replaced with a special token: [BLANK]. The term replaced by the blank is the answer term. The passage is  relevant as determined by a BM25 search, and answer-bearing (containing the answer  term). Unlike BERT’s cloze task, where the answer must be drawn from the model itself, the answer is found in a passage  using language understanding.     We hope to progress to a model of general purpose language modeling that uses an indexed long  term memory to retrieve world knowledge, rather than holding it in the densely activated transformer encoder layers. BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pre-trained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension and an effort to avoid encoding general knowledge in the transformer network itself. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple reading comprehension (MRC) and paraphrasing datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also establish a new SOTA in HotpotQA, improving answer prediction F1 by 4 F1 points and supporting fact prediction by 1 F1 point. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.|sl:tag|tag:language_model
Online dictionary|skos:broader|Langues
Okapi BM25|skos:broader|Probabilistic relevance model
Quantum computing|skos:broader|Computers
NLP|skos:broader|Semantic technology
Driverless car|skos:broader|Automobile 2.0
Eclipse tip|skos:broader|Dev tips
Content industries|skos:broader|Capitalistes
Méthodes agiles|skos:broader|Management
A Tutorial on Distance Metric Learning: Mathematical Foundations, Algorithms and Experiments distance metric learning, a branch of machine learning that aims to learn distances from the data Distance metric learning is a branch of machine learning that aims to learn distances from the data. Distance metric learning can be useful to improve similarity learning algorithms, and also has applications in dimensionality reduction. This paper describes the distance metric learning problem and analyzes its main mathematical foundations. In addition, it also discusses some of the most popular distance metric learning techniques used in classification, showing their goals and the required information to understand and use them. Furthermore, some experiments to evaluate the performance of the different algorithms are also provided. Finally, this paper discusses several possibilities of future work in this topic.|sl:arxiv_author|Salvador García
Database to RDF mapping|skos:broader|Database
Rosetta|skos:broader|Comète
Similarity queries|skos:broader|Information retrieval: techniques
R|skos:broader|Data mining tools
Astrophysique|skos:broader|Astronomie
C2GWeb and Product description|skos:broader|C2GWeb: SEO
Okapi BM25|skos:broader|Ranking (information retrieval)
spurl|skos:broader|Tagging
KODE|skos:broader|Radix trees
Giovanni Tummarello|skos:broader|Technical girls and guys
Generative models that can be used to analyze the evolution of (unobserved) topics of a collection of documents over time.br/  extension to Latent Dirichlet Allocation (LDA) that can handle sequential documents|skos:broader|A statistical model for discovering the abstract topics that occur in a collection of documents.      
Interactive Concept Mining on Personal Data -- Bootstrapping Semantic Services Semantic services (e.g. Semantic Desktops) are still afflicted by a cold start problem: in the beginning, the user's personal information sphere, i.e. files, mails, bookmarks, etc., is not represented by the system. Information extraction tools used to kick-start the system typically create 1:1 representations of the different information items. Higher level concepts, for example found in file names, mail subjects or in the content body of these items, are not extracted. Leaving these concepts out may lead to underperformance, having to many of them (e.g. by making every found term a concept) will clutter the arising knowledge graph with non-helpful relations. In this paper, we present an interactive concept mining approach proposing concept candidates gathered by exploiting given schemata of usual personal information management applications and analysing the personal information sphere using various metrics. To heed the subjective view of the user, a graphical user interface allows to easily rank and give feedback on proposed concept candidates, thus keeping only those actually considered relevant. A prototypical implementation demonstrates major steps of our approach.|sl:tag|tag:arxiv_doc
Visually rich documents|skos:broader|2D-NLP
Self-Attention|skos:broader|Attention mechanism
A Theoretical Analysis of Contrastive Unsupervised Representation Learning [blog post](/doc/?uri=http%3A%2F%2Fwww.offconvex.org%2F2019%2F03%2F19%2FCURL%2F) Recent empirical works have successfully used unlabeled data to learn feature representations that are broadly useful in downstream classification tasks. Several of these methods are reminiscent of the well-known word2vec embedding algorithm: leveraging availability of pairs of semantically similar data points and negative samples, the learner forces the inner product of representations of similar pairs with each other to be higher on average than with negative samples. The current paper uses the term contrastive learning for such algorithms and presents a theoretical framework for analyzing them by introducing latent classes and hypothesizing that semantically similar points are sampled from the same latent class. This framework allows us to show provable guarantees on the performance of the learned representations on the average classification task that is comprised of a subset of the same set of latent classes. Our generalization bound also shows that learned representations can reduce (labeled) sample complexity on downstream tasks. We conduct controlled experiments in both the text and image domains to support the theory.|sl:tag|tag:sanjeev_arora
GINCO (Culture)|skos:broader|Culture et sem web
IPython|skos:broader|Jupyter
MongoDB|skos:broader|NOSQL
Pangloss: Fast Entity Linking in Noisy Text Environments a production system for entity disambiguation on messy tex, based  on probabilistic tokenization and context-dependent document embeddings    Probabilistic tokenization: uses the method described [here](/doc/2019/07/mining_quality_phrases_from_mas) Entity linking is the task of mapping potentially ambiguous terms in text to their constituent entities in a knowledge base like Wikipedia. This is useful for organizing content, extracting structured data from textual documents, and in machine learning relevance applications like semantic search, knowledge graph construction, and question answering. Traditionally, this work has focused on text that has been well-formed, like news articles, but in common real world datasets such as messaging, resumes, or short-form social media, non-grammatical, loosely-structured text adds a new dimension to this problem. This paper presents Pangloss, a production system for entity disambiguation on noisy text. Pangloss combines a probabilistic linear-time key phrase identification algorithm with a semantic similarity engine based on context-dependent document embeddings to achieve better than state-of-the-art results (5% in F1) compared to other research or commercially available systems. In addition, Pangloss leverages a local embedded database with a tiered architecture to house its statistics and metadata, which allows rapid disambiguation in streaming contexts and on-device disambiguation in low-memory environments such as mobile phones.|sl:arxiv_author|Scott Blackburn
Verger de Gado à Niamey|skos:broader|Affaires de Gado à Niamey
KGE KG embedding Knowledge graph embedding|skos:broader|embedding
Excel|skos:broader|Spreadsheets
OWL ontology|skos:broader|Ontologies
Afrique du Nord|skos:broader|Afrique
Support vector machine|skos:broader|Statistical classification
 bobdc.blog|skos:broader|Technical guys
Capitalisme financier|skos:broader|Finance
Similarity learning|skos:broader|Supervised machine learning
Locality Sensitive Hashing|skos:broader|Similarity queries
Blackbox NLP|skos:broader|Explainable NLP
del.icio.us|skos:broader|Social bookmarking
SOAP vs REST|skos:broader|Web Services
Carte|skos:broader|Géographie
Description Logic|skos:broader|Formal knowledge representation language
IBM|skos:broader|Entreprise
gnizr|skos:broader|Social bookmarking
Biterm Topic Model|skos:broader|Topic Modeling over Short Texts
Microsoft Concept Graph|skos:broader|Knowledge Graphs in NLP
Topic Modeling over Short Texts by Incorporating Word Embeddings New method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo-texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic Inferring topics from the overwhelming amount of short texts becomes a critical but challenging task for many content analysis tasks, such as content charactering, user interest profiling, and emerging topic detecting. Existing methods such as probabilistic latent semantic analysis (PLSA) and latent Dirichlet allocation (LDA) cannot solve this prob- lem very well since only very limited word co-occurrence information is available in short texts. This paper studies how to incorporate the external word correlation knowledge into short texts to improve the coherence of topic modeling. Based on recent results in word embeddings that learn se- mantically representations for words from a large corpus, we introduce a novel method, Embedding-based Topic Model (ETM), to learn latent topics from short texts. ETM not only solves the problem of very limited word co-occurrence information by aggregating short texts into long pseudo- texts, but also utilizes a Markov Random Field regularized model that gives correlated words a better chance to be put into the same topic. The experiments on real-world datasets validate the effectiveness of our model comparing with the state-of-the-art models.|sl:arxiv_firstAuthor|Jipeng Qiang
Stacked Approximated Regression Machine: A Simple Deep Learning Approach This paper seems too good to be true! They can train a VGG-like net VERY quickly to good accuracy, without backprop. With the agreement of my coauthors, I Zhangyang Wang would like to withdraw the manuscript Stacked Approximated Regression Machine: A Simple Deep Learning Approach. Some experimental procedures were not included in the manuscript, which makes a part of important claims not meaningful. In the relevant research, I was solely responsible for carrying out the experiments; the other coauthors joined in the discussions leading to the main algorithm. Please see the updated text for more details.|sl:arxiv_author|Qing Ling
Linked Data API|skos:broader|API
Latent Semantic Analysis|skos:broader|Distributional semantics
LOD mailing list|skos:broader|Linked Data
Elevage porcin|skos:broader|Agriculture
Physique des particules|skos:broader|Physique
IA/ML: domaines d'application|skos:broader|Machine learning
AJAR|skos:broader|RDF
Origines de l'homme|skos:broader|Evolution
W3C|skos:broader|Internet
DeepType: Multilingual Entity Linking by Neural Type System Evolution The wealth of structured (e.g. Wikidata) and unstructured data about the world available today presents an incredible opportunity for tomorrow's Artificial Intelligence. So far, integration of these two different modalities is a difficult process, involving many decisions concerning how best to represent the information so that it will be captured or useful, and hand-labeling large amounts of data. DeepType overcomes this challenge by explicitly integrating symbolic information into the reasoning process of a neural network with a type system. First we construct a type system, and second, we use it to constrain the outputs of a neural network to respect the symbolic structure. We achieve this by reformulating the design problem into a mixed integer problem: create a type system and subsequently train a neural network with it. In this reformulation discrete variables select which parent-child relations from an ontology are types within the type system, while continuous variables control a classifier fit to the type system. The original problem cannot be solved exactly, so we propose a 2-step algorithm: 1) heuristic search or stochastic optimization over discrete variables that define a type system informed by an Oracle and a Learnability heuristic, 2) gradient descent to fit classifier parameters. We apply DeepType to the problem of Entity Linking on three standard datasets (i.e. WikiDisamb30, CoNLL (YAGO), TAC KBP 2010) and find that it outperforms all existing solutions by a wide margin, including approaches that rely on a human-designed type system or recent deep learning-based entity embeddings, while explicitly using symbolic information lets it integrate new entities without retraining.|sl:arxiv_author|Jonathan Raiman
Named Entity Disambiguation using Deep Learning on Graphs Evaluation of different deep learning techniques to create  a context vector from graphs, aimed at high-accuracy NED. (neural  approach for entity disambiguation using graphs as background  knowledge)     We tackle Named Entity Disambiguation (NED) by comparing entities  in short sentences with Wikidata graphs. Creating a context vector  from graphs through deep learning is a challenging problem that has  never been applied to NED. Our main contribution is to present an  experimental study of recent neural techniques, as well as a discussion  about which graph features are most important for the disambiguation  task...    [published paper](https://rd.springer.com/chapter/10.1007/978-3-030-15719-7_10)      In NED, the system  must be able to generate a context for an entity in a text and an entity  in a knowledge base, then correctly link the two.    Explore whether representing graphs  as triplets is more useful than using the full topological information of the graph    We tackle \\ac{NED} by comparing entities in short sentences with \\wikidata{} graphs. Creating a context vector from graphs through deep learning is a challenging problem that has never been applied to \\ac{NED}. Our main contribution is to present an experimental study of recent neural techniques, as well as a discussion about which graph features are most important for the disambiguation task. In addition, a new dataset (\\wikidatadisamb{}) is created to allow a clean and scalable evaluation of \\ac{NED} with \\wikidata{} entries, and to be used as a reference in future research. In the end our results show that a \\ac{Bi-LSTM} encoding of the graph triplets performs best, improving upon the baseline models and scoring an \ m{F1} value of $91.6\\%$ on the \\wikidatadisamb{} test set|sl:arxiv_firstAuthor|Alberto Cetoli
Text Classification|skos:broader|Statistical classification
Conditional random fields|skos:broader|Machine learning: techniques
group of related models that are used to produce word embeddings|skos:broader|[Best presentation](doc:2020/06/on_word_embeddings) about word embeddings, by [Sebastian Ruder](tag:sebastian_ruder)    Capture the idea that one can express “meaning” of words using a vector, so that the cosine of the angle between the vectors captures semantic similarity.    A set of language modeling and feature learning techniques where words from the vocabulary (and possibly phrases thereof) are mapped to vectors of real numbers in a low dimensional space, relative to the vocabulary size.     ~ Context-predicting models    ~ Latent feature representations of words    Paramaterized function mapping words in some language to vectors (perhaps 200 to 500 dimensions). Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with much lower dimension.    Plongement lexical in French    Word embedding of a word: a succinct representation of the distribution of other words around this word.    Methods to generate the mapping include neural networks, dimensionality reduction on the word co-occurrence matrix, probabilistic models, and explicit representation in terms of the context in which words appear.    In the new generation of models, the vector estimation problem is handled as a supervised task, where the weights in a word vector are set to maximize the probability of the contexts in which the word is observed in the corpus    The mapping may be generated training a neural network on a large corpus to predict a word given a context (Continuous Bag Of Words model) or to predict the context given a word (skip gram model). The context is a window of surrounding words.    The most known software to produce word embeddings is Tomas Mikolov's Word2vec. Pre-trained word embeddings are also available in the word2vec code.google page.    Applications:     - search document ranking  - boost the performance in NLP tasks such as syntactic parsing and sentiment analysis.          
Distilling the Knowledge in a Neural Network  a different kind of training, which we call “distillation” to transfer the  knowledge from the cumbersome model to a small model that is more  suitable for deployment       Caruana and his collaborators have shown that it is possible to compress the knowledge in an [#ensemble](/tag/ensemble_learning.html) into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST. A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.|sl:arxiv_author|Geoffrey Hinton
The Description Length of Deep Learning Models  Solomonoff’s general theory of inference (Solomonoff, 1964) and the [Minimum Description Length Principle](tag:minimum_description_length_principle) (Grünwald, 2007; Rissanen, 2007) formalize [Occam's razor](tag:occam_s_razor), and hold that a good model of data is a model that is good at losslessly  compressing the data, including the cost of describing the model itself. Deep neural  networks might seem to go against this principle given the large number of  parameters to be encoded.  We demonstrate experimentally the ability of deep neural networks to compress  the training data even when accounting for parameter encoding. Solomonoff's general theory of inference and the Minimum Description Length principle formalize Occam's razor, and hold that a good model of data is a model that is good at losslessly compressing the data, including the cost of describing the model itself. Deep neural networks might seem to go against this principle given the large number of parameters to be encoded. We demonstrate experimentally the ability of deep neural networks to compress the training data even when accounting for parameter encoding. The compression viewpoint originally motivated the use of variational methods in neural networks. Unexpectedly, we found that these variational methods provide surprisingly poor compression bounds, despite being explicitly built to minimize such bounds. This might explain the relatively poor practical performance of variational methods in deep learning. On the other hand, simple incremental encoding methods yield excellent compression values on deep networks, vindicating Solomonoff's approach.|sl:arxiv_author|Yann Ollivier
RDF data visualization|skos:broader|Data Visualization Tools
Notes on Cardinal's Matrices These notes are motivated by the work of Jean-Paul Cardinal on symmetric matrices related to the Mertens function. He showed that certain norm bounds on his matrices implied the Riemann hypothesis. Using a different matrix norm we show an equivalence of the Riemann hypothesis to suitable norm bounds on his matrices in the new norm. Then we specify a deformed version of his Mertens function matrices that unconditionally satisfies a norm bound that is of the same strength as his Riemann hypothesis bound.|sl:tag|tag:jean_paul
Workshop|skos:broader|Event
URI encoding|skos:broader|URI
Mafia|skos:broader|Grands problèmes
Torture|skos:broader|Horreur
Terre cuite|skos:broader|Archéologie
Word embedding technique (unsupervised learning algorithm for obtaining vector representations for words) based on factorizing a matrix of word co-occurence statistics (Training is performed on aggregated global word-word co-occurrence statistics from a corpus).   Resulting representations showcase interesting linear substructures of the word vector space.      |skos:broader|[Best presentation](doc:2020/06/on_word_embeddings) about word embeddings, by [Sebastian Ruder](tag:sebastian_ruder)    Capture the idea that one can express “meaning” of words using a vector, so that the cosine of the angle between the vectors captures semantic similarity.    A set of language modeling and feature learning techniques where words from the vocabulary (and possibly phrases thereof) are mapped to vectors of real numbers in a low dimensional space, relative to the vocabulary size.     ~ Context-predicting models    ~ Latent feature representations of words    Paramaterized function mapping words in some language to vectors (perhaps 200 to 500 dimensions). Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with much lower dimension.    Plongement lexical in French    Word embedding of a word: a succinct representation of the distribution of other words around this word.    Methods to generate the mapping include neural networks, dimensionality reduction on the word co-occurrence matrix, probabilistic models, and explicit representation in terms of the context in which words appear.    In the new generation of models, the vector estimation problem is handled as a supervised task, where the weights in a word vector are set to maximize the probability of the contexts in which the word is observed in the corpus    The mapping may be generated training a neural network on a large corpus to predict a word given a context (Continuous Bag Of Words model) or to predict the context given a word (skip gram model). The context is a window of surrounding words.    The most known software to produce word embeddings is Tomas Mikolov's Word2vec. Pre-trained word embeddings are also available in the word2vec code.google page.    Applications:     - search document ranking  - boost the performance in NLP tasks such as syntactic parsing and sentiment analysis.          
Extinction d'espèces|skos:broader|Grands problèmes
HTTP GET vs POST|skos:broader|Web architecture
Hongkong|skos:broader|China
JCS - Java Caching System|skos:broader|apache.org
Unsupervised Deep Embedding for Clustering Analysis Relatively little work has focused on learning representations for clustering. In this paper, we propose Deep Embedded Clustering (DEC), a method that simultaneously learns feature representations and cluster assignments using deep neural networks. DEC learns a mapping from the data space to a lower-dimensional feature space in which it iteratively optimizes a clustering objective Clustering is central to many data-driven application domains and has been studied extensively in terms of distance functions and grouping algorithms. Relatively little work has focused on learning representations for clustering. In this paper, we propose Deep Embedded Clustering (DEC), a method that simultaneously learns feature representations and cluster assignments using deep neural networks. DEC learns a mapping from the data space to a lower-dimensional feature space in which it iteratively optimizes a clustering objective. Our experimental evaluations on image and text corpora show significant improvement over state-of-the-art methods.|sl:tag|tag:cluster_analysis
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:arxiv_author|Jiawei Han
MaxEnt classifier (Multinomial logistic regression)|skos:broader|Maxent models
Don't waste my time|skos:broader|Temps
Latent semantic indexing LSA LSI|skos:broader|Vectorial semantics
Describing a Knowledge Base We aim to automatically generate natural language descriptions about an input structured knowledge base (KB). We build our generation framework based on a pointer network which can copy facts from the input KB, and add two attention mechanisms: (i) slot-aware attention to capture the association between a slot type and its corresponding slot value; and (ii) a new \\emph{table position self-attention} to capture the inter-dependencies among related slots. For evaluation, besides standard metrics including BLEU, METEOR, and ROUGE, we propose a KB reconstruction based metric by extracting a KB from the generation output and comparing it with the input KB. We also create a new data set which includes 106,216 pairs of structured KBs and their corresponding natural language descriptions for two distinct entity types. Experiments show that our approach significantly outperforms state-of-the-art methods. The reconstructed KB achieves 68.8% - 72.6% F-score.|sl:arxiv_firstAuthor|Qingyun Wang
Joint Embedding of Hierarchical Categories and Entities for Concept Categorization and Dataless Classification a framework that embeds entities and categories into a semantic space by integrating structured  knowledge and taxonomy hierarchy from large knowledge bases.    two methods:    1. Category Embedding model): it replaces the entities in the context with their directly  labeled categories to build categories’ context;   2. Hierarchical Category Embedding: it  further incorporates all ancestor categories of the context entities to utilize the hierarchical information. Due to the lack of structured knowledge applied in learning distributed representation of cate- gories, existing work cannot incorporate category hierarchies into entity information. We propose a framework that embeds entities and categories into a semantic space by integrating structured knowledge and taxonomy hierarchy from large knowledge bases. The framework allows to com- pute meaningful semantic relatedness between entities and categories. Our framework can han- dle both single-word concepts and multiple-word concepts with superior performance on concept categorization and yield state of the art results on dataless hierarchical classification.|sl:tag|tag:nlp_hierarchical_text_classification
Knowledge Graphs|skos:broader|Graph
fast.ai|skos:broader|Machine Learning Course
Dimensionality reduction|skos:broader|Machine learning: techniques
Kadhafi|skos:broader|Dictateur
RDF Net API|skos:broader|API
Embeddings in Information Retrieval|skos:broader|Neural Models for Information Retrieval
How can we use knowledge graph in computing?    A knowledge graph is a symbolic and logical system but applications often involve numerical computing in continuous spaces.  Formal logic is neither tractable nor robust when dealing with knowledge graph. Hence the idea of Knowledge graph embeddings.    Generally, each entity is represented  as a point in that space while each relation is interpreted as an operation over entity embeddings (eg. in Bordes et al. transE, a translation). The embedding representations are usually learnt by minimizing a global loss function involving all entities and relations so that each entity  embedding encodes both local and global connectivity patterns of the original graph.  |skos:broader|Traditionally, networks are usually represented as adjacency matrices. This suffers from data sparsity and high-dimensionality. Network embeddings aim to represent network  vertices into a low-dimensional vector space, by preserving  both network topology structure and node content information.    Algorithms are typically unsupervised  and can be broadly classified into  three groups ([source](/doc/2019/07/_1901_00596_a_comprehensive_su)):    - matrix factorization  - random walks   - deep learning approaches (graph neural networks - GNNs)  	- graph convolution networks (GraphSage)  	- graph attention networks,   	- graph auto-encoders (e.g., DNGR and SDNE)  	- graph generative networks,   	- graph spatial-temporal networks.    Node embeddings (intuition: similar nodes should have similar vectors).    - Laplacian EigenMap (an eigenvector based computation, OK when matrix is not too large)  - LINE Large-scale Information Network Embedding, most cited paper at WWW2015; Breadth first search  - DeepWalk (Perozzi et al. 2014) (the technique to learn word embeddings adapted to nodes: treating nodes as words and generating short random walks as sentences)  - Node2Vec (2016) (mixed strategy)    etc.  
Catastrophe humanitaire|skos:broader|Horreur
Terre de Feu|skos:broader|Argentine
A Strong Baseline for Learning Cross-Lingual Word Embeddings from Sentence Alignments While cross-lingual word embeddings have been studied extensively in recent years, the qualitative differences between the different algorithms remain vague. We observe that whether or not an algorithm uses a particular feature set (sentence IDs) accounts for a significant performance gap among these algorithms. This feature set is also used by traditional alignment algorithms, such as IBM Model-1, which demonstrate similar performance to state-of-the-art embedding algorithms on a variety of benchmarks. Overall, we observe that different algorithmic approaches for utilizing the sentence ID feature space result in similar performance. This paper draws both empirical and theoretical parallels between the embedding and alignment literature, and suggests that adding additional sources of information, which go beyond the traditional signal of bilingual sentence-aligned corpora, may substantially improve cross-lingual word embeddings, and that future baselines should at least take such features into account.|sl:arxiv_author|Anders Søgaard
NOSQL|skos:broader|Database
A Comprehensive Survey on Graph Neural Networks an overview of graph neural networks (GNNs) in data mining and machine learning fields Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.|sl:tag|tag:arxiv_doc
Mashups|skos:broader|Web 2.0
Concept Bottleneck Models  We seek to learn models that we can interact with using high-level concepts... We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these concept bottleneck models by editing their predicted concept values and propagating these changes to the final prediction... These models allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time. We seek to learn models that we can interact with using high-level concepts: if the model did not think there was a bone spur in the x-ray, would it still predict severe arthritis? State-of-the-art models today do not typically support the manipulation of concepts like the existence of bone spurs, as they are trained end-to-end to go directly from raw input (e.g., pixels) to output (e.g., arthritis severity). We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these \\emph{concept bottleneck models} by editing their predicted concept values and propagating these changes to the final prediction. On x-ray grading and bird identification, concept bottleneck models achieve competitive accuracy with standard end-to-end models, while enabling interpretation in terms of high-level clinical concepts (bone spurs) or bird attributes (wing color). These models also allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time.|sl:tag|tag:arxiv_doc
RapidMiner|skos:broader|Data mining tools
Rébellion touarègue|skos:broader|Touareg
Pre-trained Models for Natural Language Processing: A Survey Recently, the emergence of pre-trained models (PTMs) has brought natural language processing (NLP) to a new era. In this survey, we provide a comprehensive review of PTMs for NLP. We first briefly introduce language representation learning and its research progress. Then we systematically categorize existing PTMs based on a taxonomy with four perspectives. Next, we describe how to adapt the knowledge of PTMs to the downstream tasks. Finally, we outline some potential directions of PTMs for future research. This survey is purposed to be a hands-on guide for understanding, using, and developing PTMs for various NLP tasks.|sl:tag|tag:survey
Mandelbrot|skos:broader|Fractales
Resources-Oriented Web Services|skos:broader|HATEOAS
Concept Bottleneck Models|skos:broader|Machine learning: techniques
A Strong Baseline for Learning Cross-Lingual Word Embeddings from Sentence Alignments While cross-lingual word embeddings have been studied extensively in recent years, the qualitative differences between the different algorithms remain vague. We observe that whether or not an algorithm uses a particular feature set (sentence IDs) accounts for a significant performance gap among these algorithms. This feature set is also used by traditional alignment algorithms, such as IBM Model-1, which demonstrate similar performance to state-of-the-art embedding algorithms on a variety of benchmarks. Overall, we observe that different algorithmic approaches for utilizing the sentence ID feature space result in similar performance. This paper draws both empirical and theoretical parallels between the embedding and alignment literature, and suggests that adding additional sources of information, which go beyond the traditional signal of bilingual sentence-aligned corpora, may substantially improve cross-lingual word embeddings, and that future baselines should at least take such features into account.|sl:tag|tag:yoav_goldberg
Littérature russe|skos:broader|Russie
Vue.js|skos:broader|Javascript framework
create.js|skos:broader|Interactive Knowledge Stack
Longformer: The Long-Document Transformer  Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Following prior work on long-sequence transformers, we evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8. In contrast to most prior work, we also pretrain Longformer and finetune it on a variety of downstream tasks. Our pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA.|sl:arxiv_firstAuthor|Iz Beltagy
Natural language generation|skos:broader|NLP tasks / problems
Sphere packing|skos:broader|Grands problèmes mathématiques
Aggregating word embeddings through a mean, max,  min. . . function is still one of the most easy and widely used techniques to derive sentence embeddings, often in combination with an MLP or convolutional network (Weston et al. (2014); dos Santos and Gatti (2014); Yin and Schu ̈tze (2015); Collobert et al. (2011)). On one hand, the word order is lost, which can be important in e.g. paraphrase identification. On the other hand, the methods are simple, out-of-the-box and do not require a fixed length input.|skos:broader|[Best presentation](doc:2020/06/on_word_embeddings) about word embeddings, by [Sebastian Ruder](tag:sebastian_ruder)    Capture the idea that one can express “meaning” of words using a vector, so that the cosine of the angle between the vectors captures semantic similarity.    A set of language modeling and feature learning techniques where words from the vocabulary (and possibly phrases thereof) are mapped to vectors of real numbers in a low dimensional space, relative to the vocabulary size.     ~ Context-predicting models    ~ Latent feature representations of words    Paramaterized function mapping words in some language to vectors (perhaps 200 to 500 dimensions). Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with much lower dimension.    Plongement lexical in French    Word embedding of a word: a succinct representation of the distribution of other words around this word.    Methods to generate the mapping include neural networks, dimensionality reduction on the word co-occurrence matrix, probabilistic models, and explicit representation in terms of the context in which words appear.    In the new generation of models, the vector estimation problem is handled as a supervised task, where the weights in a word vector are set to maximize the probability of the contexts in which the word is observed in the corpus    The mapping may be generated training a neural network on a large corpus to predict a word given a context (Continuous Bag Of Words model) or to predict the context given a word (skip gram model). The context is a window of surrounding words.    The most known software to produce word embeddings is Tomas Mikolov's Word2vec. Pre-trained word embeddings are also available in the word2vec code.google page.    Applications:     - search document ranking  - boost the performance in NLP tasks such as syntactic parsing and sentiment analysis.          
ML and physics|skos:broader|Machine learning
Certificat de nationalité|skos:broader|Administration française
InceptionTime: Finding AlexNet for Time Series Classification Time series classification (TSC) is the area of machine learning interested in learning how to assign labels to time series. The last few decades of work in this area have led to significant progress in the accuracy of classifiers, with the state of the art now represented by the HIVE-COTE algorithm. While extremely accurate, HIVE-COTE is infeasible to use in many applications because of its very high training time complexity in O(N^2T^4) for a dataset with N time series of length T. For example, it takes HIVE-COTE more than 72,000s to learn from a small dataset with N=700 time series of short length T=46. Deep learning, on the other hand, has now received enormous attention because of its high scalability and state-of-the-art accuracy in computer vision and natural language processing tasks. Deep learning for TSC has only very recently started to be explored, with the first few architectures developed over the last 3 years only. The accuracy of deep learning for TSC has been raised to a competitive level, but has not quite reached the level of HIVE-COTE. This is what this paper achieves: outperforming HIVE-COTE's accuracy together with scalability. We take an important step towards finding the AlexNet network for TSC by presenting InceptionTime---an ensemble of deep Convolutional Neural Network (CNN) models, inspired by the Inception-v4 architecture. Our experiments show that InceptionTime slightly outperforms HIVE-COTE with a win/draw/loss on the UCR archive of 40/6/39. Not only is InceptionTime more accurate, but it is much faster: InceptionTime learns from that same dataset with 700 time series in 2,300s but can also learn from a dataset with 8M time series in 13 hours, a quantity of data that is fully out of reach of HIVE-COTE.|sl:arxiv_author|Charlotte Pelletier
Desktop applications|skos:broader|Informatique
R (programming language)|skos:broader|Data analysis
Named Entity Recognition with Extremely Limited Data Named Entity Search (NES)     We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.     We do not propose this as a replacement  for NER, but as something to be used for an ephemeral or contextual  class of entity, when it does not make sense to label hundreds or  thousands of instances to learn a classifier Traditional information retrieval treats named entity recognition as a pre-indexing corpus annotation task, allowing entity tags to be indexed and used during search. Named entity taggers themselves are typically trained on thousands or tens of thousands of examples labeled by humans. However, there is a long tail of named entities classes, and for these cases, labeled data may be impossible to find or justify financially. We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.|sl:tag|tag:information_retrieval
Learning Sparse, Distributed Representations using the Hebbian Principle The \fire together, wire together\ Hebbian model is a central principle for learning in neuroscience, but surprisingly, it has found limited applicability in modern machine learning. In this paper, we take a first step towards bridging this gap, by developing flavors of competitive Hebbian learning which produce sparse, distributed neural codes using online adaptation with minimal tuning The fire together, wire together Hebbian model is a central principle for learning in neuroscience, but surprisingly, it has found limited applicability in modern machine learning. In this paper, we take a first step towards bridging this gap, by developing flavors of competitive Hebbian learning which produce sparse, distributed neural codes using online adaptation with minimal tuning. We propose an unsupervised algorithm, termed Adaptive Hebbian Learning (AHL). We illustrate the distributed nature of the learned representations via output entropy computations for synthetic data, and demonstrate superior performance, compared to standard alternatives such as autoencoders, in training a deep convolutional net on standard image datasets.|sl:tag|tag:arxiv_doc
Laser|skos:broader|Physique
SparqlPress|skos:broader|WordPress
Barack's Wife Hillary: Using Knowledge-Graphs for Fact-Aware Language Modeling  a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset, a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark. In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language model's ability to complete sentences requiring factual knowledge, showing that the KGLM outperforms even very large language models in generating facts.|sl:tag|tag:kg_and_nlp
Bringing Light Into the Dark: A Large-scale Evaluation of Knowledge Graph Embedding Models Under a Unified Framework The heterogeneity in recently published knowledge graph embedding models' implementations, training, and evaluation has made fair and thorough comparisons difficult. In order to assess the reproducibility of previously published results, we re-implemented and evaluated 19 interaction models in the PyKEEN software package. Here, we outline which results could be reproduced with their reported hyper-parameters, which could only be reproduced with alternate hyper-parameters, and which could not be reproduced at all as well as provide insight as to why this might be the case. We then performed a large-scale benchmarking on four datasets with several thousands of experiments and 21,246 GPU hours of computation time. We present insights gained as to best practices, best configurations for each model, and where improvements could be made over previously published best configurations. Our results highlight that the combination of model architecture, training approach, loss function, and the explicit modeling of inverse relations is crucial for a model's performances, and not only determined by the model architecture. We provide evidence that several architectures can obtain results competitive to the state-of-the-art when configured carefully. We have made all code, experimental configurations, results, and analyses that lead to our interpretations available at https://github.com/pykeen/pykeen and https://github.com/pykeen/benchmarking|sl:arxiv_author|Max Berrendorf
Semantic Negotiation|skos:broader|Semantic Web
Web 2.0 businesses|skos:broader|Web 2.0
Etat policier|skos:broader|Société
Natural Language Processing (almost) from Scratch seminal work    Abstract:     a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements   We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.|sl:arxiv_author|Jason Weston
Blogger|skos:broader|Blog
Nissan|skos:broader|Entreprise
Croisade des Albigeois|skos:broader|Croisades
Passage AI|skos:broader|Chatbots
Paradoxe Einstein-Podolsky-Rosen|skos:broader|Mécanique quantique
Vito|skos:broader|Ami
Architecture|skos:broader|Art
Arctique|skos:broader|Régions polaires
Musée archéologique de Bagdad|skos:broader|Mésopotamie
SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver Integrating logical reasoning within deep learning architectures has been a major goal of modern AI systems. In this paper, we propose a new direction toward this goal by introducing a differentiable (smoothed) maximum satisfiability (MAXSAT) solver that can be integrated into the loop of larger deep learning systems. Our (approximate) solver is based upon a fast coordinate descent approach to solving the semidefinite program (SDP) associated with the MAXSAT problem. We show how to analytically differentiate through the solution to this SDP and efficiently solve the associated backward pass. We demonstrate that by integrating this solver into end-to-end learning systems, we can learn the logical structure of challenging problems in a minimally supervised fashion. In particular, we show that we can learn the parity function using single-bit supervision (a traditionally hard task for deep networks) and learn how to play 9x9 Sudoku solely from examples. We also solve a visual Sudok problem that maps images of Sudoku puzzles to their associated logical solutions by combining our MAXSAT solver with a traditional convolutional architecture. Our approach thus shows promise in integrating logical structures within deep learning.|sl:tag|tag:constraint_satisfaction_problem
James Hendler|skos:broader|Technical girls and guys
Brexit|skos:broader|Royaume Uni
Bill de hÓra|skos:broader|Technical girls and guys
Coursera|skos:broader|MOOC
fastai: A Layered API for Deep Learning Paper describing the fast.ai v2 API fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes: a new type dispatch system for Python along with a semantic type hierarchy for tensors; a GPU-optimized computer vision library which can be extended in pure Python; an optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 4-5 lines of code; a novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training; a new data block API; and much more. We have used this library to successfully create a complete deep learning course, which we were able to write more quickly than using previous approaches, and the code was more clear. The library is already in wide use in research, industry, and teaching. NB: This paper covers fastai v2, which is currently in pre-release at http://dev.fast.ai/|sl:arxiv_firstAuthor|Jeremy Howard
Guillaume Lample|skos:broader|NLP@Facebook
Dev tips|skos:broader|Tips
Langue française|skos:broader|Langues
Italie|skos:broader|Europe
Loi sur le téléchargement|skos:broader|Le gouvernement Chirac est trop con
Layered Graph Embedding for Entity Recommendation using Wikipedia in the Yahoo! Knowledge Graph an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia In this paper, we describe an embedding-based entity recommendation framework for Wikipedia that organizes Wikipedia into a collection of graphs layered on top of each other, learns complementary entity representations from their topology and content, and combines them with a lightweight learning-to-rank approach to recommend related entities on Wikipedia. Through offline and online evaluations, we show that the resulting embeddings and recommendations perform well in terms of quality and user engagement. Balancing simplicity and quality, this framework provides default entity recommendations for English and other languages in the Yahoo! Knowledge Graph, which Wikipedia is a core subset of.|sl:tag|tag:brad_pitt
Tribunal Pénal International|skos:broader|Institutions internationales
France : dysfonctionnement administratif|skos:broader|France : bureaucratie
DeepType: Multilingual Entity Linking by Neural Type System Evolution The wealth of structured (e.g. Wikidata) and unstructured data about the world available today presents an incredible opportunity for tomorrow's Artificial Intelligence. So far, integration of these two different modalities is a difficult process, involving many decisions concerning how best to represent the information so that it will be captured or useful, and hand-labeling large amounts of data. DeepType overcomes this challenge by explicitly integrating symbolic information into the reasoning process of a neural network with a type system. First we construct a type system, and second, we use it to constrain the outputs of a neural network to respect the symbolic structure. We achieve this by reformulating the design problem into a mixed integer problem: create a type system and subsequently train a neural network with it. In this reformulation discrete variables select which parent-child relations from an ontology are types within the type system, while continuous variables control a classifier fit to the type system. The original problem cannot be solved exactly, so we propose a 2-step algorithm: 1) heuristic search or stochastic optimization over discrete variables that define a type system informed by an Oracle and a Learnability heuristic, 2) gradient descent to fit classifier parameters. We apply DeepType to the problem of Entity Linking on three standard datasets (i.e. WikiDisamb30, CoNLL (YAGO), TAC KBP 2010) and find that it outperforms all existing solutions by a wide margin, including approaches that rely on a human-designed type system or recent deep learning-based entity embeddings, while explicitly using symbolic information lets it integrate new entities without retraining.|sl:tag|tag:entity_linking
Irlande|skos:broader|Pays d'Europe
Learning Deep Latent Spaces for Multi-Label Classification Uses [Deep Canonical Correlation Analysis](/tag/deep_canonical_correlation_analysis) and autoencoder structures to learn a latent subspace from both feature and label domains for multi-label classification.    (several implementations on github)       Multi-label classification is a practical yet challenging task in machine learning related fields, since it requires the prediction of more than one label category for each input instance. We propose a novel deep neural networks (DNN) based model, Canonical Correlated AutoEncoder (C2AE), for solving this task. Aiming at better relating feature and label domain data for improved classification, we uniquely perform joint feature and label embedding by deriving a deep latent space, followed by the introduction of label-correlation sensitive loss function for recovering the predicted label outputs. Our C2AE is achieved by integrating the DNN architectures of canonical correlation analysis and autoencoder, which allows end-to-end learning and prediction with the ability to exploit label dependency. Moreover, our C2AE can be easily extended to address the learning problem with missing labels. Our experiments on multiple datasets with different scales confirm the effectiveness and robustness of our proposed method, which is shown to perform favorably against state-of-the-art methods for multi-label classification.|sl:arxiv_author|Wei-Chieh Wu
Orange (data mining)|skos:broader|Python
formalism of information retrieval useful to derive  functions that rank matching documents according to their relevance to a given search query.|skos:broader|Finding items that are similar to a given query is the core  aspect of search and retrieval systems, as well as of  recommendation engines.
Epimorphics json-rdf|skos:broader|RDF-in-JSON
A Comprehensive Survey on Graph Neural Networks an overview of graph neural networks (GNNs) in data mining and machine learning fields Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.|sl:arxiv_author|Chengqi Zhang
Mac OS X Tip|skos:broader|Mac OS X
React.js|skos:broader|Javascript framework
Fungal infections|skos:broader|Champignon
ML|skos:broader|Data analysis
No Fuss Distance Metric Learning using Proxies  We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity...   Traditionnaly, supervision is expressed in the form of sets of points that follow  an ordinal relationship – an anchor point x is similar to  a set of positive points Y , and dissimilar to a set of negative  points Z, and a loss defined over these distances is minimized.   Triplet-Based methods are challenging to optimize (a main issue is the need for finding informative triplets).     We propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss.    Mentioned in this [blog post](/doc/2020/01/training_a_speaker_embedding_fr):     Proxy based triplet learning: instead of generating triplets, we learn an embedding for each class and use the learnt embedding as a proxy for triplets as part of the training. In other words, we can train end to end without the computationally expensive step of resampling triplets after each network update.    Near the conclusion:     Our formulation of Proxy-NCA loss produces a loss very  similar to the standard cross-entropy loss used in classification.  However, we arrive at our formulation from a different  direction: we are not interested in the actual classifier and  indeed discard the proxies once the model has been trained.  Instead, the proxies are auxiliary variables, enabling more  effective optimization of the embedding model parameters.  As such, our formulation not only enables us to surpass the  state of the art in zero-shot learning, but also offers an explanation  to the effectiveness of the standard trick of training  a classifier, and using its penultimate layer’s output as the  embedding. We address the problem of distance metric learning (DML), defined as learning a distance consistent with a notion of semantic similarity. Traditionally, for this problem supervision is expressed in the form of sets of points that follow an ordinal relationship -- an anchor point $x$ is similar to a set of positive points $Y$, and dissimilar to a set of negative points $Z$, and a loss defined over these distances is minimized. While the specifics of the optimization differ, in this work we collectively call this type of supervision Triplets and all methods that follow this pattern Triplet-Based methods. These methods are challenging to optimize. A main issue is the need for finding informative triplets, which is usually achieved by a variety of tricks such as increasing the batch size, hard or semi-hard triplet mining, etc. Even with these tricks, the convergence rate of such methods is slow. In this paper we propose to optimize the triplet loss on a different space of triplets, consisting of an anchor data point and similar and dissimilar proxy points which are learned as well. These proxies approximate the original data points, so that a triplet loss over the proxies is a tight upper bound of the original loss. This proxy-based loss is empirically better behaved. As a result, the proxy-loss improves on state-of-art results for three standard zero-shot learning datasets, by up to 15% points, while converging three times as fast as other triplet-based losses.|sl:arxiv_author|Thomas K. Leung
Memristor|skos:broader|Bio inspired computing devices
Reformer: The Efficient Transformer Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O($L^2$) to O($L\\log L$), where $L$ is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of $N$ times, where $N$ is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.|sl:arxiv_firstAuthor|Nikita Kitaev
African origin of modern humans|skos:broader|Origines de l'homme
Eclipse tip|skos:broader|Eclipse
Empires d'Afrique de l'Ouest|skos:broader|Histoire de l'Afrique
Sarkozy|skos:broader|Homme politique
Gradient descent|skos:broader|Algorithmes
Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data Word embeddings are a popular approach to unsupervised learning of word relationships that are widely used in natural language processing. In this article, we present a new set of embeddings for medical concepts learned using an extremely large collection of multimodal medical data. Leaning on recent theoretical insights, we demonstrate how an insurance claims database of 60 million members, a collection of 20 million clinical notes, and 1.7 million full text biomedical journal articles can be combined to embed concepts into a common space, resulting in the largest ever set of embeddings for 108,477 medical concepts. To evaluate our approach, we present a new benchmark methodology based on statistical power specifically designed to test embeddings of medical concepts. Our approach, called cui2vec, attains state-of-the-art performance relative to previous methods in most instances. Finally, we provide a downloadable set of pre-trained embeddings for other researchers to use, as well as an online tool for interactive exploration of the cui2vec embeddings|sl:arxiv_firstAuthor|Andrew L. Beam
IBM SPSS Text Analytics for Surveys|skos:broader|IBM
Wordnet|skos:broader|Princeton
RDF and SOA|skos:broader|RDF
Christine Golbreich|skos:broader|SW guys (and girls)
Web|skos:broader|Internet
Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call fooling images (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.|sl:tag|tag:arxiv_doc
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:arxiv_author|Nate Gruver
sig.ma|skos:broader|DERI
SIMILE Exhibit|skos:broader|JavaScript
DSSM (Deep Semantic Similarity Model)|skos:broader|Embeddings in Information Retrieval
Shanghai Expo 2010|skos:broader|Shanghaï
Neurones|skos:broader|Brain
Combining knowledge graphs|skos:broader|Knowledge Graphs
Neural Models for Information Retrieval|skos:broader|Information retrieval
TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network how to add a set of new concepts to an existing taxonomy.     [Tweet](https://twitter.com/mickeyjs6/status/1253772146142216194?s=20) [GitHub](https://github.com/mickeystroller/TaxoExpan)     we study the taxonomy expansion task: given an  existing taxonomy and a set of new emerging concepts, we aim  to automatically expand the taxonomy to incorporate these new  concepts (without changing the existing relations in the given taxonomy).     To the best of our knowledge, this is the first study on how to  expand an existing directed acyclic graph (as we model a taxonomy  as a DAG) using self-supervised learning.    Self-supervised framework, the existing taxonomy being used as training data: it learns a model to predict whether a query concept is the direct hyponym of an anchor concept.      2 techniques:     1. a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy,   2. a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data.     Regarding 1: uses [GNN](/tag/graph_neural_networks.html) to model the ego network of concepts (potential “siblings”  and “grand parents” of the query concept).     Regular  GNNs fail to distinguish nodes with different relative positions to  the query (i.e., some nodes are grand parents of the query while  the others are siblings of the query). To address this limitation, we  present a simple but effective enhancement to inject such position  information into GNNs using position embedding. We show that  such embedding can be easily integrated with existing GNN architectures  (e.g., [GCN](/tag/graph_convolutional_networks) and GAT) and significantly boosts the  prediction performance    Regarding point 2: uses InfoNCE loss, cf. [Contrastive Predictive Coding](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1807.03748)     Instead of predicting  whether each individual ⟨query concept, anchor concept⟩ pair  is positive or not, we first group all pairs sharing the same query  concept into a single training instance and learn a model to select  the positive pair among other negative ones from the group.     (Hum, ça me rappelle quelque chose)     assume each concept (in existing taxonomy + set of new concepts) has an initial embedding  vector learned from some text associated with this concept.    To keep things tractable, only attempts to find a single parent node of each new concept. Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of query concept, anchor concept pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.|sl:arxiv_author|Chi Wang
Calais (jungle)|skos:broader|Immigration
Coursera: Web Intelligence and Big Data|skos:broader|Big Data
Coursera: A History of the World since 1300|skos:broader|Histoire du monde
Transposon|skos:broader|Genetics Génétique
Link to me|skos:broader|fps
Semantic Web Client Library|skos:broader|GRDDL
Neural coding|skos:broader|Neuroscience
Advances in Pre-Training Distributed Word Representations  we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks Many Natural Language Processing applications nowadays rely on pre-trained word representations estimated from large text corpora such as news collections, Wikipedia and Web Crawl. In this paper, we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks.|sl:tag|tag:arxiv_doc
ANN used for unsupervised learning of efficient codings: learning a representation (encoding) for a set of data, typically for the purpose of dimensionality reduction.    an unsupervised neural network  which is trained to reconstruct a given input  from its latent representation (Bengio, 2009).    Unlike principal components analysis, the encoding and decoding steps are not limited to linear transformations (PCA learns an encoding linear transform, while auto-encoders learn an encoding program).  |skos:broader|process of reducing the number of random variables under consideration. Can be divided into feature selection and feature extraction.
Biodiversity|skos:broader|Biologie
Continual Learning|skos:broader|Machine learning: techniques
GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden unit), or embedding-free units such as image pixels.|sl:tag|tag:ruslan_salakhutdinov
Virtuoso: review|skos:broader|Virtuoso
Semanlink|skos:broader|fps
Digital Video|skos:broader|Technologie
Jeffrey T. Pollock|skos:broader|Technical girls and guys
Cliqz|skos:broader|Brouteur
Constraints in the SW|skos:broader|Semantic Web
Paradise Papers|skos:broader|Leaks
Synonym URIs|skos:broader|URI
Entity Embeddings of Categorical Variables  We map categorical variables in a function approximation problem into Euclidean spaces, which are the entity embeddings of the categorical variables. The mapping is learned by a neural network during the standard supervised training process. Entity embedding not only reduces memory usage and speeds up neural networks compared with one-hot encoding, but more importantly by mapping similar values close to each other in the embedding space it reveals the intrinsic properties of the categorical variables We map categorical variables in a function approximation problem into Euclidean spaces, which are the entity embeddings of the categorical variables. The mapping is learned by a neural network during the standard supervised training process. Entity embedding not only reduces memory usage and speeds up neural networks compared with one-hot encoding, but more importantly by mapping similar values close to each other in the embedding space it reveals the intrinsic properties of the categorical variables. We applied it successfully in a recent Kaggle competition and were able to reach the third position with relative simple features. We further demonstrate in this paper that entity embedding helps the neural network to generalize better when the data is sparse and statistics is unknown. Thus it is especially useful for datasets with lots of high cardinality features, where other methods tend to overfit. We also demonstrate that the embeddings obtained from the trained neural network boost the performance of all tested machine learning methods considerably when used as the input features instead. As entity embedding defines a distance measure for categorical variables it can be used for visualizing categorical data and for data clustering.|sl:tag|tag:arxiv_doc
Volkswagate|skos:broader|Volkswagen
Conscience artificielle|skos:broader|Conscience
Word Translation Without Parallel Data  we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent studies showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally describe experiments on the English-Esperanto low-resource language pair, on which there only exists a limited amount of parallel data, to show the potential impact of our method in fully unsupervised machine translation. Our code, embeddings and dictionaries are publicly available.|sl:arxiv_author|Ludovic Denoyer
Euro Crisis|skos:broader|Crise financière
Andrew McCallum|skos:broader|AI girls and guys
JUnit|skos:broader|Unit test
DARPA|skos:broader|Armée américaine
Semantic Overflow|skos:broader|Q&A
Musique en ligne|skos:broader|Musique
Apple Developer Connection|skos:broader|Apple
Learning to Remember Rare Events  a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training.    Our memory module can be easily added to any part of a supervised neural network Despite recent advances, memory-augmented deep neural networks are still limited when it comes to life-long and one-shot learning, especially in remembering rare events. We present a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training. Our memory module can be easily added to any part of a supervised neural network. To show its versatility we add it to a number of networks, from simple convolutional ones tested on image classification to deep sequence-to-sequence and recurrent-convolutional models. In all cases, the enhanced network gains the ability to remember and do life-long one-shot learning. Our module remembers training examples shown many thousands of steps in the past and it can successfully generalize from them. We set new state-of-the-art for one-shot learning on the Omniglot dataset and demonstrate, for the first time, life-long one-shot learning in recurrent neural networks on a large-scale machine translation task.|sl:arxiv_author|Łukasz Kaiser
Marchands d'arme|skos:broader|Industrie de l'armement
Martin Hepp|skos:broader|SW guys (and girls)
Exponential Organizations|skos:broader|Technological singularity
Keyword/keyphrase extraction|skos:broader|Phrases (NLP)
Social bookmarking|skos:broader|Social Networks
Jacqueline de Romilly|skos:broader|Grèce antique
Docker-Python|skos:broader|Python
TheWebConf 2019|skos:broader|TheWebConf
Linear classifier|skos:broader|Supervised machine learning
Eau de Mars|skos:broader|Eau extraterrestre
Neural Architectures for Named Entity Recognition Neural architectures for NER that use no language-specific resources or features beyond a small amount of supervised training data and unlabeled corpora.      Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.|sl:arxiv_author|Sandeep Subramanian
Luis Buñuel|skos:broader|Réalisateur
gnizr|skos:broader|Semanlink related
Inductive bias|skos:broader|Bias
rdfQuery|skos:broader|Javascript RDF
Describing a Knowledge Base We aim to automatically generate natural language descriptions about an input structured knowledge base (KB). We build our generation framework based on a pointer network which can copy facts from the input KB, and add two attention mechanisms: (i) slot-aware attention to capture the association between a slot type and its corresponding slot value; and (ii) a new \\emph{table position self-attention} to capture the inter-dependencies among related slots. For evaluation, besides standard metrics including BLEU, METEOR, and ROUGE, we propose a KB reconstruction based metric by extracting a KB from the generation output and comparing it with the input KB. We also create a new data set which includes 106,216 pairs of structured KBs and their corresponding natural language descriptions for two distinct entity types. Experiments show that our approach significantly outperforms state-of-the-art methods. The reconstructed KB achieves 68.8% - 72.6% F-score.|sl:arxiv_author|Heng Ji
Retrofitting Word Vectors to Semantic Lexicons Method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed.     Graph-based learning technique for using lexical relational resources to obtain higher quality semantic vectors, which we call “retrofitting.” Retrofitting is applied as a post-processing step by running belief propagation on a graph constructed from lexicon-derived relational information to update word vectors. This allows retrofitting to be used on pre-trained word vectors obtained using any vector training model.    [github](https://github.com/mfaruqui/retrofitting)     Vector space word representations are learned from distributional information of words in large corpora. Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database. This paper proposes a method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed. Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, we obtain substantial improvements starting with a variety of word vector models. Our refinement method outperforms prior techniques for incorporating semantic lexicons into the word vector training algorithms.|sl:arxiv_author|Manaal Faruqui
Google ranking|skos:broader|Google
Generalization through Memorization: Nearest Neighbor Language Models extend LMs with nearest neighbor search in embedding space We introduce $k$NN-LMs, which extend a pre-trained neural language model (LM) by linearly interpolating it with a $k$-nearest neighbors ($k$NN) model. The nearest neighbors are computed according to distance in the pre-trained LM embedding space, and can be drawn from any text collection, including the original LM training data. Applying this augmentation to a strong Wikitext-103 LM, with neighbors drawn from the original training set, our $k$NN-LM achieves a new state-of-the-art perplexity of 15.79 - a 2.9 point improvement with no additional training. We also show that this approach has implications for efficiently scaling up to larger training sets and allows for effective domain adaptation, by simply varying the nearest neighbor datastore, again without further training. Qualitatively, the model is particularly helpful in predicting rare patterns, such as factual knowledge. Together, these results strongly suggest that learning similarity between sequences of text is easier than predicting the next word, and that nearest neighbor search is an effective approach for language modeling in the long tail.|sl:tag|tag:arxiv_doc
Boosting|skos:broader|Ensemble learning
\Why Should I Trust You?\: Explaining the Predictions of Any Classifier technique that explains the predictions of any classifier by learning an interpretable model locally around the prediction Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.|sl:arxiv_author|Carlos Guestrin
Basic|skos:broader|Programming language
N3|skos:broader|RDF
BlackboxNLP (2018 workshop)|skos:broader|Workshop
Apache Marmotta|skos:broader|LDP: implementations
Histoire anglaise|skos:broader|Royaume Uni
GoodRelations/Renault|skos:broader|GoodRelations
How can we use knowledge graph in computing?    A knowledge graph is a symbolic and logical system but applications often involve numerical computing in continuous spaces.  Formal logic is neither tractable nor robust when dealing with knowledge graph. Hence the idea of Knowledge graph embeddings.    Generally, each entity is represented  as a point in that space while each relation is interpreted as an operation over entity embeddings (eg. in Bordes et al. transE, a translation). The embedding representations are usually learnt by minimizing a global loss function involving all entities and relations so that each entity  embedding encodes both local and global connectivity patterns of the original graph.  |skos:broader|The objective of embedding methods is to organize symbolic objects (e.g., words, entities, concepts) in a way such that their similarity in the embedding space reflects their semantic or functional similarity  
Text: dimension reduction|skos:broader|Dimensionality reduction
folksonomies ontologies|skos:broader|Tagging
Truffe|skos:broader|Gastronomie
Knowledge Graph Conference 2019|skos:broader|Enterprise Knowledge Graph
NLP: pretraining|skos:broader|NLP techniques
Eclipse Juno|skos:broader|Eclipse
URIBurner.com|skos:broader|OpenLink Software
Span Selection Pre-training for Question Answering  a new pre-training task inspired by reading  comprehension and an effort to avoid encoding general knowledge in the transformer network itself    Current transformer architectures store general knowledge - large models, long pre-training time. Better to offload the requirement of general knowledge to a sparsely activated network.    Span selection as an additional auxiliary task: the query is a sentence drawn from a corpus  with a term replaced with a special token: [BLANK]. The term replaced by the blank is the answer term. The passage is  relevant as determined by a BM25 search, and answer-bearing (containing the answer  term). Unlike BERT’s cloze task, where the answer must be drawn from the model itself, the answer is found in a passage  using language understanding.     We hope to progress to a model of general purpose language modeling that uses an indexed long  term memory to retrieve world knowledge, rather than holding it in the densely activated transformer encoder layers. BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pre-trained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension and an effort to avoid encoding general knowledge in the transformer network itself. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple reading comprehension (MRC) and paraphrasing datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also establish a new SOTA in HotpotQA, improving answer prediction F1 by 4 F1 points and supporting fact prediction by 1 F1 point. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.|sl:tag|tag:memory_in_deep_learning
Postman|skos:broader|REST
Business Intelligence and Semantic Web|skos:broader|Business intelligence
National Geographic|skos:broader|Géographie
Siri|skos:broader|Voice AI
Cloud and Linked Data|skos:broader|Cloud and Linked Data
Delip Rao|skos:broader|NLP girls and guys
A Comprehensive Survey on Graph Neural Networks an overview of graph neural networks (GNNs) in data mining and machine learning fields Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.|sl:arxiv_firstAuthor|Zonghan Wu
Darfour|skos:broader|Catastrophe humanitaire
Jersey Cache-Control|skos:broader|jersey
SDB: A SPARQL Database for Jena|skos:broader|SQL
Tag ontology|skos:broader|Ontologies
Computational Neuroscience|skos:broader|Neuroscience
Knowledge Graph Embeddings and Explainable AI survey of     - the state-of-the-art in the field of knowledge graph embeddings  - methods for explaining predictions obtained via knowledge graph embeddings. Knowledge graph embeddings are now a widely adopted approach to knowledge representation in which entities and relationships are embedded in vector spaces. In this chapter, we introduce the reader to the concept of knowledge graph embeddings by explaining what they are, how they can be generated and how they can be evaluated. We summarize the state-of-the-art in this field by describing the approaches that have been introduced to represent knowledge in the vector space. In relation to knowledge representation, we consider the problem of explainability, and discuss models and methods for explaining predictions obtained via knowledge graph embeddings.|sl:tag|tag:knowledge_graph_embeddings
Maïs|skos:broader|Agriculture
Matières premières|skos:broader|Economie
Barnaby Jack|skos:broader|Hackers
summly|skos:broader|Text Summarization
Von Mises-Fisher Loss for Training Sequence to Sequence Models with Continuous Outputs predicting embeddings instead of word IDs (avoids a discrete softmax, using a new loss)    [@honnibal](https://twitter.com/honnibal/status/1073513114468081664)     The Softmax function is used in the final layer of nearly all existing sequence-to-sequence models for language generation. However, it is usually the slowest layer to compute which limits the vocabulary size to a subset of most frequent types; and it has a large memory footprint. We propose a general technique for replacing the softmax layer with a continuous embedding layer. Our primary innovations are a novel probabilistic loss, and a training and inference procedure in which we generate a probability distribution over pre-trained word embeddings, instead of a multinomial distribution over the vocabulary obtained via softmax. We evaluate this new class of sequence-to-sequence models with continuous outputs on the task of neural machine translation. We show that our models obtain upto 2.5x speed-up in training time while performing on par with the state-of-the-art models in terms of translation quality. These models are capable of handling very large vocabularies without compromising on translation quality. They also produce more meaningful errors than in the softmax-based models, as these errors typically lie in a subspace of the vector space of the reference translations.|sl:arxiv_author|Sachin Kumar
Relation Extraction|skos:broader|Knowledge Graph Completion
Meta Content Framework|skos:broader|Apple
LODr|skos:broader|Alexandre Passant
Ethereum|skos:broader|Blockchain
Chinafrique|skos:broader|China
Astrophysique|skos:broader|Cosmologie
Fact verification|skos:broader|NLP tasks / problems
m2eclipse|skos:broader|Eclipse
Locality Sensitive Hashing|skos:broader|Big Data
NG4J|skos:broader|Chris Bizer
Compagnies pétrolières|skos:broader|Entreprise
Labeled Data|skos:broader|Training data
Node Embeddings|skos:broader|Graph Embeddings
Semantic mashups|skos:broader|Semantic Web : Application
Mission Villani sur l'IA|skos:broader|Politique économique française
Knowledge Graph + Deep Learning|skos:broader|Domain Knowledge + Deep Learning
Unifying distillation and privileged information A framework to learn from multiple machines and data representations, unifying two techniques that enable machines to learn from other machines: [distillation](tag:knowledge_distillation) ([Hinton et al., 2015](doc:2020/04/1503_02531_distilling_the_kno)) and privileged information (Vapnik & Izmailov, 2015)   Distillation (Hinton et al., 2015) and privileged information (Vapnik & Izmailov, 2015) are two techniques that enable machines to learn from other machines. This paper unifies these two techniques into generalized distillation, a framework to learn from multiple machines and data representations. We provide theoretical and causal insight about the inner workings of generalized distillation, extend it to unsupervised, semisupervised and multitask learning scenarios, and illustrate its efficacy on a variety of numerical simulations on both synthetic and real-world data.|sl:tag|tag:arxiv_doc
Probabilistic relevance model|skos:broader|Information retrieval: techniques
NLP tools|skos:broader|NLP
JavaOne|skos:broader|Conférences
Random forest|skos:broader|Machine learning: techniques
Nikolai Vavilov|skos:broader|Scientifique
Regroupement familial et test ADN de filiation|skos:broader|Ca craint
Unifying distillation and privileged information A framework to learn from multiple machines and data representations, unifying two techniques that enable machines to learn from other machines: [distillation](tag:knowledge_distillation) ([Hinton et al., 2015](doc:2020/04/1503_02531_distilling_the_kno)) and privileged information (Vapnik & Izmailov, 2015)   Distillation (Hinton et al., 2015) and privileged information (Vapnik & Izmailov, 2015) are two techniques that enable machines to learn from other machines. This paper unifies these two techniques into generalized distillation, a framework to learn from multiple machines and data representations. We provide theoretical and causal insight about the inner workings of generalized distillation, extend it to unsupervised, semisupervised and multitask learning scenarios, and illustrate its efficacy on a variety of numerical simulations on both synthetic and real-world data.|sl:arxiv_author|Bernhard Schölkopf
Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.|sl:tag|tag:arxiv_doc
Topic2Vec: Learning Distributed Representations of Topics Topic2Vec aims at learning topic representations along with word representations. Considering the simplicity and efficient solution, we just follow the optimization scheme that used in Word2Vec Latent Dirichlet Allocation (LDA) mining thematic structure of documents plays an important role in nature language processing and machine learning areas. However, the probability distribution from LDA only describes the statistical relationship of occurrences in the corpus and usually in practice, probability is not the best choice for feature representations. Recently, embedding methods have been proposed to represent words and documents by learning essential concepts and representations, such as Word2Vec and Doc2Vec. The embedded representations have shown more effectiveness than LDA-style representations in many tasks. In this paper, we propose the Topic2Vec approach which can learn topic representations in the same semantic vector space with words, as an alternative to probability. The experimental results show that Topic2Vec achieves interesting and meaningful results.|sl:arxiv_firstAuthor|Li-Qiang Niu
Multilingual embeddings|skos:broader|Embeddings in NLP
nbdev.fast.ai|skos:broader|Jupyter
From Word to Sense Embeddings: A Survey on Vector Representations of Meaning Survey focused on semantic representation of meaning (methods that try to directly model individual meanings of words).    Pb with word embeddings: the meaning conflation deficiency (representing a word with all its possible meanings as a single vector). Can be addressed by a method for modelling unambiguous lexical meaning.    two main branches of sense representation :    - unsupervised   - knowledge-based Over the past years, distributed semantic representations have proved to be effective and flexible keepers of prior knowledge to be integrated into downstream applications. This survey focuses on the representation of meaning. We start from the theoretical background behind word vector space models and highlight one of their major limitations: the meaning conflation deficiency, which arises from representing a word with all its possible meanings as a single vector. Then, we explain how this deficiency can be addressed through a transition from the word level to the more fine-grained level of word senses (in its broader acceptation) as a method for modelling unambiguous lexical meaning. We present a comprehensive overview of the wide range of techniques in the two main branches of sense representation, i.e., unsupervised and knowledge-based. Finally, this survey covers the main evaluation procedures and applications for this type of representation, and provides an analysis of four of its important aspects: interpretability, sense granularity, adaptability to different domains and compositionality.|sl:tag|tag:survey
Zapata|skos:broader|Mexique
Number of neurons|skos:broader|Brain
Apple Java|skos:broader|Apple
K-BERT: Enabling Language Representation with Knowledge Graph a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by equipped with a KG without pre-training by-self because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts.|sl:arxiv_author|Peng Zhou
RDF database|skos:broader|RDF and database
Akhênaton|skos:broader|Pharaon
Text: dimension reduction|skos:broader|NLP techniques
Dan Brickley|skos:broader|Technical girls and guys
Hubble|skos:broader|NASA
Relational inductive biases|skos:broader|Inductive bias
Diable de Tasmanie|skos:broader|Endangered Species
Span Selection Pre-training for Question Answering  a new pre-training task inspired by reading  comprehension and an effort to avoid encoding general knowledge in the transformer network itself    Current transformer architectures store general knowledge - large models, long pre-training time. Better to offload the requirement of general knowledge to a sparsely activated network.    Span selection as an additional auxiliary task: the query is a sentence drawn from a corpus  with a term replaced with a special token: [BLANK]. The term replaced by the blank is the answer term. The passage is  relevant as determined by a BM25 search, and answer-bearing (containing the answer  term). Unlike BERT’s cloze task, where the answer must be drawn from the model itself, the answer is found in a passage  using language understanding.     We hope to progress to a model of general purpose language modeling that uses an indexed long  term memory to retrieve world knowledge, rather than holding it in the densely activated transformer encoder layers. BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pre-trained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension and an effort to avoid encoding general knowledge in the transformer network itself. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple reading comprehension (MRC) and paraphrasing datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also establish a new SOTA in HotpotQA, improving answer prediction F1 by 4 F1 points and supporting fact prediction by 1 F1 point. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.|sl:arxiv_author|Lin Pan
Tortures américaines|skos:broader|USA
Receiver operating characteristic. Plot used to diagnostic ability of a binary classifier as its discrimination threshold is varied.     Plotting the true positive rate (TPR: recall) against the false positive rate (FPR: fall-out or probability of false alarm ) at various threshold settings.  |skos:broader|the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations whose category membership is known.
Thesaurus|skos:broader|Thesaurus & Taxonomies 
Antiquité de l'Inde|skos:broader|Antiquité
Energie sombre|skos:broader|Physique
Jena|skos:broader|RDF Framework
Wikification|skos:broader|Entity linking
1ere guerre mondiale|skos:broader|Histoire du XXe siècle
Doc2Vec|skos:broader|Document embeddings
Knowledge Graphs|skos:broader|Knowledge
Google Structured Data Testing Tool|skos:broader|Google: SEO
KG-BERT: BERT for Knowledge Graph Completion Pre-trained language models for knowledge graph completion. Triples are treated as textual sequences. (Hum, j'ai déjà vu ça quelque part) Knowledge graphs are important resources for many artificial intelligence tasks but often suffer from incompleteness. In this work, we propose to use pre-trained language models for knowledge graph completion. We treat triples in knowledge graphs as textual sequences and propose a novel framework named Knowledge Graph Bidirectional Encoder Representations from Transformer (KG-BERT) to model these triples. Our method takes entity and relation descriptions of a triple as input and computes scoring function of the triple with the KG-BERT language model. Experimental results on multiple benchmark knowledge graphs show that our method can achieve state-of-the-art performance in triple classification, link prediction and relation prediction tasks.|sl:arxiv_firstAuthor|Liang Yao
Sarkozy|skos:broader|Politique française
Tahar Ben Jelloun|skos:broader|Ecrivain
PRISM|skos:broader|NSA
Passage AI|skos:broader|AI: startups
Jardinage|skos:broader|Jardin
N-ary Relations on the Semantic Web|skos:broader|Semantic Web
Metagenomics|skos:broader|Biodiversité
node.js|skos:broader|JavaScript
Roméo Dallaire|skos:broader|ONU
Pillage du palais d'été|skos:broader|Pékin
SPIN functions|skos:broader|TopBraid/SPIN
Parameter-free Sentence Embedding via Orthogonal Basis training-free approach for building sentence representations, Geometric Embedding (GEM), based on the geometric structure of word embedding space.     we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word’s novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace    [on www.groundai.com](https://www.groundai.com/project/zero-training-sentence-embedding-via-orthogonal-basis/)    [Open Revieww](/doc/?uri=https%3A%2F%2Fopenreview.net%2Fforum%3Fid%3DrJedbn0ctQ) ; [Related to this paper](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1704.05358)       We propose a simple and robust non-parameterized approach for building sentence representations. Inspired by the Gram-Schmidt Process in geometric theory, we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word's novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace. Following this motivation, we develop an innovative method based on orthogonal basis to combine pre-trained word embeddings into sentence representations. This approach requires zero parameters, along with efficient inference performance. We evaluate our approach on 11 downstream NLP tasks. Our model shows superior performance compared with non-parameterized alternatives and it is competitive to other approaches relying on either large amounts of labelled data or prolonged training time.|sl:arxiv_author|Weizhu Chen
Californie|skos:broader|USA
Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.|sl:arxiv_author|Luciano Serafini
Javascript RDF|skos:broader|RDF
Semantic Web, Semantic Me.|skos:broader|Hi, I am http://www.semanlink.net/tag/fps 
Learned Index Structures|skos:broader|Machine learning: techniques
SVM|skos:broader|Kernel trick Kernel method
Empire colonial français|skos:broader|Colonisation
Pará|skos:broader|Amazonie
Zitgist|skos:broader|Semantic Web Services
Yahoo!|skos:broader|Entreprise
Mladic|skos:broader|Méchant
Perceptron|skos:broader|Supervised machine learning
Gore Vidal|skos:broader|Romancier
Attention Is All You Need  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.|sl:arxiv_author|Niki Parmar
Neural Architectures for Named Entity Recognition Neural architectures for NER that use no language-specific resources or features beyond a small amount of supervised training data and unlabeled corpora.      Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.|sl:tag|tag:named_entity_recognition
Knowledge-driven embeddings|skos:broader|Knowledge bases
LinkTo Semanlink|skos:broader|Link to me
Belo Horizonte|skos:broader|Brésil
Economies d'énergie|skos:broader|Energie
Transfer Learning for Sequence Labeling Using Source Model and Target Data use-case ex: NER when the target data contains new categories In this paper, we propose an approach for transferring the knowledge of a neural model for sequence labeling, learned from the source domain, to a new model trained on a target domain, where new label categories appear. Our transfer learning (TL) techniques enable to adapt the source model using the target data and new categories, without accessing to the source data. Our solution consists in adding new neurons in the output layer of the target model and transferring parameters from the source model, which are then fine-tuned with the target data. Additionally, we propose a neural adapter to learn the difference between the source and the target label distribution, which provides additional important information to the target model. Our experiments on Named Entity Recognition show that (i) the learned knowledge in the source model can be effectively transferred when the target data contains new categories and (ii) our neural adapter further improves such transfer.|sl:tag|tag:sequence_labeling
Belém|skos:broader|Pará
John Pereira|skos:broader|SW guys (and girls)
Mona Lisa|skos:broader|Peinture
Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation   An embedding method specifically designed for NED that jointly maps words and entities into the same continuous vector space.    We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words Named Entity Disambiguation (NED) refers to the task of resolving multiple named entity mentions in a document to their correct references in a knowledge base (KB) (e.g., Wikipedia). In this paper, we propose a novel embedding method specifically designed for NED. The proposed method jointly maps words and entities into the same continuous vector space. We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words. By combining contexts based on the proposed embedding with standard NED features, we achieved state-of-the-art accuracy of 93.1% on the standard CoNLL dataset and 85.2% on the TAC 2010 dataset.|sl:tag|tag:combining_word_and_entity_embeddings
Mur de Berlin|skos:broader|Histoire
Conventional topic models implicitly capture the document-level word co-occurrence patterns to reveal topics. This may not work well on short texts, because of data sparsity.    Compared with long texts, topic discovery from short  texts has the following three challenges:     - only very limited word co-occurrence information is available,  - the frequency of words plays a less discriminative role,   - and the limited contexts make it more dicult to identify the senses of ambiguous words    |skos:broader|A statistical model for discovering the abstract topics that occur in a collection of documents.      
Joint Embedding of Hierarchical Categories and Entities for Concept Categorization and Dataless Classification a framework that embeds entities and categories into a semantic space by integrating structured  knowledge and taxonomy hierarchy from large knowledge bases.    two methods:    1. Category Embedding model): it replaces the entities in the context with their directly  labeled categories to build categories’ context;   2. Hierarchical Category Embedding: it  further incorporates all ancestor categories of the context entities to utilize the hierarchical information. Due to the lack of structured knowledge applied in learning distributed representation of cate- gories, existing work cannot incorporate category hierarchies into entity information. We propose a framework that embeds entities and categories into a semantic space by integrating structured knowledge and taxonomy hierarchy from large knowledge bases. The framework allows to com- pute meaningful semantic relatedness between entities and categories. Our framework can han- dle both single-word concepts and multiple-word concepts with superior performance on concept categorization and yield state of the art results on dataless hierarchical classification.|sl:arxiv_author|Katia Sycara
PlaneteAfrique|skos:broader|Afrique
Film fantastique|skos:broader|Film
Pixelwise dense prediction|skos:broader|Computer vision
OwlSight|skos:broader|Google Web Toolkit
Linear Algebraic Structure of Word Senses, with Applications to Polysemy  Here it is shown that multiple word senses reside  in linear superposition within the word  embedding and simple sparse coding can recover  vectors that approximately capture the  senses     Each extracted word sense is accompanied by one of about  2000 “discourse atoms” that gives a succinct description of which other words co-occur with that word sense.     The success of the approach is mathematically explained using a variant of  the random walk on discourses model    (random walk: a generative model for language). Under the assumptions of this model,  there  exists a linear relationship between the vector of a  word w and the vectors of the words in its contexts (It is not the average of the words in w's context, but in a given corpus the matrix of the linear relationship does not depend on w. It can be estimated, and so we can compute the embedding of a word from the contexts it belongs to)    [Related blog post](/doc/?uri=https%3A%2F%2Fwww.offconvex.org%2F2016%2F07%2F10%2Fembeddingspolysemy%2F)   Word embeddings are ubiquitous in NLP and information retrieval, but it is unclear what they represent when the word is polysemous. Here it is shown that multiple word senses reside in linear superposition within the word embedding and simple sparse coding can recover vectors that approximately capture the senses. The success of our approach, which applies to several embedding methods, is mathematically explained using a variant of the random walk on discourses model (Arora et al., 2016). A novel aspect of our technique is that each extracted word sense is accompanied by one of about 2000 discourse atoms that gives a succinct description of which other words co-occur with that word sense. Discourse atoms can be of independent interest, and make the method potentially more useful. Empirical tests are used to verify and support the theory.|sl:tag|tag:lexical_ambiguity
RDFa 1.1|skos:broader|RDFa
Érythrée|skos:broader|Afrique de l'Est
Probing Neural Network Comprehension of Natural Language Arguments what has BERT learned about argument comprehension?    [Comments](/doc/2019/07/bert_s_success_in_some_benchmar) We are surprised to find that BERT's peak performance of 77% on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.|sl:tag|tag:bertology
Firefox extension|skos:broader|Firefox
Medical Information Search|skos:broader|Medical IR, ML, IA
Music of Africa|skos:broader|Musique
[Notes](/doc/2020/01/Semanlink%20dev%20notes.md)|skos:broader|Semantic Web, Semantic Me.
Shanghai Expo 2010|skos:broader|Exposition universelle
JSONP|skos:broader|Ajax
Lula|skos:broader|Chef d'état
Decision tree learning|skos:broader|Supervised machine learning
The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives [blog post](http://www.semanlink.net/doc/2019/09/evolution_of_representations_in) We seek to understand how the representations of individual tokens and the structure of the learned feature space evolve between layers in deep neural networks under different learning objectives. We focus on the Transformers for our analysis as they have been shown effective on various tasks, including machine translation (MT), standard left-to-right language models (LM) and masked language modeling (MLM). Previous work used black-box probing tasks to show that the representations learned by the Transformer differ significantly depending on the objective. In this work, we use canonical correlation analysis and mutual information estimators to study how information flows across Transformer layers and how this process depends on the choice of learning objective. For example, as you go from bottom to top layers, information about the past in left-to-right language models gets vanished and predictions about the future get formed. In contrast, for MLM, representations initially acquire information about the context around the token, partially forgetting the token identity and producing a more generalized token representation. The token identity then gets recreated at the top MLM layers.|sl:tag|tag:arxiv_doc
Ofir|skos:broader|Amazonie
Label-aware Document Representation via Hybrid Attention for Extreme Multi-Label Text Classification  This paper is motivated to better explore the semantic relationship between each document and extreme labels by taking advantage of both document content and label correlation. Our objective is to establish an explicit label-aware representation for each document with a hybrid attention deep neural network model(LAHA) Extreme multi-label text classification (XMTC) aims at tagging a document with most relevant labels from an extremely large-scale label set. It is a challenging problem especially for the tail labels because there are only few training documents to build classifier. This paper is motivated to better explore the semantic relationship between each document and extreme labels by taking advantage of both document content and label correlation. Our objective is to establish an explicit label-aware representation for each document with a hybrid attention deep neural network model(LAHA). LAHA consists of three parts. The first part adopts a multi-label self-attention mechanism to detect the contribution of each word to labels. The second part exploits the label structure and document content to determine the semantic connection between words and labels in a same latent space. An adaptive fusion strategy is designed in the third part to obtain the final label-aware document representation so that the essence of previous two parts can be sufficiently integrated. Extensive experiments have been conducted on six benchmark datasets by comparing with the state-of-the-art methods. The results show the superiority of our proposed LAHA method, especially on the tail labels.|sl:tag|tag:extreme_classification
Natural Language Processing (almost) from Scratch seminal work    Abstract:     a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements   We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.|sl:arxiv_author|Michael Karlen
Metropolitan Museum of Art|skos:broader|New York
Multi-task learning|skos:broader|Machine learning: techniques
Tchernobyl|skos:broader|Catastrophe industrielle
Zotero|skos:broader|Firefox extension
Detecting Potential Topics In News Using BERT, CRF and Wikipedia For a news content distribution platform like Dailyhunt, Named Entity Recognition is a pivotal task for building better user recommendation and notification algorithms. Apart from identifying names, locations, organisations from the news for 13+ Indian languages and use them in algorithms, we also need to identify n-grams which do not necessarily fit in the definition of Named-Entity, yet they are important. For example, me too movement, beef ban, alwar mob lynching. In this exercise, given an English language text, we are trying to detect case-less n-grams which convey important information and can be used as topics and/or hashtags for a news. Model is built using Wikipedia titles data, private English news corpus and BERT-Multilingual pre-trained model, Bi-GRU and CRF architecture. It shows promising results when compared with industry best Flair, Spacy and Stanford-caseless-NER in terms of F1 and especially Recall.|sl:tag|tag:named_entity_recognition
Structured Knowledge Distillation for Dense Prediction In this paper, we consider transferring the structure information from large networks to small ones for dense prediction tasks. Previous knowledge distillation strategies used for dense prediction tasks often directly borrow the distillation scheme for image classification and perform knowledge distillation for each pixel separately, leading to sub-optimal performance. Here we propose to distill structured knowledge from large networks to small networks, taking into account the fact that dense prediction is a structured prediction problem. Specifically, we study two structured distillation schemes: i)pair-wise distillation that distills the pairwise similarities by building a static graph, and ii)holistic distillation that uses adversarial training to distill holistic knowledge. The effectiveness of our knowledge distillation approaches is demonstrated by extensive experiments on three dense prediction tasks: semantic segmentation, depth estimation, and object detection.|sl:arxiv_firstAuthor|Yifan Liu
A Brief Introduction to Machine Learning for Engineers This monograph aims at providing an introduction to key concepts, algorithms, and theoretical results in machine learning. The treatment concentrates on probabilistic models for supervised and unsupervised learning problems. It introduces fundamental concepts and algorithms by building on first principles, while also exposing the reader to more advanced topics with extensive pointers to the literature, within a unified notation and mathematical framework. The material is organized according to clearly defined categories, such as discriminative and generative models, frequentist and Bayesian approaches, exact and approximate inference, as well as directed and undirected models. This monograph is meant as an entry point for researchers with a background in probability and linear algebra.|sl:tag|tag:machine_learning
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:tag|tag:sentence_embeddings
\Why Should I Trust You?\: Explaining the Predictions of Any Classifier technique that explains the predictions of any classifier by learning an interpretable model locally around the prediction Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.|sl:arxiv_author|Sameer Singh
Scalable Nearest Neighbor Search for Optimal Transport The Optimal Transport (a.k.a. Wasserstein) distance is an increasingly popular similarity measure for rich data domains, such as images or text documents. This raises the necessity for fast nearest neighbor search with respect to this distance, a problem that poses a substantial computational bottleneck for various tasks on massive datasets. In this work, we study fast tree-based approximation algorithms for searching nearest neighbors w.r.t. the Wasserstein-1 distance. A standard tree-based technique, known as Quadtree, has been previously shown to obtain good results. We introduce a variant of this algorithm, called Flowtree, and formally prove it achieves asymptotically better accuracy. Our extensive experiments, on real-world text and image datasets, show that Flowtree improves over various baselines and existing methods in either running time or accuracy. In particular, its quality of approximation is in line with previous high-accuracy methods, while its running time is much faster.|sl:tag|tag:arxiv_doc
Chanson|skos:broader|Musique
Pre-training via Paraphrasing We introduce MARGE, a pre-trained sequence-to-sequence model learned with an unsupervised multi-lingual multi-document paraphrasing objective. MARGE provides an alternative to the dominant masked language modeling paradigm, where we self-supervise the reconstruction of target text by retrieving a set of related texts (in many languages) and conditioning on them to maximize the likelihood of generating the original. We show it is possible to jointly learn to do retrieval and reconstruction, given only a random initialization. The objective noisily captures aspects of paraphrase, translation, multi-document summarization, and information retrieval, allowing for strong zero-shot performance on several tasks. For example, with no additional task-specific training we achieve BLEU scores of up to 35.8 for document translation. We further show that fine-tuning gives strong performance on a range of discriminative and generative tasks in many languages, making MARGE the most generally applicable pre-training method to date.|sl:arxiv_firstAuthor|Mike Lewis
Génétique humaine|skos:broader|Génome
RDA|skos:broader|Allemagne
Feature selection|skos:broader|Machine learning: techniques
Banque Centrale Européenne|skos:broader|Institutions européennes
ML/NLP blog|skos:broader|NLP
Championnats du monde à Paris-Saint Denis, 2003|skos:broader|Championnat du monde d'athlétisme
Apache Shiro|skos:broader|Java dev
Iran|skos:broader|Asie
Python-NLP|skos:broader|Python
Apache Hive|skos:broader|Hadoop
Mars/Curiosity|skos:broader|Exploration marsienne
Corent|skos:broader|Auvergne
Google Visualization API|skos:broader|JavaScript
Robert McLiam Wilson|skos:broader|Irlande du Nord
Youtube tutorial|skos:broader|YouTube video
Wikification|skos:broader|Wikipedia
Ant|skos:broader|Dev tools
Délocalisations|skos:broader|Mondialisation
Fast.ai course|skos:broader|fast.ai
Deep Mutual Learning  In this paper we explore a different but related idea to model distillation – that of mutual learning. Distillation starts with a powerful large and pre-trained teacher network and performs one-way knowledge transfer to a small untrained student. In contrast, in mutual learning we start with a pool of untrained students who learn simultaneously to solve the task together.    [critic here](doc:2020/06/1804_03235_large_scale_distri):     Zhang et al. (2017) reported a benefit in quality over  basic distillation, but they compare distilling model M1 into model M2 with training model M1  and model M2 using codistillation; they do not compare to distilling an ensemble of models M1  and M2 into model M3.     ...     we can achieve the 70.7% they report for online  distillation using traditional offline distillation. Model distillation is an effective and widely used technique to transfer knowledge from a teacher to a student network. The typical application is to transfer from a powerful large network or ensemble to a small network, that is better suited to low-memory or fast execution requirements. In this paper, we present a deep mutual learning (DML) strategy where, rather than one way transfer between a static pre-defined teacher and a student, an ensemble of students learn collaboratively and teach each other throughout the training process. Our experiments show that a variety of network architectures benefit from mutual learning and achieve compelling results on CIFAR-100 recognition and Market-1501 person re-identification benchmarks. Surprisingly, it is revealed that no prior powerful teacher network is necessary -- mutual learning of a collection of simple student networks works, and moreover outperforms distillation from a more powerful yet static teacher.|sl:tag|tag:arxiv_doc
Bidirectional LSTM-CRF Models for Sequence Tagging In this paper, we propose a variety of Long Short-Term Memory (LSTM) based models for sequence tagging. These models include LSTM networks, bidirectional LSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer (LSTM-CRF) and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work is the first to apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model to NLP benchmark sequence tagging data sets. We show that the BI-LSTM-CRF model can efficiently use both past and future input features thanks to a bidirectional LSTM component. It can also use sentence level tag information thanks to a CRF layer. The BI-LSTM-CRF model can produce state of the art (or close to) accuracy on POS, chunking and NER data sets. In addition, it is robust and has less dependence on word embedding as compared to previous observations.|sl:arxiv_author|Kai Yu
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|Sebastian Neumaier
Bertrand Sajus|skos:broader|SW guys (and girls)
AQMI|skos:broader|Sahel
Stacked Approximated Regression Machine: A Simple Deep Learning Approach This paper seems too good to be true! They can train a VGG-like net VERY quickly to good accuracy, without backprop. With the agreement of my coauthors, I Zhangyang Wang would like to withdraw the manuscript Stacked Approximated Regression Machine: A Simple Deep Learning Approach. Some experimental procedures were not included in the manuscript, which makes a part of important claims not meaningful. In the relevant research, I was solely responsible for carrying out the experiments; the other coauthors joined in the discussions leading to the main algorithm. Please see the updated text for more details.|sl:tag|tag:deep_learning
Pfizer|skos:broader|Industrie pharmaceutique
Peter Chilson|skos:broader|Peace Corps
Web Application Threats|skos:broader|Web dev
Bibliothéconomie|skos:broader|Bibliothèque
IPv6|skos:broader|Internet
Prix Nobel|skos:broader|Science
Union européenne|skos:broader|Europe
Google Web Toolkit|skos:broader|Google
Statistical classification|skos:broader|Machine learning: problems
SKOS|skos:broader|Thesaurus & Taxonomies 
Deep pre-training in NLP|skos:broader|Language Modeling Statistical Language Model
CoKE: Contextualized Knowledge Graph Embedding A method to build contextualized entity and relation embeddings. Entities and relations may appear in different graph contexts. Edges and paths, both formulated as sequences of entities and relations, are passed as input to a Transformer encoder to learn the contextualized representations..    [Github](https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE) Knowledge graph embedding, which projects symbolic entities and relations into continuous vector spaces, is gaining increasing attention. Previous methods allow a single static embedding for each entity or relation, ignoring their intrinsic contextual nature, i.e., entities and relations may appear in different graph contexts, and accordingly, exhibit different properties. This work presents Contextualized Knowledge Graph Embedding (CoKE), a novel paradigm that takes into account such contextual nature, and learns dynamic, flexible, and fully contextualized entity and relation embeddings. Two types of graph contexts are studied: edges and paths, both formulated as sequences of entities and relations. CoKE takes a sequence as input and uses a Transformer encoder to obtain contextualized representations. These representations are hence naturally adaptive to the input, capturing contextual meanings of entities and relations therein. Evaluation on a wide variety of public benchmarks verifies the superiority of CoKE in link prediction and path query answering. It performs consistently better than, or at least equally well as current state-of-the-art in almost every case, in particular offering an absolute improvement of 21.0% in H@10 on path query answering. Our code is available at \\url{https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE}.|sl:arxiv_author|Hua Wu
Tandja|skos:broader|Chef d'état
Exploring the Limits of Language Modeling recent advances in Recurrent Neural Networks for large scale Language Modeling In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon.|sl:arxiv_author|Yonghui Wu
Talis platform|skos:broader|Semantic Web Dev
Text in KG embeddings|skos:broader|Entity embeddings
Mission \Voulet-Chanoine\|skos:broader|Empire colonial français
Folksonomy|skos:broader|Tagging
Evaluation of sentence embeddings in downstream and linguistic probing tasks a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets     We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.           Despite the fast developmental pace of new sentence embedding methods, it is still challenging to find comprehensive evaluations of these different techniques. In the past years, we saw significant improvements in the field of sentence embeddings and especially towards the development of universal sentence encoders that could provide inductive transfer to a wide variety of downstream tasks. In this work, we perform a comprehensive evaluation of recent methods using a wide variety of downstream and linguistic feature probing tasks. We show that a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets. We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.|sl:arxiv_firstAuthor|Christian S. Perone
A Strong Baseline for Learning Cross-Lingual Word Embeddings from Sentence Alignments While cross-lingual word embeddings have been studied extensively in recent years, the qualitative differences between the different algorithms remain vague. We observe that whether or not an algorithm uses a particular feature set (sentence IDs) accounts for a significant performance gap among these algorithms. This feature set is also used by traditional alignment algorithms, such as IBM Model-1, which demonstrate similar performance to state-of-the-art embedding algorithms on a variety of benchmarks. Overall, we observe that different algorithmic approaches for utilizing the sentence ID feature space result in similar performance. This paper draws both empirical and theoretical parallels between the embedding and alignment literature, and suggests that adding additional sources of information, which go beyond the traditional signal of bilingual sentence-aligned corpora, may substantially improve cross-lingual word embeddings, and that future baselines should at least take such features into account.|sl:arxiv_author|Omer Levy
HAL|skos:broader|RESTful Web Services
Distilling Structured Knowledge into Embeddings for Explainable and Accurate Recommendation distilling structured knowledge from a differentiable path-based recommendation model.     proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons Recently, the embedding-based recommendation models (e.g., matrix factorization and deep models) have been prevalent in both academia and industry due to their effectiveness and flexibility. However, they also have such intrinsic limitations as lacking explainability and suffering from data sparsity. In this paper, we propose an end-to-end joint learning framework to get around these limitations without introducing any extra overhead by distilling structured knowledge from a differentiable path-based recommendation model. Through extensive experiments, we show that our proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons.|sl:arxiv_author|Hanning Zhou
Poutine|skos:broader|Méchant
Krakatoa|skos:broader|Volcan
Tim Berners-Lee|skos:broader|Technical girls and guys
Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus.     In practice, some questions are best answered  using text, while others are best answered using  KBs. A natural question, then, is how to effectively  combine both types of information. Surprisingly  little prior work has looked at this problem. Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting. Source code is available at https://github.com/OceanskySun/GraftNet .|sl:arxiv_author|Ruslan Salakhutdinov
Topic embeddings|skos:broader|Embeddings
Learning Semantic Similarity for Very Short Texts In order to pair short text  fragments—as a concatenation of separate words—an adequate  distributed sentence representation is needed. Main contribution: a first step towards a hybrid method that  combines the strength of dense distributed representations—  as opposed to sparse term matching—with the strength of  tf-idf based methods. The combination of word embeddings and tf-idf  information might lead to a better model for semantic content  within very short text fragments. Levering data on social media, such as Twitter and Facebook, requires information retrieval algorithms to become able to relate very short text fragments to each other. Traditional text similarity methods such as tf-idf cosine-similarity, based on word overlap, mostly fail to produce good results in this case, since word overlap is little or non-existent. Recently, distributed word representations, or word embeddings, have been shown to successfully allow words to match on the semantic level. In order to pair short text fragments - as a concatenation of separate words - an adequate distributed sentence representation is needed, in existing literature often obtained by naively combining the individual word representations. We therefore investigated several text representations as a combination of word embeddings in the context of semantic pair matching. This paper investigates the effectiveness of several such naive techniques, as well as traditional tf-idf similarity, for fragments of different lengths. Our main contribution is a first step towards a hybrid method that combines the strength of dense distributed representations - as opposed to sparse term matching - with the strength of tf-idf based methods to automatically reduce the impact of less informative terms. Our new approach outperforms the existing techniques in a toy experimental set-up, leading to the conclusion that the combination of word embeddings and tf-idf information might lead to a better model for semantic content within very short text fragments.|sl:arxiv_author|Cedric De Boom
URIBurner.com|skos:broader|Linked Data
Java concurrency|skos:broader|Java
Maven-Eclipse on My mac|skos:broader|Maven
Describing a Knowledge Base We aim to automatically generate natural language descriptions about an input structured knowledge base (KB). We build our generation framework based on a pointer network which can copy facts from the input KB, and add two attention mechanisms: (i) slot-aware attention to capture the association between a slot type and its corresponding slot value; and (ii) a new \\emph{table position self-attention} to capture the inter-dependencies among related slots. For evaluation, besides standard metrics including BLEU, METEOR, and ROUGE, we propose a KB reconstruction based metric by extracting a KB from the generation output and comparing it with the input KB. We also create a new data set which includes 106,216 pairs of structured KBs and their corresponding natural language descriptions for two distinct entity types. Experiments show that our approach significantly outperforms state-of-the-art methods. The reconstructed KB achieves 68.8% - 72.6% F-score.|sl:arxiv_author|Boliang Zhang
NLP 4 Requirements Engineering|skos:broader|NLP: use cases
An Introduction to Conditional Random Fields Often we wish to predict a large number of variables that depend on each other as well as on other observed variables. Structured prediction methods are essentially a combination of classification and graphical modeling, combining the ability of graphical models to compactly model multivariate data with the ability of classification methods to perform prediction using large sets of input features. This tutorial describes conditional random fields, a popular probabilistic method for structured prediction. CRFs have seen wide application in natural language processing, computer vision, and bioinformatics. We describe methods for inference and parameter estimation for CRFs, including practical issues for implementing large scale CRFs. We do not assume previous knowledge of graphical modeling, so this tutorial is intended to be useful to practitioners in a wide variety of fields.|sl:arxiv_author|Charles Sutton
Representation Learning with Contrastive Predictive Coding  a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful [autoregressive models](/tag/autoregressive_model). We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using [negative sampling](/tag/negative_sampling).    a contrastive method that can be applied to any form of data that can be expressed in an ordered sequence: text, speech, video... While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.|sl:tag|tag:representation_learning
Industrie textile|skos:broader|Economie
Gaz de schiste|skos:broader|Energies fossiles \non conventionnelles\
Japonais|skos:broader|Langues vivantes
PAC|skos:broader|Union européenne
XSLT|skos:broader|XSL
Industrie minière|skos:broader|industrie
Learning Sparse, Distributed Representations using the Hebbian Principle The \fire together, wire together\ Hebbian model is a central principle for learning in neuroscience, but surprisingly, it has found limited applicability in modern machine learning. In this paper, we take a first step towards bridging this gap, by developing flavors of competitive Hebbian learning which produce sparse, distributed neural codes using online adaptation with minimal tuning The fire together, wire together Hebbian model is a central principle for learning in neuroscience, but surprisingly, it has found limited applicability in modern machine learning. In this paper, we take a first step towards bridging this gap, by developing flavors of competitive Hebbian learning which produce sparse, distributed neural codes using online adaptation with minimal tuning. We propose an unsupervised algorithm, termed Adaptive Hebbian Learning (AHL). We illustrate the distributed nature of the learned representations via output entropy computations for synthetic data, and demonstrate superior performance, compared to standard alternatives such as autoencoders, in training a deep convolutional net on standard image datasets.|sl:tag|tag:hebbian_theory
EDUCE: Explaining model Decisions through Unsupervised Concepts Extraction  Providing explanations along with predictions is crucial in some text processing tasks. Therefore, we propose a new self-interpretable model that performs output prediction and simultaneously provides an explanation in terms of the presence of particular concepts in the input. To do so, our model's prediction relies solely on a low-dimensional binary representation of the input, where each feature denotes the presence or absence of concepts.    Presented in these [slides](/doc/2019/12/unsupervised_learning_with_text) Providing explanations along with predictions is crucial in some text processing tasks. Therefore, we propose a new self-interpretable model that performs output prediction and simultaneously provides an explanation in terms of the presence of particular concepts in the input. To do so, our model's prediction relies solely on a low-dimensional binary representation of the input, where each feature denotes the presence or absence of concepts. The presence of a concept is decided from an excerpt i.e. a small sequence of consecutive words in the text. Relevant concepts for the prediction task at hand are automatically defined by our model, avoiding the need for concept-level annotations. To ease interpretability, we enforce that for each concept, the corresponding excerpts share similar semantics and are differentiable from each others. We experimentally demonstrate the relevance of our approach on text classification and multi-sentiment analysis tasks.|sl:tag|tag:explainable_nlp
Transformers as Soft Reasoners over Language  AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. We provide the first demonstration that this is possible, and characterize the extent of this capability. To do this, we use a collection of synthetic datasets that test increasing levels of reasoning complexity (number of rules, presence of negation, and depth of chaining). We find transformers appear to learn rule-based reasoning with high (99%) accuracy on these datasets, and in a way that generalizes to test data requiring substantially deeper chaining than in the training data (95%+ scores). We also demonstrate that the models transfer well to two hand-authored rulebases, and to rulebases paraphrased into more natural language. These findings are significant as it suggests a new role for transformers, namely as a limited soft theorem prover operating over explicit theories in language. This in turn suggests new possibilities for explainability, correctability, and counterfactual reasoning in question-answering. All datasets and a live demo are available at http://rule-reasoning.apps.allenai.org/|sl:tag|tag:attention_is_all_you_need
KGAT: Knowledge Graph Attention Network for Recommendation To provide more accurate, diverse, and explainable recommendation, it is compulsory to go beyond modeling user-item interactions and take side information into account. Traditional methods like factorization machine (FM) cast it as a supervised learning problem, which assumes each interaction as an independent instance with side information encoded. Due to the overlook of the relations among instances or items (e.g., the director of a movie is also an actor of another movie), these methods are insufficient to distill the collaborative signal from the collective behaviors of users. In this work, we investigate the utility of knowledge graph (KG), which breaks down the independent interaction assumption by linking items with their attributes. We argue that in such a hybrid structure of KG and user-item graph, high-order relations --- which connect two items with one or multiple linked attributes --- are an essential factor for successful recommendation. We propose a new method named Knowledge Graph Attention Network (KGAT) which explicitly models the high-order connectivities in KG in an end-to-end fashion. It recursively propagates the embeddings from a node's neighbors (which can be users, items, or attributes) to refine the node's embedding, and employs an attention mechanism to discriminate the importance of the neighbors. Our KGAT is conceptually advantageous to existing KG-based recommendation methods, which either exploit high-order relations by extracting paths or implicitly modeling them with regularization. Empirical results on three public benchmarks show that KGAT significantly outperforms state-of-the-art methods like Neural FM and RippleNet. Further studies verify the efficacy of embedding propagation for high-order relation modeling and the interpretability benefits brought by the attention mechanism.|sl:arxiv_author|Meng Liu
Périodes glacières|skos:broader|Géologie
Emerging Cross-lingual Structure in Pretrained Language Models We study the problem of multilingual masked language modeling, i.e. the training of a single model on concatenated text from multiple languages, and present a detailed study of several factors that influence why these models are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from independently trained models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these symmetries seem to be automatically discovered and aligned during the joint training process.|sl:arxiv_author|Veselin Stoyanov
Exploring the Limits of Language Modeling recent advances in Recurrent Neural Networks for large scale Language Modeling In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon.|sl:arxiv_author|Mike Schuster
The Case for Learned Index Structures  we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs  Indexes are models: a B-Tree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term learned indexes. The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show, that by using neural nets we are able to outperform cache-optimized B-Trees by up to 70% in speed while saving an order-of-magnitude in memory over several real-world data sets. More importantly though, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work just provides a glimpse of what might be possible.|sl:arxiv_author|Jeffrey Dean
Crime contre l'Humanité|skos:broader|Crime
Towards Understanding Linear Word Analogies A surprising property of word vectors is that word analogies can often be solved with vector arithmetic. However, it is unclear why arithmetic operators correspond to non-linear embedding models such as skip-gram with negative sampling (SGNS). We provide a formal explanation of this phenomenon without making the strong assumptions that past theories have made about the vector space and word distribution. Our theory has several implications. Past work has conjectured that linear substructures exist in vector spaces because relations can be represented as ratios; we prove that this holds for SGNS. We provide novel justification for the addition of SGNS word vectors by showing that it automatically down-weights the more frequent word, as weighting schemes do ad hoc. Lastly, we offer an information theoretic interpretation of Euclidean distance in vector spaces, justifying its use in capturing word dissimilarity.|sl:tag|tag:word_embedding
Relational Databases and the Semantic Web|skos:broader|Semantic Web
Detecting Potential Topics In News Using BERT, CRF and Wikipedia For a news content distribution platform like Dailyhunt, Named Entity Recognition is a pivotal task for building better user recommendation and notification algorithms. Apart from identifying names, locations, organisations from the news for 13+ Indian languages and use them in algorithms, we also need to identify n-grams which do not necessarily fit in the definition of Named-Entity, yet they are important. For example, me too movement, beef ban, alwar mob lynching. In this exercise, given an English language text, we are trying to detect case-less n-grams which convey important information and can be used as topics and/or hashtags for a news. Model is built using Wikipedia titles data, private English news corpus and BERT-Multilingual pre-trained model, Bi-GRU and CRF architecture. It shows promising results when compared with industry best Flair, Spacy and Stanford-caseless-NER in terms of F1 and especially Recall.|sl:tag|tag:conditional_random_field
Leonardo da Vinci|skos:broader|Renaissance
Symmetric matrices related to the Mertens function In this paper we explore a family of congruences over N from which a sequence of symmetric matrices related to the Mertens function is built. From the results of numerical experiments we formulate a conjecture, about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may play a more important role in this classical and difficult problem.  In this paper we explore a family of congruences over $\\N^\\ast$ from which one builds a sequence of symmetric matrices related to the Mertens function. From the results of numerical experiments, we formulate a conjecture about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may come to play a more important role in this classical and difficult problem.|sl:tag|tag:hypothese_de_riemann
SourceForge|skos:broader|Open Source
Knowledge Graph Embeddings|skos:broader|Graph Embeddings
Visualizing and Measuring the Geometry of BERT  At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.|sl:tag|tag:these_irit_renault_biblio
IBM Watson|skos:broader|IBM
Mémoire humaine|skos:broader|Mémoire
In multi-label classification, each sample can be associated with a set of class labels. It is distinct from multi-class classification which aims to predict a single mutually exclusive label.    Methods (non exhaustive list):    - Dividing the original multi-label classification problem into multiple independent binary classification tasks      - computationally expensive      - cannot identify the correlation between label information  - Label embedding based approaches (deriving a latent label space with reduced dimensionality)      - correlation between the labels can be implicitly exploited    eg. replace the final softmax layer with a Sigmoid layer and use Binary Cross Entropy loss function to optimize the model.|skos:broader|the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations whose category membership is known.
Dynamic Object Model Pattern|skos:broader|Programming
Courtadon|skos:broader|Sculpture
Multi-Task Deep Neural Networks for Natural Language Understanding outperforms BERT in nine of eleven benchmark NLP tasks In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations in order to adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7% (2.2% absolute improvement). We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. The code and pre-trained models are publicly available at https://github.com/namisan/mt-dnn.|sl:arxiv_firstAuthor|Xiaodong Liu
Biohackers|skos:broader|OGM
OpenLink Software|skos:broader|Semantic web company
Déforestation|skos:broader|Forêt
Exploring the Limits of Language Modeling recent advances in Recurrent Neural Networks for large scale Language Modeling In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon.|sl:arxiv_author|Noam Shazeer
Amazonie|skos:broader|Brésil
Machine learning: techniques|skos:broader|Machine learning
Kernel methods|skos:broader|Algorithmes
LinkNBed: Multi-Graph Representation Learning with Entity Linkage   a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure     We posit that combining  graph alignment task with deep representation  learning across multi-relational graphs has potential  to induce a synergistic effect on both tasks Knowledge graphs have emerged as an important model for studying complex multi-relational data. This has given rise to the construction of numerous large scale but incomplete knowledge graphs encoding information extracted from various resources. An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledge-based inference for many downstream applications. To this end, we propose LinkNBed, a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure. Experiments on link prediction and entity linkage demonstrate substantial improvements over the state-of-the-art relational learning approaches.|sl:tag|tag:combining_knowledge_graphs
Christopher Olah|skos:broader|AI girls and guys
Messenger|skos:broader|Mercure (Planète)
FaceNet: A Unified Embedding for Face Recognition and Clustering Learns a Euclidean embedding per image     Uses a deep CNN trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method.     state-of-the-art face recognition performance using only 128-bytes per face.      Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves 95.12%. Our system cuts the error rate in comparison to the best published result by 30% on both datasets. We also introduce the concept of harmonic embeddings, and a harmonic triplet loss, which describe different versions of face embeddings (produced by different networks) that are compatible to each other and allow for direct comparison between each other.|sl:arxiv_author|Florian Schroff
nbdev.fast.ai|skos:broader|Python tools
Architecture en terre|skos:broader|Architecture
AutoML-Zero: Evolving Machine Learning Algorithms From Scratch  Fun AutoML-Zero experiments: Evolutionary search discovers fundamental ML algorithms from scratch, e.g., small neural nets with backprop.   Can evolution be the “Master Algorithm”? ;) Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.|sl:arxiv_author|Chen Liang
Deep Learning for Symbolic Mathematics Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.|sl:tag|tag:arxiv_doc
Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.|sl:arxiv_author|Artur d'Avila Garcez
On Extractive and Abstractive Neural Document Summarization with Transformer Language Models  Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper. We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We show that this extractive step significantly improves summarization results. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher rouge scores. Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper.|sl:tag|tag:automatic_summarization
ANN: introduction|skos:broader|Introduction
RDF graph versioning|skos:broader|RDF dev
OSEMA/DERI-Renault paper|skos:broader|Configuration and SW
Zemanta|skos:broader|Semantic tagging
A Dual Embedding Space Model for Document Ranking Investigate neural word embeddings as a source of evidence in document ranking.    Presented in [this Stanford course on IR](/doc/?uri=https%3A%2F%2Fweb.stanford.edu%2Fclass%2Fcs276%2Fhandouts%2Flecture20-distributed-representations.pdf) by Chris Manning (starting slide 44)    They train a word2vec model, but retain both the input and the output projections.     During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs.      However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives A fundamental goal of search engines is to identify, given a query, documents that have relevant text. This is intrinsically difficult because the query and the document may use different vocabulary, or the document may contain query words without being relevant. We investigate neural word embeddings as a source of evidence in document ranking. We train a word2vec embedding model on a large unlabelled query corpus, but in contrast to how the model is commonly used, we retain both the input and the output projections, allowing us to leverage both the embedding spaces to derive richer distributional relationships. During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs. We postulate that the proposed Dual Embedding Space Model (DESM) captures evidence on whether a document is about a query term in addition to what is modelled by traditional term-frequency based approaches. Our experiments show that the DESM can re-rank top documents returned by a commercial Web search engine, like Bing, better than a term-matching based signal like TF-IDF. However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives, retrieving documents that are only loosely related to the query. We demonstrate that this problem can be solved effectively by ranking based on a linear mixture of the DESM and the word counting features.|sl:arxiv_firstAuthor|Bhaskar Mitra
Reinhard Mey|skos:broader|Chanson
Loosely formatted text|skos:broader|NLP tasks / problems
Magnétisme|skos:broader|Physique
Lagos|skos:broader|Nigeria
iOS|skos:broader|Apple
Luis Buñuel|skos:broader|Espagne
Probabilités|skos:broader|Mathématiques
Linked Learning 2012|skos:broader|Linked Learning
Censure et maltraitance animale|skos:broader|Agriculture industrielle
Chrome extension|skos:broader|Chrome
Neural Ranking Models with Weak Supervision Main Idea: To leverage large amounts of unsupervised data to infer “weak” labels and use that signal for learning supervised models as if we had the ground truth labels. See [blog post](/doc/?uri=http%3A%2F%2Fmostafadehghani.com%2F2017%2F04%2F23%2Fbeating-the-teacher-neural-ranking-models-with-weak-supervision%2F):     This is truly awesome since we have only used  BM25 as the supervisor to train a model which performs better than BM25 itself!   Despite the impressive improvements achieved by unsupervised deep neural networks in computer vision and NLP tasks, such improvements have not yet been observed in ranking for information retrieval. The reason may be the complexity of the ranking problem, as it is not obvious how to learn from queries and documents when no supervised signal is available. Hence, in this paper, we propose to train a neural ranking model using weak supervision, where labels are obtained automatically without human annotators or any external resources (e.g., click data). To this aim, we use the output of an unsupervised ranking model, such as BM25, as a weak supervision signal. We further train a set of simple yet effective ranking models based on feed-forward neural networks. We study their effectiveness under various learning scenarios (point-wise and pair-wise models) and using different input representations (i.e., from encoding query-document pairs into dense/sparse vectors to using word embedding representation). We train our networks using tens of millions of training instances and evaluate it on two standard collections: a homogeneous news collection(Robust) and a heterogeneous large-scale web collection (ClueWeb). Our experiments indicate that employing proper objective functions and letting the networks to learn the input representation based on weakly supervised data leads to impressive performance, with over 13% and 35% MAP improvements over the BM25 model on the Robust and the ClueWeb collections. Our findings also suggest that supervised neural ranking models can greatly benefit from pre-training on large amounts of weakly labeled data that can be easily obtained from unsupervised IR models.|sl:tag|tag:okapi_bm25
Multi-class classification|skos:broader|Statistical classification
Spark (Java web framework)|skos:broader|Java microframeworks
Big data & semantic web|skos:broader|Semantic Web
rplug|skos:broader|C2GWeb
Energie sombre|skos:broader|Masse manquante
A Comprehensive Survey on Graph Neural Networks an overview of graph neural networks (GNNs) in data mining and machine learning fields Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.|sl:arxiv_author|Fengwen Chen
African land grab|skos:broader|Agriculture africaine
Neural Ranking Models with Weak Supervision Main Idea: To leverage large amounts of unsupervised data to infer “weak” labels and use that signal for learning supervised models as if we had the ground truth labels. See [blog post](/doc/?uri=http%3A%2F%2Fmostafadehghani.com%2F2017%2F04%2F23%2Fbeating-the-teacher-neural-ranking-models-with-weak-supervision%2F):     This is truly awesome since we have only used  BM25 as the supervisor to train a model which performs better than BM25 itself!   Despite the impressive improvements achieved by unsupervised deep neural networks in computer vision and NLP tasks, such improvements have not yet been observed in ranking for information retrieval. The reason may be the complexity of the ranking problem, as it is not obvious how to learn from queries and documents when no supervised signal is available. Hence, in this paper, we propose to train a neural ranking model using weak supervision, where labels are obtained automatically without human annotators or any external resources (e.g., click data). To this aim, we use the output of an unsupervised ranking model, such as BM25, as a weak supervision signal. We further train a set of simple yet effective ranking models based on feed-forward neural networks. We study their effectiveness under various learning scenarios (point-wise and pair-wise models) and using different input representations (i.e., from encoding query-document pairs into dense/sparse vectors to using word embedding representation). We train our networks using tens of millions of training instances and evaluate it on two standard collections: a homogeneous news collection(Robust) and a heterogeneous large-scale web collection (ClueWeb). Our experiments indicate that employing proper objective functions and letting the networks to learn the input representation based on weakly supervised data leads to impressive performance, with over 13% and 35% MAP improvements over the BM25 model on the Robust and the ClueWeb collections. Our findings also suggest that supervised neural ranking models can greatly benefit from pre-training on large amounts of weakly labeled data that can be easily obtained from unsupervised IR models.|sl:tag|tag:these_irit_renault_biblio_initiale
Corée|skos:broader|Asie
Web search|skos:broader|Search Engines
Jiroft|skos:broader|Découverte archéologique
A Brief Introduction to Machine Learning for Engineers This monograph aims at providing an introduction to key concepts, algorithms, and theoretical results in machine learning. The treatment concentrates on probabilistic models for supervised and unsupervised learning problems. It introduces fundamental concepts and algorithms by building on first principles, while also exposing the reader to more advanced topics with extensive pointers to the literature, within a unified notation and mathematical framework. The material is organized according to clearly defined categories, such as discriminative and generative models, frequentist and Bayesian approaches, exact and approximate inference, as well as directed and undirected models. This monograph is meant as an entry point for researchers with a background in probability and linear algebra.|sl:arxiv_firstAuthor|Osvaldo Simeone
Corse|skos:broader|France
A Dual Embedding Space Model for Document Ranking Investigate neural word embeddings as a source of evidence in document ranking.    Presented in [this Stanford course on IR](/doc/?uri=https%3A%2F%2Fweb.stanford.edu%2Fclass%2Fcs276%2Fhandouts%2Flecture20-distributed-representations.pdf) by Chris Manning (starting slide 44)    They train a word2vec model, but retain both the input and the output projections.     During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs.      However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives A fundamental goal of search engines is to identify, given a query, documents that have relevant text. This is intrinsically difficult because the query and the document may use different vocabulary, or the document may contain query words without being relevant. We investigate neural word embeddings as a source of evidence in document ranking. We train a word2vec embedding model on a large unlabelled query corpus, but in contrast to how the model is commonly used, we retain both the input and the output projections, allowing us to leverage both the embedding spaces to derive richer distributional relationships. During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs. We postulate that the proposed Dual Embedding Space Model (DESM) captures evidence on whether a document is about a query term in addition to what is modelled by traditional term-frequency based approaches. Our experiments show that the DESM can re-rank top documents returned by a commercial Web search engine, like Bing, better than a term-matching based signal like TF-IDF. However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives, retrieving documents that are only loosely related to the query. We demonstrate that this problem can be solved effectively by ranking based on a linear mixture of the DESM and the word counting features.|sl:arxiv_author|Nick Craswell
Pangloss: Fast Entity Linking in Noisy Text Environments a production system for entity disambiguation on messy tex, based  on probabilistic tokenization and context-dependent document embeddings    Probabilistic tokenization: uses the method described [here](/doc/2019/07/mining_quality_phrases_from_mas) Entity linking is the task of mapping potentially ambiguous terms in text to their constituent entities in a knowledge base like Wikipedia. This is useful for organizing content, extracting structured data from textual documents, and in machine learning relevance applications like semantic search, knowledge graph construction, and question answering. Traditionally, this work has focused on text that has been well-formed, like news articles, but in common real world datasets such as messaging, resumes, or short-form social media, non-grammatical, loosely-structured text adds a new dimension to this problem. This paper presents Pangloss, a production system for entity disambiguation on noisy text. Pangloss combines a probabilistic linear-time key phrase identification algorithm with a semantic similarity engine based on context-dependent document embeddings to achieve better than state-of-the-art results (5% in F1) compared to other research or commercially available systems. In addition, Pangloss leverages a local embedded database with a tiered architecture to house its statistics and metadata, which allows rapid disambiguation in streaming contexts and on-device disambiguation in low-memory environments such as mobile phones.|sl:tag|tag:arxiv_doc
Guerre chimique|skos:broader|War
Pfizer|skos:broader|Entreprise
Technological singularity|skos:broader|Anticipation
About Semanlink|skos:broader|Semanlink
Hypothèse de Riemann|skos:broader|Riemann
Social Web|skos:broader|Social Semantic Web
Hayabusa|skos:broader|Astéroïde
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:tag|tag:google_deepmind
New Africa|skos:broader|Favoris
Greffe de tête|skos:broader|Brain
Differentiable Top-k Operator with Optimal Transport  if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator   ...   We apply the proposed operator to the [k-nearest neighbors](tag:k_nearest_neighbors_algorithm) and [beam search](tag:beam_search) algorithms, and demonstrate improved performance The top-k operation, i.e., finding the k largest or smallest elements from a collection of scores, is an important model component, which is widely used in information retrieval, machine learning, and data mining. However, if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator. Specifically, our SOFT top-k operator approximates the output of the top-k operation as the solution of an Entropic Optimal Transport (EOT) problem. The gradient of the SOFT operator can then be efficiently approximated based on the optimality conditions of EOT problem. We apply the proposed operator to the k-nearest neighbors and beam search algorithms, and demonstrate improved performance.|sl:arxiv_author|Yujia Xie
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:arxiv_author|Stephen H. Bach
Entities as Experts: Sparse Memory Access with Entity Supervision   the problem of capturing declarative knowledge in the learned parameters of a language model...     Entities as Experts (EaE) can access distinct memories of the entities mentioned in a piece of text;     To understand the motivation for distinct and  independent entity representations: A traditional Transformer would need to build an internal representation  of Charles Darwin from the words “Charles”  and “Darwin”... Conversely, EAE can access  a dedicated representation of “Charles Darwin”,  which is a memory of all of the contexts in which  this entity has previously been mentioned.... Having retrieved  and re-integrated this memory it is much easier for  EAE to relate the question to the answer     EaE's entity representations are learned directly from text. Correct identification, and representation, of entities is essential to EaE's performance    Based on transformer architecture    Extension: [Facts as Experts](doc:2020/07/2007_00849_facts_as_experts_) We focus on the problem of capturing declarative knowledge in the learned parameters of a language model. We introduce a new model, Entities as Experts (EaE), that can access distinct memories of the entities mentioned in a piece of text. Unlike previous efforts to integrate entity knowledge into sequence models, EaE's entity representations are learned directly from text. These representations capture sufficient knowledge to answer TriviaQA questions such as Which Dr. Who villain has been played by Roger Delgado, Anthony Ainley, Eric Roberts?. EaE outperforms a Transformer model with $30\\times$ the parameters on this task. According to the Lama knowledge probes, EaE also contains more factual knowledge than a similar sized Bert. We show that associating parameters with specific entities means that EaE only needs to access a fraction of its parameters at inference time, and we show that the correct identification, and representation, of entities is essential to EaE's performance. We also argue that the discrete and independent entity representations in EaE make it more modular and interpretable than the Transformer architecture on which it is based.|sl:arxiv_author|Tom Kwiatkowski
Personal-information management|skos:broader|Informatique
Efficient Estimation of Word Representations in Vector Space We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.   We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.|sl:arxiv_author|Jeffrey Dean
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:arxiv_author|Steve Yuan
URI dereferencing|skos:broader|Web architecture
StarSpace: Embed All The Things! We present StarSpace, a general-purpose neural embedding model that can solve a wide variety of problems: labeling tasks such as text classification, ranking tasks such as information retrieval/web search, collaborative filtering-based or content-based recommendation, embedding of multi-relational graphs, and learning word, sentence or document level embeddings. In each case the model works by embedding those entities comprised of discrete features and comparing them against each other -- learning similarities dependent on the task. Empirical results on a number of tasks show that StarSpace is highly competitive with existing methods, whilst also being generally applicable to new cases where those methods are not.|sl:tag|tag:arxiv_doc
cluster analysis which seeks to build a hierarchy of clusters.    2 kinds:    - Agglomerative  - Divisive|skos:broader|the task of grouping a set of objects in such a way that objects in the same group (cluster) are more similar (in some sense or another) to each other than to those in other groups.  
Machines teaching machines|skos:broader|Machine learning
Histoire de l'astronomie|skos:broader|Astronomie
Semantic Web P2P|skos:broader|Peer to peer
KODE|skos:broader|Database
SIMILE Timeline|skos:broader|Timeline
Solr and NLP|skos:broader|NLP tools
IHM web|skos:broader|Web dev
TopBraid/SPIN|skos:broader|SPARQL
NER|skos:broader|Entity Analysis
Hierarchical Memory Networks  hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory Memory networks are neural networks with an explicit memory component that can be both read and written to by the network. The memory is often addressed in a soft way using a softmax function, making end-to-end training with backpropagation possible. However, this is not computationally scalable for applications which require the network to read from extremely large memories. On the other hand, it is well known that hard attention mechanisms based on reinforcement learning are challenging to train successfully. In this paper, we explore a form of hierarchical memory network, which can be considered as a hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory. Specifically, we propose to incorporate Maximum Inner Product Search (MIPS) in the training and inference procedures for our hierarchical memory network. We explore the use of various state-of-the art approximate MIPS techniques and report results on SimpleQuestions, a challenging large scale factoid question answering task.|sl:arxiv_author|Pascal Vincent
Virtuoso|skos:broader|TripleStore
Word Mover’s Distance|skos:broader|Text Similarity
fps and WWW 2008|skos:broader|WWW 2008
Resources-Oriented Web Services|skos:broader|Restful semantic web services
RDF bus|skos:broader|RDF
A Tutorial on Distance Metric Learning: Mathematical Foundations, Algorithms and Experiments distance metric learning, a branch of machine learning that aims to learn distances from the data Distance metric learning is a branch of machine learning that aims to learn distances from the data. Distance metric learning can be useful to improve similarity learning algorithms, and also has applications in dimensionality reduction. This paper describes the distance metric learning problem and analyzes its main mathematical foundations. In addition, it also discusses some of the most popular distance metric learning techniques used in classification, showing their goals and the required information to understand and use them. Furthermore, some experiments to evaluate the performance of the different algorithms are also provided. Finally, this paper discusses several possibilities of future work in this topic.|sl:arxiv_author|Francisco Herrera
fps notes|skos:broader|fps
RDF bus|skos:broader|Semantic Integration Hub
Niamey|skos:broader|Ville
End-to-End Neural Entity Linking  We presented the first neural end-to-end entity linking  model and show the benefit of jointly optimizing  entity recognition and linking. Leveraging key  components, namely word, entity and mention embeddings,  we prove that engineered features can  be almost completely replaced by modern neural  networks. Entity Linking (EL) is an essential task for semantic text understanding and information extraction. Popular methods separately address the Mention Detection (MD) and Entity Disambiguation (ED) stages of EL, without leveraging their mutual dependency. We here propose the first neural end-to-end EL system that jointly discovers and links entities in a text document. The main idea is to consider all possible spans as potential mentions and learn contextual similarity scores over their entity candidates that are useful for both MD and ED decisions. Key components are context-aware mention embeddings, entity embeddings and a probabilistic mention - entity map, without demanding other engineered features. Empirically, we show that our end-to-end method significantly outperforms popular systems on the Gerbil platform when enough training data is available. Conversely, if testing datasets follow different annotation conventions compared to the training set (e.g. queries/ tweets vs news documents), our ED model coupled with a traditional NER system offers the best or second best EL accuracy.|sl:arxiv_firstAuthor|Nikolaos Kolitsas
Pillage du palais d'été|skos:broader|Histoire de la Chine
Virtuoso:doc|skos:broader|Virtuoso
Integrating Tomcat with Apache|skos:broader|Developer documentation
Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus.     In practice, some questions are best answered  using text, while others are best answered using  KBs. A natural question, then, is how to effectively  combine both types of information. Surprisingly  little prior work has looked at this problem. Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting. Source code is available at https://github.com/OceanskySun/GraftNet .|sl:tag|tag:open_domain_question_answering
snorql|skos:broader|SPARQL en javascript
Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks  Sentence-BERT  (SBERT), a modification of the pretrained  BERT network that use siamese and triplet network  structures to derive semantically meaningful  sentence embeddings that can be compared  using cosine-similarity.    Important because     - BERT ist unsuitable for semantic similarity  search as well as for unsupervised tasks  like clustering.  - simple methods such as using the CLS token give low quality sentence embeddings    However, the purpose of SBERT sentence embeddings  are not to be used for transfer learning for other  tasks.    [Related blog post](/doc/2020/01/richer_sentence_embeddings_usin); [Github](https://github.com/UKPLab/sentence-transformers) BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.|sl:tag|tag:sentence_similarity
Makolab|skos:broader|Pologne
National Taiwan University|skos:broader|Taiwan
Ópera do Malandro|skos:broader|Chico Buarque
External memory algorithm|skos:broader|Mémoire (informatique)
Tech company|skos:broader|Entreprise
fps AND LDOW2008|skos:broader|SW in Technical Automotive Documentation
Loi sur le voile|skos:broader|Con de Chirac
Visualizing and Measuring the Geometry of BERT  At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.|sl:tag|tag:arxiv_doc
Agriculture|skos:broader|Grands problèmes
Parameter-free Sentence Embedding via Orthogonal Basis training-free approach for building sentence representations, Geometric Embedding (GEM), based on the geometric structure of word embedding space.     we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word’s novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace    [on www.groundai.com](https://www.groundai.com/project/zero-training-sentence-embedding-via-orthogonal-basis/)    [Open Revieww](/doc/?uri=https%3A%2F%2Fopenreview.net%2Fforum%3Fid%3DrJedbn0ctQ) ; [Related to this paper](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1704.05358)       We propose a simple and robust non-parameterized approach for building sentence representations. Inspired by the Gram-Schmidt Process in geometric theory, we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word's novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace. Following this motivation, we develop an innovative method based on orthogonal basis to combine pre-trained word embeddings into sentence representations. This approach requires zero parameters, along with efficient inference performance. We evaluate our approach on 11 downstream NLP tasks. Our model shows superior performance compared with non-parameterized alternatives and it is competitive to other approaches relying on either large amounts of labelled data or prolonged training time.|sl:arxiv_author|Ziyi Yang
Big Data Tools|skos:broader|Tools
Eau extraterrestre|skos:broader|Eau
OpenAI|skos:broader|Artificial Intelligence
hyperSOLutions|skos:broader|My old things
Google car|skos:broader|AI@Google
NLP conference|skos:broader|AI Conference
RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space  We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.|sl:tag|tag:arxiv_doc
jersey|skos:broader|Open Source
Rural India|skos:broader|Inde
Similarity learning|skos:broader|Machine learning: problems
Semantic Web Crawler|skos:broader|Semantic Web : Tools
ISP / Servlet Hosting|skos:broader|ISP
RDF browser|skos:broader|Linked Data
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|Lukas Schmelzeisen
Configuration as Linked Data|skos:broader|Configuration
Joint Embedding of Hierarchical Categories and Entities for Concept Categorization and Dataless Classification a framework that embeds entities and categories into a semantic space by integrating structured  knowledge and taxonomy hierarchy from large knowledge bases.    two methods:    1. Category Embedding model): it replaces the entities in the context with their directly  labeled categories to build categories’ context;   2. Hierarchical Category Embedding: it  further incorporates all ancestor categories of the context entities to utilize the hierarchical information. Due to the lack of structured knowledge applied in learning distributed representation of cate- gories, existing work cannot incorporate category hierarchies into entity information. We propose a framework that embeds entities and categories into a semantic space by integrating structured knowledge and taxonomy hierarchy from large knowledge bases. The framework allows to com- pute meaningful semantic relatedness between entities and categories. Our framework can han- dle both single-word concepts and multiple-word concepts with superior performance on concept categorization and yield state of the art results on dataless hierarchical classification.|sl:tag|tag:entity_embeddings
OWL|skos:broader|Semantic Web Dev
Transformers|skos:broader|Self-Attention
Obama|skos:broader|Président des USA
Polynesians|skos:broader|Peuples
Virtuoso|skos:broader|OpenLink Software
LOD & museum|skos:broader|Musée
Banksy|skos:broader|Peintre
End-To-End Memory Networks Neural network with a recurrent attention model over a possibly large external memory.    cité par [#A. Bordes](/tag/antoine_bordes) à [#ParisIsAI conf 2018](/tag/france_is_ai_2018.html) We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network (Weston et al., 2015) but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.|sl:arxiv_author|Sainbayar Sukhbaatar
Coursera: NLP class|skos:broader|Coursera
Amérique profonde|skos:broader|USA
Espèces menacées|skos:broader|Grands problèmes
Greenpeace|skos:broader|ONG
GRDDL|skos:broader|Semantic Web
CFPM|skos:broader|Musique du Niger
Traditionally, networks are usually represented as adjacency matrices. This suffers from data sparsity and high-dimensionality. Network embeddings aim to represent network  vertices into a low-dimensional vector space, by preserving  both network topology structure and node content information.    Algorithms are typically unsupervised  and can be broadly classified into  three groups ([source](/doc/2019/07/_1901_00596_a_comprehensive_su)):    - matrix factorization  - random walks   - deep learning approaches (graph neural networks - GNNs)  	- graph convolution networks (GraphSage)  	- graph attention networks,   	- graph auto-encoders (e.g., DNGR and SDNE)  	- graph generative networks,   	- graph spatial-temporal networks.    Node embeddings (intuition: similar nodes should have similar vectors).    - Laplacian EigenMap (an eigenvector based computation, OK when matrix is not too large)  - LINE Large-scale Information Network Embedding, most cited paper at WWW2015; Breadth first search  - DeepWalk (Perozzi et al. 2014) (the technique to learn word embeddings adapted to nodes: treating nodes as words and generating short random walks as sentences)  - Node2Vec (2016) (mixed strategy)    etc.  |skos:broader|The objective of embedding methods is to organize symbolic objects (e.g., words, entities, concepts) in a way such that their similarity in the embedding space reflects their semantic or functional similarity  
Hash Embeddings for Efficient Word Representations  A hash embedding may be seen as an interpolation between  a standard word embedding and a word embedding created using a random hash  function (the hashing trick).    recommandé par [Raphaël Sourty](tag:raphaelsty) We present hash embeddings, an efficient method for representing words in a continuous vector form. A hash embedding may be seen as an interpolation between a standard word embedding and a word embedding created using a random hash function (the hashing trick). In hash embeddings each token is represented by $k$ $d$-dimensional embeddings vectors and one $k$ dimensional weight vector. The final $d$ dimensional representation of the token is the product of the two. Rather than fitting the embedding vectors for each token these are selected by the hashing trick from a shared pool of $B$ embedding vectors. Our experiments show that hash embeddings can easily deal with huge vocabularies consisting of millions of tokens. When using a hash embedding there is no need to create a dictionary before training nor to perform any kind of vocabulary pruning after training. We show that models trained using hash embeddings exhibit at least the same level of performance as models trained using regular embeddings across a wide range of tasks. Furthermore, the number of parameters needed by such an embedding is only a fraction of what is required by a regular embedding. Since standard embeddings and embeddings constructed using the hashing trick are actually just special cases of a hash embedding, hash embeddings can be considered an extension and improvement over the existing regular embedding types.|sl:arxiv_firstAuthor|Dan Svenstrup
BERT for Joint Intent Classification and Slot Filling  Experimental results show that our  proposed joint BERT model outperforms BERT  models modeling intent classification and slot filling  separately, demonstrating the efficacy of exploiting  the relationship between the two tasks.    Adding a CRF on top of the model doesn't improve the results. Intent classification and slot filling are two essential tasks for natural language understanding. They often suffer from small-scale human-labeled training data, resulting in poor generalization capability, especially for rare words. Recently a new language representation model, BERT (Bidirectional Encoder Representations from Transformers), facilitates pre-training deep bidirectional representations on large-scale unlabeled corpora, and has created state-of-the-art models for a wide variety of natural language processing tasks after simple fine-tuning. However, there has not been much effort on exploring BERT for natural language understanding. In this work, we propose a joint intent classification and slot filling model based on BERT. Experimental results demonstrate that our proposed model achieves significant improvement on intent classification accuracy, slot filling F1, and sentence-level semantic frame accuracy on several public benchmark datasets, compared to the attention-based recurrent neural network models and slot-gated models.|sl:tag|tag:alibaba
