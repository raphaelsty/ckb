Photons corrélés|skos:broader|Mécanique quantique
Régions polaires|skos:broader|Géographie
Ex URSS URSS|skos:broader|Ex URSS URSS
blojsom|skos:broader|Java
Mines d'or|skos:broader|Or
Attention Is All You Need  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.|sl:arxiv_author|Jakob Uszkoreit
Chine : écologie|skos:broader|Crise écologique
Sony|skos:broader|Entreprise
Génocide rwandais|skos:broader|La communauté internationale est une garce
Large scale distributed neural network training through online distillation   we use codistillation to refer to distillation performed:   1. using the same architecture for all the models;   2. using the same dataset to train all the models; and   3. using the distillation loss during training before any model has fully converged.     In general, we believe the quality gains of codistillation over well-tuned offline distillation will be  minor in practice and the more interesting research direction is exploring codistillation as a distributed  training algorithm     Codistillation with  the same data seems to be slightly better than the baseline, but codistillation using different data  gets much better results. These results show that the codistilling models are indeed successfully  transmitting useful information about different parts of the training data to each other.    Related to [Deep mutual learning](doc:2020/05/1706_00384_deep_mutual_learni) paper Techniques such as ensembling and distillation promise model quality improvements when paired with almost any base model. However, due to increased test-time cost (for ensembles) and increased complexity of the training pipeline (for distillation), these techniques are challenging to use in industrial settings. In this paper we explore a variant of distillation which is relatively straightforward to use as it does not require a complicated multi-stage setup or many new hyperparameters. Our first claim is that online distillation enables us to use extra parallelism to fit very large datasets about twice as fast. Crucially, we can still speed up training even after we have already reached the point at which additional parallelism provides no benefit for synchronous or asynchronous stochastic gradient descent. Two neural networks trained on disjoint subsets of the data can share knowledge by encouraging each model to agree with the predictions the other model would have made. These predictions can come from a stale version of the other model so they can be safely computed using weights that only rarely get transmitted. Our second claim is that online distillation is a cost-effective way to make the exact predictions of a model dramatically more reproducible. We support our claims using experiments on the Criteo Display Ad Challenge dataset, ImageNet, and the largest to-date dataset used for neural language modeling, containing $6\\times 10^{11}$ tokens and based on the Common Crawl repository of web data.|sl:arxiv_firstAuthor|Rohan Anil
End-to-End Neural Entity Linking  We presented the first neural end-to-end entity linking  model and show the benefit of jointly optimizing  entity recognition and linking. Leveraging key  components, namely word, entity and mention embeddings,  we prove that engineered features can  be almost completely replaced by modern neural  networks. Entity Linking (EL) is an essential task for semantic text understanding and information extraction. Popular methods separately address the Mention Detection (MD) and Entity Disambiguation (ED) stages of EL, without leveraging their mutual dependency. We here propose the first neural end-to-end EL system that jointly discovers and links entities in a text document. The main idea is to consider all possible spans as potential mentions and learn contextual similarity scores over their entity candidates that are useful for both MD and ED decisions. Key components are context-aware mention embeddings, entity embeddings and a probabilistic mention - entity map, without demanding other engineered features. Empirically, we show that our end-to-end method significantly outperforms popular systems on the Gerbil platform when enough training data is available. Conversely, if testing datasets follow different annotation conventions compared to the training set (e.g. queries/ tweets vs news documents), our ED model coupled with a traditional NER system offers the best or second best EL accuracy.|sl:arxiv_author|Thomas Hofmann
The Description Length of Deep Learning Models  Solomonoff’s general theory of inference (Solomonoff, 1964) and the [Minimum Description Length Principle](tag:minimum_description_length_principle) (Grünwald, 2007; Rissanen, 2007) formalize [Occam's razor](tag:occam_s_razor), and hold that a good model of data is a model that is good at losslessly  compressing the data, including the cost of describing the model itself. Deep neural  networks might seem to go against this principle given the large number of  parameters to be encoded.  We demonstrate experimentally the ability of deep neural networks to compress  the training data even when accounting for parameter encoding. Solomonoff's general theory of inference and the Minimum Description Length principle formalize Occam's razor, and hold that a good model of data is a model that is good at losslessly compressing the data, including the cost of describing the model itself. Deep neural networks might seem to go against this principle given the large number of parameters to be encoded. We demonstrate experimentally the ability of deep neural networks to compress the training data even when accounting for parameter encoding. The compression viewpoint originally motivated the use of variational methods in neural networks. Unexpectedly, we found that these variational methods provide surprisingly poor compression bounds, despite being explicitly built to minimize such bounds. This might explain the relatively poor practical performance of variational methods in deep learning. On the other hand, simple incremental encoding methods yield excellent compression values on deep networks, vindicating Solomonoff's approach.|sl:tag|tag:facebook_fair
Web Application Threats|skos:broader|Cybersecurity Sécurité informatique
MaxEnt classifier (Multinomial logistic regression)|skos:broader|Logistic regression
Trou noir|skos:broader|Astronomie
Named Entity Recognition with Extremely Limited Data Named Entity Search (NES)     We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.     We do not propose this as a replacement  for NER, but as something to be used for an ephemeral or contextual  class of entity, when it does not make sense to label hundreds or  thousands of instances to learn a classifier Traditional information retrieval treats named entity recognition as a pre-indexing corpus annotation task, allowing entity tags to be indexed and used during search. Named entity taggers themselves are typically trained on thousands or tens of thousands of examples labeled by humans. However, there is a long tail of named entities classes, and for these cases, labeled data may be impossible to find or justify financially. We propose exploring named entity recognition as a search task, where the named entity class of interest is a query, and entities of that class are the relevant documents. What should that query look like? Can we even perform NER-style labeling with tens of labels? This study presents an exploration of CRF-based NER models with handcrafted features and of how we might transform them into search queries.|sl:arxiv_author|James Allan
Lee Feigenbaum|skos:broader|SW guys (and girls)
Hippies|skos:broader|I like I like
Pentagon|skos:broader|USA
Sentiment analysis|skos:broader|Sentiment
Filme brasileiro@pt|skos:broader|Film
Java|skos:broader|Sun Microsystems
Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus.     In practice, some questions are best answered  using text, while others are best answered using  KBs. A natural question, then, is how to effectively  combine both types of information. Surprisingly  little prior work has looked at this problem. Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting. Source code is available at https://github.com/OceanskySun/GraftNet .|sl:arxiv_author|William W. Cohen
What is life ?|skos:broader|Biology
ERNIE: Enhanced Language Representation with Informative Entities  We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.|sl:arxiv_author|Zhiyuan Liu
RDF|skos:broader|Data Interchange Format
SemTechBiz|skos:broader|Semantic Web conferences
Milliardaire|skos:broader|Money
Unsupervised Transfer Learning for Spoken Language Understanding in Intelligent Agents  We apply ELMo, ULMFiT (unsupervised transfer) with supervised transfer to reduce labeled data required for launching domains in Alexa by 10-15x User interaction with voice-powered agents generates large amounts of unlabeled utterances. In this paper, we explore techniques to efficiently transfer the knowledge from these unlabeled utterances to improve model performance on Spoken Language Understanding (SLU) tasks. We use Embeddings from Language Model (ELMo) to take advantage of unlabeled data by learning contextualized word representations. Additionally, we propose ELMo-Light (ELMoL), a faster and simpler unsupervised pre-training method for SLU. Our findings suggest unsupervised pre-training on a large corpora of unlabeled utterances leads to significantly better SLU performance compared to training from scratch and it can even outperform conventional supervised transfer. Additionally, we show that the gains from unsupervised transfer techniques can be further improved by supervised transfer. The improvements are more pronounced in low resource settings and when using only 1000 labeled in-domain samples, our techniques match the performance of training from scratch on 10-15x more labeled in-domain data.|sl:tag|tag:amazon_alexa
Caetano Veloso|skos:broader|Brésil
Animal|skos:broader|Biology
Web Services|skos:broader|Web
NLP@Stanford|skos:broader|AI@Stanford
Etat policier|skos:broader|Police
Text Editor|skos:broader|Tools
Attentats 13-11-2015|skos:broader|Terrorisme islamiste
Deep Learning frameworks|skos:broader|Frameworks
Self-Taught Hashing for Fast Similarity Search Emphasise following issue in Semantic Hashing: obtaining the codes for previously unseen documents. Propose following approach:  first find the optimal l-bit binary codes for all documents in  the given corpus via unsupervised learning, then train  l classifiers via supervised learning to predict the l-bit code  for any query document unseen before.    (méthode résumée [ici](https://www.semanticscholar.org/paper/Semantic-hashing-using-tags-and-topic-modeling-Wang-Zhang/1a0f660f70fd179003edc271694736baaa39dec4))       The ability of fast similarity search at large scale is of great importance to many Information Retrieval (IR) applications. A promising way to accelerate similarity search is semantic hashing which designs compact binary codes for a large number of documents so that semantically similar documents are mapped to similar codes (within a short Hamming distance). Although some recently proposed techniques are able to generate high-quality codes for documents known in advance, obtaining the codes for previously unseen documents remains to be a very challenging problem. In this paper, we emphasise this issue and propose a novel Self-Taught Hashing (STH) approach to semantic hashing: we first find the optimal $l$-bit binary codes for all documents in the given corpus via unsupervised learning, and then train $l$ classifiers via supervised learning to predict the $l$-bit code for any query document unseen before. Our experiments on three real-world text datasets show that the proposed approach using binarised Laplacian Eigenmap (LapEig) and linear Support Vector Machine (SVM) outperforms state-of-the-art techniques significantly.|sl:tag|tag:semantic_hashing
Musique du Niger|skos:broader|Music of Africa
Named Entity Disambiguation using Deep Learning on Graphs Evaluation of different deep learning techniques to create  a context vector from graphs, aimed at high-accuracy NED. (neural  approach for entity disambiguation using graphs as background  knowledge)     We tackle Named Entity Disambiguation (NED) by comparing entities  in short sentences with Wikidata graphs. Creating a context vector  from graphs through deep learning is a challenging problem that has  never been applied to NED. Our main contribution is to present an  experimental study of recent neural techniques, as well as a discussion  about which graph features are most important for the disambiguation  task...    [published paper](https://rd.springer.com/chapter/10.1007/978-3-030-15719-7_10)      In NED, the system  must be able to generate a context for an entity in a text and an entity  in a knowledge base, then correctly link the two.    Explore whether representing graphs  as triplets is more useful than using the full topological information of the graph    We tackle \\ac{NED} by comparing entities in short sentences with \\wikidata{} graphs. Creating a context vector from graphs through deep learning is a challenging problem that has never been applied to \\ac{NED}. Our main contribution is to present an experimental study of recent neural techniques, as well as a discussion about which graph features are most important for the disambiguation task. In addition, a new dataset (\\wikidatadisamb{}) is created to allow a clean and scalable evaluation of \\ac{NED} with \\wikidata{} entries, and to be used as a reference in future research. In the end our results show that a \\ac{Bi-LSTM} encoding of the graph triplets performs best, improving upon the baseline models and scoring an \ m{F1} value of $91.6\\%$ on the \\wikidatadisamb{} test set|sl:arxiv_author|Marc Sloan
Learning to Remember Rare Events  a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training.    Our memory module can be easily added to any part of a supervised neural network Despite recent advances, memory-augmented deep neural networks are still limited when it comes to life-long and one-shot learning, especially in remembering rare events. We present a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training. Our memory module can be easily added to any part of a supervised neural network. To show its versatility we add it to a number of networks, from simple convolutional ones tested on image classification to deep sequence-to-sequence and recurrent-convolutional models. In all cases, the enhanced network gains the ability to remember and do life-long one-shot learning. Our module remembers training examples shown many thousands of steps in the past and it can successfully generalize from them. We set new state-of-the-art for one-shot learning on the Omniglot dataset and demonstrate, for the first time, life-long one-shot learning in recurrent neural networks on a large-scale machine translation task.|sl:arxiv_author|Aurko Roy
Travailler moins|skos:broader|Travail
RNN-LM|skos:broader|RNN
Macron|skos:broader|Homme politique
Subword Semantic Hashing for Intent Classification on Small Datasets In this paper, we introduce the use of Semantic Hashing as embedding for the task of Intent Classification and achieve state-of-the-art performance on three frequently used benchmarks. Intent Classification on a small dataset is a challenging task for data-hungry state-of-the-art Deep Learning based systems. Semantic Hashing is an attempt to overcome such a challenge and learn robust text classification. Current word embedding based are dependent on vocabularies. One of the major drawbacks of such methods is out-of-vocabulary terms, especially when having small training datasets and using a wider vocabulary. This is the case in Intent Classification for chatbots, where typically small datasets are extracted from internet communication. Two problems arise by the use of internet communication. First, such datasets miss a lot of terms in the vocabulary to use word embeddings efficiently. Second, users frequently make spelling errors. Typically, the models for intent classification are not trained with spelling errors and it is difficult to think about ways in which users will make mistakes. Models depending on a word vocabulary will always face such issues. An ideal classifier should handle spelling errors inherently. With Semantic Hashing, we overcome these challenges and achieve state-of-the-art results on three datasets: AskUbuntu, Chatbot, and Web Application. Our benchmarks are available online: https://github.com/kumar-shridhar/Know-Your-Intent|sl:arxiv_author|Gyorgy Kovacs
Missing Labels (ML)|skos:broader|Supervised machine learning
Spark (Java web framework)|skos:broader|Java 8 lambdas
Mutualisme|skos:broader|Biology
Littérature|skos:broader|Art
Explosions cosmiques|skos:broader|Astronomie
Adolescents|skos:broader|Jeunesse
Peintre|skos:broader|Peinture
ESWC|skos:broader|Semantic Web conferences
A Call for More Rigor in Unsupervised Cross-lingual Learning  a scenario without any parallel data and abundant monolingual data is unrealistic in practice We review motivations, definition, approaches, and methodology for unsupervised cross-lingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of the world's languages. However, we argue that a scenario without any parallel data and abundant monolingual data is unrealistic in practice. We also discuss different training signals that have been used in previous work, which depart from the pure unsupervised setting. We then describe common methodological issues in tuning and evaluation of unsupervised cross-lingual models and present best practices. Finally, we provide a unified outlook for different types of research in this area (i.e., cross-lingual word embeddings, deep multilingual pretraining, and unsupervised machine translation) and argue for comparable evaluation of these models.|sl:arxiv_author|Gorka Labaka
Synonym URIs|skos:broader|Linking Open Data
Bitcoin|skos:broader|Peer to peer
Semantic Folding Theory And its Application in Semantic Fingerprinting Human language is recognized as a very complex domain since decades. No computer system has been able to reach human levels of performance so far. The only known computational system capable of proper language processing is the human brain. While we gather more and more data about the brain, its fundamental computational processes still remain obscure. The lack of a sound computational brain theory also prevents the fundamental understanding of Natural Language Processing. As always when science lacks a theoretical foundation, statistical modeling is applied to accommodate as many sampled real-world data as possible. An unsolved fundamental issue is the actual representation of language (data) within the brain, denoted as the Representational Problem. Starting with Jeff Hawkins' Hierarchical Temporal Memory (HTM) theory, a consistent computational theory of the human cortex, we have developed a corresponding theory of language data representation: The Semantic Folding Theory. The process of encoding words, by using a topographic semantic space as distributional reference frame into a sparse binary representational vector is called Semantic Folding and is the central topic of this document. Semantic Folding describes a method of converting language from its symbolic representation (text) into an explicit, semantically grounded representation that can be generically processed by Hawkins' HTM networks. As it turned out, this change in representation, by itself, can solve many complex NLP problems by applying Boolean operators and a generic similarity function like the Euclidian Distance. Many practical problems of statistical NLP systems, like the high cost of computation, the fundamental incongruity of precision and recall , the complex tuning procedures etc., can be elegantly overcome by applying Semantic Folding.|sl:arxiv_author|Francisco De Sousa Webber
Generalization through Memorization: Nearest Neighbor Language Models extend LMs with nearest neighbor search in embedding space We introduce $k$NN-LMs, which extend a pre-trained neural language model (LM) by linearly interpolating it with a $k$-nearest neighbors ($k$NN) model. The nearest neighbors are computed according to distance in the pre-trained LM embedding space, and can be drawn from any text collection, including the original LM training data. Applying this augmentation to a strong Wikitext-103 LM, with neighbors drawn from the original training set, our $k$NN-LM achieves a new state-of-the-art perplexity of 15.79 - a 2.9 point improvement with no additional training. We also show that this approach has implications for efficiently scaling up to larger training sets and allows for effective domain adaptation, by simply varying the nearest neighbor datastore, again without further training. Qualitatively, the model is particularly helpful in predicting rare patterns, such as factual knowledge. Together, these results strongly suggest that learning similarity between sequences of text is easier than predicting the next word, and that nearest neighbor search is an effective approach for language modeling in the long tail.|sl:tag|tag:language_model
Linear Algebraic Structure of Word Senses, with Applications to Polysemy  Here it is shown that multiple word senses reside  in linear superposition within the word  embedding and simple sparse coding can recover  vectors that approximately capture the  senses     Each extracted word sense is accompanied by one of about  2000 “discourse atoms” that gives a succinct description of which other words co-occur with that word sense.     The success of the approach is mathematically explained using a variant of  the random walk on discourses model    (random walk: a generative model for language). Under the assumptions of this model,  there  exists a linear relationship between the vector of a  word w and the vectors of the words in its contexts (It is not the average of the words in w's context, but in a given corpus the matrix of the linear relationship does not depend on w. It can be estimated, and so we can compute the embedding of a word from the contexts it belongs to)    [Related blog post](/doc/?uri=https%3A%2F%2Fwww.offconvex.org%2F2016%2F07%2F10%2Fembeddingspolysemy%2F)   Word embeddings are ubiquitous in NLP and information retrieval, but it is unclear what they represent when the word is polysemous. Here it is shown that multiple word senses reside in linear superposition within the word embedding and simple sparse coding can recover vectors that approximately capture the senses. The success of our approach, which applies to several embedding methods, is mathematically explained using a variant of the random walk on discourses model (Arora et al., 2016). A novel aspect of our technique is that each extracted word sense is accompanied by one of about 2000 discourse atoms that gives a succinct description of which other words co-occur with that word sense. Discourse atoms can be of independent interest, and make the method potentially more useful. Empirical tests are used to verify and support the theory.|sl:arxiv_author|Yuanzhi Li
Semantic Vector Encoding and Similarity Search Using Fulltext Search Engines  The ubiquity of semantic vector space modeling raises the challenge of efficient searching in dense, high-dimensional vector spaces. We would naturally want to take advantage of the design and optimizations behind modern fulltext engines like Elasticsearch so as to meet the scalability and robustness demands of modern IR applications. This is the research challenge addressed in this paper.   The paper describes novel ways of encoding dense vectors into text documents, allowing the use of traditional inverted index engines.    [blog post](https://rare-technologies.com/semantic-search-fulltext-engine-acl-2017/)   Vector representations and vector space modeling (VSM) play a central role in modern machine learning. We propose a novel approach to `vector similarity searching' over dense semantic representations of words and documents that can be deployed on top of traditional inverted-index-based fulltext engines, taking advantage of their robustness, stability, scalability and ubiquity. We show that this approach allows the indexing and querying of dense vectors in text domains. This opens up exciting avenues for major efficiency gains, along with simpler deployment, scaling and monitoring. The end result is a fast and scalable vector database with a tunable trade-off between vector search performance and quality, backed by a standard fulltext engine such as Elasticsearch. We empirically demonstrate its querying performance and quality by applying this solution to the task of semantic searching over a dense vector representation of the entire English Wikipedia.|sl:tag|tag:semantic_search
StarSpace: Embed All The Things! We present StarSpace, a general-purpose neural embedding model that can solve a wide variety of problems: labeling tasks such as text classification, ranking tasks such as information retrieval/web search, collaborative filtering-based or content-based recommendation, embedding of multi-relational graphs, and learning word, sentence or document level embeddings. In each case the model works by embedding those entities comprised of discrete features and comparing them against each other -- learning similarities dependent on the task. Empirical results on a number of tasks show that StarSpace is highly competitive with existing methods, whilst also being generally applicable to new cases where those methods are not.|sl:arxiv_firstAuthor|Ledell Wu
Origine de l'agriculture|skos:broader|Agriculture
Wolfram Language|skos:broader|Stephen Wolfram
Transnets|skos:broader|Journal Le Monde
ELMo|skos:broader|Word sense / Lexical ambiguity
Semantic Web : Application|skos:broader|Semantic Web
Pollueurs payeurs|skos:broader|Pollution
The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives [blog post](http://www.semanlink.net/doc/2019/09/evolution_of_representations_in) We seek to understand how the representations of individual tokens and the structure of the learned feature space evolve between layers in deep neural networks under different learning objectives. We focus on the Transformers for our analysis as they have been shown effective on various tasks, including machine translation (MT), standard left-to-right language models (LM) and masked language modeling (MLM). Previous work used black-box probing tasks to show that the representations learned by the Transformer differ significantly depending on the objective. In this work, we use canonical correlation analysis and mutual information estimators to study how information flows across Transformer layers and how this process depends on the choice of learning objective. For example, as you go from bottom to top layers, information about the past in left-to-right language models gets vanished and predictions about the future get formed. In contrast, for MLM, representations initially acquire information about the context around the token, partially forgetting the token identity and producing a more generalized token representation. The token identity then gets recreated at the top MLM layers.|sl:arxiv_author|Ivan Titov
Label-Embedding for Image Classification Attributes act as intermediate representations that enable parameter sharing between classes, a must when training data is scarce. We propose to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors. We introduce a function that measures the compatibility between an image and a label embedding. The parameters of this function are learned on a training set of labeled samples to ensure that, given an image, the correct classes rank higher than the incorrect ones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasets show that the proposed framework outperforms the standard Direct Attribute Prediction baseline in a zero-shot learning scenario. Label embedding enjoys a built-in ability to leverage alternative sources of information instead of or in addition to attributes, such as e.g. class hierarchies or textual descriptions. Moreover, label embedding encompasses the whole range of learning settings from zero-shot learning to regular learning with a large number of labeled examples.|sl:arxiv_author|Zaid Harchaoui
Domain Knowledge + Deep Learning|skos:broader|Deep Learning
SW in Technical Automotive Documentation|skos:broader|Technical documentation
OWL ontology|skos:broader|OWL
Richard Cyganiak|skos:broader|Technical girls and guys
Nazisme|skos:broader|Méchant
Continent de plastique|skos:broader|Plastic
Aidan Hogan|skos:broader|SW guys (and girls)
faiss|skos:broader|Nearest neighbor search
XTech|skos:broader|Conférences
Terres agricoles|skos:broader|Agriculture
A Call for More Rigor in Unsupervised Cross-lingual Learning  a scenario without any parallel data and abundant monolingual data is unrealistic in practice We review motivations, definition, approaches, and methodology for unsupervised cross-lingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of the world's languages. However, we argue that a scenario without any parallel data and abundant monolingual data is unrealistic in practice. We also discuss different training signals that have been used in previous work, which depart from the pure unsupervised setting. We then describe common methodological issues in tuning and evaluation of unsupervised cross-lingual models and present best practices. Finally, we provide a unified outlook for different types of research in this area (i.e., cross-lingual word embeddings, deep multilingual pretraining, and unsupervised machine translation) and argue for comparable evaluation of these models.|sl:arxiv_author|Mikel Artetxe
Semantic CMS|skos:broader|CMS
SW Wiki|skos:broader|Semantic Web
Jeff Hawkins|skos:broader|AI girls and guys
Web server|skos:broader|Web Serving
Pierre Rebour|skos:broader|Ami
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:tag|tag:combinatorial_generalization
Encelade|skos:broader|Saturne
Uncertainty in Deep Learning|skos:broader|Deep Learning
Grève du sexe|skos:broader|Sexe
Lexicon Infused Phrase Embeddings for Named Entity Resolution Employs lexicons as part of the word embedding training:      The skip-gram model can be trained to  predict not only neighboring words but also lexicon  membership of the central word (or phrase).    Quickly demonstrates how we can plug phrase embeddings  into an existing log-linear CRF System.     Most state-of-the-art approaches for named-entity recognition (NER) use semi supervised information in the form of word clusters and lexicons. Recently neural network-based language models have been explored, as they as a byproduct generate highly informative vector representations for words, known as word embeddings. In this paper we present two contributions: a new form of learning word embeddings that can leverage information from relevant lexicons to improve the representations, and the first system to use neural word embeddings to achieve state-of-the-art results on named-entity recognition in both CoNLL and Ontonotes NER. Our system achieves an F1 score of 90.90 on the test set for CoNLL 2003---significantly better than any previous system trained on public data, and matching a system employing massive private industrial query-log data.|sl:tag|tag:named_entity_recognition
Neural Bag of Words|skos:broader|NLP techniques
Neo4j|skos:broader|NOSQL
SemWeb Pro|skos:broader|Paris
Crète antique|skos:broader|Antiquité
Javascript tool|skos:broader|Dev tools
Economie allemande|skos:broader|Allemagne
Chirac|skos:broader|Politique française
Semantic web : Use cases|skos:broader|Semantic Web
ElasticSearch|skos:broader|Search Engines
AI teams|skos:broader|Artificial Intelligence
Enhancing the Power of Cardinal's Algorithm Cardinal's factorization algorithm of 1996 splits a univariate polynomial into two factors with root sets separated by the imaginary axis, which is an important goal itself and a basic step toward root-finding. The novelty of the algorithm and its potential power have been well recognized by experts immediately, but by 2016, that is, two decades later, its practical value still remains nil, particularly because of the high computational cost of performing its final stage by means of computing approximate greatest common divisor of two polynomials. We briefly recall Cardinal's algorithm and its difficulties, amend it based on some works performed since 1996, extend its power to splitting out factors of a more general class, and reduce the final stage of the algorithm to quite manageable computations with structured matrices. Some of our techniques can be of independent interest for matrix computations.|sl:tag|tag:polynomial
BBC semantic publishing|skos:broader|Good
Compressive Transformers for Long-Range Sequence Modelling  the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning.    [Blog post](/doc/2020/02/a_new_model_and_dataset_for_lon) We present the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning. We find the Compressive Transformer obtains state-of-the-art language modelling results in the WikiText-103 and Enwik8 benchmarks, achieving 17.1 ppl and 0.97 bpc respectively. We also find it can model high-frequency speech effectively and can be used as a memory mechanism for RL, demonstrated on an object matching task. To promote the domain of long-range sequence learning, we propose a new open-vocabulary language modelling benchmark derived from books, PG-19.|sl:arxiv_author|Jack W. Rae
LOD|skos:broader|LD
Film américain|skos:broader|Film
ULMFiT|skos:broader|Pre-Trained Language Models
Still a Pain in the Neck: Evaluating Text Representations on Lexical Composition How well do contextualized word embeddings address lexical composition? They are good in recognizing meaning shift (\give in\ is different from \give\) but much worse with revealing implicit meaning (\hot tea\ is about temperature, \hot debate\ isn't). Building meaningful phrase representations is challenging because phrase meanings are not simply the sum of their constituent meanings. Lexical composition can shift the meanings of the constituent words and introduce implicit information. We tested a broad range of textual representations for their capacity to address these issues. We found that as expected, contextualized word representations perform better than static word embeddings, more so on detecting meaning shift than in recovering implicit information, in which their performance is still far from that of humans. Our evaluation suite, including 5 tasks related to lexical composition effects, can serve future research aiming to improve such representations.|sl:arxiv_author|Vered Shwartz
Chef d'état|skos:broader|Homme célèbre
Mallet|skos:broader|Java tool
Venus de Brassempouy|skos:broader|Arts premiers
A Brief Introduction to Machine Learning for Engineers This monograph aims at providing an introduction to key concepts, algorithms, and theoretical results in machine learning. The treatment concentrates on probabilistic models for supervised and unsupervised learning problems. It introduces fundamental concepts and algorithms by building on first principles, while also exposing the reader to more advanced topics with extensive pointers to the literature, within a unified notation and mathematical framework. The material is organized according to clearly defined categories, such as discriminative and generative models, frequentist and Bayesian approaches, exact and approximate inference, as well as directed and undirected models. This monograph is meant as an entry point for researchers with a background in probability and linear algebra.|sl:tag|tag:introduction
Chant|skos:broader|Musique
FaceNet: A Unified Embedding for Face Recognition and Clustering Learns a Euclidean embedding per image     Uses a deep CNN trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method.     state-of-the-art face recognition performance using only 128-bytes per face.      Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves 95.12%. Our system cuts the error rate in comparison to the best published result by 30% on both datasets. We also introduce the concept of harmonic embeddings, and a harmonic triplet loss, which describe different versions of face embeddings (produced by different networks) that are compatible to each other and allow for direct comparison between each other.|sl:arxiv_author|James Philbin
On the Efficacy of Knowledge Distillation Evaluation of the efficacy  of knowledge distillation and its dependence on student  and teacher architectures. IEEE International Conference on Computer Vision (ICCV), 2019     Despite  widespread use, an understanding of when the student can  learn from the teacher is missing.     Our key finding  is that knowledge distillation is not a panacea and cannot  succeed when student capacity is too low to successfully  mimic the teacher. We have presented an approach  to mitigate this issue by stopping teacher training early In this paper, we present a thorough evaluation of the efficacy of knowledge distillation and its dependence on student and teacher architectures. Starting with the observation that more accurate teachers often don't make good teachers, we attempt to tease apart the factors that affect knowledge distillation performance. We find crucially that larger models do not often make better teachers. We show that this is a consequence of mismatched capacity, and that small students are unable to mimic large teachers. We find typical ways of circumventing this (such as performing a sequence of knowledge distillation steps) to be ineffective. Finally, we show that this effect can be mitigated by stopping the teacher's training early. Our results generalize across datasets and models.|sl:arxiv_author|Jang Hyun Cho
Kenya|skos:broader|Afrique de l'Est
JavaOne|skos:broader|Java
Combining text and structured data (ML-NLP)|skos:broader|NLP techniques
Learning Deep Latent Spaces for Multi-Label Classification Uses [Deep Canonical Correlation Analysis](/tag/deep_canonical_correlation_analysis) and autoencoder structures to learn a latent subspace from both feature and label domains for multi-label classification.    (several implementations on github)       Multi-label classification is a practical yet challenging task in machine learning related fields, since it requires the prediction of more than one label category for each input instance. We propose a novel deep neural networks (DNN) based model, Canonical Correlated AutoEncoder (C2AE), for solving this task. Aiming at better relating feature and label domain data for improved classification, we uniquely perform joint feature and label embedding by deriving a deep latent space, followed by the introduction of label-correlation sensitive loss function for recovering the predicted label outputs. Our C2AE is achieved by integrating the DNN architectures of canonical correlation analysis and autoencoder, which allows end-to-end learning and prediction with the ability to exploit label dependency. Moreover, our C2AE can be easily extended to address the learning problem with missing labels. Our experiments on multiple datasets with different scales confirm the effectiveness and robustness of our proposed method, which is shown to perform favorably against state-of-the-art methods for multi-label classification.|sl:arxiv_author|Yu-Chiang Frank Wang
RDFa parser|skos:broader|RDFa
Efficient Estimation of Word Representations in Vector Space We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.   We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.|sl:tag|tag:tomas_mikolov
Archéologie amazonienne|skos:broader|Civilisations précolombiennes
Joint Embedding of Hierarchical Categories and Entities for Concept Categorization and Dataless Classification a framework that embeds entities and categories into a semantic space by integrating structured  knowledge and taxonomy hierarchy from large knowledge bases.    two methods:    1. Category Embedding model): it replaces the entities in the context with their directly  labeled categories to build categories’ context;   2. Hierarchical Category Embedding: it  further incorporates all ancestor categories of the context entities to utilize the hierarchical information. Due to the lack of structured knowledge applied in learning distributed representation of cate- gories, existing work cannot incorporate category hierarchies into entity information. We propose a framework that embeds entities and categories into a semantic space by integrating structured knowledge and taxonomy hierarchy from large knowledge bases. The framework allows to com- pute meaningful semantic relatedness between entities and categories. Our framework can han- dle both single-word concepts and multiple-word concepts with superior performance on concept categorization and yield state of the art results on dataless hierarchical classification.|sl:tag|tag:arxiv_doc
hyperdoc2vec: Distributed Representations of Hypertext Documents Hypertext documents, such as web pages and academic papers, are of great importance in delivering information in our daily life. Although being effective on plain documents, conventional text embedding methods suffer from information loss if directly adapted to hyper-documents. In this paper, we propose a general embedding approach for hyper-documents, namely, hyperdoc2vec, along with four criteria characterizing necessary information that hyper-document embedding models should preserve. Systematic comparisons are conducted between hyperdoc2vec and several competitors on two tasks, i.e., paper classification and citation recommendation, in the academic paper domain. Analyses and experiments both validate the superiority of hyperdoc2vec to other models w.r.t. the four criteria.|sl:tag|tag:embeddings
Sequence labeling|skos:broader|Machine learning: problems
Fossile vivant|skos:broader|Biology
Multi-Task Deep Neural Networks for Natural Language Understanding outperforms BERT in nine of eleven benchmark NLP tasks In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations in order to adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7% (2.2% absolute improvement). We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. The code and pre-trained models are publicly available at https://github.com/namisan/mt-dnn.|sl:arxiv_author|Pengcheng He
fastai: A Layered API for Deep Learning Paper describing the fast.ai v2 API fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes: a new type dispatch system for Python along with a semantic type hierarchy for tensors; a GPU-optimized computer vision library which can be extended in pure Python; an optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 4-5 lines of code; a novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training; a new data block API; and much more. We have used this library to successfully create a complete deep learning course, which we were able to write more quickly than using previous approaches, and the code was more clear. The library is already in wide use in research, industry, and teaching. NB: This paper covers fastai v2, which is currently in pre-release at http://dev.fast.ai/|sl:tag|tag:arxiv_doc
Pubby|skos:broader|Linking Open Data
Crise de la dette publique grecque|skos:broader|Crise de la dette
Fulani|skos:broader|Peuples
RDF data visualization|skos:broader|Data visualisation
Rare words (NLP)|skos:broader|NLP tasks / problems
Machine learning|skos:broader|Data science
Mars Express|skos:broader|Mars 2004
Mongol|skos:broader|Peuples
Jsonld/Jena|skos:broader|Jena
Jean Rouch|skos:broader|Réalisateur
Banco|skos:broader|Architecture en terre
XQuery|skos:broader|XML
A La Carte Embedding|skos:broader|Sanjeev Arora
KG Embeddings Library|skos:broader|Machine Learning library
Large scale distributed neural network training through online distillation   we use codistillation to refer to distillation performed:   1. using the same architecture for all the models;   2. using the same dataset to train all the models; and   3. using the distillation loss during training before any model has fully converged.     In general, we believe the quality gains of codistillation over well-tuned offline distillation will be  minor in practice and the more interesting research direction is exploring codistillation as a distributed  training algorithm     Codistillation with  the same data seems to be slightly better than the baseline, but codistillation using different data  gets much better results. These results show that the codistilling models are indeed successfully  transmitting useful information about different parts of the training data to each other.    Related to [Deep mutual learning](doc:2020/05/1706_00384_deep_mutual_learni) paper Techniques such as ensembling and distillation promise model quality improvements when paired with almost any base model. However, due to increased test-time cost (for ensembles) and increased complexity of the training pipeline (for distillation), these techniques are challenging to use in industrial settings. In this paper we explore a variant of distillation which is relatively straightforward to use as it does not require a complicated multi-stage setup or many new hyperparameters. Our first claim is that online distillation enables us to use extra parallelism to fit very large datasets about twice as fast. Crucially, we can still speed up training even after we have already reached the point at which additional parallelism provides no benefit for synchronous or asynchronous stochastic gradient descent. Two neural networks trained on disjoint subsets of the data can share knowledge by encouraging each model to agree with the predictions the other model would have made. These predictions can come from a stale version of the other model so they can be safely computed using weights that only rarely get transmitted. Our second claim is that online distillation is a cost-effective way to make the exact predictions of a model dramatically more reproducible. We support our claims using experiments on the Criteo Display Ad Challenge dataset, ImageNet, and the largest to-date dataset used for neural language modeling, containing $6\\times 10^{11}$ tokens and based on the Common Crawl repository of web data.|sl:arxiv_author|Gabriel Pereyra
Multilevel models (also known as hierarchical linear models, nested data models, mixed models, random coefficient, random-effects models, random parameter models, or split-plot designs) are statistical models of parameters that vary at more than one level. An example could be a model of student performance that contains measures for individual students as well as measures for classrooms within which the students are grouped. These models can be seen as generalizations of linear models (in particular, linear regression), although they can also extend to non-linear models.    |skos:broader|a statistical process for estimating the relationships among variables.  
Semantic web company|skos:broader|Tech company
Linear Algebraic Structure of Word Senses, with Applications to Polysemy  Here it is shown that multiple word senses reside  in linear superposition within the word  embedding and simple sparse coding can recover  vectors that approximately capture the  senses     Each extracted word sense is accompanied by one of about  2000 “discourse atoms” that gives a succinct description of which other words co-occur with that word sense.     The success of the approach is mathematically explained using a variant of  the random walk on discourses model    (random walk: a generative model for language). Under the assumptions of this model,  there  exists a linear relationship between the vector of a  word w and the vectors of the words in its contexts (It is not the average of the words in w's context, but in a given corpus the matrix of the linear relationship does not depend on w. It can be estimated, and so we can compute the embedding of a word from the contexts it belongs to)    [Related blog post](/doc/?uri=https%3A%2F%2Fwww.offconvex.org%2F2016%2F07%2F10%2Fembeddingspolysemy%2F)   Word embeddings are ubiquitous in NLP and information retrieval, but it is unclear what they represent when the word is polysemous. Here it is shown that multiple word senses reside in linear superposition within the word embedding and simple sparse coding can recover vectors that approximately capture the senses. The success of our approach, which applies to several embedding methods, is mathematically explained using a variant of the random walk on discourses model (Arora et al., 2016). A novel aspect of our technique is that each extracted word sense is accompanied by one of about 2000 discourse atoms that gives a succinct description of which other words co-occur with that word sense. Discourse atoms can be of independent interest, and make the method potentially more useful. Empirical tests are used to verify and support the theory.|sl:arxiv_author|Andrej Risteski
Linking Enterprise Data|skos:broader|Semantic Enterprise
Armement|skos:broader|Militaire
An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks For most deep learning practitioners, sequence modeling is synonymous with recurrent networks. Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation. Given a new sequence modeling task or dataset, which architecture should one use? We conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling. The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks. Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as LSTMs across a diverse range of tasks and datasets, while demonstrating longer effective memory. We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks. To assist related work, we have made code available at http://github.com/locuslab/TCN .|sl:tag|tag:arxiv_doc
Looks like everything (up to 2020-07-14) refers to this [github project](doc:2020/07/ukplab_sentence_transformers_s), [paper (Sentence-BERT)](doc:2019/08/_1908_10084_sentence_bert_sen)|skos:broader|In practice, many NLP applications rely on a simple sentence embedding: the average of the  embeddings of the words in it. We can do better.    Ex of use (besides trivial ones such as classification and similarity): use sentence embeddings to cluster  sentences in documents, which aids in the automatic extraction  of key information from large bodies of text.  
SPARQL endpoint|skos:broader|SPARQL
Twine|skos:broader|Social software
Institutions européennes|skos:broader|Europe
Princeton|skos:broader|Universités américaines
Paris|skos:broader|Ville
Carl Lewis|skos:broader|Sportif
Data Scientists|skos:broader|Data science
Diacritics in URI|skos:broader|Diacritics
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:arxiv_author|Brian Strope
Japonais|skos:broader|Japon
Enterprise Knowledge Graph|skos:broader|Semantic Enterprise Architecture
Hello Edge: Keyword Spotting on Microcontrollers Keyword spotting (KWS) is a critical component for enabling speech based user interactions on smart devices. It requires real-time response and high accuracy for good user experience. Recently, neural networks have become an attractive choice for KWS architecture because of their superior accuracy compared to traditional speech processing algorithms. Due to its always-on nature, KWS application has highly constrained power budget and typically runs on tiny microcontrollers with limited memory and compute capability. The design of neural network architecture for KWS must consider these constraints. In this work, we perform neural network architecture evaluation and exploration for running KWS on resource-constrained microcontrollers. We train various neural network architectures for keyword spotting published in literature to compare their accuracy and memory/compute requirements. We show that it is possible to optimize these neural network architectures to fit within the memory and compute constraints of microcontrollers without sacrificing accuracy. We further explore the depthwise separable convolutional neural network (DS-CNN) and compare it against other neural network architectures. DS-CNN achieves an accuracy of 95.4%, which is ~10% higher than the DNN model with similar number of parameters.|sl:arxiv_author|Naveen Suda
Baïkal|skos:broader|Eau
Smoothed Inverse Frequency: a linear representation of a sentence which is better than the simple average of the embeddings of its words    2 ideas:    - assign to each word a weighting that depends on the frequency of the word it the corpus (reminiscent of TF-IDF)  - some denoising (removing the component from the top singular direction)        Todo (?): check implementation as a [sklearn Vectorizer](https://github.com/ChristophAlt/embedding_vectorizer)  |skos:broader|In practice, many NLP applications rely on a simple sentence embedding: the average of the  embeddings of the words in it. We can do better.    Ex of use (besides trivial ones such as classification and similarity): use sentence embeddings to cluster  sentences in documents, which aids in the automatic extraction  of key information from large bodies of text.  
Digital economy|skos:broader|Internet
Self-Taught Convolutional Neural Networks for Short Text Clustering  We propose a flexible short text clustering framework which explores the feasibility and effectiveness of combining CNN and traditional unsupervised dimensionality reduction methods.     Non-biased deep feature representations can be learned through our self- taught CNN framework which does not use any external tags/labels or complicated NLP pre-processing.     The original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations.    [conf paper, same authors](http://www.aclweb.org/anthology/W15-1509) ; [gitgub repo (matlab)](https://github.com/jacoxu/STC2)   Short text clustering is a challenging problem due to its sparseness of text representation. Here we propose a flexible Self-Taught Convolutional neural network framework for Short Text Clustering (dubbed STC^2), which can flexibly and successfully incorporate more useful semantic features and learn non-biased deep text representation in an unsupervised manner. In our framework, the original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction methods. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations. Extensive experimental results demonstrate that the proposed framework is effective, flexible and outperform several popular clustering methods when tested on three public short text datasets.|sl:arxiv_firstAuthor|Jiaming Xu
Representing Sentences as Low-Rank Subspaces  We observe a simple geometry of sentences -- the word representations of a given sentence roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors.    A sentence of N words is a matrix (300, N) (if 300 is the dim of the word embeddings space). We take the eg. 4 (hyperparam) heaviest singular values - a subspace with dim 4    Similarity between docs: principal angle between the subspaces (reminiscent of cosine similarity)     Sentences are important semantic units of natural language. A generic, distributional representation of sentences that can capture the latent semantics is beneficial to multiple downstream applications. We observe a simple geometry of sentences -- the word representations of a given sentence (on average 10.23 words in all SemEval datasets with a standard deviation 4.84) roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors. Such an unsupervised representation is empirically validated via semantic textual similarity tasks on 19 different datasets, where it outperforms the sophisticated neural network models, including skip-thought vectors, by 15% on average.|sl:arxiv_author|Pramod Viswanath
14 juillet|skos:broader|Révolution française
eClassOWL|skos:broader|Product description
Continual Lifelong Learning with Neural Networks: A Review Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.|sl:arxiv_firstAuthor|German I. Parisi
In practice, many NLP applications rely on a simple sentence embedding: the average of the  embeddings of the words in it. We can do better.    Ex of use (besides trivial ones such as classification and similarity): use sentence embeddings to cluster  sentences in documents, which aids in the automatic extraction  of key information from large bodies of text.  |skos:broader|The objective of embedding methods is to organize symbolic objects (e.g., words, entities, concepts) in a way such that their similarity in the embedding space reflects their semantic or functional similarity  
Origines de l'homme|skos:broader|Paléontologie humaine
Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings (i.e. semantic representations) of word sequences as well. We present a simple but efficient unsupervised objective to train distributed representations of sentences. Our method outperforms the state-of-the-art unsupervised models on most benchmark tasks, highlighting the robustness of the produced general-purpose sentence embeddings.|sl:arxiv_author|Prakhar Gupta
DSSM (Deep Semantic Similarity Model)|skos:broader|Siamese networks
Traversing Knowledge Graphs in Vector Space Knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new \compositional\ training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. Path queries on a knowledge graph can be used to answer compositional questions such as What languages are spoken by people living in Lisbon?. However, knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new compositional training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. On a standard knowledge base completion task, we also demonstrate that compositional training acts as a novel form of structural regularization, reliably improving performance across all base models (reducing errors by up to 43%) and achieving new state-of-the-art results.|sl:tag|tag:path_queries
Antibiotiques|skos:broader|Médecine
Louis Jouvet|skos:broader|Acteur
Natural Language Processing (almost) from Scratch seminal work    Abstract:     a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements   We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.|sl:tag|tag:nlp
Distilling the Knowledge in a Neural Network  a different kind of training, which we call “distillation” to transfer the  knowledge from the cumbersome model to a small model that is more  suitable for deployment       Caruana and his collaborators have shown that it is possible to compress the knowledge in an [#ensemble](/tag/ensemble_learning.html) into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST. A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.|sl:arxiv_author|Oriol Vinyals
Tomcat tips|skos:broader|Tomcat
Validation: XML vs RDF|skos:broader|RDF vs XML
Coursera: Computational Neuroscience|skos:broader|Coursera
Fractales|skos:broader|Mathématiques
Guerres coloniales|skos:broader|War
Championnats du monde à Paris-Saint Denis, 2003|skos:broader|Paris
FBI|skos:broader|USA
Graph neural networks|skos:broader|Neural networks
PBS|skos:broader|Télévision
Songhaï|skos:broader|Afrique de l'Ouest
RDF performance issues|skos:broader|RDF
EDUCE: Explaining model Decisions through Unsupervised Concepts Extraction  Providing explanations along with predictions is crucial in some text processing tasks. Therefore, we propose a new self-interpretable model that performs output prediction and simultaneously provides an explanation in terms of the presence of particular concepts in the input. To do so, our model's prediction relies solely on a low-dimensional binary representation of the input, where each feature denotes the presence or absence of concepts.    Presented in these [slides](/doc/2019/12/unsupervised_learning_with_text) Providing explanations along with predictions is crucial in some text processing tasks. Therefore, we propose a new self-interpretable model that performs output prediction and simultaneously provides an explanation in terms of the presence of particular concepts in the input. To do so, our model's prediction relies solely on a low-dimensional binary representation of the input, where each feature denotes the presence or absence of concepts. The presence of a concept is decided from an excerpt i.e. a small sequence of consecutive words in the text. Relevant concepts for the prediction task at hand are automatically defined by our model, avoiding the need for concept-level annotations. To ease interpretability, we enforce that for each concept, the corresponding excerpts share similar semantics and are differentiable from each others. We experimentally demonstrate the relevance of our approach on text classification and multi-sentiment analysis tasks.|sl:arxiv_firstAuthor|Diane Bouchacourt
Stemming|skos:broader|NLP techniques
Satellite images|skos:broader|Photo
Automating the search for a patent's prior art with a full text similarity search [github](https://github.com/helmersl/patent_similarity_search)    mouais     More than ever, technical inventions are the symbol of our society's advance. Patents guarantee their creators protection against infringement. For an invention being patentable, its novelty and inventiveness have to be assessed. Therefore, a search for published work that describes similar inventions to a given patent application needs to be performed. Currently, this so-called search for prior art is executed with semi-automatically composed keyword queries, which is not only time consuming, but also prone to errors. In particular, errors may systematically arise by the fact that different keywords for the same technical concepts may exist across disciplines. In this paper, a novel approach is proposed, where the full text of a given patent application is compared to existing patents using machine learning and natural language processing techniques to automatically detect inventions that are similar to the one described in the submitted document. Various state-of-the-art approaches for feature extraction and document comparison are evaluated. In addition to that, the quality of the current search process is assessed based on ratings of a domain expert. The evaluation results show that our automated approach, besides accelerating the search process, also improves the search results for prior art with respect to their quality.|sl:arxiv_author|Lea Helmers
Javascript tips|skos:broader|Dev tips
Neuroevolution|skos:broader|Evolutionary computation
paggr|skos:broader|Benjamin Nowack
Cambridge Analytica|skos:broader|Dark side of Tech
StarSpace: Embed All The Things! We present StarSpace, a general-purpose neural embedding model that can solve a wide variety of problems: labeling tasks such as text classification, ranking tasks such as information retrieval/web search, collaborative filtering-based or content-based recommendation, embedding of multi-relational graphs, and learning word, sentence or document level embeddings. In each case the model works by embedding those entities comprised of discrete features and comparing them against each other -- learning similarities dependent on the task. Empirical results on a number of tasks show that StarSpace is highly competitive with existing methods, whilst also being generally applicable to new cases where those methods are not.|sl:tag|tag:nlp_facebook
Unsupervised Transfer Learning for Spoken Language Understanding in Intelligent Agents  We apply ELMo, ULMFiT (unsupervised transfer) with supervised transfer to reduce labeled data required for launching domains in Alexa by 10-15x User interaction with voice-powered agents generates large amounts of unlabeled utterances. In this paper, we explore techniques to efficiently transfer the knowledge from these unlabeled utterances to improve model performance on Spoken Language Understanding (SLU) tasks. We use Embeddings from Language Model (ELMo) to take advantage of unlabeled data by learning contextualized word representations. Additionally, we propose ELMo-Light (ELMoL), a faster and simpler unsupervised pre-training method for SLU. Our findings suggest unsupervised pre-training on a large corpora of unlabeled utterances leads to significantly better SLU performance compared to training from scratch and it can even outperform conventional supervised transfer. Additionally, we show that the gains from unsupervised transfer techniques can be further improved by supervised transfer. The improvements are more pronounced in low resource settings and when using only 1000 labeled in-domain samples, our techniques match the performance of training from scratch on 10-15x more labeled in-domain data.|sl:tag|tag:transfer_learning
Representation Learning with Contrastive Predictive Coding  a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful [autoregressive models](/tag/autoregressive_model). We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using [negative sampling](/tag/negative_sampling).    a contrastive method that can be applied to any form of data that can be expressed in an ordered sequence: text, speech, video... While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.|sl:arxiv_author|Oriol Vinyals
sig.ma|skos:broader|Giovanni Tummarello
URL|skos:broader|Dev
The information bottleneck method  We define the relevant information in a signal x ∈ X as being the information that this signal provides about another signal y ∈ Y. Examples include the information that face images provide about the names of the people portrayed, or the information that speech sounds provide about the words spoken. Understanding the signal x requires more than just predicting y, it also requires specifying which features of X play a role in the prediction. We formalize this problem as that of finding a short code for X that preserves the maximum information about Y. That is, we squeeze the information that X provides about Y through a ‘bottleneck’ formed by a limited set of codewords X ̃... This approach yields an exact set of self consistent equations for the coding rules X → X ̃ and X ̃ → Y .    (from the intro) : how to define meaningful / relevant information? An issue left out of information theory by Shannon (focus on the problem of transmitting information rather than judging its value to the recipient) -leads to  consider statistical and information theoretic principles as almost irrelevant  for the question of meaning.      In contrast, we argue here that information theory,  in particular lossy source compression, provides a natural quantitative  approach to the question of “relevant information.” Specifically, we formulate  a variational principle for the extraction or efficient representation of  relevant information.     We define the relevant information in a signal $x\\in X$ as being the information that this signal provides about another signal $y\\in \\Y$. Examples include the information that face images provide about the names of the people portrayed, or the information that speech sounds provide about the words spoken. Understanding the signal $x$ requires more than just predicting $y$, it also requires specifying which features of $\\X$ play a role in the prediction. We formalize this problem as that of finding a short code for $\\X$ that preserves the maximum information about $\\Y$. That is, we squeeze the information that $\\X$ provides about $\\Y$ through a `bottleneck' formed by a limited set of codewords $\\tX$. This constrained optimization problem can be seen as a generalization of rate distortion theory in which the distortion measure $d(x,\\x)$ emerges from the joint statistics of $\\X$ and $\\Y$. This approach yields an exact set of self consistent equations for the coding rules $X \\to \\tX$ and $\\tX \\to \\Y$. Solutions to these equations can be found by a convergent re-estimation method that generalizes the Blahut-Arimoto algorithm. Our variational principle provides a surprisingly rich framework for discussing a variety of problems in signal processing and learning, as will be described in detail elsewhere.|sl:tag|tag:information_bottleneck_method
Anaconda|skos:broader|Python 4 Data science
SPARQL en javascript|skos:broader|JavaScript
Artificial Intelligence|skos:broader|Informatique
Uberisation|skos:broader|Uber
ADN mitochondrial|skos:broader|ADN
Zombie PCs|skos:broader|Cybersecurity Sécurité informatique
Alphago|skos:broader|Google
Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale  study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude.   Snorkel DryBell, a new weak supervision management system for this setting.    [Blog post](/doc/2019/06/google_ai_blog_harnessing_orga) Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes.|sl:arxiv_firstAuthor|Stephen H. Bach
Intent classification and slot filling|skos:broader|Intent detection
Serbie|skos:broader|Yougoslavie Ex Yougoslavie
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:arxiv_author|Rohun Saxena
Amérique latine|skos:broader|Amérique
Graph Convolutional Networks (GCNs) strike a balance between modeling the full structure of the  graph dynamically, as the tensor model does, and modeling the local neighbourhood structure through  extracted features (as substructure counting methods and RDF2Vec do). ([source](/doc/2019/08/the_knowledge_graph_as_the_defa))  |skos:broader|Feed-forward artificial neural network where the individual neurons are tiled in such a way that they respond to overlapping regions in the visual field. CNN use convolutions over the input layer to compute the output. Widely used models for image and video recognition.    Main assumption: Data are compositional, they are formed of patterns that are:    - Local  - Stationary  - Multi-scale (hierarchical)    ConvNets leverage the compositionality structure: They extract compositional features and feed them to classifier, recommender, etc (end-to-end).
Automotive and web technologies|skos:broader|Automobile
Equitation|skos:broader|Cheval
France / Afrique|skos:broader|Afrique francophone
SPARQL: sample code|skos:broader|Sample code
iphone app|skos:broader|iphone
Scandale des écoutes en Allemagne|skos:broader|NSA spying scandal
Developer documentation|skos:broader|Documentation
CoKE: Contextualized Knowledge Graph Embedding A method to build contextualized entity and relation embeddings. Entities and relations may appear in different graph contexts. Edges and paths, both formulated as sequences of entities and relations, are passed as input to a Transformer encoder to learn the contextualized representations..    [Github](https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE) Knowledge graph embedding, which projects symbolic entities and relations into continuous vector spaces, is gaining increasing attention. Previous methods allow a single static embedding for each entity or relation, ignoring their intrinsic contextual nature, i.e., entities and relations may appear in different graph contexts, and accordingly, exhibit different properties. This work presents Contextualized Knowledge Graph Embedding (CoKE), a novel paradigm that takes into account such contextual nature, and learns dynamic, flexible, and fully contextualized entity and relation embeddings. Two types of graph contexts are studied: edges and paths, both formulated as sequences of entities and relations. CoKE takes a sequence as input and uses a Transformer encoder to obtain contextualized representations. These representations are hence naturally adaptive to the input, capturing contextual meanings of entities and relations therein. Evaluation on a wide variety of public benchmarks verifies the superiority of CoKE in link prediction and path query answering. It performs consistently better than, or at least equally well as current state-of-the-art in almost every case, in particular offering an absolute improvement of 21.0% in H@10 on path query answering. Our code is available at \\url{https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE}.|sl:tag|tag:arxiv_doc
Language Models as Knowledge Bases? an analysis of the relational knowledge present in pretrained language models shows an ability of these models to recall factual knowledge  Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as fill-in-the-blank cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.|sl:tag|tag:knowledge_graph_deep_learning
Wikidata/RDF|skos:broader|RDF
LDA2vec|skos:broader|Word embeddings
Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation   An embedding method specifically designed for NED that jointly maps words and entities into the same continuous vector space.    We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words Named Entity Disambiguation (NED) refers to the task of resolving multiple named entity mentions in a document to their correct references in a knowledge base (KB) (e.g., Wikipedia). In this paper, we propose a novel embedding method specifically designed for NED. The proposed method jointly maps words and entities into the same continuous vector space. We extend the skip-gram model by using two models. The KB graph model learns the relatedness of entities using the link structure of the KB, whereas the anchor context model aims to align vectors such that similar words and entities occur close to one another in the vector space by leveraging KB anchors and their context words. By combining contexts based on the proposed embedding with standard NED features, we achieved state-of-the-art accuracy of 93.1% on the standard CoNLL dataset and 85.2% on the TAC 2010 dataset.|sl:tag|tag:arxiv_doc
Unifying distillation and privileged information A framework to learn from multiple machines and data representations, unifying two techniques that enable machines to learn from other machines: [distillation](tag:knowledge_distillation) ([Hinton et al., 2015](doc:2020/04/1503_02531_distilling_the_kno)) and privileged information (Vapnik & Izmailov, 2015)   Distillation (Hinton et al., 2015) and privileged information (Vapnik & Izmailov, 2015) are two techniques that enable machines to learn from other machines. This paper unifies these two techniques into generalized distillation, a framework to learn from multiple machines and data representations. We provide theoretical and causal insight about the inner workings of generalized distillation, extend it to unsupervised, semisupervised and multitask learning scenarios, and illustrate its efficacy on a variety of numerical simulations on both synthetic and real-world data.|sl:tag|tag:machines_teaching_machines
Islamisme|skos:broader|Islam
rdfQuery|skos:broader|RDFa tool
Label-Embedding for Image Classification Attributes act as intermediate representations that enable parameter sharing between classes, a must when training data is scarce. We propose to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors. We introduce a function that measures the compatibility between an image and a label embedding. The parameters of this function are learned on a training set of labeled samples to ensure that, given an image, the correct classes rank higher than the incorrect ones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasets show that the proposed framework outperforms the standard Direct Attribute Prediction baseline in a zero-shot learning scenario. Label embedding enjoys a built-in ability to leverage alternative sources of information instead of or in addition to attributes, such as e.g. class hierarchies or textual descriptions. Moreover, label embedding encompasses the whole range of learning settings from zero-shot learning to regular learning with a large number of labeled examples.|sl:tag|tag:arxiv_doc
ULMFiT|skos:broader|Contextualized word representations
Massacre de la Saint-Barthélemy|skos:broader|Crimes de l'église catholique
Jure Leskovec|skos:broader|AI girls and guys
Word Representations via Gaussian Embedding  Current work in lexical distributed representations maps each word to a point vector in low-dimensional space. Mapping instead to a density provides many interesting advantages     Novel word embedding algorithms that embed words directly as Gaussian distributional potential functions in an infinite dimensional function space. This allows us to map word types not only to vectors but to soft regions in space, modeling uncertainty, inclusion, and entailment, as well as providing a rich geometry of the latent space. Current work in lexical distributed representations maps each word to a point vector in low-dimensional space. Mapping instead to a density provides many interesting advantages, including better capturing uncertainty about a representation and its relationships, expressing asymmetries more naturally than dot product or cosine similarity, and enabling more expressive parameterization of decision boundaries. This paper advocates for density-based distributed embeddings and presents a method for learning representations in the space of Gaussian distributions. We compare performance on various word embedding benchmarks, investigate the ability of these embeddings to model entailment and other asymmetric relationships, and explore novel properties of the representation.|sl:tag|tag:gaussian_embedding
Çatalhöyük|skos:broader|Archéologie
Document embeddings|skos:broader|Embeddings in NLP
Juifs|skos:broader|Peuples
INRIA|skos:broader|Informatique
Efficient Estimation of Word Representations in Vector Space We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.   We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.|sl:arxiv_author|Kai Chen
Frederick Giasson|skos:broader|Technical girls and guys
Productivité|skos:broader|Economie
JSON-LD|skos:broader|Linked Data
Word embeddings|skos:broader|NN 4 NLP
Semencier|skos:broader|Agriculture industrielle
Eau|skos:broader|Grands problèmes
Gates|skos:broader|Technical guys
Hongrie|skos:broader|Europe
Ruby on Rails|skos:broader|Ruby
Java in python|skos:broader|Python
What Does BERT Look At? An Analysis of BERT's Attention Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT's attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT's attention.|sl:arxiv_author|Urvashi Khandelwal
Sparse dictionary learning|skos:broader|Representation learning
GAN|skos:broader|Unsupervised machine learning
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:arxiv_author|Thomas Dean
Niger : pétrole|skos:broader|Niger
APIs and Linked Data|skos:broader|API
Vietnam|skos:broader|Asie
M3 Multi Media Museum|skos:broader|Musée
Libération|skos:broader|Liberté
Bosnie|skos:broader|Yougoslavie Ex Yougoslavie
Parenté à plaisanterie|skos:broader|Rigolo
Neo-fascites|skos:broader|Fascisme
Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data Word embeddings are a popular approach to unsupervised learning of word relationships that are widely used in natural language processing. In this article, we present a new set of embeddings for medical concepts learned using an extremely large collection of multimodal medical data. Leaning on recent theoretical insights, we demonstrate how an insurance claims database of 60 million members, a collection of 20 million clinical notes, and 1.7 million full text biomedical journal articles can be combined to embed concepts into a common space, resulting in the largest ever set of embeddings for 108,477 medical concepts. To evaluate our approach, we present a new benchmark methodology based on statistical power specifically designed to test embeddings of medical concepts. Our approach, called cui2vec, attains state-of-the-art performance relative to previous methods in most instances. Finally, we provide a downloadable set of pre-trained embeddings for other researchers to use, as well as an online tool for interactive exploration of the cui2vec embeddings|sl:arxiv_author|Benjamin Kompa
SproutCore|skos:broader|JavaScript librairies
Toyota|skos:broader|Entreprise
Intellectuel|skos:broader|Penseur
Ruby|skos:broader|Programming language
Ténéré|skos:broader|Sahara
Embeddings in Information Retrieval|skos:broader|Information retrieval
Active learning|skos:broader|Machine learning: techniques
Massively multiplayer online games|skos:broader|Jeux en ligne
Jeremy Howard|skos:broader|AI girls and guys
Universal Language Model Fine-tuning for Text Classification code is available in the fastai lib    [blog post](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html)    [see also](/doc/?uri=https%3A%2F%2Fyashuseth.blog%2F2018%2F06%2F17%2Funderstanding-universal-language-model-fine-tuning-ulmfit%2F)             Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.|sl:tag|tag:arxiv_doc
Artiste|skos:broader|Art
Explainable NLP|skos:broader|Deep NLP
Do Deep Nets Really Need to be Deep? Currently, deep neural networks are the state of the art on problems such as speech recognition and computer vision. In this extended abstract, we show that shallow feed-forward networks can learn the complex functions previously learned by deep nets and achieve accuracies previously only achievable with deep models. Moreover, in some cases the shallow neural nets can learn these deep functions using a total number of parameters similar to the original deep model. We evaluate our method on the TIMIT phoneme recognition task and are able to train shallow fully-connected nets that perform similarly to complex, well-engineered, deep convolutional architectures. Our success in training shallow neural nets to mimic deeper models suggests that there probably exist better algorithms for training shallow feed-forward nets than those currently available.|sl:arxiv_author|Rich Caruana
foaf+ssl|skos:broader|foaf
End-To-End Entity Linking|skos:broader|Entity linking
Locality-sensitive hashing (LSH) reduces the dimensionality of high-dimensional data. LSH hashes input items so that similar items map to the same “buckets” with high probability (the number of buckets being much smaller than the number of possible input items). LSH has much in common with data clustering and [#nearest neighbor search](nearest_neighbor_search).    LSH employs random linear projections (followed by random thresholding) to map data points close in an Euclidean space to similar codes.    See Also [#sparse distributed memory](/tag/sparse_distributed_memory), associative memory              |skos:broader|Finding items that are similar to a given query is the core  aspect of search and retrieval systems, as well as of  recommendation engines.
Alistair Miles|skos:broader|SW guys (and girls)
supervised learning models used for classification and regression analysis.    An SVM model is a representation of the training examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible.    Non-probabilistic binary linear classifier (some methods exist to use SVM in a probabilistic classification setting). Can be made non-linear with the kernel trick (implicitly mapping the inputs into high-dimensional feature spaces.)        |skos:broader|the machine learning task of inferring a function from labeled training data.
KG-BERT: BERT for Knowledge Graph Completion Pre-trained language models for knowledge graph completion. Triples are treated as textual sequences. (Hum, j'ai déjà vu ça quelque part) Knowledge graphs are important resources for many artificial intelligence tasks but often suffer from incompleteness. In this work, we propose to use pre-trained language models for knowledge graph completion. We treat triples in knowledge graphs as textual sequences and propose a novel framework named Knowledge Graph Bidirectional Encoder Representations from Transformer (KG-BERT) to model these triples. Our method takes entity and relation descriptions of a triple as input and computes scoring function of the triple with the KG-BERT language model. Experimental results on multiple benchmark knowledge graphs show that our method can achieve state-of-the-art performance in triple classification, link prediction and relation prediction tasks.|sl:tag|tag:bert
Antimilitarisme|skos:broader|Militaire
Beethoven|skos:broader|Musicien
Bayesian classification|skos:broader|Machine learning: techniques
Crète antique|skos:broader|Grèce
Hackers|skos:broader|Informatique
Knowledge Engineering|skos:broader|Knowledge
Antonin Artaud|skos:broader|Ecrivain
Héctor Lavoe|skos:broader|Salsa
Restaurant|skos:broader|Gastronomie
VirtualBox|skos:broader|Oracle
Pubby|skos:broader|Chris Bizer
Differentiable Top-k Operator with Optimal Transport  if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator   ...   We apply the proposed operator to the [k-nearest neighbors](tag:k_nearest_neighbors_algorithm) and [beam search](tag:beam_search) algorithms, and demonstrate improved performance The top-k operation, i.e., finding the k largest or smallest elements from a collection of scores, is an important model component, which is widely used in information retrieval, machine learning, and data mining. However, if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator. Specifically, our SOFT top-k operator approximates the output of the top-k operation as the solution of an Entropic Optimal Transport (EOT) problem. The gradient of the SOFT operator can then be efficiently approximated based on the optimality conditions of EOT problem. We apply the proposed operator to the k-nearest neighbors and beam search algorithms, and demonstrate improved performance.|sl:arxiv_author|Hongyuan Zha
Nick Clegg|skos:broader|Homme politique
Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs [GitHub](https://github.com/deepakn97/relationPrediction) [Blog post](/doc/2020/04/deepak_nathani_%7C_pay_attention_) The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention based feature embedding that captures both entity and relation features in any given entity's neighborhood. Additionally, we also encapsulate relation clusters and multihop relations in our model. Our empirical study offers insights into the efficacy of our attention based model and we show marked performance gains in comparison to state of the art methods on all datasets.|sl:arxiv_firstAuthor|Deepak Nathani
A Dual Embedding Space Model for Document Ranking Investigate neural word embeddings as a source of evidence in document ranking.    Presented in [this Stanford course on IR](/doc/?uri=https%3A%2F%2Fweb.stanford.edu%2Fclass%2Fcs276%2Fhandouts%2Flecture20-distributed-representations.pdf) by Chris Manning (starting slide 44)    They train a word2vec model, but retain both the input and the output projections.     During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs.      However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives A fundamental goal of search engines is to identify, given a query, documents that have relevant text. This is intrinsically difficult because the query and the document may use different vocabulary, or the document may contain query words without being relevant. We investigate neural word embeddings as a source of evidence in document ranking. We train a word2vec embedding model on a large unlabelled query corpus, but in contrast to how the model is commonly used, we retain both the input and the output projections, allowing us to leverage both the embedding spaces to derive richer distributional relationships. During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs. We postulate that the proposed Dual Embedding Space Model (DESM) captures evidence on whether a document is about a query term in addition to what is modelled by traditional term-frequency based approaches. Our experiments show that the DESM can re-rank top documents returned by a commercial Web search engine, like Bing, better than a term-matching based signal like TF-IDF. However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives, retrieving documents that are only loosely related to the query. We demonstrate that this problem can be solved effectively by ranking based on a linear mixture of the DESM and the word counting features.|sl:arxiv_author|Bhaskar Mitra
Continual Lifelong Learning with Neural Networks: A Review Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.|sl:arxiv_author|Christopher Kanan
Bruxelles|skos:broader|Belgique
A Survey on Knowledge Graph Embeddings with Literals: Which model links better Literal-ly? Knowledge Graphs (KGs) are composed of structured information about a particular domain in the form of entities and relations. In addition to the structured information KGs help in facilitating interconnectivity and interoperability between different resources represented in the Linked Data Cloud. KGs have been used in a variety of applications such as entity linking, question answering, recommender systems, etc. However, KG applications suffer from high computational and storage costs. Hence, there arises the necessity for a representation able to map the high dimensional KGs into low dimensional spaces, i.e., embedding space, preserving structural as well as relational information. This paper conducts a survey of KG embedding models which not only consider the structured information contained in the form of entities and relations in a KG but also the unstructured information represented as literals such as text, numerical values, images, etc. Along with a theoretical analysis and comparison of the methods proposed so far for generating KG embeddings with literals, an empirical evaluation of the different methods under identical settings has been performed for the general task of link prediction.|sl:arxiv_author|Mehwish Alam
Elevage porcin|skos:broader|Porc
Minting URIs|skos:broader|URI
OpenStructs|skos:broader|Frederick Giasson
W3C|skos:broader|Technologie
Mixture distribution|skos:broader|Statistics
Attention Is All You Need  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.|sl:tag|tag:arxiv_doc
Backpropagation vs Biology|skos:broader|Computational Neuroscience
Comète|skos:broader|Astéroïde
Mésopotamie|skos:broader|Irak
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Vinicius Zambaldi
Machine Learning + Semantic Web|skos:broader|Knowledge Graphs
\Why Should I Trust You?\: Explaining the Predictions of Any Classifier technique that explains the predictions of any classifier by learning an interpretable model locally around the prediction Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.|sl:arxiv_firstAuthor|Marco Tulio Ribeiro
L'Afrique à la Bastille - 13 juillet 2007|skos:broader|14 juillet
Bidirectional LSTM-CRF Models for Sequence Tagging In this paper, we propose a variety of Long Short-Term Memory (LSTM) based models for sequence tagging. These models include LSTM networks, bidirectional LSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer (LSTM-CRF) and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work is the first to apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model to NLP benchmark sequence tagging data sets. We show that the BI-LSTM-CRF model can efficiently use both past and future input features thanks to a bidirectional LSTM component. It can also use sentence level tag information thanks to a CRF layer. The BI-LSTM-CRF model can produce state of the art (or close to) accuracy on POS, chunking and NER data sets. In addition, it is robust and has less dependence on word embedding as compared to previous observations.|sl:tag|tag:bi_lstm
Yougoslavie Ex Yougoslavie|skos:broader|Europe
Internet regulation|skos:broader|Internet
La Ronde de Nuit|skos:broader|Rembrandt
An efficient framework for learning sentence representations Quick Thoughts. Framework for learning sentence representations from unlabelled data.     we reformulate the problem of predicting the context in which a sentence appears as a classification problem.   In this work we propose a simple and efficient framework for learning sentence representations from unlabelled data. Drawing inspiration from the distributional hypothesis and recent work on learning sentence representations, we reformulate the problem of predicting the context in which a sentence appears as a classification problem. Given a sentence and its context, a classifier distinguishes context sentences from other contrastive sentences based on their vector representations. This allows us to efficiently learn different types of encoding functions, and we show that the model learns high-quality sentence representations. We demonstrate that our sentence representations outperform state-of-the-art unsupervised and supervised representation learning methods on several downstream NLP tasks that involve understanding sentence semantics while achieving an order of magnitude speedup in training time.|sl:arxiv_author|Honglak Lee
Machine Learning: business|skos:broader|Machine learning
Elda|skos:broader|Jena
Croissance|skos:broader|Economie
Pillage du palais d'été|skos:broader|Histoire coloniale
data labeling is usually the bottleneck in developing NLP applications. Pbs of shifting contexts on social networks|skos:broader|the bottleneck of getting labeled training data
Financial Data|skos:broader|Finance
Learning with Memory Embeddings Embedding learning, a.k.a. representation learning, has been shown to be able to model large-scale semantic knowledge graphs. A key concept is a mapping of the knowledge graph to a tensor representation whose entries are predicted by models using latent representations of generalized entities. Latent variable models are well suited to deal with the high dimensionality and sparsity of typical knowledge graphs. In recent publications the embedding models were extended to also consider time evolutions, time patterns and subsymbolic representations. In this paper we map embedding models, which were developed purely as solutions to technical problems for modelling temporal knowledge graphs, to various cognitive memory functions, in particular to semantic and concept memory, episodic memory, sensory memory, short-term memory, and working memory. We discuss learning, query answering, the path from sensory input to semantic decoding, and the relationship between episodic memory and semantic memory. We introduce a number of hypotheses on human memory that can be derived from the developed mathematical models.|sl:arxiv_author|Cristóbal Esteban
Weapon of mass distraction|skos:broader|The web sucks
Attention in Graphs|skos:broader|Attention mechanism
Dosso|skos:broader|Jerma
Extracting Tables from Documents using Conditional Generative Adversarial Networks and Genetic Algorithms Extracting information from tables in documents presents a significant challenge in many industries and in academic research. Existing methods which take a bottom-up approach of integrating lines into cells and rows or columns neglect the available prior information relating to table structure. Our proposed method takes a top-down approach, first using a generative adversarial network to map a table image into a standardised `skeleton' table form denoting the approximate row and column borders without table content, then fitting renderings of candidate latent table structures to the skeleton structure using a distance measure optimised by a genetic algorithm.|sl:tag|tag:pdf_extract
Vénus|skos:broader|Système solaire
Java 7|skos:broader|Java
Animal rights|skos:broader|Animal
The Description Length of Deep Learning Models  Solomonoff’s general theory of inference (Solomonoff, 1964) and the [Minimum Description Length Principle](tag:minimum_description_length_principle) (Grünwald, 2007; Rissanen, 2007) formalize [Occam's razor](tag:occam_s_razor), and hold that a good model of data is a model that is good at losslessly  compressing the data, including the cost of describing the model itself. Deep neural  networks might seem to go against this principle given the large number of  parameters to be encoded.  We demonstrate experimentally the ability of deep neural networks to compress  the training data even when accounting for parameter encoding. Solomonoff's general theory of inference and the Minimum Description Length principle formalize Occam's razor, and hold that a good model of data is a model that is good at losslessly compressing the data, including the cost of describing the model itself. Deep neural networks might seem to go against this principle given the large number of parameters to be encoded. We demonstrate experimentally the ability of deep neural networks to compress the training data even when accounting for parameter encoding. The compression viewpoint originally motivated the use of variational methods in neural networks. Unexpectedly, we found that these variational methods provide surprisingly poor compression bounds, despite being explicitly built to minimize such bounds. This might explain the relatively poor practical performance of variational methods in deep learning. On the other hand, simple incremental encoding methods yield excellent compression values on deep networks, vindicating Solomonoff's approach.|sl:tag|tag:dl_why_does_it_work
Economie de la gratuité|skos:broader|Economie
Climate crisis|skos:broader|Grands problèmes
KBPedia|skos:broader|Frederick Giasson
Keep new|skos:broader|To do
Graph Convolution for Multimodal Information Extraction from Visually Rich Documents Visually rich documents (VRDs) are ubiquitous in daily business and life. Examples are purchase receipts, insurance policy documents, custom declaration forms and so on. In VRDs, visual and layout information is critical for document understanding, and texts in such documents cannot be serialized into the one-dimensional sequence without losing information. Classic information extraction models such as BiLSTM-CRF typically operate on text sequences and do not incorporate visual features. In this paper, we introduce a graph convolution based model to combine textual and visual information presented in VRDs. Graph embeddings are trained to summarize the context of a text segment in the document, and further combined with text embeddings for entity extraction. Extensive experiments have been conducted to show that our method outperforms BiLSTM-CRF baselines by significant margins, on two real-world datasets. Additionally, ablation studies are also performed to evaluate the effectiveness of each component of our model.|sl:tag|tag:visually_rich_documents
Personal archives|skos:broader|Personal-information management
Djibouti|skos:broader|Afrique de l'Est
Coursera: Deep Learning|skos:broader|Machine Learning Course
Janis Joplin|skos:broader|Musicien
Cassandra|skos:broader|apache.org
Meta Reinforcement Learning|skos:broader|Reinforcement learning
OS X Unix|skos:broader|Unix
ELMo|skos:broader|Deep NLP
Cross-Modal Retrieval|skos:broader|Information retrieval
A Dual Embedding Space Model for Document Ranking Investigate neural word embeddings as a source of evidence in document ranking.    Presented in [this Stanford course on IR](/doc/?uri=https%3A%2F%2Fweb.stanford.edu%2Fclass%2Fcs276%2Fhandouts%2Flecture20-distributed-representations.pdf) by Chris Manning (starting slide 44)    They train a word2vec model, but retain both the input and the output projections.     During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs.      However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives A fundamental goal of search engines is to identify, given a query, documents that have relevant text. This is intrinsically difficult because the query and the document may use different vocabulary, or the document may contain query words without being relevant. We investigate neural word embeddings as a source of evidence in document ranking. We train a word2vec embedding model on a large unlabelled query corpus, but in contrast to how the model is commonly used, we retain both the input and the output projections, allowing us to leverage both the embedding spaces to derive richer distributional relationships. During ranking we map the query words into the input space and the document words into the output space, and compute a query-document relevance score by aggregating the cosine similarities across all the query-document word pairs. We postulate that the proposed Dual Embedding Space Model (DESM) captures evidence on whether a document is about a query term in addition to what is modelled by traditional term-frequency based approaches. Our experiments show that the DESM can re-rank top documents returned by a commercial Web search engine, like Bing, better than a term-matching based signal like TF-IDF. However, when ranking a larger set of candidate documents, we find the embeddings-based approach is prone to false positives, retrieving documents that are only loosely related to the query. We demonstrate that this problem can be solved effectively by ranking based on a linear mixture of the DESM and the word counting features.|sl:arxiv_author|Eric Nalisnick
Champignon|skos:broader|Biology
Pubby|skos:broader|Richard Cyganiak
Archéologie européenne|skos:broader|Archéologie
Mission \Voulet-Chanoine\|skos:broader|Horreur
VOAF|skos:broader|RDF Vocabularies
danbri|skos:broader|Web sémantique sw
Stanford POS Tagger|skos:broader|Part Of Speech Tagging
Word Representations via Gaussian Embedding  Current work in lexical distributed representations maps each word to a point vector in low-dimensional space. Mapping instead to a density provides many interesting advantages     Novel word embedding algorithms that embed words directly as Gaussian distributional potential functions in an infinite dimensional function space. This allows us to map word types not only to vectors but to soft regions in space, modeling uncertainty, inclusion, and entailment, as well as providing a rich geometry of the latent space. Current work in lexical distributed representations maps each word to a point vector in low-dimensional space. Mapping instead to a density provides many interesting advantages, including better capturing uncertainty about a representation and its relationships, expressing asymmetries more naturally than dot product or cosine similarity, and enabling more expressive parameterization of decision boundaries. This paper advocates for density-based distributed embeddings and presents a method for learning representations in the space of Gaussian distributions. We compare performance on various word embedding benchmarks, investigate the ability of these embeddings to model entailment and other asymmetric relationships, and explore novel properties of the representation.|sl:arxiv_firstAuthor|Luke Vilnis
TextBlob|skos:broader|NLTK
Longformer: The Long-Document Transformer  Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Following prior work on long-sequence transformers, we evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8. In contrast to most prior work, we also pretrain Longformer and finetune it on a variety of downstream tasks. Our pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA.|sl:tag|tag:allen_institute_for_ai_a2i
Talis platform|skos:broader|Talis
hyperdoc2vec: Distributed Representations of Hypertext Documents Hypertext documents, such as web pages and academic papers, are of great importance in delivering information in our daily life. Although being effective on plain documents, conventional text embedding methods suffer from information loss if directly adapted to hyper-documents. In this paper, we propose a general embedding approach for hyper-documents, namely, hyperdoc2vec, along with four criteria characterizing necessary information that hyper-document embedding models should preserve. Systematic comparisons are conducted between hyperdoc2vec and several competitors on two tasks, i.e., paper classification and citation recommendation, in the academic paper domain. Analyses and experiments both validate the superiority of hyperdoc2vec to other models w.r.t. the four criteria.|sl:arxiv_author|Haisong Zhang
Microsoft Concept Graph|skos:broader|Microsoft Research
M3 Multi Media Museum|skos:broader|hyperSOLutions
La main à la pâte|skos:broader|Education
SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver Integrating logical reasoning within deep learning architectures has been a major goal of modern AI systems. In this paper, we propose a new direction toward this goal by introducing a differentiable (smoothed) maximum satisfiability (MAXSAT) solver that can be integrated into the loop of larger deep learning systems. Our (approximate) solver is based upon a fast coordinate descent approach to solving the semidefinite program (SDP) associated with the MAXSAT problem. We show how to analytically differentiate through the solution to this SDP and efficiently solve the associated backward pass. We demonstrate that by integrating this solver into end-to-end learning systems, we can learn the logical structure of challenging problems in a minimally supervised fashion. In particular, we show that we can learn the parity function using single-bit supervision (a traditionally hard task for deep networks) and learn how to play 9x9 Sudoku solely from examples. We also solve a visual Sudok problem that maps images of Sudoku puzzles to their associated logical solutions by combining our MAXSAT solver with a traditional convolutional architecture. Our approach thus shows promise in integrating logical structures within deep learning.|sl:arxiv_author|Zico Kolter
Learning by Abstraction: The Neural State Machine  Given an image, we first predict a probabilistic graph  that represents its underlying semantics and serves as a structured world model.  Then, we perform sequential reasoning over the graph, iteratively traversing its  nodes to answer a given question or draw a new inference. In contrast to most  neural architectures that are designed to closely interact with the raw sensory  data, our model operates instead in an abstract latent space, by transforming both  the visual and linguistic modalities into semantic concept-based representations,  thereby achieving enhanced transparency and modularity.     Drawing inspiration from [Bengio’s consciousness prior](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1709.08568)... We introduce the Neural State Machine, seeking to bridge the gap between the neural and symbolic views of AI and integrate their complementary strengths for the task of visual reasoning. Given an image, we first predict a probabilistic graph that represents its underlying semantics and serves as a structured world model. Then, we perform sequential reasoning over the graph, iteratively traversing its nodes to answer a given question or draw a new inference. In contrast to most neural architectures that are designed to closely interact with the raw sensory data, our model operates instead in an abstract latent space, by transforming both the visual and linguistic modalities into semantic concept-based representations, thereby achieving enhanced transparency and modularity. We evaluate our model on VQA-CP and GQA, two recent VQA datasets that involve compositionality, multi-step inference and diverse reasoning skills, achieving state-of-the-art results in both cases. We provide further experiments that illustrate the model's strong generalization capacity across multiple dimensions, including novel compositions of concepts, changes in the answer distribution, and unseen linguistic structures, demonstrating the qualities and efficacy of our approach.|sl:tag|tag:consciousness_prior
Prohibition des narcotiques|skos:broader|Drogues
Sarkozy et la recherche|skos:broader|Recherche française
Origine de la vie|skos:broader|Evolution
Microsoft Concept Graph|skos:broader|NLU
Moussa Poussi|skos:broader|Musicien
Linked Data API|skos:broader|Linked Data
RDF Tools|skos:broader|Semantic Web : Tools
Training data|skos:broader|Machine learning
OwlSight|skos:broader|OWL ontology browser
GNU Octave|skos:broader|Programming language
Vaccin|skos:broader|Médecine
A Survey on Deep Learning for Named Entity Recognition mainly focus on generic NEs in English language Named entity recognition (NER) is the task to identify mentions of rigid designators from text belonging to predefined semantic types such as person, location, organization etc. NER always serves as the foundation for many natural language applications such as question answering, text summarization, and machine translation. Early NER systems got a huge success in achieving good performance with the cost of human engineering in designing domain-specific features and rules. In recent years, deep learning, empowered by continuous real-valued vector representations and semantic composition through nonlinear processing, has been employed in NER systems, yielding stat-of-the-art performance. In this paper, we provide a comprehensive review on existing deep learning techniques for NER. We first introduce NER resources, including tagged NER corpora and off-the-shelf NER tools. Then, we systematically categorize existing works based on a taxonomy along three axes: distributed representations for input, context encoder, and tag decoder. Next, we survey the most representative methods for recent applied techniques of deep learning in new NER problem settings and applications. Finally, we present readers with the challenges faced by NER systems and outline future directions in this area.|sl:tag|tag:named_entity_recognition
Brain|skos:broader|Biology
BigQuery|skos:broader|Google Cloud
A Review of Relational Machine Learning for Knowledge Graphs Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be trained on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive datasets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Google's Knowledge Vault project as an example of such combination.|sl:arxiv_firstAuthor|Maximilian Nickel
Tabulator|skos:broader|AJAR
Tagging|skos:broader|Semanlink related
A Primer on Neural Network Models for Natural Language Processing Over the past few years, neural networks have re-emerged as powerful machine-learning models, yielding state-of-the-art results in fields such as image recognition and speech processing. More recently, neural network models started to be applied also to textual natural language signals, again with very promising results. This tutorial surveys neural network models from the perspective of natural language processing research, in an attempt to bring natural-language researchers up to speed with the neural techniques. The tutorial covers input encoding for natural language tasks, feed-forward networks, convolutional networks, recurrent networks and recursive networks, as well as the computation graph abstraction for automatic gradient computation.|sl:tag|tag:arxiv_doc
Biodiversité : effondrement|skos:broader|Crise écologique
A system for rapidly creating training sets with weak supervision     The System for Programmatically Building and Managing Training Data|skos:broader|Noisy, limited, or imprecise sources are used to provide supervision signal for labeling large amounts of training data in a supervised learning setting    Programmatic or otherwise more efficient but noisier ways of generating training label  
JSON Visualization|skos:broader|JSON
Ontologies|skos:broader|Knowledge Representation
Débarquement|skos:broader|2eme guerre mondiale
Verts|skos:broader|Politique
FIBO|skos:broader|Ontologies
Slot tagging|skos:broader|Chatbots
Chirac|skos:broader|Homme politique
La France est un pays régicide|skos:broader|France
RapidMiner/Java|skos:broader|RapidMiner
CNN 4 NLP|skos:broader|NN 4 NLP
Semantic Media Wiki|skos:broader|Semantic Wiki
Siri|skos:broader|Apple Software
Span Selection Pre-training for Question Answering  a new pre-training task inspired by reading  comprehension and an effort to avoid encoding general knowledge in the transformer network itself    Current transformer architectures store general knowledge - large models, long pre-training time. Better to offload the requirement of general knowledge to a sparsely activated network.    Span selection as an additional auxiliary task: the query is a sentence drawn from a corpus  with a term replaced with a special token: [BLANK]. The term replaced by the blank is the answer term. The passage is  relevant as determined by a BM25 search, and answer-bearing (containing the answer  term). Unlike BERT’s cloze task, where the answer must be drawn from the model itself, the answer is found in a passage  using language understanding.     We hope to progress to a model of general purpose language modeling that uses an indexed long  term memory to retrieve world knowledge, rather than holding it in the densely activated transformer encoder layers. BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pre-trained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension and an effort to avoid encoding general knowledge in the transformer network itself. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple reading comprehension (MRC) and paraphrasing datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also establish a new SOTA in HotpotQA, improving answer prediction F1 by 4 F1 points and supporting fact prediction by 1 F1 point. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.|sl:tag|tag:arxiv_doc
Explainable NLP|skos:broader|Explainable AI
Visualizing and Measuring the Geometry of BERT  At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.|sl:arxiv_author|Adam Pearce
FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence [github](https://github.com/google-research/fixmatch)     we demonstrate the power of a  simple combination of two common Semi-Supervised Learning methods: consistency  regularization and pseudo-labeling.    1. First generates pseudo-labels using the model’s  predictions on weakly-augmented unlabeled images. For a  given image, the pseudo-label is only retained if the model  produces a high-confidence prediction.   2. The model is then  trained to predict the pseudo-label when fed a strongly augmented  version of the same image. Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. In this paper, we demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling. Our algorithm, FixMatch, first generates pseudo-labels using the model's predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just 4 labels per class. Since FixMatch bears many similarities to existing SSL methods that achieve worse performance, we carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. We make our code available at https://github.com/google-research/fixmatch.|sl:arxiv_author|Ekin D. Cubuk
OntoWiki|skos:broader|Semantic Web : Tools
Unsupervised deep pre-training|skos:broader|Pretrained models
A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efficient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximally preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We first introduce the formal definition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work address these challenges in their solutions. Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efficiency, problem settings, techniques and application scenarios.|sl:arxiv_author|Hongyun Cai
Mac software|skos:broader|Software
Topic Models + Word embedding|skos:broader|Word embeddings
AutoML-Zero: Evolving Machine Learning Algorithms From Scratch  Fun AutoML-Zero experiments: Evolutionary search discovers fundamental ML algorithms from scratch, e.g., small neural nets with backprop.   Can evolution be the “Master Algorithm”? ;) Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.|sl:tag|tag:arxiv_doc
Devices|skos:broader|Informatique
Darfour|skos:broader|Génocide
Angela Merkel|skos:broader|Chef d'état
Barcamp|skos:broader|Event
Job title normalization|skos:broader|NLP + Human Resources
Wikileaks|skos:broader|Leaks
Syngenta|skos:broader|Suisse
Weak supervision|skos:broader|Machine learning: techniques
ARQ property functions|skos:broader|ARQ
Future Combat Systems|skos:broader|Armement
Hadoop|skos:broader|apache.org
Boucle ferroviaire d’Afrique de l’Ouest|skos:broader|Bolloré
Differentiable Reasoning over a Virtual Knowledge Base  We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases.    [(Bhuwan Dhingra PhD Thesis)](doc:2020/07/end_to_end_learning_with_text_) We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. On HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking approach to retrieving the relevant passages required to answer a question. DrKIT is also very efficient, processing 10-100x more queries per second than existing multi-hop systems.|sl:tag|tag:multi_hop_reasonning
Variational Inference: A Review for Statisticians One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.|sl:tag|tag:survey
A Comprehensive Survey on Graph Neural Networks an overview of graph neural networks (GNNs) in data mining and machine learning fields Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.|sl:tag|tag:graph_neural_networks
Energie solaire|skos:broader|Energies renouvelables
Semanlink2|skos:broader|Semanlink
Distilling Structured Knowledge into Embeddings for Explainable and Accurate Recommendation distilling structured knowledge from a differentiable path-based recommendation model.     proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons Recently, the embedding-based recommendation models (e.g., matrix factorization and deep models) have been prevalent in both academia and industry due to their effectiveness and flexibility. However, they also have such intrinsic limitations as lacking explainability and suffering from data sparsity. In this paper, we propose an end-to-end joint learning framework to get around these limitations without introducing any extra overhead by distilling structured knowledge from a differentiable path-based recommendation model. Through extensive experiments, we show that our proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons.|sl:tag|tag:recommender_systems
Masse manquante|skos:broader|Enigmes de la physique
End-To-End Memory Networks Neural network with a recurrent attention model over a possibly large external memory.    cité par [#A. Bordes](/tag/antoine_bordes) à [#ParisIsAI conf 2018](/tag/france_is_ai_2018.html) We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network (Weston et al., 2015) but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.|sl:arxiv_author|Arthur Szlam
The Consciousness Prior consciousness seen as the formation of a low-dimensional combination of a few concepts constituting a conscious thought, i.e., consciousness as awareness at a particular time instant: the projection of a big vector (all the things conscious and unconscious in brain). Attention: additional mechanism describing what mind chooses to focus on.    [YouTube video](/doc/?uri=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYr1mOzC93xs) A new prior is proposed for learning representations of high-level concepts of the kind we manipulate with language. This prior can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by cognitive neuroscience theories of consciousness, seen as a bottleneck through which just a few elements, after having been selected by attention from a broader pool, are then broadcast and condition further processing, both in perception and decision-making. The set of recently selected elements one becomes aware of is seen as forming a low-dimensional conscious state. This conscious state is combining the few concepts constituting a conscious thought, i.e., what one is immediately conscious of at a particular moment. We claim that this architectural and information-processing constraint corresponds to assumptions about the joint distribution between high-level concepts. To the extent that these assumptions are generally true (and the form of natural language seems consistent with them), they can form a useful prior for representation learning. A low-dimensional thought or conscious state is analogous to a sentence: it involves only a few variables and yet can make a statement with very high probability of being true. This is consistent with a joint distribution (over high-level concepts) which has the form of a sparse factor graph, i.e., where the dependencies captured by each factor of the factor graph involve only very few variables while creating a strong dip in the overall energy function. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in a form similar to facts and rules, albeit capturing uncertainty as well as efficient search mechanisms implemented by attention mechanisms.|sl:tag|tag:arxiv_doc
Cocteau|skos:broader|Poète
RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space  We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.|sl:arxiv_firstAuthor|Zhiqing Sun
Concept Bottleneck Models  We seek to learn models that we can interact with using high-level concepts... We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these concept bottleneck models by editing their predicted concept values and propagating these changes to the final prediction... These models allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time. We seek to learn models that we can interact with using high-level concepts: if the model did not think there was a bone spur in the x-ray, would it still predict severe arthritis? State-of-the-art models today do not typically support the manipulation of concepts like the existence of bone spurs, as they are trained end-to-end to go directly from raw input (e.g., pixels) to output (e.g., arthritis severity). We revisit the classic idea of first predicting concepts that are provided at training time, and then using these concepts to predict the label. By construction, we can intervene on these \\emph{concept bottleneck models} by editing their predicted concept values and propagating these changes to the final prediction. On x-ray grading and bird identification, concept bottleneck models achieve competitive accuracy with standard end-to-end models, while enabling interpretation in terms of high-level clinical concepts (bone spurs) or bird attributes (wing color). These models also allow for richer human-model interaction: accuracy improves significantly if we can correct model mistakes on concepts at test time.|sl:arxiv_firstAuthor|Pang Wei Koh
Installing WordPress|skos:broader|WordPress
NLP@IBM|skos:broader|NLP Teams
Censure et maltraitance animale|skos:broader|Censorship
Nuclear Power? No thanks|skos:broader|Industrie nucléaire
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Oriol Vinyals
Uncertainty Reasoning AND Semantic Web|skos:broader|Uncertainty Reasoning
Do Deep Nets Really Need to be Deep? Currently, deep neural networks are the state of the art on problems such as speech recognition and computer vision. In this extended abstract, we show that shallow feed-forward networks can learn the complex functions previously learned by deep nets and achieve accuracies previously only achievable with deep models. Moreover, in some cases the shallow neural nets can learn these deep functions using a total number of parameters similar to the original deep model. We evaluate our method on the TIMIT phoneme recognition task and are able to train shallow fully-connected nets that perform similarly to complex, well-engineered, deep convolutional architectures. Our success in training shallow neural nets to mimic deeper models suggests that there probably exist better algorithms for training shallow feed-forward nets than those currently available.|sl:arxiv_firstAuthor|Lei Jimmy Ba
Machine translation|skos:broader|Cross-lingual NLP
Recurrent neural network|skos:broader|Neural networks
Binary classification models with \Uncertain\ predictions Binary classification models which can assign probabilities to categories such as the tissue is 75% likely to be tumorous or the chemical is 25% likely to be toxic are well understood statistically, but their utility as an input to decision making is less well explored. We argue that users need to know which is the most probable outcome, how likely that is to be true and, in addition, whether the model is capable enough to provide an answer. It is the last case, where the potential outcomes of the model explicitly include don't know that is addressed in this paper. Including this outcome would better separate those predictions that can lead directly to a decision from those where more data is needed. Where models produce an Uncertain answer similar to a human reply of don't know or 50:50 in the examples we refer to earlier, this would translate to actions such as operate on tumour or remove compound from use where the models give a more true than not answer. Where the models judge the result Uncertain the practical decision might be carry out more detailed laboratory testing of compound or commission new tissue analyses. The paper presents several examples where we first analyse the effect of its introduction, then present a methodology for separating Uncertain from binary predictions and finally, we provide arguments for its use in practice.|sl:tag|tag:arxiv_doc
gensim|skos:broader|Python-NLP
JsonLD + MongoDB|skos:broader|JSON-LD
NN / Symbolic AI hybridation|skos:broader|Artificial Intelligence
The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives [blog post](http://www.semanlink.net/doc/2019/09/evolution_of_representations_in) We seek to understand how the representations of individual tokens and the structure of the learned feature space evolve between layers in deep neural networks under different learning objectives. We focus on the Transformers for our analysis as they have been shown effective on various tasks, including machine translation (MT), standard left-to-right language models (LM) and masked language modeling (MLM). Previous work used black-box probing tasks to show that the representations learned by the Transformer differ significantly depending on the objective. In this work, we use canonical correlation analysis and mutual information estimators to study how information flows across Transformer layers and how this process depends on the choice of learning objective. For example, as you go from bottom to top layers, information about the past in left-to-right language models gets vanished and predictions about the future get formed. In contrast, for MLM, representations initially acquire information about the context around the token, partially forgetting the token identity and producing a more generalized token representation. The token identity then gets recreated at the top MLM layers.|sl:arxiv_firstAuthor|Elena Voita
Denny Vrandečić|skos:broader|SW guys (and girls)
Livesearch|skos:broader|IHM web
Nasca|skos:broader|Civilisations précolombiennes
Apprentissage|skos:broader|Divers
Large Memory Layers with Product Keys  a structured memory which can be easily integrated into a neural network. The memory is very large by design and therefore significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time.     a key-value memory layer that can increase model capacity for a negligible computational cost. A 12-layer transformer with a memory outperforms a 24-layer transformer, and is 2x faster!     [Implementation](/doc/2019/08/product_key_memory_pkm_minima) This paper introduces a structured memory which can be easily integrated into a neural network. The memory is very large by design and significantly increases the capacity of the architecture, by up to a billion parameters with a negligible computational overhead. Its design and access pattern is based on product keys, which enable fast and exact nearest neighbor search. The ability to increase the number of parameters while keeping the same computational budget lets the overall system strike a better trade-off between prediction accuracy and computation efficiency both at training and test time. This memory layer allows us to tackle very large scale language modeling tasks. In our experiments we consider a dataset with up to 30 billion words, and we plug our memory layer in a state-of-the-art transformer-based architecture. In particular, we found that a memory augmented model with only 12 layers outperforms a baseline transformer model with 24 layers, while being twice faster at inference time. We release our code for reproducibility purposes.|sl:arxiv_author|Guillaume Lample
Cybersecurity Sécurité informatique|skos:broader|Security
Linear classifier|skos:broader|Statistical classification
Agriculture africaine|skos:broader|Agriculture
Voyager|skos:broader|Missions spatiales
KR|skos:broader|IA AI
Hydra|skos:broader|REST
Todo list|skos:broader|To do
Catholicisme|skos:broader|Religion
Coupe du monde de football|skos:broader|Football
Grounded Language Learning|skos:broader|NLP
Voiture électrique|skos:broader|Automotive
Pangloss: Fast Entity Linking in Noisy Text Environments a production system for entity disambiguation on messy tex, based  on probabilistic tokenization and context-dependent document embeddings    Probabilistic tokenization: uses the method described [here](/doc/2019/07/mining_quality_phrases_from_mas) Entity linking is the task of mapping potentially ambiguous terms in text to their constituent entities in a knowledge base like Wikipedia. This is useful for organizing content, extracting structured data from textual documents, and in machine learning relevance applications like semantic search, knowledge graph construction, and question answering. Traditionally, this work has focused on text that has been well-formed, like news articles, but in common real world datasets such as messaging, resumes, or short-form social media, non-grammatical, loosely-structured text adds a new dimension to this problem. This paper presents Pangloss, a production system for entity disambiguation on noisy text. Pangloss combines a probabilistic linear-time key phrase identification algorithm with a semantic similarity engine based on context-dependent document embeddings to achieve better than state-of-the-art results (5% in F1) compared to other research or commercially available systems. In addition, Pangloss leverages a local embedded database with a tiered architecture to house its statistics and metadata, which allows rapid disambiguation in streaming contexts and on-device disambiguation in low-memory environments such as mobile phones.|sl:arxiv_author|Matthew Hayes
Table-based Fact Verification|skos:broader|Fact verification
Distilling Structured Knowledge into Embeddings for Explainable and Accurate Recommendation distilling structured knowledge from a differentiable path-based recommendation model.     proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons Recently, the embedding-based recommendation models (e.g., matrix factorization and deep models) have been prevalent in both academia and industry due to their effectiveness and flexibility. However, they also have such intrinsic limitations as lacking explainability and suffering from data sparsity. In this paper, we propose an end-to-end joint learning framework to get around these limitations without introducing any extra overhead by distilling structured knowledge from a differentiable path-based recommendation model. Through extensive experiments, we show that our proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons.|sl:tag|tag:knowledge_distillation
Droit et internet|skos:broader|Internet
Hypercard|skos:broader|Apple Software
Spectral clustering|skos:broader|Dimensionality reduction
ElasticSearch: annotated text field|skos:broader|Entities
MPAA|skos:broader|Content industries
Distributed Representations of Sentences and Documents Paragraph Vector: an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents.Represents each document by a dense vector which is trained to predict words in the document. Overcomes the weaknesses of the [Bag Of Words](/tag/bag_of_words) model (order of words, semantic of words)       Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, powerful, strong and Paris are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.|sl:arxiv_author|Tomas Mikolov
Document Embedding with Paragraph Vectors Paragraph Vectors has been recently proposed as an unsupervised method for learning distributed representations for pieces of texts. In their work, the authors showed that the method can learn an embedding of movie review texts which can be leveraged for sentiment analysis. That proof of concept, while encouraging, was rather narrow. Here we consider tasks other than sentiment analysis, provide a more thorough comparison of Paragraph Vectors to other document modelling algorithms such as Latent Dirichlet Allocation, and evaluate performance of the method as we vary the dimensionality of the learned representation. We benchmarked the models on two document similarity data sets, one from Wikipedia, one from arXiv. We observe that the Paragraph Vector method performs significantly better than other methods, and propose a simple improvement to enhance embedding quality. Somewhat surprisingly, we also show that much like word embeddings, vector operations on Paragraph Vectors can perform useful semantic results.|sl:tag|tag:arxiv_doc
Universités américaines|skos:broader|Enseignement supérieur
Text feature extraction|skos:broader|Text: dimension reduction
Protégé|skos:broader|Stanford
hyperdoc2vec: Distributed Representations of Hypertext Documents Hypertext documents, such as web pages and academic papers, are of great importance in delivering information in our daily life. Although being effective on plain documents, conventional text embedding methods suffer from information loss if directly adapted to hyper-documents. In this paper, we propose a general embedding approach for hyper-documents, namely, hyperdoc2vec, along with four criteria characterizing necessary information that hyper-document embedding models should preserve. Systematic comparisons are conducted between hyperdoc2vec and several competitors on two tasks, i.e., paper classification and citation recommendation, in the academic paper domain. Analyses and experiments both validate the superiority of hyperdoc2vec to other models w.r.t. the four criteria.|sl:arxiv_author|Jialong Han
HttpUnit|skos:broader|Web dev
SPARQL AND Jena|skos:broader|SPARQL
Multiagent AI|skos:broader|Artificial Intelligence
HDMI|skos:broader|DRM
Learning to Remember Rare Events  a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training.    Our memory module can be easily added to any part of a supervised neural network Despite recent advances, memory-augmented deep neural networks are still limited when it comes to life-long and one-shot learning, especially in remembering rare events. We present a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training. Our memory module can be easily added to any part of a supervised neural network. To show its versatility we add it to a number of networks, from simple convolutional ones tested on image classification to deep sequence-to-sequence and recurrent-convolutional models. In all cases, the enhanced network gains the ability to remember and do life-long one-shot learning. Our module remembers training examples shown many thousands of steps in the past and it can successfully generalize from them. We set new state-of-the-art for one-shot learning on the Omniglot dataset and demonstrate, for the first time, life-long one-shot learning in recurrent neural networks on a large-scale machine translation task.|sl:tag|tag:google_brain
Civilisation élamite|skos:broader|Antiquité iranienne
Search Engines|skos:broader|Internet
each entity is defined by a short textual description, and the model must read these descriptions together with the mention context to make the linking decisions. |skos:broader|= named entity disambiguation: the task of resolving multiple named entity mentions in a document to their correct references in a knowledge base.
apache.org|skos:broader|Software
Network embeddings Representation Learning on Networks Graph representation learning Network Representation Learning|skos:broader|embedding
Mac OS X Web serving|skos:broader|Web Serving
the machine learning task of inferring a function from labeled training data.|skos:broader|Machine learning focuses on prediction, based on known properties learned from the training data. Data mining (which is the analysis step of Knowledge Discovery in Databases) focuses on the discovery of (previously) unknown properties on the data.    [Glossary (by google)](https://developers.google.com/machine-learning/glossary/)
Encoding Categorical Variables with Conjugate Bayesian Models for WeWork Lead Scoring Engine  To encode high-cardinality categorical variables, we introduce a technique based on traditional Bayesian statistics. This technique is a paradigm for ensemble modeling, specifically stacking, where the base learner consists of a problem- specific conjugate Bayesian model (CBM)   Applied Data Scientists throughout various industries are commonly faced with the challenging task of encoding high-cardinality categorical features into digestible inputs for machine learning algorithms. This paper describes a Bayesian encoding technique developed for WeWork's lead scoring engine which outputs the probability of a person touring one of our office spaces based on interaction, enrichment, and geospatial data. We present a paradigm for ensemble modeling which mitigates the need to build complicated preprocessing and encoding schemes for categorical variables. In particular, domain-specific conjugate Bayesian models are employed as base learners for features in a stacked ensemble model. For each column of a categorical feature matrix we fit a problem-specific prior distribution, for example, the Beta distribution for a binary classification problem. In order to analytically derive the moments of the posterior distribution, we update the prior with the conjugate likelihood of the corresponding target variable for each unique value of the given categorical feature. This function of column and value encodes the categorical feature matrix so that the final learner in the ensemble model ingests low-dimensional numerical input. Experimental results on both curated and real world datasets demonstrate impressive accuracy and computational efficiency on a variety of problem archetypes. Particularly, for the lead scoring engine at WeWork -- where some categorical features have as many as 300,000 levels -- we have seen an AUC improvement from 0.87 to 0.97 through implementing conjugate Bayesian model encoding.|sl:arxiv_author|Austin Slakey
Servlet|skos:broader|Java
Journal Le Monde|skos:broader|Presse
Faille de sécurité|skos:broader|Cybersecurity Sécurité informatique
Drupal/RDF|skos:broader|Drupal
R2RML|skos:broader|Relational Databases and the Semantic Web
IBM Watson|skos:broader|Artificial Intelligence
Biotech industry|skos:broader|Biotechnologies Biotechnologies
Coal seam fire|skos:broader|Fire
gnizr|skos:broader|Tagging
Encyclopédie collaborative|skos:broader|Encyclopédie
ERNIE: Enhanced Language Representation with Informative Entities  We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.|sl:tag|tag:acl_2019
Extinction d'espèces|skos:broader|Biodiversité
Recurrent Memory Networks for Language Modeling  Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge.     In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data.     We demonstrate the power of RMN on language modeling and sentence completion tasks.     On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.   Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge. In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data. We demonstrate the power of RMN on language modeling and sentence completion tasks. On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform in-depth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.|sl:arxiv_author|Arianna Bisazza
RDF-in-JSON|skos:broader|RDF
Erta Ale|skos:broader|Ethiopie
Ecrivain|skos:broader|Homme célèbre
A Comprehensive Survey on Graph Neural Networks an overview of graph neural networks (GNNs) in data mining and machine learning fields Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.|sl:arxiv_author|Zonghan Wu
Paludisme|skos:broader|Maladie
Fichage génétique|skos:broader|Etat policier
EigenVectors|skos:broader|Linear algebra
Rocard|skos:broader|Homme politique
WTP|skos:broader|Eclipse
Ubuntu|skos:broader|Linux
Macaw: An Extensible Conversational Information Seeking Platform Conversational information seeking (CIS) has been recognized as a major emerging research area in information retrieval. Such research will require data and tools, to allow the implementation and study of conversational systems. This paper introduces Macaw, an open-source framework with a modular architecture for CIS research. Macaw supports multi-turn, multi-modal, and mixed-initiative interactions, and enables research for tasks such as document retrieval, question answering, recommendation, and structured data exploration. It has a modular design to encourage the study of new CIS algorithms, which can be evaluated in batch mode. It can also integrate with a user interface, which allows user studies and data collection in an interactive mode, where the back end can be fully algorithmic or a wizard of oz setup. Macaw is distributed under the MIT License.|sl:arxiv_author|Nick Craswell
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:arxiv_author|Andrea Tacchetti
Medical IR, ML, IA|skos:broader|IA/ML: domaines d'application
Disparition de langues vivantes|skos:broader|Langues vivantes
CoKE: Contextualized Knowledge Graph Embedding A method to build contextualized entity and relation embeddings. Entities and relations may appear in different graph contexts. Edges and paths, both formulated as sequences of entities and relations, are passed as input to a Transformer encoder to learn the contextualized representations..    [Github](https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE) Knowledge graph embedding, which projects symbolic entities and relations into continuous vector spaces, is gaining increasing attention. Previous methods allow a single static embedding for each entity or relation, ignoring their intrinsic contextual nature, i.e., entities and relations may appear in different graph contexts, and accordingly, exhibit different properties. This work presents Contextualized Knowledge Graph Embedding (CoKE), a novel paradigm that takes into account such contextual nature, and learns dynamic, flexible, and fully contextualized entity and relation embeddings. Two types of graph contexts are studied: edges and paths, both formulated as sequences of entities and relations. CoKE takes a sequence as input and uses a Transformer encoder to obtain contextualized representations. These representations are hence naturally adaptive to the input, capturing contextual meanings of entities and relations therein. Evaluation on a wide variety of public benchmarks verifies the superiority of CoKE in link prediction and path query answering. It performs consistently better than, or at least equally well as current state-of-the-art in almost every case, in particular offering an absolute improvement of 21.0% in H@10 on path query answering. Our code is available at \\url{https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE}.|sl:arxiv_author|Wenbin Jiang
Synthetic Genome|skos:broader|Artificial life
Obélisque d'Axoum|skos:broader|Pillage de vestiges antiques
Large deviations for the perceptron model and consequences for active learning the task of choosing the subset of samples to be labeled from a fixed finite pool of samples Active learning is a branch of machine learning that deals with problems where unlabeled data is abundant yet obtaining labels is expensive. The learning algorithm has the possibility of querying a limited number of samples to obtain the corresponding labels, subsequently used for supervised learning. In this work, we consider the task of choosing the subset of samples to be labeled from a fixed finite pool of samples. We assume the pool of samples to be a random matrix and the ground truth labels to be generated by a single-layer teacher random neural network. We employ replica methods to analyze the large deviations for the accuracy achieved after supervised learning on a subset of the original pool. These large deviations then provide optimal achievable performance boundaries for any active learning algorithm. We show that the optimal learning performance can be efficiently approached by simple message-passing active learning algorithms. We also provide a comparison with the performance of some other popular active learning strategies.|sl:tag|tag:arxiv_doc
Alan Kay|skos:broader|Technical girls and guys
Bush|skos:broader|Chef d'état
AI@Google|skos:broader|Artificial Intelligence
Emerging Cross-lingual Structure in Pretrained Language Models We study the problem of multilingual masked language modeling, i.e. the training of a single model on concatenated text from multiple languages, and present a detailed study of several factors that influence why these models are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from independently trained models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these symmetries seem to be automatically discovered and aligned during the joint training process.|sl:arxiv_author|Haoran Li
Learning Deep Latent Spaces for Multi-Label Classification Uses [Deep Canonical Correlation Analysis](/tag/deep_canonical_correlation_analysis) and autoencoder structures to learn a latent subspace from both feature and label domains for multi-label classification.    (several implementations on github)       Multi-label classification is a practical yet challenging task in machine learning related fields, since it requires the prediction of more than one label category for each input instance. We propose a novel deep neural networks (DNN) based model, Canonical Correlated AutoEncoder (C2AE), for solving this task. Aiming at better relating feature and label domain data for improved classification, we uniquely perform joint feature and label embedding by deriving a deep latent space, followed by the introduction of label-correlation sensitive loss function for recovering the predicted label outputs. Our C2AE is achieved by integrating the DNN architectures of canonical correlation analysis and autoencoder, which allows end-to-end learning and prediction with the ability to exploit label dependency. Moreover, our C2AE can be easily extended to address the learning problem with missing labels. Our experiments on multiple datasets with different scales confirm the effectiveness and robustness of our proposed method, which is shown to perform favorably against state-of-the-art methods for multi-label classification.|sl:arxiv_firstAuthor|Chih-Kuan Yeh
Hash Embeddings for Efficient Word Representations  A hash embedding may be seen as an interpolation between  a standard word embedding and a word embedding created using a random hash  function (the hashing trick).    recommandé par [Raphaël Sourty](tag:raphaelsty) We present hash embeddings, an efficient method for representing words in a continuous vector form. A hash embedding may be seen as an interpolation between a standard word embedding and a word embedding created using a random hash function (the hashing trick). In hash embeddings each token is represented by $k$ $d$-dimensional embeddings vectors and one $k$ dimensional weight vector. The final $d$ dimensional representation of the token is the product of the two. Rather than fitting the embedding vectors for each token these are selected by the hashing trick from a shared pool of $B$ embedding vectors. Our experiments show that hash embeddings can easily deal with huge vocabularies consisting of millions of tokens. When using a hash embedding there is no need to create a dictionary before training nor to perform any kind of vocabulary pruning after training. We show that models trained using hash embeddings exhibit at least the same level of performance as models trained using regular embeddings across a wide range of tasks. Furthermore, the number of parameters needed by such an embedding is only a fraction of what is required by a regular embedding. Since standard embeddings and embeddings constructed using the hashing trick are actually just special cases of a hash embedding, hash embeddings can be considered an extension and improvement over the existing regular embedding types.|sl:arxiv_author|Ole Winther
Micropayments on the web|skos:broader|Finance
Talis platform|skos:broader|Semantic Web Platform
Browser : back button|skos:broader|Web dev
AI, robots and jobs|skos:broader|Artificial Intelligence
RDF and database|skos:broader|Semantic Web: databases
Puceron|skos:broader|Insecte
Semanlink|skos:broader|RDF Application
Banlieue|skos:broader|Ville
Extracting Tables from Documents using Conditional Generative Adversarial Networks and Genetic Algorithms Extracting information from tables in documents presents a significant challenge in many industries and in academic research. Existing methods which take a bottom-up approach of integrating lines into cells and rows or columns neglect the available prior information relating to table structure. Our proposed method takes a top-down approach, first using a generative adversarial network to map a table image into a standardised `skeleton' table form denoting the approximate row and column borders without table content, then fitting renderings of candidate latent table structures to the skeleton structure using a distance measure optimised by a genetic algorithm.|sl:tag|tag:generative_adversarial_network
Film allemand|skos:broader|Allemagne
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:arxiv_author|Jesse Thomason
\Self-Governing Neural Networks\|skos:broader|  
Histoire de l'art|skos:broader|Art
Conscience|skos:broader|Brain
Peinture|skos:broader|Art
Selective Question Answering under Domain Shift How you can get a QA model to abstain from answering when it doesn’t know the answer.     Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. To avoid giving wrong answers, question answering (QA) models need to know when to abstain from answering. Moreover, users often ask questions that diverge from the model's training data, making errors more likely and thus abstention more critical. In this work, we propose the setting of selective question answering under domain shift, in which a QA model is tested on a mixture of in-domain and out-of-domain data, and must answer (i.e., not abstain on) as many questions as possible while maintaining high accuracy. Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. Crucially, the calibrator benefits from observing the model's behavior on out-of-domain data, even if from a different domain than the test data. We combine this method with a SQuAD-trained QA model and evaluate on mixtures of SQuAD and five other QA datasets. Our method answers 56% of questions while maintaining 80% accuracy; in contrast, directly using the model's probabilities only answers 48% at 80% accuracy.|sl:arxiv_firstAuthor|Amita Kamath
WWW 2009|skos:broader|TheWebConf
RDFa Lite|skos:broader|RDFa
explains the predictions of a classifier by learning an interpretable model locally around the prediction |skos:broader|the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations whose category membership is known.
Protégé|skos:broader|Ontologies
Machine Learning + Semantic Web|skos:broader|Machine learning
Servlet|skos:broader|Java dev
Hierarchical temporal memory|skos:broader|Memory-prediction framework
Meta Content Framework|skos:broader|Guha
France : dysfonctionnement administratif|skos:broader|Administration française
Coursera: Web Intelligence and Big Data|skos:broader|Coursera
An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks For most deep learning practitioners, sequence modeling is synonymous with recurrent networks. Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation. Given a new sequence modeling task or dataset, which architecture should one use? We conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling. The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks. Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as LSTMs across a diverse range of tasks and datasets, while demonstrating longer effective memory. We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks. To assist related work, we have made code available at http://github.com/locuslab/TCN .|sl:arxiv_author|Shaojie Bai
A Metric Learning Reality Check Deep metric learning papers from the past four years have consistently claimed great advances in accuracy, often more than doubling the performance of decade-old methods. In this paper, we take a closer look at the field to see if this is actually true. We find flaws in the experimental setup of these papers, and propose a new way to evaluate metric learning algorithms. Finally, we present experimental results that show that the improvements over time have been marginal at best.|sl:tag|tag:ml_evaluation
Semantic Enterprise|skos:broader|Semantic Web
Afrique Centrale|skos:broader|Afrique
Glyphosate|skos:broader|Monsanto
Transformers as Soft Reasoners over Language  AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. AI has long pursued the goal of having systems reason over explicitly provided knowledge, but building suitable representations has proved challenging. Here we explore whether transformers can similarly learn to reason (or emulate reasoning), but using rules expressed in language, thus bypassing a formal representation. We provide the first demonstration that this is possible, and characterize the extent of this capability. To do this, we use a collection of synthetic datasets that test increasing levels of reasoning complexity (number of rules, presence of negation, and depth of chaining). We find transformers appear to learn rule-based reasoning with high (99%) accuracy on these datasets, and in a way that generalizes to test data requiring substantially deeper chaining than in the training data (95%+ scores). We also demonstrate that the models transfer well to two hand-authored rulebases, and to rulebases paraphrased into more natural language. These findings are significant as it suggests a new role for transformers, namely as a limited soft theorem prover operating over explicit theories in language. This in turn suggests new possibilities for explainability, correctability, and counterfactual reasoning in question-answering. All datasets and a live demo are available at http://rule-reasoning.apps.allenai.org/|sl:arxiv_author|Oyvind Tafjord
CoKE: Contextualized Knowledge Graph Embedding A method to build contextualized entity and relation embeddings. Entities and relations may appear in different graph contexts. Edges and paths, both formulated as sequences of entities and relations, are passed as input to a Transformer encoder to learn the contextualized representations..    [Github](https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE) Knowledge graph embedding, which projects symbolic entities and relations into continuous vector spaces, is gaining increasing attention. Previous methods allow a single static embedding for each entity or relation, ignoring their intrinsic contextual nature, i.e., entities and relations may appear in different graph contexts, and accordingly, exhibit different properties. This work presents Contextualized Knowledge Graph Embedding (CoKE), a novel paradigm that takes into account such contextual nature, and learns dynamic, flexible, and fully contextualized entity and relation embeddings. Two types of graph contexts are studied: edges and paths, both formulated as sequences of entities and relations. CoKE takes a sequence as input and uses a Transformer encoder to obtain contextualized representations. These representations are hence naturally adaptive to the input, capturing contextual meanings of entities and relations therein. Evaluation on a wide variety of public benchmarks verifies the superiority of CoKE in link prediction and path query answering. It performs consistently better than, or at least equally well as current state-of-the-art in almost every case, in particular offering an absolute improvement of 21.0% in H@10 on path query answering. Our code is available at \\url{https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE}.|sl:tag|tag:baidu
Keras Functional API|skos:broader|Keras
Mac OS X Web serving|skos:broader|Mac OS X
Deep latent variable models assume a generative process whereby a simple random variable is transformed from the latent space to the observed, output space through a deep neural network. Generative Adversarial Networks (GAN) and Variational Autoencoders (VAE) are two of the most popular variants of this approach|skos:broader|statistical model that relates a set of observable variables (manifest variables) to a set of latent variables     A latent variable is one which is not directly observed but which is assumed to affect observed variables. Latent variable models therefore attempt to model the underlying structure of the observed variables, offering an explanation of the dependencies between observed variables which are then seen as conditionally independent, given the latent variable(s). ([source](https://supernlp.github.io/2018/11/10/emnlp-2018/))  
Map–territory relation|skos:broader|General semantics
www.topquadrant.com|skos:broader|Semantic Web : entreprise Semantic Web: enterprise
Attention Models in Graphs: A Survey  An attention mechanism aids a model by  allowing it to focus on the most relevant parts of the input to make decisions   Graph-structured data arise naturally in many different application domains. By representing data as graphs, we can capture entities (i.e., nodes) as well as their relationships (i.e., edges) with each other. Many useful insights can be derived from graph-structured data as demonstrated by an ever-growing body of work focused on graph mining. However, in the real-world, graphs can be both large - with many complex patterns - and noisy which can pose a problem for effective graph mining. An effective way to deal with this issue is to incorporate attention into graph mining solutions. An attention mechanism allows a method to focus on task-relevant parts of the graph, helping it to make better decisions. In this work, we conduct a comprehensive and focused survey of the literature on the emerging field of graph attention models. We introduce three intuitive taxonomies to group existing work. These are based on problem setting (type of input and output), the type of attention mechanism used, and the task (e.g., graph classification, link prediction, etc.). We motivate our taxonomies through detailed examples and use each to survey competing approaches from a unique standpoint. Finally, we highlight several challenges in the area and discuss promising directions for future work.|sl:arxiv_author|John Boaz Lee
Beijing Genomics Institute|skos:broader|Chine : technologie
DL: why does it work?|skos:broader|Deep Learning
Un ivrogne dans la brousse|skos:broader|Nigeria
Variational Inference: A Review for Statisticians One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.|sl:arxiv_author|David M. Blei
Statistical relational learning|skos:broader|Machine learning: problems
Rome|skos:broader|Ville
Brésil|skos:broader|Amérique du sud
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:tag|tag:ray_kurzweil
David Beckett|skos:broader|SW guys (and girls)
Dictateur|skos:broader|Dictature
Dalai Lama|skos:broader|Boudhisme
NLU|skos:broader|NLP tasks / problems
VoIP|skos:broader|Téléphone
FaceNet: A Unified Embedding for Face Recognition and Clustering Learns a Euclidean embedding per image     Uses a deep CNN trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method.     state-of-the-art face recognition performance using only 128-bytes per face.      Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves 95.12%. Our system cuts the error rate in comparison to the best published result by 30% on both datasets. We also introduce the concept of harmonic embeddings, and a harmonic triplet loss, which describe different versions of face embeddings (produced by different networks) that are compatible to each other and allow for direct comparison between each other.|sl:arxiv_firstAuthor|Florian Schroff
Efficient Estimation of Word Representations in Vector Space We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.   We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.|sl:tag|tag:arxiv_doc
Trust in the Web of Data|skos:broader|Web of data
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:tag|tag:arxiv_doc
Capitalism Surveillance|skos:broader|Vive le capitalisme !
Security and REST|skos:broader|Cybersecurity Sécurité informatique
gnowsis|skos:broader|Semantic Desktop
DRM|skos:broader|Propriété intellectuelle
Deep Learning|skos:broader|Neural networks
Niamey|skos:broader|Niger
Munich|skos:broader|Allemagne
SKOS|skos:broader|Semanlink related
Foxconn|skos:broader|Chine
Référentiel des opérations|skos:broader|APV evolution
Syrian Civil War|skos:broader|Syrie
Bertrand Russell|skos:broader|Prix Nobel
Symmetric matrices related to the Mertens function In this paper we explore a family of congruences over N from which a sequence of symmetric matrices related to the Mertens function is built. From the results of numerical experiments we formulate a conjecture, about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may play a more important role in this classical and difficult problem.  In this paper we explore a family of congruences over $\\N^\\ast$ from which one builds a sequence of symmetric matrices related to the Mertens function. From the results of numerical experiments, we formulate a conjecture about the growth of the quadratic norm of these matrices, which implies the Riemann hypothesis. This suggests that matrix analysis methods may come to play a more important role in this classical and difficult problem.|sl:arxiv_author|Jean-Paul Cardinal
Compressive Transformers for Long-Range Sequence Modelling  the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning.    [Blog post](/doc/2020/02/a_new_model_and_dataset_for_lon) We present the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning. We find the Compressive Transformer obtains state-of-the-art language modelling results in the WikiText-103 and Enwik8 benchmarks, achieving 17.1 ppl and 0.97 bpc respectively. We also find it can model high-frequency speech effectively and can be used as a memory mechanism for RL, demonstrated on an object matching task. To promote the domain of long-range sequence learning, we propose a new open-vocabulary language modelling benchmark derived from books, PG-19.|sl:tag|tag:nlp_long_documents
Pre-trained Models for Natural Language Processing: A Survey Recently, the emergence of pre-trained models (PTMs) has brought natural language processing (NLP) to a new era. In this survey, we provide a comprehensive review of PTMs for NLP. We first briefly introduce language representation learning and its research progress. Then we systematically categorize existing PTMs based on a taxonomy with four perspectives. Next, we describe how to adapt the knowledge of PTMs to the downstream tasks. Finally, we outline some potential directions of PTMs for future research. This survey is purposed to be a hands-on guide for understanding, using, and developing PTMs for various NLP tasks.|sl:arxiv_author|Yige Xu
Apache Mahout|skos:broader|Machine Learning tool
Plastic print|skos:broader|3D
limule|skos:broader|Curiosité naturelle
Language model|skos:broader|Unsupervised machine learning
Knowledge Graphs Draws together many topics & perspectives regarding Knowledge Graphs. 18 co-authors, lead by Aidan Hogan. (Regarding language models for embedding, they refer to [Wang et al. Knowledge Graph Embedding: A Survey of Approaches and Applications](/doc/2019/05/knowledge_graph_embedding_a_su)) In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After a general introduction, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.|sl:arxiv_author|Gerard de Melo
Banque mondiale|skos:broader|Economie
Neural networks|skos:broader|Machine learning: techniques
Roy T. Fielding|skos:broader|Technical girls and guys
Accueil étranger|skos:broader|Cons de Français
Coursera: Machine Learning|skos:broader|Machine Learning Course
Detecting Out-of-Distribution Examples with In-distribution Examples and Gram Matrices  we propose to detect OOD examples by identifying inconsistencies between activity patterns and class predicted...    Unlike many approaches, this can be used with any pre-trained softmax classifier and does not require access to OOD data When presented with Out-of-Distribution (OOD) examples, deep neural networks yield confident, incorrect predictions. Detecting OOD examples is challenging, and the potential risks are high. In this paper, we propose to detect OOD examples by identifying inconsistencies between activity patterns and class predicted. We find that characterizing activity patterns by Gram matrices and identifying anomalies in gram matrix values can yield high OOD detection rates. We identify anomalies in the gram matrices by simply comparing each value with its respective range observed over the training data. Unlike many approaches, this can be used with any pre-trained softmax classifier and does not require access to OOD data for fine-tuning hyperparameters, nor does it require OOD access for inferring parameters. The method is applicable across a variety of architectures and vision datasets and, for the important and surprisingly hard task of detecting far-from-distribution out-of-distribution examples, it generally performs better than or equal to state-of-the-art OOD detection methods (including those that do assume access to OOD examples).|sl:arxiv_author|Chandramouli Shama Sastry
Londres|skos:broader|Ville
WWW 2007|skos:broader|TheWebConf
LDOW2008|skos:broader|LDOW
The Guardian|skos:broader|Presse
NLP@IBM|skos:broader|IBM
SPARQL 1.1|skos:broader|SPARQL
Perelman|skos:broader|Conjecture de Poincaré
Web tools|skos:broader|Dev
Named Entity Disambiguation using Deep Learning on Graphs Evaluation of different deep learning techniques to create  a context vector from graphs, aimed at high-accuracy NED. (neural  approach for entity disambiguation using graphs as background  knowledge)     We tackle Named Entity Disambiguation (NED) by comparing entities  in short sentences with Wikidata graphs. Creating a context vector  from graphs through deep learning is a challenging problem that has  never been applied to NED. Our main contribution is to present an  experimental study of recent neural techniques, as well as a discussion  about which graph features are most important for the disambiguation  task...    [published paper](https://rd.springer.com/chapter/10.1007/978-3-030-15719-7_10)      In NED, the system  must be able to generate a context for an entity in a text and an entity  in a knowledge base, then correctly link the two.    Explore whether representing graphs  as triplets is more useful than using the full topological information of the graph    We tackle \\ac{NED} by comparing entities in short sentences with \\wikidata{} graphs. Creating a context vector from graphs through deep learning is a challenging problem that has never been applied to \\ac{NED}. Our main contribution is to present an experimental study of recent neural techniques, as well as a discussion about which graph features are most important for the disambiguation task. In addition, a new dataset (\\wikidatadisamb{}) is created to allow a clean and scalable evaluation of \\ac{NED} with \\wikidata{} entries, and to be used as a reference in future research. In the end our results show that a \\ac{Bi-LSTM} encoding of the graph triplets performs best, improving upon the baseline models and scoring an \ m{F1} value of $91.6\\%$ on the \\wikidatadisamb{} test set|sl:tag|tag:arxiv_doc
Facial Recognition|skos:broader|Image recognition
Zemanta|skos:broader|Semantic Web : Application
Yves Roth|skos:broader|Lycée Alain
Span Selection Pre-training for Question Answering  a new pre-training task inspired by reading  comprehension and an effort to avoid encoding general knowledge in the transformer network itself    Current transformer architectures store general knowledge - large models, long pre-training time. Better to offload the requirement of general knowledge to a sparsely activated network.    Span selection as an additional auxiliary task: the query is a sentence drawn from a corpus  with a term replaced with a special token: [BLANK]. The term replaced by the blank is the answer term. The passage is  relevant as determined by a BM25 search, and answer-bearing (containing the answer  term). Unlike BERT’s cloze task, where the answer must be drawn from the model itself, the answer is found in a passage  using language understanding.     We hope to progress to a model of general purpose language modeling that uses an indexed long  term memory to retrieve world knowledge, rather than holding it in the densely activated transformer encoder layers. BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pre-trained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension and an effort to avoid encoding general knowledge in the transformer network itself. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple reading comprehension (MRC) and paraphrasing datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also establish a new SOTA in HotpotQA, improving answer prediction F1 by 4 F1 points and supporting fact prediction by 1 F1 point. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.|sl:arxiv_author|Dinesh Garg
Statistical machine translation|skos:broader|Machine translation
Semantic Camp Paris|skos:broader|Semantic Web
Publication scientifique|skos:broader|Science
Traversing Knowledge Graphs in Vector Space Knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new \compositional\ training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. Path queries on a knowledge graph can be used to answer compositional questions such as What languages are spoken by people living in Lisbon?. However, knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new compositional training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. On a standard knowledge base completion task, we also demonstrate that compositional training acts as a novel form of structural regularization, reliably improving performance across all base models (reducing errors by up to 43%) and achieving new state-of-the-art results.|sl:tag|tag:knowledge_graph_completion
Neural Ranking Models with Weak Supervision Main Idea: To leverage large amounts of unsupervised data to infer “weak” labels and use that signal for learning supervised models as if we had the ground truth labels. See [blog post](/doc/?uri=http%3A%2F%2Fmostafadehghani.com%2F2017%2F04%2F23%2Fbeating-the-teacher-neural-ranking-models-with-weak-supervision%2F):     This is truly awesome since we have only used  BM25 as the supervisor to train a model which performs better than BM25 itself!   Despite the impressive improvements achieved by unsupervised deep neural networks in computer vision and NLP tasks, such improvements have not yet been observed in ranking for information retrieval. The reason may be the complexity of the ranking problem, as it is not obvious how to learn from queries and documents when no supervised signal is available. Hence, in this paper, we propose to train a neural ranking model using weak supervision, where labels are obtained automatically without human annotators or any external resources (e.g., click data). To this aim, we use the output of an unsupervised ranking model, such as BM25, as a weak supervision signal. We further train a set of simple yet effective ranking models based on feed-forward neural networks. We study their effectiveness under various learning scenarios (point-wise and pair-wise models) and using different input representations (i.e., from encoding query-document pairs into dense/sparse vectors to using word embedding representation). We train our networks using tens of millions of training instances and evaluate it on two standard collections: a homogeneous news collection(Robust) and a heterogeneous large-scale web collection (ClueWeb). Our experiments indicate that employing proper objective functions and letting the networks to learn the input representation based on weakly supervised data leads to impressive performance, with over 13% and 35% MAP improvements over the BM25 model on the Robust and the ClueWeb collections. Our findings also suggest that supervised neural ranking models can greatly benefit from pre-training on large amounts of weakly labeled data that can be easily obtained from unsupervised IR models.|sl:arxiv_author|Jaap Kamps
Ghana|skos:broader|Afrique de l'Ouest
Cazuza|skos:broader|Musique
Backpropagation|skos:broader|Algorithmes
Barack's Wife Hillary: Using Knowledge-Graphs for Fact-Aware Language Modeling  a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset, a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark. In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language model's ability to complete sentences requiring factual knowledge, showing that the KGLM outperforms even very large language models in generating facts.|sl:arxiv_author|Sameer Singh
Information sur internet|skos:broader|Journalisme
Lord's Resistance Army|skos:broader|Horreur
Parameter-free Sentence Embedding via Orthogonal Basis training-free approach for building sentence representations, Geometric Embedding (GEM), based on the geometric structure of word embedding space.     we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word’s novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace    [on www.groundai.com](https://www.groundai.com/project/zero-training-sentence-embedding-via-orthogonal-basis/)    [Open Revieww](/doc/?uri=https%3A%2F%2Fopenreview.net%2Fforum%3Fid%3DrJedbn0ctQ) ; [Related to this paper](/doc/?uri=https%3A%2F%2Farxiv.org%2Fabs%2F1704.05358)       We propose a simple and robust non-parameterized approach for building sentence representations. Inspired by the Gram-Schmidt Process in geometric theory, we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is the word's novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace. Following this motivation, we develop an innovative method based on orthogonal basis to combine pre-trained word embeddings into sentence representations. This approach requires zero parameters, along with efficient inference performance. We evaluate our approach on 11 downstream NLP tasks. Our model shows superior performance compared with non-parameterized alternatives and it is competitive to other approaches relying on either large amounts of labelled data or prolonged training time.|sl:arxiv_firstAuthor|Ziyi Yang
Périclès|skos:broader|Grèce antique
Differentiable Top-k Operator with Optimal Transport  if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator   ...   We apply the proposed operator to the [k-nearest neighbors](tag:k_nearest_neighbors_algorithm) and [beam search](tag:beam_search) algorithms, and demonstrate improved performance The top-k operation, i.e., finding the k largest or smallest elements from a collection of scores, is an important model component, which is widely used in information retrieval, machine learning, and data mining. However, if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator. Specifically, our SOFT top-k operator approximates the output of the top-k operation as the solution of an Entropic Optimal Transport (EOT) problem. The gradient of the SOFT operator can then be efficiently approximated based on the optimality conditions of EOT problem. We apply the proposed operator to the k-nearest neighbors and beam search algorithms, and demonstrate improved performance.|sl:arxiv_author|Wei Wei
Sören Auer|skos:broader|SW guys (and girls)
Lingo|skos:broader|Carrot2
ELMo|skos:broader|AllenNLP
Livesearch|skos:broader|Web dev
Madonna|skos:broader|Musicien
Windows Media Player|skos:broader|Windows
Scientifique|skos:broader|Homme célèbre
Wiki|skos:broader|Software
Linked Data Dev|skos:broader|Linked Data
Semantic Camp Paris|skos:broader|Barcamp
Extracting Tables from Documents using Conditional Generative Adversarial Networks and Genetic Algorithms Extracting information from tables in documents presents a significant challenge in many industries and in academic research. Existing methods which take a bottom-up approach of integrating lines into cells and rows or columns neglect the available prior information relating to table structure. Our proposed method takes a top-down approach, first using a generative adversarial network to map a table image into a standardised `skeleton' table form denoting the approximate row and column borders without table content, then fitting renderings of candidate latent table structures to the skeleton structure using a distance measure optimised by a genetic algorithm.|sl:tag|tag:genetic_algorithm
Mongol|skos:broader|Asie
Yoshua Bengio|skos:broader|NLP girls and guys
Agriculture industrielle|skos:broader|Agriculture
Forward chaining|skos:broader|Entailment
Combining knowledge graphs|skos:broader|Multiple Knowledge Bases
Semantic markup in HTML|skos:broader|RDF
Hierarchical clustering|skos:broader|Clustering
BP|skos:broader|Compagnies pétrolières
Hierarchical Memory Networks  hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory Memory networks are neural networks with an explicit memory component that can be both read and written to by the network. The memory is often addressed in a soft way using a softmax function, making end-to-end training with backpropagation possible. However, this is not computationally scalable for applications which require the network to read from extremely large memories. On the other hand, it is well known that hard attention mechanisms based on reinforcement learning are challenging to train successfully. In this paper, we explore a form of hierarchical memory network, which can be considered as a hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory. Specifically, we propose to incorporate Maximum Inner Product Search (MIPS) in the training and inference procedures for our hierarchical memory network. We explore the use of various state-of-the art approximate MIPS techniques and report results on SimpleQuestions, a challenging large scale factoid question answering task.|sl:arxiv_firstAuthor|Sarath Chandar
Ajax|skos:broader|Asynchronous
RDF in files|skos:broader|RDF
Knowledge Enhanced Contextual Word Representations General method to embed multiple knowledge bases into pre-trained language models (KB in the   sense as fixed collection of entity nodes)     The key idea is to explicitly model  entity spans in the input text and use an entity  linker to retrieve relevant entity embeddings from  a KB to form knowledge enhanced entity-span  representations.   Then,  update contextual word representations via a form of word-to-entity attention.    In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert's runtime is comparable to BERT's and it scales to large KBs.|sl:tag|tag:knowledge_driven_embeddings
Documentation tool|skos:broader|Dev tools
Synthetic life|skos:broader|Synthetic biology
Semi-supervised Clustering for Short Text via Deep Representation Learning semi-supervised method for short text clustering, where we represent texts as distributed vectors with neural networks, and use a small amount of labeled data to specify our intention for clustering. We design a novel objective to combine the representation learning process and the k-means clustering process together, and optimize the objective with both labeled data and unlabeled data iteratively until convergence through three steps:     1. assign each short text to its nearest centroid based on its representation from the current neural networks;  2. re-estimate the cluster centroids based on cluster assignments from step (1);  3. update neural networks according to the objective by keeping centroids and cluster assignments fixed.   In this work, we propose a semi-supervised method for short text clustering, where we represent texts as distributed vectors with neural networks, and use a small amount of labeled data to specify our intention for clustering. We design a novel objective to combine the representation learning process and the k-means clustering process together, and optimize the objective with both labeled data and unlabeled data iteratively until convergence through three steps: (1) assign each short text to its nearest centroid based on its representation from the current neural networks; (2) re-estimate the cluster centroids based on cluster assignments from step (1); (3) update neural networks according to the objective by keeping centroids and cluster assignments fixed. Experimental results on four datasets show that our method works significantly better than several other text clustering methods.|sl:tag|tag:clustering_of_text_documents
Google Web Toolkit|skos:broader|Ajax
SKOS editor|skos:broader|Semanlink related
Epimorphics json-rdf|skos:broader|Epimorphics
Spark (Java web framework)|skos:broader|Microservices
RDF2VEC|skos:broader|RDF embeddings
Javascript RDF Parser|skos:broader|Javascript RDF
Tabulator|skos:broader|Tim Berners-Lee
Parrot|skos:broader|RDF-OWL documentation tool
Rio de Janeiro|skos:broader|Brésil
LDOW2012|skos:broader|WWW 2012
JCS - Java Caching System|skos:broader|Cache
public-vocabs@w3.org|skos:broader|schema.org
StarSpace: Embed All The Things! We present StarSpace, a general-purpose neural embedding model that can solve a wide variety of problems: labeling tasks such as text classification, ranking tasks such as information retrieval/web search, collaborative filtering-based or content-based recommendation, embedding of multi-relational graphs, and learning word, sentence or document level embeddings. In each case the model works by embedding those entities comprised of discrete features and comparing them against each other -- learning similarities dependent on the task. Empirical results on a number of tasks show that StarSpace is highly competitive with existing methods, whilst also being generally applicable to new cases where those methods are not.|sl:arxiv_author|Antoine Bordes
Named Entity Disambiguation using Deep Learning on Graphs Evaluation of different deep learning techniques to create  a context vector from graphs, aimed at high-accuracy NED. (neural  approach for entity disambiguation using graphs as background  knowledge)     We tackle Named Entity Disambiguation (NED) by comparing entities  in short sentences with Wikidata graphs. Creating a context vector  from graphs through deep learning is a challenging problem that has  never been applied to NED. Our main contribution is to present an  experimental study of recent neural techniques, as well as a discussion  about which graph features are most important for the disambiguation  task...    [published paper](https://rd.springer.com/chapter/10.1007/978-3-030-15719-7_10)      In NED, the system  must be able to generate a context for an entity in a text and an entity  in a knowledge base, then correctly link the two.    Explore whether representing graphs  as triplets is more useful than using the full topological information of the graph    We tackle \\ac{NED} by comparing entities in short sentences with \\wikidata{} graphs. Creating a context vector from graphs through deep learning is a challenging problem that has never been applied to \\ac{NED}. Our main contribution is to present an experimental study of recent neural techniques, as well as a discussion about which graph features are most important for the disambiguation task. In addition, a new dataset (\\wikidatadisamb{}) is created to allow a clean and scalable evaluation of \\ac{NED} with \\wikidata{} entries, and to be used as a reference in future research. In the end our results show that a \\ac{Bi-LSTM} encoding of the graph triplets performs best, improving upon the baseline models and scoring an \ m{F1} value of $91.6\\%$ on the \\wikidatadisamb{} test set|sl:tag|tag:wikidata
NSA spying scandal|skos:broader|Edward Snowden
Text Classification|skos:broader|NLP tasks / problems
Jérusalem|skos:broader|Israël
Wikidata query service|skos:broader|Wikidata
K-BERT: Enabling Language Representation with Knowledge Graph a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by equipped with a KG without pre-training by-self because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts.|sl:arxiv_author|Qi Ju
Sebastian Schaffert|skos:broader|SW guys (and girls)
RDF Schema|skos:broader|RDF
Chef d'état|skos:broader|Homme politique
BAM! Born-Again Multi-Task Networks for Natural Language Understanding  knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers It can be challenging to train multi-task neural networks that outperform or even match their single-task counterparts. To help address this, we propose using knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers. We evaluate our approach by multi-task fine-tuning BERT on the GLUE benchmark. Our method consistently improves over standard single-task and multi-task training.|sl:tag|tag:kd_mkb_biblio
fastai: A Layered API for Deep Learning Paper describing the fast.ai v2 API fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes: a new type dispatch system for Python along with a semantic type hierarchy for tensors; a GPU-optimized computer vision library which can be extended in pure Python; an optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 4-5 lines of code; a novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training; a new data block API; and much more. We have used this library to successfully create a complete deep learning course, which we were able to write more quickly than using previous approaches, and the code was more clear. The library is already in wide use in research, industry, and teaching. NB: This paper covers fastai v2, which is currently in pre-release at http://dev.fast.ai/|sl:arxiv_author|Sylvain Gugger
iMovie|skos:broader|Mac software
Prolétaire|skos:broader|Prolétarisation
Selective Question Answering under Domain Shift How you can get a QA model to abstain from answering when it doesn’t know the answer.     Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. To avoid giving wrong answers, question answering (QA) models need to know when to abstain from answering. Moreover, users often ask questions that diverge from the model's training data, making errors more likely and thus abstention more critical. In this work, we propose the setting of selective question answering under domain shift, in which a QA model is tested on a mixture of in-domain and out-of-domain data, and must answer (i.e., not abstain on) as many questions as possible while maintaining high accuracy. Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. Crucially, the calibrator benefits from observing the model's behavior on out-of-domain data, even if from a different domain than the test data. We combine this method with a SQuAD-trained QA model and evaluate on mixtures of SQuAD and five other QA datasets. Our method answers 56% of questions while maintaining 80% accuracy; in contrast, directly using the model's probabilities only answers 48% at 80% accuracy.|sl:tag|tag:question_answering
Truffe|skos:broader|Champignon
Boko Haram|skos:broader|Nigeria
Unit test|skos:broader|Dev
Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.|sl:arxiv_author|Luis C. Lamb
Binary classification models with \Uncertain\ predictions Binary classification models which can assign probabilities to categories such as the tissue is 75% likely to be tumorous or the chemical is 25% likely to be toxic are well understood statistically, but their utility as an input to decision making is less well explored. We argue that users need to know which is the most probable outcome, how likely that is to be true and, in addition, whether the model is capable enough to provide an answer. It is the last case, where the potential outcomes of the model explicitly include don't know that is addressed in this paper. Including this outcome would better separate those predictions that can lead directly to a decision from those where more data is needed. Where models produce an Uncertain answer similar to a human reply of don't know or 50:50 in the examples we refer to earlier, this would translate to actions such as operate on tumour or remove compound from use where the models give a more true than not answer. Where the models judge the result Uncertain the practical decision might be carry out more detailed laboratory testing of compound or commission new tissue analyses. The paper presents several examples where we first analyse the effect of its introduction, then present a methodology for separating Uncertain from binary predictions and finally, we provide arguments for its use in practice.|sl:arxiv_author|Simon Thomas
Entity Embeddings of Categorical Variables  We map categorical variables in a function approximation problem into Euclidean spaces, which are the entity embeddings of the categorical variables. The mapping is learned by a neural network during the standard supervised training process. Entity embedding not only reduces memory usage and speeds up neural networks compared with one-hot encoding, but more importantly by mapping similar values close to each other in the embedding space it reveals the intrinsic properties of the categorical variables We map categorical variables in a function approximation problem into Euclidean spaces, which are the entity embeddings of the categorical variables. The mapping is learned by a neural network during the standard supervised training process. Entity embedding not only reduces memory usage and speeds up neural networks compared with one-hot encoding, but more importantly by mapping similar values close to each other in the embedding space it reveals the intrinsic properties of the categorical variables. We applied it successfully in a recent Kaggle competition and were able to reach the third position with relative simple features. We further demonstrate in this paper that entity embedding helps the neural network to generalize better when the data is sparse and statistics is unknown. Thus it is especially useful for datasets with lots of high cardinality features, where other methods tend to overfit. We also demonstrate that the embeddings obtained from the trained neural network boost the performance of all tested machine learning methods considerably when used as the input features instead. As entity embedding defines a distance measure for categorical variables it can be used for visualizing categorical data and for data clustering.|sl:arxiv_firstAuthor|Cheng Guo
Jazz|skos:broader|Musique
Minimum Description Length Principle|skos:broader|Information theory
RDF Parser|skos:broader|RDF Tools
Chirac|skos:broader|Cons de Français
Inde|skos:broader|Asie
Language Models as Knowledge Bases? an analysis of the relational knowledge present in pretrained language models shows an ability of these models to recall factual knowledge  Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as fill-in-the-blank cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.|sl:arxiv_firstAuthor|Fabio Petroni
Darfour|skos:broader|Soudan
Marseillaise|skos:broader|Hymne national
Acoustique musicale|skos:broader|Musique
Asie centrale|skos:broader|Asie
Relational inductive biases, deep learning, and graph networks  generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI     Here we explore how to improve modern AI's capacity for combinatorial generalization by  biasing learning towards structured representations and computations, and in particular, systems  that operate on graphs. Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between hand-engineering and end-to-end learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.|sl:tag|tag:artificial_general_intelligence
Poisson|skos:broader|Animal
- Intent classification: predicting the intent of a query  - slot filling extracts semantic concepts in the query (a sequence labeling task that tags the input word sequence).    For example the user query could be “Find me an  action movie by Steven Spielberg”. The intent here is “find_movie” while  the slots are “genre” with value “action” and “directed_by” with value  “Steven Spielberg”.|skos:broader|Intent classification: predicting the intent of a query
A Survey on Knowledge Graph Embeddings with Literals: Which model links better Literal-ly? Knowledge Graphs (KGs) are composed of structured information about a particular domain in the form of entities and relations. In addition to the structured information KGs help in facilitating interconnectivity and interoperability between different resources represented in the Linked Data Cloud. KGs have been used in a variety of applications such as entity linking, question answering, recommender systems, etc. However, KG applications suffer from high computational and storage costs. Hence, there arises the necessity for a representation able to map the high dimensional KGs into low dimensional spaces, i.e., embedding space, preserving structural as well as relational information. This paper conducts a survey of KG embedding models which not only consider the structured information contained in the form of entities and relations in a KG but also the unstructured information represented as literals such as text, numerical values, images, etc. Along with a theoretical analysis and comparison of the methods proposed so far for generating KG embeddings with literals, an empirical evaluation of the different methods under identical settings has been performed for the general task of link prediction.|sl:tag|tag:arxiv_doc
Françafrique|skos:broader|France / Afrique
Word2Bits - Quantized Word Vectors We show that high quality quantized word vectors using 1-2 bits per parameter can be learned by introducing a quantization function into Word2Vec. We furthermore show that training with the quantization function acts as a regularizer Word vectors require significant amounts of memory and storage, posing issues to resource limited devices like mobile phones and GPUs. We show that high quality quantized word vectors using 1-2 bits per parameter can be learned by introducing a quantization function into Word2Vec. We furthermore show that training with the quantization function acts as a regularizer. We train word vectors on English Wikipedia (2017) and evaluate them on standard word similarity and analogy tasks and on question answering (SQuAD). Our quantized word vectors not only take 8-16x less space than full precision (32 bit) word vectors but also outperform them on word similarity tasks and question answering.|sl:arxiv_author|Maximilian Lam
Explosions cosmiques|skos:broader|Rayons cosmiques
XTech 2006|skos:broader|XTech
Nebra Sky Disc|skos:broader|Âge du bronze
La communauté internationale est une garce|skos:broader|Communauté internationale
Word Translation Without Parallel Data  we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent studies showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally describe experiments on the English-Esperanto low-resource language pair, on which there only exists a limited amount of parallel data, to show the potential impact of our method in fully unsupervised machine translation. Our code, embeddings and dictionaries are publicly available.|sl:tag|tag:ludovic_denoyer
Sport de combat|skos:broader|Sport
NLP@Stanford|skos:broader|Stanford
Danny Ayers|skos:broader|SW guys (and girls)
Equivalence mining|skos:broader|Synonym URIs
intent classification intent detection|skos:broader|Moteur de recherche
Attention Models in Graphs: A Survey  An attention mechanism aids a model by  allowing it to focus on the most relevant parts of the input to make decisions   Graph-structured data arise naturally in many different application domains. By representing data as graphs, we can capture entities (i.e., nodes) as well as their relationships (i.e., edges) with each other. Many useful insights can be derived from graph-structured data as demonstrated by an ever-growing body of work focused on graph mining. However, in the real-world, graphs can be both large - with many complex patterns - and noisy which can pose a problem for effective graph mining. An effective way to deal with this issue is to incorporate attention into graph mining solutions. An attention mechanism allows a method to focus on task-relevant parts of the graph, helping it to make better decisions. In this work, we conduct a comprehensive and focused survey of the literature on the emerging field of graph attention models. We introduce three intuitive taxonomies to group existing work. These are based on problem setting (type of input and output), the type of attention mechanism used, and the task (e.g., graph classification, link prediction, etc.). We motivate our taxonomies through detailed examples and use each to survey competing approaches from a unique standpoint. Finally, we highlight several challenges in the area and discuss promising directions for future work.|sl:arxiv_author|Ryan A. Rossi
Baidu|skos:broader|Search Engines
Chine|skos:broader|Asie
Munich|skos:broader|Ville
Giovanni Tummarello|skos:broader|SW guys (and girls)
Loi sur le téléchargement|skos:broader|Droit et internet
Compressive Transformers for Long-Range Sequence Modelling  the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning.    [Blog post](/doc/2020/02/a_new_model_and_dataset_for_lon) We present the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning. We find the Compressive Transformer obtains state-of-the-art language modelling results in the WikiText-103 and Enwik8 benchmarks, achieving 17.1 ppl and 0.97 bpc respectively. We also find it can model high-frequency speech effectively and can be used as a memory mechanism for RL, demonstrated on an object matching task. To promote the domain of long-range sequence learning, we propose a new open-vocabulary language modelling benchmark derived from books, PG-19.|sl:tag|tag:sequence_to_sequence_learning
NLP sample code|skos:broader|NLP
Stardust|skos:broader|Missions spatiales
public-vocabs@w3.org|skos:broader|Web Schemas Task Force
fps blog|skos:broader|fps
OntoWiki|skos:broader|Linked Data publishing
Niger|skos:broader|Sahel
Pays d'Europe|skos:broader|Europe
Java Server Faces|skos:broader|Servlet
A Survey on Deep Learning for Named Entity Recognition mainly focus on generic NEs in English language Named entity recognition (NER) is the task to identify mentions of rigid designators from text belonging to predefined semantic types such as person, location, organization etc. NER always serves as the foundation for many natural language applications such as question answering, text summarization, and machine translation. Early NER systems got a huge success in achieving good performance with the cost of human engineering in designing domain-specific features and rules. In recent years, deep learning, empowered by continuous real-valued vector representations and semantic composition through nonlinear processing, has been employed in NER systems, yielding stat-of-the-art performance. In this paper, we provide a comprehensive review on existing deep learning techniques for NER. We first introduce NER resources, including tagged NER corpora and off-the-shelf NER tools. Then, we systematically categorize existing works based on a taxonomy along three axes: distributed representations for input, context encoder, and tag decoder. Next, we survey the most representative methods for recent applied techniques of deep learning in new NER problem settings and applications. Finally, we present readers with the challenges faced by NER systems and outline future directions in this area.|sl:arxiv_author|Aixin Sun
Attali|skos:broader|Intellectuel
SKOS/OWL|skos:broader|SKOS
machine translation paradigm where translations are generated on the basis of statistical models whose parameters are derived from the analysis of bilingual text corpora. The statistical approach contrasts with the rule-based approaches to machine translation as well as with example-based machine translation    |skos:broader|sub-field of computational linguistics that investigates the use of software to translate text or speech from one language to another
Lord of the Flies|skos:broader|Roman
Diacritics in URI|skos:broader|URI encoding
MOAT|skos:broader|Linked Data
Ecole|skos:broader|Education
Censure et maltraitance animale|skos:broader|Factory farming
Brain vs Deep Learning|skos:broader|Neuroscience AND Machine learning
BERT Rediscovers the Classical NLP Pipeline  We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.   Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.|sl:arxiv_author|Dipanjan Das
Revisiting Semi-Supervised Learning with Graph Embeddings We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.|sl:tag|tag:arxiv_doc
Protégé|skos:broader|OWL tool
Extinction de masse|skos:broader|Catastrophe
The Matrix Calculus You Need For Deep Learning Related blog post [The Math Behind Neural Networks](https://towardsdatascience.com/step-by-step-the-math-behind-neural-networks-490dc1f3cfd9) This paper is an attempt to explain all the matrix calculus you need in order to understand the training of deep neural networks. We assume no math knowledge beyond what you learned in calculus 1, and provide links to help you refresh the necessary math where needed. Note that you do not need to understand this material before you start learning to train and use deep learning in practice; rather, this material is for those who are already familiar with the basics of neural networks, and wish to deepen their understanding of the underlying math. Don't worry if you get stuck at some point along the way---just go back and reread the previous section, and try writing down and working through some examples. And if you're still stuck, we're happy to answer your questions in the Theory category at forums.fast.ai. Note: There is a reference section at the end of the paper summarizing all the key matrix calculus rules and terminology discussed here. See related articles at http://explained.ai|sl:tag|tag:matrix_calculus
France|skos:broader|Europe
The Limits to Growth|skos:broader|Economie
Evaluation of sentence embeddings in downstream and linguistic probing tasks a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets     We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.           Despite the fast developmental pace of new sentence embedding methods, it is still challenging to find comprehensive evaluations of these different techniques. In the past years, we saw significant improvements in the field of sentence embeddings and especially towards the development of universal sentence encoders that could provide inductive transfer to a wide variety of downstream tasks. In this work, we perform a comprehensive evaluation of recent methods using a wide variety of downstream and linguistic feature probing tasks. We show that a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets. We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.|sl:tag|tag:arxiv_doc
AI@Facebook|skos:broader|Facebook
Rapport Villani|skos:broader|IA AI
Natural Language Processing (almost) from Scratch seminal work    Abstract:     a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements   We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.|sl:tag|tag:multitask_learning_in_nlp
Natural Language Semantic Search|skos:broader|Deep Learning
Class based language models|skos:broader|Language model
ML/NLP blog|skos:broader|Machine learning
Placentaires, marsupiaux et monotrèmes|skos:broader|Monotrèmes
Amanuensis: The Programmer's Apprentice The use of natural language to facilitate communication  between the expert programmer and apprentice AI system.     an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants.     [#Dehaene](/tag/stanislas_dehaene)'s work extends the [#Global Workspace Theory](/tag/global_workspace_theory) of Bernard Baars. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a [#consciousness prior](/tag/consciousness_prior.html) and deep reinforcement learning suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving. This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.|sl:arxiv_author|Catherine Wong
Experience Grounds Language Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.|sl:tag|tag:survey
StarSpace: Embed All The Things! We present StarSpace, a general-purpose neural embedding model that can solve a wide variety of problems: labeling tasks such as text classification, ranking tasks such as information retrieval/web search, collaborative filtering-based or content-based recommendation, embedding of multi-relational graphs, and learning word, sentence or document level embeddings. In each case the model works by embedding those entities comprised of discrete features and comparing them against each other -- learning similarities dependent on the task. Empirical results on a number of tasks show that StarSpace is highly competitive with existing methods, whilst also being generally applicable to new cases where those methods are not.|sl:tag|tag:starspace
OpenAI GPT|skos:broader|Pre-Trained Language Models
Termite|skos:broader|Insecte
Asie mineure|skos:broader|Turquie
Antimatière|skos:broader|Physique des particules
Obélisque d'Axoum|skos:broader|Mussolini
Pre-trained Models for Natural Language Processing: A Survey Recently, the emergence of pre-trained models (PTMs) has brought natural language processing (NLP) to a new era. In this survey, we provide a comprehensive review of PTMs for NLP. We first briefly introduce language representation learning and its research progress. Then we systematically categorize existing PTMs based on a taxonomy with four perspectives. Next, we describe how to adapt the knowledge of PTMs to the downstream tasks. Finally, we outline some potential directions of PTMs for future research. This survey is purposed to be a hands-on guide for understanding, using, and developing PTMs for various NLP tasks.|sl:arxiv_firstAuthor|Xipeng Qiu
BERT Rediscovers the Classical NLP Pipeline  We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.   Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.|sl:tag|tag:arxiv_doc
Chris Bizer|skos:broader|Technical girls and guys
M3 Multi Media Museum|skos:broader|My old things
Coursera: NLP class|skos:broader|NLP@Stanford
Exploration marsienne|skos:broader|Mars
Text Summarization|skos:broader|NLP tasks / problems
Differentiable Top-k Operator with Optimal Transport  if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator   ...   We apply the proposed operator to the [k-nearest neighbors](tag:k_nearest_neighbors_algorithm) and [beam search](tag:beam_search) algorithms, and demonstrate improved performance The top-k operation, i.e., finding the k largest or smallest elements from a collection of scores, is an important model component, which is widely used in information retrieval, machine learning, and data mining. However, if the top-k operation is implemented in an algorithmic way, e.g., using bubble algorithm, the resulting model cannot be trained in an end-to-end way using prevalent gradient descent algorithms. This is because these implementations typically involve swapping indices, whose gradient cannot be computed. Moreover, the corresponding mapping from the input scores to the indicator vector of whether this element belongs to the top-k set is essentially discontinuous. To address the issue, we propose a smoothed approximation, namely the SOFT (Scalable Optimal transport-based diFferenTiable) top-k operator. Specifically, our SOFT top-k operator approximates the output of the top-k operation as the solution of an Entropic Optimal Transport (EOT) problem. The gradient of the SOFT operator can then be efficiently approximated based on the optimality conditions of EOT problem. We apply the proposed operator to the k-nearest neighbors and beam search algorithms, and demonstrate improved performance.|sl:arxiv_author|Tomas Pfister
Constraint Satisfaction Problem|skos:broader|Constraint Programming
Hadoop|skos:broader|Big Data
Feynman|skos:broader|Physicien
Education and Linked Data|skos:broader|Linked Data
Universal Sentence Encoder models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks.     With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task    mixes an unsupervised task using a large corpus together with the supervised SNLI task, leveraging the [#Transformer](/tag/attention_is_all_you_need) architecture We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.|sl:arxiv_author|Noah Constant
TextRank|skos:broader|Keyword/keyphrase extraction
Tag cloud|skos:broader|Tagging
Data Publica|skos:broader|Data portal
Jena GRDDL Reader|skos:broader|Jena
blogmarks|skos:broader|Social bookmarking
Natural Language Processing with Small Feed-Forward Networks google guys:      We show that small and shallow feed- forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.   We show that small and shallow feed-forward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.|sl:arxiv_author|David Weiss
Linked Data Browser|skos:broader|Linked Data
Galileo (spacecraft)|skos:broader|Jupiter
Symbiose|skos:broader|Biology
Structured Knowledge Distillation for Dense Prediction In this paper, we consider transferring the structure information from large networks to small ones for dense prediction tasks. Previous knowledge distillation strategies used for dense prediction tasks often directly borrow the distillation scheme for image classification and perform knowledge distillation for each pixel separately, leading to sub-optimal performance. Here we propose to distill structured knowledge from large networks to small networks, taking into account the fact that dense prediction is a structured prediction problem. Specifically, we study two structured distillation schemes: i)pair-wise distillation that distills the pairwise similarities by building a static graph, and ii)holistic distillation that uses adversarial training to distill holistic knowledge. The effectiveness of our knowledge distillation approaches is demonstrated by extensive experiments on three dense prediction tasks: semantic segmentation, depth estimation, and object detection.|sl:arxiv_author|Jingdong Wang
Topic2Vec: Learning Distributed Representations of Topics Topic2Vec aims at learning topic representations along with word representations. Considering the simplicity and efficient solution, we just follow the optimization scheme that used in Word2Vec Latent Dirichlet Allocation (LDA) mining thematic structure of documents plays an important role in nature language processing and machine learning areas. However, the probability distribution from LDA only describes the statistical relationship of occurrences in the corpus and usually in practice, probability is not the best choice for feature representations. Recently, embedding methods have been proposed to represent words and documents by learning essential concepts and representations, such as Word2Vec and Doc2Vec. The embedded representations have shown more effectiveness than LDA-style representations in many tasks. In this paper, we propose the Topic2Vec approach which can learn topic representations in the same semantic vector space with words, as an alternative to probability. The experimental results show that Topic2Vec achieves interesting and meaningful results.|sl:tag|tag:topic_embeddings
BERT Rediscovers the Classical NLP Pipeline  We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.   Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.|sl:arxiv_firstAuthor|Ian Tenney
Learning with Memory Embeddings Embedding learning, a.k.a. representation learning, has been shown to be able to model large-scale semantic knowledge graphs. A key concept is a mapping of the knowledge graph to a tensor representation whose entries are predicted by models using latent representations of generalized entities. Latent variable models are well suited to deal with the high dimensionality and sparsity of typical knowledge graphs. In recent publications the embedding models were extended to also consider time evolutions, time patterns and subsymbolic representations. In this paper we map embedding models, which were developed purely as solutions to technical problems for modelling temporal knowledge graphs, to various cognitive memory functions, in particular to semantic and concept memory, episodic memory, sensory memory, short-term memory, and working memory. We discuss learning, query answering, the path from sensory input to semantic decoding, and the relationship between episodic memory and semantic memory. We introduce a number of hypotheses on human memory that can be derived from the developed mathematical models.|sl:tag|tag:memory_embeddings
Néandertal|skos:broader|Origines de l'homme
Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus.     In practice, some questions are best answered  using text, while others are best answered using  KBs. A natural question, then, is how to effectively  combine both types of information. Surprisingly  little prior work has looked at this problem. Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting. Source code is available at https://github.com/OceanskySun/GraftNet .|sl:tag|tag:these_irit_renault_biblio
Consciousness Prior|skos:broader|Conscience artificielle
Learning Deep Latent Spaces for Multi-Label Classification Uses [Deep Canonical Correlation Analysis](/tag/deep_canonical_correlation_analysis) and autoencoder structures to learn a latent subspace from both feature and label domains for multi-label classification.    (several implementations on github)       Multi-label classification is a practical yet challenging task in machine learning related fields, since it requires the prediction of more than one label category for each input instance. We propose a novel deep neural networks (DNN) based model, Canonical Correlated AutoEncoder (C2AE), for solving this task. Aiming at better relating feature and label domain data for improved classification, we uniquely perform joint feature and label embedding by deriving a deep latent space, followed by the introduction of label-correlation sensitive loss function for recovering the predicted label outputs. Our C2AE is achieved by integrating the DNN architectures of canonical correlation analysis and autoencoder, which allows end-to-end learning and prediction with the ability to exploit label dependency. Moreover, our C2AE can be easily extended to address the learning problem with missing labels. Our experiments on multiple datasets with different scales confirm the effectiveness and robustness of our proposed method, which is shown to perform favorably against state-of-the-art methods for multi-label classification.|sl:tag|tag:multi_label_classification
Apache Spark|skos:broader|apache.org
Innoraise|skos:broader|Social Networks
KGAT: Knowledge Graph Attention Network for Recommendation To provide more accurate, diverse, and explainable recommendation, it is compulsory to go beyond modeling user-item interactions and take side information into account. Traditional methods like factorization machine (FM) cast it as a supervised learning problem, which assumes each interaction as an independent instance with side information encoded. Due to the overlook of the relations among instances or items (e.g., the director of a movie is also an actor of another movie), these methods are insufficient to distill the collaborative signal from the collective behaviors of users. In this work, we investigate the utility of knowledge graph (KG), which breaks down the independent interaction assumption by linking items with their attributes. We argue that in such a hybrid structure of KG and user-item graph, high-order relations --- which connect two items with one or multiple linked attributes --- are an essential factor for successful recommendation. We propose a new method named Knowledge Graph Attention Network (KGAT) which explicitly models the high-order connectivities in KG in an end-to-end fashion. It recursively propagates the embeddings from a node's neighbors (which can be users, items, or attributes) to refine the node's embedding, and employs an attention mechanism to discriminate the importance of the neighbors. Our KGAT is conceptually advantageous to existing KG-based recommendation methods, which either exploit high-order relations by extracting paths or implicitly modeling them with regularization. Empirical results on three public benchmarks show that KGAT significantly outperforms state-of-the-art methods like Neural FM and RippleNet. Further studies verify the efficacy of embedding propagation for high-order relation modeling and the interpretability benefits brought by the attention mechanism.|sl:arxiv_author|Xiangnan He
Nok|skos:broader|Archéologie africaine
CSV|skos:broader|Tables
